{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07700089613596599,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07700089613596599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07700089613596599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07700089613596599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07700089613596599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07700089613596599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07695634497536553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07700089613596599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.474445343017578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10985238552093506,
      "backward_entropy": 0.07701517475975884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.737117767333984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985157489776612,
      "backward_entropy": 0.0769529938697815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.733015060424805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0002000321983359754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10985069274902344,
      "backward_entropy": 0.07694953680038452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.72890853881836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00030007469467818737,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984967947006226,
      "backward_entropy": 0.07701341311136882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.724801063537598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004001212655566633,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984854698181153,
      "backward_entropy": 0.07694228490193684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.359114646911621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005001692334190011,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984728336334229,
      "backward_entropy": 0.07699169715245564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.81190299987793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006001221481710672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10984587669372559,
      "backward_entropy": 0.077010624938541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.617600440979004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007001400808803737,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098442792892456,
      "backward_entropy": 0.07693053616417779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.97381591796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008001372334547341,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10984266996383667,
      "backward_entropy": 0.07698498831854926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.704375267028809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009002198930829763,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10984103679656983,
      "backward_entropy": 0.0769220855500963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.341473579406738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001000297605060041,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983927249908447,
      "backward_entropy": 0.07700524065229628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.319225311279297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011002608807757497,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10983734130859375,
      "backward_entropy": 0.07700356509950426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.049922943115234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001200422877445817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983538627624512,
      "backward_entropy": 0.07690836323632134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.759568214416504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013006707886233926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983331203460693,
      "backward_entropy": 0.076903502146403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.660977363586426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014012024039402604,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10983108282089234,
      "backward_entropy": 0.07689851522445679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.67976188659668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015019276179373264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982882976531982,
      "backward_entropy": 0.07699555820888943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.938885688781738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016025060322135687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982640981674194,
      "backward_entropy": 0.0768880844116211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.11812973022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017030382296070457,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982396602630615,
      "backward_entropy": 0.07695878876580133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31310749053955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001803606515750289,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982130765914917,
      "backward_entropy": 0.07695509327782525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.845841407775879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0019039199687540531,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981855392456055,
      "backward_entropy": 0.07695121235317653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.092755317687988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0020042196847498417,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981552600860596,
      "backward_entropy": 0.07694716586007012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.212000846862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021045508328825235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098127007484436,
      "backward_entropy": 0.0768589973449707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.707478523254395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022046102676540613,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980992317199707,
      "backward_entropy": 0.07697531912061903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.72830867767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023049809969961643,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980702638626098,
      "backward_entropy": 0.07684608300526936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.084473609924316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024052413646131754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980434417724609,
      "backward_entropy": 0.07683932781219482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.118322372436523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025055722799152136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980141162872314,
      "backward_entropy": 0.07683238718244764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.417102813720703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002605611691251397,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979825258255005,
      "backward_entropy": 0.07695961660808986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.981361389160156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002705842489376664,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979517698287963,
      "backward_entropy": 0.07695517275068495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.101154327392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028061026241630316,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10979197025299073,
      "backward_entropy": 0.07690783341725667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.44661808013916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029060300439596176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978884696960449,
      "backward_entropy": 0.07694558964835273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.797804832458496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030058035627007484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978579521179199,
      "backward_entropy": 0.07694045040342543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.96401309967041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003105618292465806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097824215888977,
      "backward_entropy": 0.07693503962622748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.783251762390137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0032055170740932226,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109778892993927,
      "backward_entropy": 0.07677798138724433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.043217658996582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003305399790406227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977540016174317,
      "backward_entropy": 0.07676931222279866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.605006217956543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034054007846862078,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977166891098022,
      "backward_entropy": 0.07686855395634969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.946342468261719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035053205210715532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976784229278565,
      "backward_entropy": 0.07675124539269342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.058992385864258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003605308011174202,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976386070251465,
      "backward_entropy": 0.07690417766571045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.107254028320312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003705775598064065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975981950759887,
      "backward_entropy": 0.07689740922715929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.276169776916504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003806288354098797,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097557783126831,
      "backward_entropy": 0.07672301928202312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.927842140197754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003906928468495607,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975155830383301,
      "backward_entropy": 0.07682829433017307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.151656150817871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004007536452263594,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974717140197754,
      "backward_entropy": 0.076819466220008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.34365463256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004107780288904905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974283218383789,
      "backward_entropy": 0.07669335603713989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.169144630432129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0042081861756742,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973852872848511,
      "backward_entropy": 0.07685928212271796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.227429389953613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004308680538088083,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097341775894165,
      "backward_entropy": 0.07685062620374891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.883553504943848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004408861044794321,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097296953201294,
      "backward_entropy": 0.07666181855731541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.983104705810547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004508615471422672,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972514152526855,
      "backward_entropy": 0.07683233420054118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.14918327331543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004608441609889269,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972062349319459,
      "backward_entropy": 0.07682264513439602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.874451637268066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004708422813564539,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971603393554688,
      "backward_entropy": 0.0766285326745775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.450010299682617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0048079947009682655,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971153974533081,
      "backward_entropy": 0.07673656940460205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.627398490905762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004907045979052782,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970686674118042,
      "backward_entropy": 0.0766050550672743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.11813735961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005006102379411459,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970232486724854,
      "backward_entropy": 0.07671216461393568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.788565635681152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0051049585454165936,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969781875610352,
      "backward_entropy": 0.07658043172624376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775116920471191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005203938577324152,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969321727752686,
      "backward_entropy": 0.07656768957773845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.535934448242188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005302574951201677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968872308731079,
      "backward_entropy": 0.0765546825197008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.440252304077148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005401671398431063,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968416929244995,
      "backward_entropy": 0.07665850056542291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.687677383422852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005500714294612408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967961549758912,
      "backward_entropy": 0.07652771472930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.101515769958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005599814001470804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967503786087036,
      "backward_entropy": 0.07651375399695502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.590878486633301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005699163302779198,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967020988464356,
      "backward_entropy": 0.07661426067352295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.75820541381836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005797600373625755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966575145721436,
      "backward_entropy": 0.07648497819900513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.50461196899414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005896212533116341,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966098308563232,
      "backward_entropy": 0.07647016313340929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.496990203857422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005994836334139109,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965635776519775,
      "backward_entropy": 0.07645501030815972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.412421226501465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006094381678849459,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965133905410766,
      "backward_entropy": 0.07643954621420966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.325428009033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00619382131844759,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964610576629638,
      "backward_entropy": 0.07653271489673191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.403728485107422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006293118465691805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964062213897705,
      "backward_entropy": 0.07659400833977593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.986200332641602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006392336916178465,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096349835395813,
      "backward_entropy": 0.07649711105558607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.386016845703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006491281557828188,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962941646575927,
      "backward_entropy": 0.07647848129272461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.297317504882812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006590609438717365,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962368249893188,
      "backward_entropy": 0.07653960916731092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.372398376464844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00669022835791111,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961788892745972,
      "backward_entropy": 0.07652068138122559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.544824600219727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0067901904694736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096116304397583,
      "backward_entropy": 0.07631868786282009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.112988471984863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006890051532536745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960544347763061,
      "backward_entropy": 0.07648091183768378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.288840293884277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006990080699324608,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959908962249756,
      "backward_entropy": 0.07627983887990315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.855106353759766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007089891470968723,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959268808364868,
      "backward_entropy": 0.07643868525822957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.850667953491211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0071897669695317745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958627462387086,
      "backward_entropy": 0.07641655868954128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.81889533996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007289738394320011,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10957924127578736,
      "backward_entropy": 0.07631170749664307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.268807411193848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007390213664621115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957159996032714,
      "backward_entropy": 0.07637046443091498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.857954025268555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00749041186645627,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956406593322754,
      "backward_entropy": 0.07634653647740682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.826739311218262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007590157445520163,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955687761306762,
      "backward_entropy": 0.07624165879355536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.30050277709961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007690004538744688,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954922437667847,
      "backward_entropy": 0.07613067494498359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.844557762145996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007790111470967531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095414400100708,
      "backward_entropy": 0.07610758807924059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.564592361450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007889769971370697,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953398942947387,
      "backward_entropy": 0.0761659410264757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.001529693603516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007989387027919292,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952636003494262,
      "backward_entropy": 0.07621627383761936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.954181671142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00808964017778635,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951807498931884,
      "backward_entropy": 0.07611231009165446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.469840049743652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008189985528588295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10950934886932373,
      "backward_entropy": 0.07601065105862087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.021191596984863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008290198631584644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950034856796265,
      "backward_entropy": 0.07605653338962132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.614700317382812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008390551432967186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109490966796875,
      "backward_entropy": 0.0760987334781223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.476591110229492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008490822277963161,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10948152542114258,
      "backward_entropy": 0.07599798176023695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.364904403686523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008591391146183014,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10947186946868896,
      "backward_entropy": 0.07596761650509304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.303622245788574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008691743016242981,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10946214199066162,
      "backward_entropy": 0.07593648963504368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.508073806762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00879232119768858,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945216417312623,
      "backward_entropy": 0.07590474022759332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.266335487365723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008892732672393322,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944231748580932,
      "backward_entropy": 0.07593262195587158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.044127464294434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00899288710206747,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943251848220825,
      "backward_entropy": 0.07583920823203193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24880313873291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009093174710869789,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942238569259644,
      "backward_entropy": 0.07580577002631293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775218963623047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009193172678351402,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10941258668899537,
      "backward_entropy": 0.07582330703735352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.702106475830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00929269753396511,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940327644348144,
      "backward_entropy": 0.07573502593570286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.070127487182617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009392223320901394,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093940019607544,
      "backward_entropy": 0.07569785912831624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.302251815795898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009491438046097755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938518047332764,
      "backward_entropy": 0.07570776674482557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.131356239318848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009590520523488522,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937639474868774,
      "backward_entropy": 0.07560687594943577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.066530227661133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009688911028206348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936844348907471,
      "backward_entropy": 0.07557443777720134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512513160705566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009787192568182945,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936028957366943,
      "backward_entropy": 0.07553988695144653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.734986305236816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009885544888675213,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935200452804565,
      "backward_entropy": 0.07554093334409925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.119243621826172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009984064847230911,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934338569641114,
      "backward_entropy": 0.07549666033850776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.809292793273926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010082465596497059,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933468341827393,
      "backward_entropy": 0.07541208134757148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.026642799377441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010181117802858353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932523012161255,
      "backward_entropy": 0.07540350490146214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.327340126037598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010279584676027298,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10931590795516968,
      "backward_entropy": 0.07535650995042589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55936336517334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010378039442002773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093064785003662,
      "backward_entropy": 0.07530817720625135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00692081451416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010476116091012955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10929751396179199,
      "backward_entropy": 0.07525861263275146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.770806312561035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010574065148830414,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092886209487915,
      "backward_entropy": 0.0751801331837972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6392974853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010672307573258877,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092789649963379,
      "backward_entropy": 0.07513054211934407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.615471839904785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010769768618047237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10927047729492187,
      "backward_entropy": 0.07517724566989475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.304935455322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010867004282772541,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10926222801208496,
      "backward_entropy": 0.07502749231126574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.021697998046875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010963881388306618,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925450325012206,
      "backward_entropy": 0.07499043809043036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.911748886108398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01106178667396307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10924487113952637,
      "backward_entropy": 0.07493302557203504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65666675567627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011159614659845829,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923533439636231,
      "backward_entropy": 0.07486526171366374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.201996803283691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011257179081439972,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10922625064849853,
      "backward_entropy": 0.07480899492899577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.956220626831055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011354295536875725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10921789407730102,
      "backward_entropy": 0.07492330339219835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.413016319274902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01145142037421465,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10920934677124024,
      "backward_entropy": 0.07469088501400417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.164265632629395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011548248119652271,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920128822326661,
      "backward_entropy": 0.0748326579729716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.477148056030273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011645219288766384,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10919280052185058,
      "backward_entropy": 0.07478606700897217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.293972969055176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011741956695914268,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10918464660644531,
      "backward_entropy": 0.07473876741197374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.385834693908691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011838900856673717,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10917596817016602,
      "backward_entropy": 0.07443877061208089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.071463584899902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011935562826693058,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10916799306869507,
      "backward_entropy": 0.07464136017693414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.594162940979004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012031774036586285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10916121006011963,
      "backward_entropy": 0.07428786489698622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.157726287841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012127885594964027,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10915461778640748,
      "backward_entropy": 0.07423542605506049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.175971031188965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012224731966853142,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914626121520996,
      "backward_entropy": 0.07416537735197279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72360610961914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012321718968451023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10913746356964112,
      "backward_entropy": 0.07443431350919935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.265567779541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012418617494404316,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10912871360778809,
      "backward_entropy": 0.07402125994364421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149598121643066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012515181675553322,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10912063121795654,
      "backward_entropy": 0.07392034265730116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.803574562072754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012611912563443184,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091120719909668,
      "backward_entropy": 0.073871201939053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.242079734802246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012709108181297779,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10910249948501587,
      "backward_entropy": 0.07376369502809313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.523330688476562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012805932201445103,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909367799758911,
      "backward_entropy": 0.07415435049268934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.771799087524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012902537360787392,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10908541679382325,
      "backward_entropy": 0.07364057170020209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.253497123718262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012999613769352436,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10907598733901977,
      "backward_entropy": 0.0735612842771742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.359881401062012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013096889480948448,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10906577110290527,
      "backward_entropy": 0.07348193062676324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.939271926879883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01319387461990118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10905601978302001,
      "backward_entropy": 0.07391238212585449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.747209072113037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013290908187627792,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1090458869934082,
      "backward_entropy": 0.0738494528664483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.1156587600708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013387318700551987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10903724431991577,
      "backward_entropy": 0.07378592756059435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03178882598877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013483417220413685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10902916193008423,
      "backward_entropy": 0.0730852418475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.967004776000977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013579185120761395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10902178287506104,
      "backward_entropy": 0.07299529181586371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.3062105178833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013675129972398281,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10901385545730591,
      "backward_entropy": 0.07298556963602702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.296833992004395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01377091184258461,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10900616645812988,
      "backward_entropy": 0.07352256774902344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.846339225769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01386654656380415,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10899871587753296,
      "backward_entropy": 0.07280706034766303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.582622528076172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0139617919921875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1089922308921814,
      "backward_entropy": 0.07338477505577935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.686805248260498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014057621359825134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10898404121398926,
      "backward_entropy": 0.07331377930111355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.335943222045898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014152978546917439,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10897700786590576,
      "backward_entropy": 0.0732420285542806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.024341583251953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014248755760490894,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10896877050399781,
      "backward_entropy": 0.07316868172751533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.014276504516602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014344225637614727,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10896129608154297,
      "backward_entropy": 0.07309437460369533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94554328918457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014439417980611324,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10895451307296752,
      "backward_entropy": 0.07211469279395209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719572067260742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014534875750541687,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10894681215286255,
      "backward_entropy": 0.07200865613089667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.996367454528809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014630462042987347,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10893872976303101,
      "backward_entropy": 0.07202702760696411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.046418190002441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014726316556334496,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10892989635467529,
      "backward_entropy": 0.07178987397087945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.617405414581299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01482188981026411,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10892176628112793,
      "backward_entropy": 0.0727029906378852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.664005279541016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014917036518454552,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10891469717025756,
      "backward_entropy": 0.0717054737938775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.00454044342041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015012290328741074,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10890722274780273,
      "backward_entropy": 0.07144541210598415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.797494888305664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015107274986803532,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10890047550201416,
      "backward_entropy": 0.07148186365763347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.06075382232666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0152019914239645,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10889437198638915,
      "backward_entropy": 0.07136711809370253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.039053916931152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015297104604542255,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10888687372207642,
      "backward_entropy": 0.07108510865105523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.186527252197266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015392527915537357,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10887829065322877,
      "backward_entropy": 0.07113226254781087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.369799613952637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015487839467823505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10886983871459961,
      "backward_entropy": 0.07210206985473633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07889461517334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015583636239171028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10885971784591675,
      "backward_entropy": 0.07200996081034343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.580397129058838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01567918248474598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10885018110275269,
      "backward_entropy": 0.07191656033198039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.778563976287842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015774277970194817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10884188413619995,
      "backward_entropy": 0.07182213995191786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.172922134399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01586907170712948,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10883437395095825,
      "backward_entropy": 0.07051009602016872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45523452758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015964331105351448,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10882515907287597,
      "backward_entropy": 0.07018010483847724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314458847045898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01605963334441185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10881518125534058,
      "backward_entropy": 0.07152912351820204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426264762878418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016154954209923744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10880483388900757,
      "backward_entropy": 0.07142798105875652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.256121635437012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016250301152467728,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10879409313201904,
      "backward_entropy": 0.06975507736206055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.426265239715576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01634613424539566,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10878143310546876,
      "backward_entropy": 0.06983384158876207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.805813789367676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01644144393503666,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10877022743225098,
      "backward_entropy": 0.06969172424740261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.957011699676514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016537019982933998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10875780582427978,
      "backward_entropy": 0.06930065155029297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.277192115783691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016632400453090668,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10874583721160888,
      "backward_entropy": 0.06914203034506904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955601692199707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016727721318602562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10873374938964844,
      "backward_entropy": 0.07077474064297146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8302903175354,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016823353245854378,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10871990919113159,
      "backward_entropy": 0.06881955597135755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642144203186035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016918674111366272,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10870683193206787,
      "backward_entropy": 0.06894773907131618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.146172523498535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017014136537909508,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10869288444519043,
      "backward_entropy": 0.0684899820221795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.91714334487915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017109498381614685,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10867896080017089,
      "backward_entropy": 0.07029655244615343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.699882984161377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017204614356160164,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10866563320159912,
      "backward_entropy": 0.06847064362631904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.093728065490723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017299437895417213,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10865311622619629,
      "backward_entropy": 0.06830657853020562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.350882530212402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017394205555319786,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10864048004150391,
      "backward_entropy": 0.06813996367984348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.848167419433594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01748907007277012,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1086271047592163,
      "backward_entropy": 0.06761816475126478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.37844181060791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017583712935447693,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10861423015594482,
      "backward_entropy": 0.06743553611967298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.293450355529785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017678461968898773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10860049724578857,
      "backward_entropy": 0.06952401002248128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.816170692443848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017773287370800972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10858608484268188,
      "backward_entropy": 0.06938758161332872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.591423988342285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017868446186184883,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10856986045837402,
      "backward_entropy": 0.0692482656902737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1461639404296875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01796378754079342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10855239629745483,
      "backward_entropy": 0.06910592979855007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2617878913879395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018058495596051216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10853720903396606,
      "backward_entropy": 0.06896160708533393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.139248847961426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018152687698602676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1085237979888916,
      "backward_entropy": 0.0662787225511339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.504919052124023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018247533589601517,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10850735902786254,
      "backward_entropy": 0.0665106905831231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.416544914245605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018342558294534683,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10848959684371948,
      "backward_entropy": 0.06851376427544488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.856344223022461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01843772456049919,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1084707498550415,
      "backward_entropy": 0.06835849417580499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.168023109436035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01853269524872303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1084522008895874,
      "backward_entropy": 0.06820107830895318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145964622497559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018627649173140526,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10843305587768555,
      "backward_entropy": 0.06570904784732395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.321763038635254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018722612410783768,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10841336250305175,
      "backward_entropy": 0.065501160091824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.695578575134277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018817681819200516,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10839262008666992,
      "backward_entropy": 0.06477627489301893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.278616428375244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018913011997938156,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10836995840072632,
      "backward_entropy": 0.06454921431011623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.378893852233887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019007815048098564,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10834914445877075,
      "backward_entropy": 0.06485857566197713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.562901496887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01910276524722576,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1083269476890564,
      "backward_entropy": 0.0646371775203281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.946918964385986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0191973727196455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10830562114715576,
      "backward_entropy": 0.06702564822302924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1856584548950195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019291341304779053,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1082868218421936,
      "backward_entropy": 0.06360235479142931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2260332107543945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019384879618883133,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10826958417892456,
      "backward_entropy": 0.06335609489017063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3938140869140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01947806589305401,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10825358629226685,
      "backward_entropy": 0.06649301449457805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.78294038772583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01957106776535511,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10823814868927002,
      "backward_entropy": 0.0663141475783454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.605149745941162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019663533195853233,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10822496414184571,
      "backward_entropy": 0.06259053283267552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.060073375701904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019755983725190163,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1082112193107605,
      "backward_entropy": 0.06595100296868218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.043190002441406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01984809897840023,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10819854736328124,
      "backward_entropy": 0.06206039587656657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.627716064453125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01993986964225769,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10818686485290527,
      "backward_entropy": 0.06179185708363851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6910400390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02003229223191738,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10817105770111084,
      "backward_entropy": 0.062257621023390025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.026989936828613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020124759525060654,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10815423727035522,
      "backward_entropy": 0.061243136723836265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8647141456604,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02021685242652893,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10813853740692139,
      "backward_entropy": 0.06174210707346598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.032700061798096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02030853182077408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10812430381774903,
      "backward_entropy": 0.06479718287785848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.415962219238281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02039993554353714,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10811073780059814,
      "backward_entropy": 0.060395929548475474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.17103910446167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020491916686296463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10809320211410522,
      "backward_entropy": 0.06439079178704156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.767136096954346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02058367244899273,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10807596445083618,
      "backward_entropy": 0.059811002678341336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.481917858123779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02067561075091362,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10805687904357911,
      "backward_entropy": 0.06397072474161784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.180066108703613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020767541602253914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10803688764572143,
      "backward_entropy": 0.06375407510333592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.582205772399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02085920423269272,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10801734924316406,
      "backward_entropy": 0.0635349088244968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.88313627243042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020951516926288605,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10799331665039062,
      "backward_entropy": 0.058601975440979004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5451579093933105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02104342356324196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10797119140625,
      "backward_entropy": 0.06308440367380778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.625091552734375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021135371178388596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10794787406921387,
      "backward_entropy": 0.06285471386379665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.17092752456665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021227426826953888,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10792285203933716,
      "backward_entropy": 0.05765969885720147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.866614818572998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021319273859262466,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1078978419303894,
      "backward_entropy": 0.058324582046932645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.787927627563477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021410781890153885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10787370204925537,
      "backward_entropy": 0.05700982941521539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.750822067260742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021502522751688957,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10784707069396973,
      "backward_entropy": 0.06190572844611274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.063281059265137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021594451740384102,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10781809091567993,
      "backward_entropy": 0.061659309599134654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.105976581573486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02168617583811283,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1077892541885376,
      "backward_entropy": 0.05707294411129422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9054765701293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021777719259262085,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1077601432800293,
      "backward_entropy": 0.05675209230846829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.926146984100342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021868951618671417,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10773147344589233,
      "backward_entropy": 0.055323130554623075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.021176338195801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021959327161312103,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10770704746246337,
      "backward_entropy": 0.056100275781419545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.580397129058838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02204958349466324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10768190622329712,
      "backward_entropy": 0.0603932605849372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.427087783813477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02213950641453266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10765761137008667,
      "backward_entropy": 0.060133669111463756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7337727546691895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022229624912142754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10763053894042969,
      "backward_entropy": 0.05986991855833265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.123472690582275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022318873554468155,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.107607901096344,
      "backward_entropy": 0.0596063666873508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.645260810852051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022407587617635727,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10758744478225708,
      "backward_entropy": 0.05441503392325507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.574771404266357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022496135905385017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10756655931472778,
      "backward_entropy": 0.05406862166192797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.804037094116211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02258453145623207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10754528045654296,
      "backward_entropy": 0.0587978031900194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.730097770690918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022672906517982483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10752248764038086,
      "backward_entropy": 0.05851945612165663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.503321647644043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022761253640055656,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10749837160110473,
      "backward_entropy": 0.053011788262261286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.852182388305664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022849440574645996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10747383832931519,
      "backward_entropy": 0.057952298058403864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.105095386505127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022938335314393044,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10744287967681884,
      "backward_entropy": 0.05229366819063822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.524540424346924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02302737534046173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10740907192230224,
      "backward_entropy": 0.05736530489391751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.24503755569458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023116832599043846,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10737078189849854,
      "backward_entropy": 0.050203796890046865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.506869792938232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023206481710076332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10732922554016114,
      "backward_entropy": 0.05675919850667318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.241654872894287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0232958123087883,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10728769302368164,
      "backward_entropy": 0.04942236344019572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.285305976867676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02338472753763199,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10724714994430543,
      "backward_entropy": 0.05044734477996826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.057662487030029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0234726220369339,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1072121262550354,
      "backward_entropy": 0.055834041701422796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.321064472198486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023560112342238426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10717804431915283,
      "backward_entropy": 0.05552376641167535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.100670337677002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023648099973797798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10713863372802734,
      "backward_entropy": 0.055207822057935924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.144762992858887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023735692724585533,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10709983110427856,
      "backward_entropy": 0.04741810427771674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.097171306610107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023822981864213943,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10706110000610351,
      "backward_entropy": 0.04854295982254876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.828406810760498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023909926414489746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10702241659164428,
      "backward_entropy": 0.054247915744781494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.870945453643799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023996420204639435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10698484182357788,
      "backward_entropy": 0.05392426252365112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9537034034729,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024082517251372337,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10694782733917237,
      "backward_entropy": 0.045784327718946666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0378098487854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0241683479398489,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10691053867340088,
      "backward_entropy": 0.053271075089772545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.946313381195068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024253984913229942,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10687223672866822,
      "backward_entropy": 0.05294074614842733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.632723331451416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024339377880096436,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10683321952819824,
      "backward_entropy": 0.044544862376319036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.674283981323242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024424368515610695,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10679498910903931,
      "backward_entropy": 0.04412843121422662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.493378162384033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02450900338590145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10675696134567261,
      "backward_entropy": 0.051938003963894315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.69129753112793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024593209847807884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10671987533569335,
      "backward_entropy": 0.05160077412923177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.12129545211792,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024677854031324387,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10667636394500732,
      "backward_entropy": 0.04287451505661011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.726108074188232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024762511253356934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10662992000579834,
      "backward_entropy": 0.05091248618231879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.013920783996582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024846911430358887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10658403635025024,
      "backward_entropy": 0.04203470216857062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.920576572418213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024931281805038452,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10653626918792725,
      "backward_entropy": 0.043335672881868154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.413448810577393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02501555345952511,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10648607015609741,
      "backward_entropy": 0.04986109336217245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.514955997467041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02509935200214386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10643644332885742,
      "backward_entropy": 0.04077389505174425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.310059070587158,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025182845070958138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10638622045516968,
      "backward_entropy": 0.04915178153249952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.039129257202148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025265170261263847,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10634373426437378,
      "backward_entropy": 0.041687568028767906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.748033046722412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025346996262669563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10630267858505249,
      "backward_entropy": 0.048446310891045466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.593974590301514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02542814239859581,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10626465082168579,
      "backward_entropy": 0.03909187846713596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.648471832275391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02550930716097355,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10622367858886719,
      "backward_entropy": 0.038671778308020696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.663900375366211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0255905669182539,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10617967844009399,
      "backward_entropy": 0.04737287759780884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6252055168151855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025671949610114098,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1061314582824707,
      "backward_entropy": 0.0470074282752143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.795424461364746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02575337328016758,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1060789704322815,
      "backward_entropy": 0.03920046819580926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.510832786560059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025834238156676292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1060285210609436,
      "backward_entropy": 0.04626762866973877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.777642250061035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02591436728835106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10598164796829224,
      "backward_entropy": 0.04589794741736518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.301598072052002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025994034484028816,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10593541860580444,
      "backward_entropy": 0.03796034389071994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9022459983825684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026073716580867767,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10588529109954833,
      "backward_entropy": 0.03754867447747125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.679027080535889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026152275502681732,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10584230422973633,
      "backward_entropy": 0.03713728653060065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.148804187774658,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026230482384562492,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10579913854598999,
      "backward_entropy": 0.03672745492723253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8775603771209717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026307910680770874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10575940608978271,
      "backward_entropy": 0.04404574632644653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.920905828475952,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026384402066469193,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10572459697723388,
      "backward_entropy": 0.035910593138800725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4596943855285645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02646011672914028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10569369792938232,
      "backward_entropy": 0.043314758274290294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.157626628875732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02653554454445839,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10566084384918213,
      "backward_entropy": 0.04294873608483209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.382452011108398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026610499247908592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10562859773635865,
      "backward_entropy": 0.04258179333474901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.811471939086914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026685195043683052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10559414625167847,
      "backward_entropy": 0.04221215181880527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.874439001083374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026760073378682137,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10555373430252075,
      "backward_entropy": 0.03200375040372213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.304792881011963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026834314689040184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10551570653915406,
      "backward_entropy": 0.04146663347880045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8341903686523438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02690834365785122,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10547527074813842,
      "backward_entropy": 0.033087962203555636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6870412826538086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02698175050318241,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10543621778488159,
      "backward_entropy": 0.04072102904319763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8658831119537354,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027054496109485626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1053995132446289,
      "backward_entropy": 0.04035047690073649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9596712589263916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02712683007121086,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10536291599273681,
      "backward_entropy": 0.030005455017089844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.903964042663574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027198873460292816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10532488822937011,
      "backward_entropy": 0.039609163999557495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.822357416152954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027270609512925148,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10528547763824463,
      "backward_entropy": 0.03923799263106452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0547072887420654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02734198607504368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10524492263793946,
      "backward_entropy": 0.028816882106992934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.612217903137207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02741231396794319,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10521031618118286,
      "backward_entropy": 0.02842749489678277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5359010696411133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027483128011226654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10516493320465088,
      "backward_entropy": 0.03812489906946818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.386775016784668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027553364634513855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10511960983276367,
      "backward_entropy": 0.037752098507351346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7612321376800537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027622971683740616,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10507549047470092,
      "backward_entropy": 0.02921672330962287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4012856483459473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027692418545484543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10502845048904419,
      "backward_entropy": 0.037009470992618136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4387552738189697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027761314064264297,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10498138666152954,
      "backward_entropy": 0.036639398998684354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3403513431549072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027829794213175774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10493354797363282,
      "backward_entropy": 0.02615985439883338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.955704689025879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027897784486413002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1048852801322937,
      "backward_entropy": 0.03590253988901774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.087005138397217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02796502411365509,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10484069585800171,
      "backward_entropy": 0.025428016980489094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5396690368652344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028032615780830383,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10478601455688477,
      "backward_entropy": 0.035170167684555054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5786783695220947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028100045397877693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10472759008407592,
      "backward_entropy": 0.03480203946431478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2310850620269775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028167346492409706,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10466444492340088,
      "backward_entropy": 0.02435134682390425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4453237056732178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02823418565094471,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10460009574890136,
      "backward_entropy": 0.03406692875756158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1228818893432617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028300819918513298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10453159809112549,
      "backward_entropy": 0.03370060523351034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0504868030548096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028366953134536743,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10446192026138305,
      "backward_entropy": 0.023307098282708064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.295055389404297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028432553634047508,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10439126491546631,
      "backward_entropy": 0.022967466049724154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.256757974624634,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02849794737994671,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10431638956069947,
      "backward_entropy": 0.024556095401446026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6534230709075928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028563132509589195,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10423750877380371,
      "backward_entropy": 0.024215870433383517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.363572835922241,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028627483174204826,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10416148900985718,
      "backward_entropy": 0.02388006779882643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.804394006729126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02869182825088501,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10407867431640624,
      "backward_entropy": 0.03153910570674472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.01686954498291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028755581006407738,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10399575233459472,
      "backward_entropy": 0.031185504462983873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8556745052337646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028819041326642036,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10390924215316773,
      "backward_entropy": 0.021005761292245653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.449392080307007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028882082551717758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1038209080696106,
      "backward_entropy": 0.030483189556333754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.734191656112671,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028944214805960655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10373485088348389,
      "backward_entropy": 0.020384593142403498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5182759761810303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02900592051446438,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10364680290222168,
      "backward_entropy": 0.020080814758936565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5136990547180176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029066963121294975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10355880260467529,
      "backward_entropy": 0.029450131787194148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5797781944274902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029127443209290504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10347044467926025,
      "backward_entropy": 0.019486569696002536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9151904582977295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918749488890171,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10338006019592286,
      "backward_entropy": 0.02877197994126214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2814831733703613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02924634888768196,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10329662561416626,
      "backward_entropy": 0.01890791952610016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.193528175354004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029304618015885353,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10321393013000488,
      "backward_entropy": 0.018623848756154377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.615445852279663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029362214729189873,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10313198566436768,
      "backward_entropy": 0.027783215045928955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6281911134719849,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02941974252462387,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10304372310638428,
      "backward_entropy": 0.01806665625837114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5453121662139893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02947593666613102,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10296397209167481,
      "backward_entropy": 0.017795523007710774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.489555835723877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029530884698033333,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10289359092712402,
      "backward_entropy": 0.026827083693610296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2413766384124756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02958591654896736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10281561613082886,
      "backward_entropy": 0.02651497721672058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.802056074142456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02964072674512863,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10273408889770508,
      "backward_entropy": 0.026203893952899508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2281737327575684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029694678261876106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10265463590621948,
      "backward_entropy": 0.025897893640730116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9250061511993408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029748478904366493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10256987810134888,
      "backward_entropy": 0.0255925456682841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.59312903881073,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02980167791247368,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10248374938964844,
      "backward_entropy": 0.017974432971742418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.317858099937439,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029853900894522667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10240163803100585,
      "backward_entropy": 0.015994206070899963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5388767719268799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029904808849096298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10232686996459961,
      "backward_entropy": 0.02470729086134169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5710575580596924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029954908415675163,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10225492715835571,
      "backward_entropy": 0.017235986060566373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7532416582107544,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03000427968800068,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10218369960784912,
      "backward_entropy": 0.015295263793733384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.808828353881836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030053289607167244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10210937261581421,
      "backward_entropy": 0.02386960718366835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.769383192062378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03010205551981926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10203044414520264,
      "backward_entropy": 0.014848068356513977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5632846355438232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03015054389834404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10194718837738037,
      "backward_entropy": 0.02332099609904819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3300474882125854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030198505148291588,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.101863431930542,
      "backward_entropy": 0.014413474334610833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6692118644714355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03024560958147049,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10178261995315552,
      "backward_entropy": 0.014202016923162673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6240047216415405,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030292483046650887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1016973614692688,
      "backward_entropy": 0.013993190394507514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6594760417938232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030339067801833153,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1016079306602478,
      "backward_entropy": 0.01378744426700804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7273895740509033,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030385423451662064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10151286125183105,
      "backward_entropy": 0.013585161003801558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8429847955703735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030431725084781647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10141094923019409,
      "backward_entropy": 0.02174047629038493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2799034118652344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03047814778983593,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10129951238632202,
      "backward_entropy": 0.02148017452822791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.428644061088562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03052370436489582,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10118913650512695,
      "backward_entropy": 0.014594059851434495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3139742612838745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030568769201636314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10107640027999878,
      "backward_entropy": 0.020973982082472906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3488768339157104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03061319701373577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10096311569213867,
      "backward_entropy": 0.020726611216862995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6567599773406982,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0306570865213871,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10084750652313232,
      "backward_entropy": 0.012443270120355818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2276235818862915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070111945271492,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10072336196899415,
      "backward_entropy": 0.020238346523708768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2409398555755615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03074449673295021,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10059940814971924,
      "backward_entropy": 0.019998292128245037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0095539093017578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03078722581267357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10047369003295899,
      "backward_entropy": 0.011918856037987603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0498712062835693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03082899935543537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10035140514373779,
      "backward_entropy": 0.013264523612128364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8245599865913391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030869970098137856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10023040771484375,
      "backward_entropy": 0.01159073164065679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2979987859725952,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0309098269790411,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10011576414108277,
      "backward_entropy": 0.01143301030000051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9026710391044617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030949639156460762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09999537467956543,
      "backward_entropy": 0.018872641854816012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1604008674621582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030988547950983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09987746477127075,
      "backward_entropy": 0.01866086655192905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0513451099395752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03102722018957138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09975541830062866,
      "backward_entropy": 0.01845073037677341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0418400764465332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031065400689840317,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09963091611862182,
      "backward_entropy": 0.010828261574109396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6049036383628845,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031103195622563362,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09950443506240844,
      "backward_entropy": 0.010683996809853448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0475105047225952,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031139569357037544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09938509464263916,
      "backward_entropy": 0.010545884569485983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.081475853919983,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03117574192583561,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09926150441169738,
      "backward_entropy": 0.010409581992361281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9438966512680054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031211817637085915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09913246631622315,
      "backward_entropy": 0.017454531457689073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7947778105735779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031247548758983612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09900186061859131,
      "backward_entropy": 0.017262942261166044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7063790559768677,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031282588839530945,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09887256622314453,
      "backward_entropy": 0.010012412236796485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8034967184066772,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031316738575696945,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09874551892280578,
      "backward_entropy": 0.011273280613952212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8916162252426147,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03135034441947937,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09861749410629272,
      "backward_entropy": 0.01671480139096578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8192973732948303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03138367459177971,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09848537445068359,
      "backward_entropy": 0.009643380012777116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7937344908714294,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03141661733388901,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09835124015808105,
      "backward_entropy": 0.009525056514475081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9776085019111633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03144912049174309,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09821496605873108,
      "backward_entropy": 0.009409381283654107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9538477063179016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031481705605983734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09807077646255494,
      "backward_entropy": 0.016019122468100652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7311195731163025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031514331698417664,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09791957736015319,
      "backward_entropy": 0.015847017367680866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7123706340789795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03154640272259712,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0977676510810852,
      "backward_entropy": 0.010402495662371317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4606921374797821,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0315779447555542,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09761509895324708,
      "backward_entropy": 0.0089632049202919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6244552731513977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03160833194851875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0974694013595581,
      "backward_entropy": 0.015354093578126695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7880427837371826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163807839155197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09732341766357422,
      "backward_entropy": 0.015199090043703714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6365001797676086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03166775032877922,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09717170596122741,
      "backward_entropy": 0.008658813105689155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7897700667381287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031696926802396774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09701894521713257,
      "backward_entropy": 0.014893185761239793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3947097957134247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031726136803627014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09685981273651123,
      "backward_entropy": 0.0147417684396108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5440683960914612,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03175416961312294,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09670719504356384,
      "backward_entropy": 0.009654313325881958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6876314878463745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03178158774971962,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0965547263622284,
      "backward_entropy": 0.014455785353978476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28132736682891846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03180893138051033,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09639713168144226,
      "backward_entropy": 0.009463343355390761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5002818703651428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183482587337494,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09624773263931274,
      "backward_entropy": 0.014182382159762912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.341072678565979,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031860172748565674,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09609805941581726,
      "backward_entropy": 0.009286900361378988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5835704207420349,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031884510070085526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09595334529876709,
      "backward_entropy": 0.00795305354727639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6035919189453125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03190881758928299,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09580430984497071,
      "backward_entropy": 0.00787612133555942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5181689858436584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031933195888996124,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09565024375915528,
      "backward_entropy": 0.009039453334278531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.438696026802063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03195728734135628,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09549348950386047,
      "backward_entropy": 0.013557956450515322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4590919613838196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031980887055397034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09533724784851075,
      "backward_entropy": 0.013438233070903353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47800901532173157,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03200412541627884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09518023133277893,
      "backward_entropy": 0.01332060992717743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6187029480934143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03202710300683975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09502133131027221,
      "backward_entropy": 0.013204351895385318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4518306851387024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032050441950559616,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09485517740249634,
      "backward_entropy": 0.013086334698730044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32301899790763855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03207338601350784,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0946872353553772,
      "backward_entropy": 0.012970575855837928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22927378118038177,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03209546580910683,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09452227354049683,
      "backward_entropy": 0.007304131156868405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5256733298301697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03211639076471329,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09436365365982055,
      "backward_entropy": 0.01275446183151669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43106088042259216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03213759511709213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09419890642166137,
      "backward_entropy": 0.012648121350341372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3153539001941681,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032158635556697845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09403162002563477,
      "backward_entropy": 0.01254278090265062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3064132630825043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032178983092308044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09386588335037231,
      "backward_entropy": 0.012441061437129974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3727979362010956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321987010538578,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09370187520980836,
      "backward_entropy": 0.012342658307817247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36097899079322815,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032218124717473984,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09353564381599426,
      "backward_entropy": 0.008121462331877815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2136506885290146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03223734721541405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09336860179901123,
      "backward_entropy": 0.012150090601709154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.320726603269577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03225555270910263,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09320558309555053,
      "backward_entropy": 0.006837303025854958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3109744191169739,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032273415476083755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09304153919219971,
      "backward_entropy": 0.011970774167113833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2600919008255005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032290998846292496,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09287725687026978,
      "backward_entropy": 0.007901474833488464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2540363371372223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03230806440114975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09271471500396729,
      "backward_entropy": 0.011798932320541806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2475208193063736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03232460841536522,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09255341291427613,
      "backward_entropy": 0.006642055594258838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27959105372428894,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03234065696597099,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09239314198493957,
      "backward_entropy": 0.0077546098166041905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27276214957237244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032356493175029755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0922322392463684,
      "backward_entropy": 0.011558935046195984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28397682309150696,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03237209469079971,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09207059144973755,
      "backward_entropy": 0.006511155929830339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23919416964054108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03238758072257042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09190754890441895,
      "backward_entropy": 0.0114052039053705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3223193883895874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032402750104665756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09174543619155884,
      "backward_entropy": 0.011330319775475396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22847867012023926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032418109476566315,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09157934188842773,
      "backward_entropy": 0.011254589590761397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14081132411956787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03243306651711464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09141381978988647,
      "backward_entropy": 0.006347391340467665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3123106360435486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03244706615805626,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09125244617462158,
      "backward_entropy": 0.0074480945865313215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22730785608291626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032461415976285934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09108685851097106,
      "backward_entropy": 0.011041238903999329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25194185972213745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03247548267245293,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09092099666595459,
      "backward_entropy": 0.006236278348498874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21582986414432526,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03248947113752365,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0907533347606659,
      "backward_entropy": 0.007329424222310384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15123118460178375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0325031541287899,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09058526754379273,
      "backward_entropy": 0.01083574526839786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20556607842445374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03251616656780243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0904204249382019,
      "backward_entropy": 0.006131477653980255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16934776306152344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03252890333533287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09025468230247498,
      "backward_entropy": 0.010708964533276029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21692070364952087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03254125639796257,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09009091258049011,
      "backward_entropy": 0.010648157861497667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.213590607047081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03255365416407585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08992648124694824,
      "backward_entropy": 0.010587220390637716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1573028266429901,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03256601840257645,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08976044058799744,
      "backward_entropy": 0.01052653623951806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23959368467330933,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03257795795798302,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0895961880683899,
      "backward_entropy": 0.005976364016532898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19604043662548065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032590124756097794,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08942809104919433,
      "backward_entropy": 0.010408245027065277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15834970772266388,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0326022244989872,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0892594337463379,
      "backward_entropy": 0.007025687230957879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15250135958194733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03261392563581467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08909152746200562,
      "backward_entropy": 0.01029150601890352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11820287257432938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03262527659535408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08892487287521363,
      "backward_entropy": 0.010235854321055941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19592799246311188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03263598307967186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08876082301139832,
      "backward_entropy": 0.005833663046360016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15002883970737457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032646868377923965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859485387802124,
      "backward_entropy": 0.010129695137341818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1757473349571228,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03265753760933876,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08842964172363281,
      "backward_entropy": 0.006883176250590218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15273083746433258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03266824781894684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08826313614845276,
      "backward_entropy": 0.010024850567181906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13969406485557556,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03267878293991089,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0880964756011963,
      "backward_entropy": 0.0057293495370282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15310627222061157,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03268904611468315,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08793023228645325,
      "backward_entropy": 0.006803881790902879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09926648437976837,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03269922733306885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08776355981826782,
      "backward_entropy": 0.005679924454953935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1431581974029541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03270876780152321,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08759937286376954,
      "backward_entropy": 0.005657033373912175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1386236995458603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032718293368816376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0874354362487793,
      "backward_entropy": 0.00977939036157396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10450224578380585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03272779658436775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08727201223373413,
      "backward_entropy": 0.009732570913102891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1379455178976059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03273691236972809,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08711073398590088,
      "backward_entropy": 0.009687604175673591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0905139148235321,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03274610638618469,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08694934844970703,
      "backward_entropy": 0.006665288988086913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10395588725805283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03275485336780548,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08679077625274659,
      "backward_entropy": 0.009599382678667704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08599408715963364,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032763317227363586,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08663321733474731,
      "backward_entropy": 0.006624126185973485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09553474932909012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03277137875556946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08647807836532592,
      "backward_entropy": 0.009517835246192085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08869636058807373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032779254019260406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08632482290267944,
      "backward_entropy": 0.009478931625684103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08516857773065567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03278683125972748,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08617298603057862,
      "backward_entropy": 0.009441392289267646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08398684114217758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032794151455163956,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08602293729782104,
      "backward_entropy": 0.00940515763229794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10459547489881516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03280121088027954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08587430715560913,
      "backward_entropy": 0.009370075331793891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09114333987236023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032808344811201096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08572567701339721,
      "backward_entropy": 0.009334626297156015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08863095939159393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032815366983413696,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08557762503623963,
      "backward_entropy": 0.005411061147848765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08036532998085022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03282227739691734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08543020486831665,
      "backward_entropy": 0.009265214204788208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08184465020895004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03282901272177696,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08528390526771545,
      "backward_entropy": 0.009231641060776181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07440324127674103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032835692167282104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08513898253440857,
      "backward_entropy": 0.009198437962267134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05884358659386635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0328422412276268,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08499583601951599,
      "backward_entropy": 0.006442582855621974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07127851992845535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03284842148423195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.084855055809021,
      "backward_entropy": 0.005338253246413337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060748402029275894,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032854482531547546,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08471561074256898,
      "backward_entropy": 0.006415143609046936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07669143378734589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032860275357961655,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08457784652709961,
      "backward_entropy": 0.009075751735104455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0659126415848732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03286610543727875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08444056510925294,
      "backward_entropy": 0.009046648939450582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07255402207374573,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032871827483177185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08430457711219788,
      "backward_entropy": 0.00901801304684745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0676373839378357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03287757933139801,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08416929244995117,
      "backward_entropy": 0.005275847597254647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03694458305835724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03288325294852257,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08403443694114685,
      "backward_entropy": 0.00896075533496009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06321439146995544,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03288840875029564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08390265107154846,
      "backward_entropy": 0.008934593035115136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06149107217788696,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032893553376197815,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08377156853675842,
      "backward_entropy": 0.008908554911613464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06382575631141663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0328986831009388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08364112973213196,
      "backward_entropy": 0.008882664144039154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058583952486515045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032903846353292465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08351094722747802,
      "backward_entropy": 0.008856640921698676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05605600029230118,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03290896862745285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08338136672973633,
      "backward_entropy": 0.008830817209349738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0474969744682312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032914068549871445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0832528829574585,
      "backward_entropy": 0.008804836206965976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06622862070798874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0329190269112587,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08312622904777527,
      "backward_entropy": 0.00877949595451355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04807106405496597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03292420879006386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08299959897994995,
      "backward_entropy": 0.008753097719616361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049076929688453674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03292929008603096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08287465572357178,
      "backward_entropy": 0.008727119200759463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0514485128223896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03293434903025627,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08275151252746582,
      "backward_entropy": 0.005154266953468323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04110661521553993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03293941915035248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08262925148010254,
      "backward_entropy": 0.008675376574198404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05747624486684799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032944321632385254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08250876665115356,
      "backward_entropy": 0.008650275568167368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030229561030864716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032949384301900864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08238804340362549,
      "backward_entropy": 0.008624475863244798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05064111575484276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03295410796999931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08227005004882812,
      "backward_entropy": 0.008600211805767484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04196581616997719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03295896202325821,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08215253949165344,
      "backward_entropy": 0.008575491607189178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03795899450778961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032963741570711136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08203601837158203,
      "backward_entropy": 0.008551110823949179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041140489280223846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03296840190887451,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819209098815918,
      "backward_entropy": 0.008527268966039022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039858534932136536,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032973069697618484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08180702924728393,
      "backward_entropy": 0.008503449459870657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03714869171380997,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03297773748636246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08169426918029785,
      "backward_entropy": 0.008479730122619204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04033644124865532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032982319593429565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08158236742019653,
      "backward_entropy": 0.00845640069908566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030479585751891136,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032986920326948166,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08147094249725342,
      "backward_entropy": 0.00843305637439092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0410882793366909,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03299133479595184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08136105537414551,
      "backward_entropy": 0.008410558104515076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026270311325788498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03299589827656746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08125198483467103,
      "backward_entropy": 0.008387502696779039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02936805598437786,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03300023078918457,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08114498853683472,
      "backward_entropy": 0.006092541333701875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030453508719801903,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03300444409251213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08103935718536377,
      "backward_entropy": 0.00834402193625768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032810404896736145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03300858661532402,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08093476295471191,
      "backward_entropy": 0.008322932653956942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025178097188472748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0330127589404583,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08083114624023438,
      "backward_entropy": 0.006064415805869632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029422657564282417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033016759902238846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08072888851165771,
      "backward_entropy": 0.008281358414226107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023566706106066704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033020731061697006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08062744140625,
      "backward_entropy": 0.008261115186744265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024111710488796234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03302454203367233,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08052735328674317,
      "backward_entropy": 0.008241630262798734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029567409306764603,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0330282561480999,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08042874932289124,
      "backward_entropy": 0.0060306572251849705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02530089020729065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033032044768333435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08033069372177123,
      "backward_entropy": 0.008203281296624077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02600475400686264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033035825937986374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08023383617401122,
      "backward_entropy": 0.00818410598569446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027941374108195305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033039629459381104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08013796806335449,
      "backward_entropy": 0.004925979922215144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025536466389894485,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033043522387742996,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08004266023635864,
      "backward_entropy": 0.005996711966064241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02094886638224125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03304745629429817,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0799482822418213,
      "backward_entropy": 0.00812568681107627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023774726316332817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03305129334330559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07985525131225586,
      "backward_entropy": 0.00810655372010337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019574465230107307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03305516019463539,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0797632098197937,
      "backward_entropy": 0.008087319632371267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0200502872467041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03305892273783684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07967244982719421,
      "backward_entropy": 0.008068567348851098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017084378749132156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03306262195110321,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07958277463912963,
      "backward_entropy": 0.008050103154447343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021648094058036804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03306618705391884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07949447631835938,
      "backward_entropy": 0.008032298750347562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022029323503375053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03306981176137924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0794069528579712,
      "backward_entropy": 0.008014335400528379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02015051059424877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03307351469993591,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07932007312774658,
      "backward_entropy": 0.007996187441878848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019278323277831078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03307724744081497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07923411130905152,
      "backward_entropy": 0.007977932691574097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018648622557520866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03308100625872612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07914921045303344,
      "backward_entropy": 0.007959643171893226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0164139736443758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033084772527217865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07906523942947388,
      "backward_entropy": 0.007941342062420316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013731902465224266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03308846056461334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07898223400115967,
      "backward_entropy": 0.007923410170608096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017176739871501923,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03309202566742897,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07890083789825439,
      "backward_entropy": 0.00790605280134413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011278831399977207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03309563547372818,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07882039546966553,
      "backward_entropy": 0.005875565939479404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010987605899572372,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03309904411435127,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07874155640602112,
      "backward_entropy": 0.005867478748162587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01339755579829216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03310226649045944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07866415977478028,
      "backward_entropy": 0.00785620262225469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011264938861131668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033105432987213135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07858778238296509,
      "backward_entropy": 0.004779523031579124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009021521545946598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03310850262641907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07851289510726929,
      "backward_entropy": 0.004772788948482937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010552048683166504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03311138227581978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07843961715698242,
      "backward_entropy": 0.007811347643534343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011378883384168148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033114176243543625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0783675491809845,
      "backward_entropy": 0.007797459761301677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011095450259745121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03311694413423538,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07829642295837402,
      "backward_entropy": 0.007783757315741645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009908411651849747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03311967849731445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07822605371475219,
      "backward_entropy": 0.007770223750008477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013757073320448399,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03312235698103905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07815684080123901,
      "backward_entropy": 0.0077569567494922215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008707034401595592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03312520310282707,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07808809280395508,
      "backward_entropy": 0.007743058933152093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01125210803002119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03312794864177704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07802057266235352,
      "backward_entropy": 0.007729611463016934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010379783809185028,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03313075751066208,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07795385122299195,
      "backward_entropy": 0.007715923090775807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01122428011149168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03313358500599861,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07788784503936767,
      "backward_entropy": 0.007702225612269508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009932521730661392,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03313650190830231,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07782241106033325,
      "backward_entropy": 0.0076881713337368434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00917221512645483,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033139441162347794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07775774002075195,
      "backward_entropy": 0.004705332633521821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008324231952428818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03314236178994179,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07769378423690795,
      "backward_entropy": 0.007660107480155097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008065606467425823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0331452414393425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07763078212738037,
      "backward_entropy": 0.007646355364057753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007985726930201054,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03314806520938873,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07756860256195068,
      "backward_entropy": 0.005750829974810283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0072912126779556274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03315086290240288,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07750726342201233,
      "backward_entropy": 0.007619448833995395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007305820006877184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033153608441352844,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07744682431221009,
      "backward_entropy": 0.00573721072740025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005212860181927681,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033156320452690125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.077387136220932,
      "backward_entropy": 0.0075933610399564104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006087849847972393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033158861100673676,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0773284912109375,
      "backward_entropy": 0.00466191354725096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0062942723743617535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033161330968141556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07727070450782776,
      "backward_entropy": 0.007569223642349243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005257656332105398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033163778483867645,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07721381783485412,
      "backward_entropy": 0.0057127827571498025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003866020357236266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03316614031791687,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07715794444084167,
      "backward_entropy": 0.0057071298360824585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0055593037977814674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03316831216216087,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07710318565368653,
      "backward_entropy": 0.0075354551275571184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004538781475275755,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03317046910524368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07704919576644897,
      "backward_entropy": 0.0075249407026502825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004691964481025934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03317255526781082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0769961953163147,
      "backward_entropy": 0.007514761553870307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036891980562359095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03317458555102348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07694390416145325,
      "backward_entropy": 0.0075048307577768964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037035637069493532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0331764854490757,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0768924593925476,
      "backward_entropy": 0.007495444681909349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004038729704916477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033178284764289856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07684183716773987,
      "backward_entropy": 0.007486523853407966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003661579452455044,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03318004682660103,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07679204940795899,
      "backward_entropy": 0.0074777619706259835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004470663145184517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03318176046013832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07674320936203002,
      "backward_entropy": 0.007469241817792256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003555527189746499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03318352624773979,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07669516801834106,
      "backward_entropy": 0.007460494836171468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003518694778904319,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03318524733185768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07664793133735656,
      "backward_entropy": 0.00460449606180191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002810033969581127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03318694233894348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07660146355628968,
      "backward_entropy": 0.007443582846058739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003086761338636279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03318854421377182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07655581831932068,
      "backward_entropy": 0.0074356165197160505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029590269550681114,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033190108835697174,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07651095390319824,
      "backward_entropy": 0.004594102501869202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024428849574178457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03319163620471954,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07646681666374207,
      "backward_entropy": 0.004590854048728943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002277370309457183,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03319308161735535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07642349004745483,
      "backward_entropy": 0.007412941091590458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00222319969907403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03319443017244339,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07638088464736939,
      "backward_entropy": 0.007406121326817406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002046385547146201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03319571539759636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07633910775184631,
      "backward_entropy": 0.007399574749999576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027195715811103582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03319692239165306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07629812955856323,
      "backward_entropy": 0.00739336179362403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021275815088301897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033198170363903046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07625794410705566,
      "backward_entropy": 0.007386995686425103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002201888943091035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03319938853383064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.076218581199646,
      "backward_entropy": 0.007380767001046075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021097706630825996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03320060297846794,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07618001103401184,
      "backward_entropy": 0.0073745813634660505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017205520998686552,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03320180997252464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07614223957061768,
      "backward_entropy": 0.004569891426298354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016251611523330212,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03320295363664627,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07610516548156739,
      "backward_entropy": 0.004567587955130471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018561463803052902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03320404142141342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07606879472732545,
      "backward_entropy": 0.007357039385371738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016336063854396343,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033205125480890274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07603306770324707,
      "backward_entropy": 0.007351486219300164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001687661511823535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03320617973804474,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07599802017211914,
      "backward_entropy": 0.007346088687578837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014790344284847379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033207230269908905,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07596364617347717,
      "backward_entropy": 0.0073407333758142256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012759262463077903,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033208250999450684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07592997550964356,
      "backward_entropy": 0.007335498101181454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010515357134863734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03320922330021858,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07589702606201172,
      "backward_entropy": 0.005611564136213726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001234932104125619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03321011736989021,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07586476802825928,
      "backward_entropy": 0.007325842148727841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013640453107655048,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033210981637239456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07583317756652833,
      "backward_entropy": 0.007321337858835856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012204748345538974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033211849629879,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07580218315124512,
      "backward_entropy": 0.00454998223317994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010293446248397231,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03321271017193794,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07577188611030579,
      "backward_entropy": 0.007312372326850891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013083703815937042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0332135334610939,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07574219703674316,
      "backward_entropy": 0.007308084931638505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011632876703515649,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03321439027786255,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07571314573287964,
      "backward_entropy": 0.0056006258560551535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001164953107945621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03321525454521179,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07568469643592834,
      "backward_entropy": 0.007299241092469957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008527350146323442,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03321613371372223,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07565679550170898,
      "backward_entropy": 0.004541519201464123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009174563456326723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033216968178749084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07562947273254395,
      "backward_entropy": 0.007290542953544193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007817036821506917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033217791467905045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07560279369354247,
      "backward_entropy": 0.007286358210775588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005279220640659332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03321857377886772,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07557666301727295,
      "backward_entropy": 0.0072823646995756365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006318932864814997,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03321926295757294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07555108070373535,
      "backward_entropy": 0.007278749512301551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005775392637588084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03321990743279457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07552610635757447,
      "backward_entropy": 0.007275313966804081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000768081343267113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033220503479242325,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07550166845321656,
      "backward_entropy": 0.004532947308487362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006217986810952425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033221110701560974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0754777431488037,
      "backward_entropy": 0.007268879148695204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000644045474473387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322169557213783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07545433044433594,
      "backward_entropy": 0.007265745765633053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006685983389616013,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033222272992134094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07543142437934876,
      "backward_entropy": 0.007262670331531101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005276654264889657,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322286158800125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07540904879570007,
      "backward_entropy": 0.007259572545687358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005429270095191896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033223431557416916,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0753872275352478,
      "backward_entropy": 0.005581679857439465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00053804722847417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322398662567139,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07536588907241822,
      "backward_entropy": 0.007253618703948127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004683423030655831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322453796863556,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07534502744674683,
      "backward_entropy": 0.007250710493988461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042163830948993564,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03322507068514824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0753246545791626,
      "backward_entropy": 0.00452417673336135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005512114730663598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322557732462883,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07530477643013,
      "backward_entropy": 0.007245188785923852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004909657291136682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322611004114151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07528536319732666,
      "backward_entropy": 0.007242389851146274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004432512214407325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322665020823479,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0752663791179657,
      "backward_entropy": 0.0072395892606841195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004044070956297219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033227190375328064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07524785995483399,
      "backward_entropy": 0.007236815161175198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004251818172633648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033227723091840744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07522975206375122,
      "backward_entropy": 0.007234079970253838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003168864350300282,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322825953364372,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07521203756332398,
      "backward_entropy": 0.007231346435017056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040042807813733816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03322876989841461,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07519476413726807,
      "backward_entropy": 0.004516810178756714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031869756639935076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033229291439056396,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07517789006233215,
      "backward_entropy": 0.007226104537645976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027193620917387307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03322979807853699,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07516143321990967,
      "backward_entropy": 0.007223537398709191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003178143233526498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323027864098549,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07514538764953613,
      "backward_entropy": 0.007221086985535092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003174662997480482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03323075920343399,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07512973546981812,
      "backward_entropy": 0.005566188030772739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002609608636703342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323124349117279,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07511443495750428,
      "backward_entropy": 0.007216215961509281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002769349957816303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0332317128777504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.075099515914917,
      "backward_entropy": 0.007213839226298862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002620109880808741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033232178539037704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07508493661880493,
      "backward_entropy": 0.007211505538887448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028466639923863113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033232640475034714,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07507070302963256,
      "backward_entropy": 0.007209197514586979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028311763890087605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03323311358690262,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07505680322647094,
      "backward_entropy": 0.005560843480957879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021474482491612434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323359787464142,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0750432014465332,
      "backward_entropy": 0.007204467223750221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017889383889269084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323407098650932,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07502993941307068,
      "backward_entropy": 0.007202138503392537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018901092698797584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323451802134514,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07501697540283203,
      "backward_entropy": 0.007199940582116445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019313451775815338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323494642972946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07500429153442383,
      "backward_entropy": 0.007197803093327416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001666834723437205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033235371112823486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07499193549156188,
      "backward_entropy": 0.007195717758602566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019211279868613929,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03323578089475632,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07497988939285279,
      "backward_entropy": 0.004502440492312114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001825769868446514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033236194401979446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07496809959411621,
      "backward_entropy": 0.007191658020019531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012931603123433888,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033236607909202576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07495656609535217,
      "backward_entropy": 0.0045007069905598955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012420838174875826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033236999064683914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07494530677795411,
      "backward_entropy": 0.007187723285622067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001361550239380449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03323736786842346,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07493435144424439,
      "backward_entropy": 0.005550944970713722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014774996088817716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033237725496292114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07492364048957825,
      "backward_entropy": 0.007184101475609673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016001093899831176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033238086849451065,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07491318583488464,
      "backward_entropy": 0.005549272315369712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011729579273378477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323845937848091,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07490294575691223,
      "backward_entropy": 0.007180493738916185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.199027408612892e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323882073163986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07489296793937683,
      "backward_entropy": 0.007178720500734117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013509075506590307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033239156007766724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0748832106590271,
      "backward_entropy": 0.0071770664718416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.875608232803643e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03323950245976448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07487366199493409,
      "backward_entropy": 0.007175361116727193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010376483987784013,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03323981538414955,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07486433982849121,
      "backward_entropy": 0.004493998984495799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.705653453944251e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03324012830853462,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07485525012016296,
      "backward_entropy": 0.005544460482067532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.223071199608967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0332404263317585,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07484636306762696,
      "backward_entropy": 0.00449273900853263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.779829269973561e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324071690440178,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07483768463134766,
      "backward_entropy": 0.007169347670343187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.856437489157543e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324100747704506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07482918500900268,
      "backward_entropy": 0.007167912191814846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.80175396357663e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324129804968834,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0748208999633789,
      "backward_entropy": 0.007166476713286506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.701371214352548e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324158489704132,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0748127818107605,
      "backward_entropy": 0.00716506689786911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.308132964884862e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033241868019104004,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07480484247207642,
      "backward_entropy": 0.005540461589892705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.683113315375522e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324215114116669,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07479706406593323,
      "backward_entropy": 0.004489091949330436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.50850561214611e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324242681264877,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07478945255279541,
      "backward_entropy": 0.007160945071114434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6875567679526284e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324269875884056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0747820258140564,
      "backward_entropy": 0.004487917241122987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.862462421646342e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324295952916145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0747747540473938,
      "backward_entropy": 0.007158348129855262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5147847888292745e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324321657419205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07476764917373657,
      "backward_entropy": 0.004486798412270016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5219061576062813e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033243466168642044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07476071119308472,
      "backward_entropy": 0.0071558596359358895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.26369440194685e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324370086193085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07475391626358033,
      "backward_entropy": 0.0071546998288896345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8390015106415376e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324393182992935,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07474726438522339,
      "backward_entropy": 0.00715355740653144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.876366827171296e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324415162205696,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07474077939987182,
      "backward_entropy": 0.004484766059451633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.337404607213102e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033244360238313675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07473445534706116,
      "backward_entropy": 0.007151422401269277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.586227078107186e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324456885457039,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07472829818725586,
      "backward_entropy": 0.007150372697247399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6237841413822025e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0332447811961174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07472227811813355,
      "backward_entropy": 0.007149321337540944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8962636861251667e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033244986087083817,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07471640110015869,
      "backward_entropy": 0.005533372776375877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.442552042542957e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324517980217934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07471067309379578,
      "backward_entropy": 0.007147341966629028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8556942197610624e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324537351727486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07470510005950928,
      "backward_entropy": 0.00714639491505093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0547955248039216e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324555978178978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07469965815544129,
      "backward_entropy": 0.007145478493637509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7031228455598466e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0332457460463047,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07469435930252075,
      "backward_entropy": 0.0044813574188285405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6053801775560714e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324592486023903,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07468917369842529,
      "backward_entropy": 0.00448098737332556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.944054565683473e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03324609622359276,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07468411922454835,
      "backward_entropy": 0.0055308375093672014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.001720324391499e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324625641107559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07467918395996094,
      "backward_entropy": 0.007142038808928596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0783176296390593e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324642404913902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07467436790466309,
      "backward_entropy": 0.007141210966640049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1925561668467708e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324658423662186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07466967105865478,
      "backward_entropy": 0.007140416238043044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0686535208369605e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324674069881439,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.074665105342865,
      "backward_entropy": 0.007139646344714695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7774624211597256e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324689716100693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07466062903404236,
      "backward_entropy": 0.007138890524705251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9953133232775144e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033247046172618866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07465626001358032,
      "backward_entropy": 0.007138158712122176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.450488889531698e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033247195184230804,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07465199232101441,
      "backward_entropy": 0.004478323376841015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.495045671617845e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324733301997185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07464781999588013,
      "backward_entropy": 0.007136738134755028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3178992048779037e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033247463405132294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07464373111724854,
      "backward_entropy": 0.007136083311504788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.388757664244622e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324758633971214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07463977336883545,
      "backward_entropy": 0.00447748891181416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4145313798508141e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324770927429199,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07463588714599609,
      "backward_entropy": 0.00713483989238739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2662358130910434e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324782848358154,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07463210821151733,
      "backward_entropy": 0.007134236395359039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2020967005810235e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033247943967580795,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07462840080261231,
      "backward_entropy": 0.007133652766545613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.783533641893882e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03324805572628975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07462478280067444,
      "backward_entropy": 0.005526460293266509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.051871913659852e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033248160034418106,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07462126016616821,
      "backward_entropy": 0.005526256230142381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.760467946762219e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033248260617256165,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07461781501770019,
      "backward_entropy": 0.007132044268978966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.989696991397068e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324836120009422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07461447715759277,
      "backward_entropy": 0.007131531006760067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.329076313704718e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324846178293228,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07461122274398804,
      "backward_entropy": 0.0071310218837526106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.487517905246932e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033248551189899445,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07460803985595703,
      "backward_entropy": 0.00447548594739702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.308055839734152e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324863687157631,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07460496425628663,
      "backward_entropy": 0.00447530671954155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.326596460188739e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033248722553253174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0746019423007965,
      "backward_entropy": 0.007129687401983473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.804530701425392e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324880450963974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07459902167320251,
      "backward_entropy": 0.007129246989885966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.868950211151969e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324888274073601,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07459615468978882,
      "backward_entropy": 0.007128843830691444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.820811566081829e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324895724654198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07459337711334228,
      "backward_entropy": 0.007128457228342692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1192754401417915e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324902802705765,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07459067106246949,
      "backward_entropy": 0.007128089666366577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.940218215982895e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324909880757332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07458803653717042,
      "backward_entropy": 0.0071277303828133475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.911637344979681e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324916958808899,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07458546161651611,
      "backward_entropy": 0.007127349575360616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.552853170025628e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324924036860466,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07458298206329346,
      "backward_entropy": 0.00712698863612281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2656579353206325e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324931114912033,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07458057403564453,
      "backward_entropy": 0.0044739478164249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.002735295216553e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0332493782043457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.074578195810318,
      "backward_entropy": 0.004473814533816444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.368112513475353e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324944153428078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07457591295242309,
      "backward_entropy": 0.007125964595211877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1356421459349804e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03324950486421585,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07457367181777955,
      "backward_entropy": 0.004473557074864705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.952114639105275e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033249564468860626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07457150220870971,
      "backward_entropy": 0.007125329640176561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6755247947439784e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0332496240735054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07456940412521362,
      "backward_entropy": 0.007125015887949202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0838352813589154e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324968367815018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07456735372543336,
      "backward_entropy": 0.007124718692567613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.421620021981653e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033249739557504654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07456536293029785,
      "backward_entropy": 0.007124423152870602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7029416287405184e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324979916214943,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07456343173980713,
      "backward_entropy": 0.00712412844101588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.499784613974043e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033249855041503906,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07456154823303222,
      "backward_entropy": 0.007123842007584042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4815217329887673e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033249907195568085,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07455970048904419,
      "backward_entropy": 0.007123570475313399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.195385832237662e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03324995934963226,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07455792427062988,
      "backward_entropy": 0.007123301426569621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.423810201435117e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03325000777840614,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07455618977546692,
      "backward_entropy": 0.004472520616319444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9586832422646694e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325005620718002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07455451488494873,
      "backward_entropy": 0.007122805549038781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7126684497270617e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033250100910663605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0745528757572174,
      "backward_entropy": 0.007122553057140774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.858096993601066e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033250145614147186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07455129027366639,
      "backward_entropy": 0.004472236252493328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7559875686856685e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325019031763077,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0745497465133667,
      "backward_entropy": 0.0071221159564124215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8068188865072443e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325023129582405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07454824447631836,
      "backward_entropy": 0.007121892438994514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6243805021076696e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033250272274017334,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07454679012298585,
      "backward_entropy": 0.004471971756882138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1961549262196058e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325031325221062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07454538345336914,
      "backward_entropy": 0.007121452854739295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4285441238826024e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0332503542304039,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07454400658607482,
      "backward_entropy": 0.007121254172590043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.246065153281961e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033250391483306885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07454266548156738,
      "backward_entropy": 0.007121057973967658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2142601235609618e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325042873620987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07454137206077575,
      "backward_entropy": 0.007120870053768158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.117630858971097e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033250465989112854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07454012632369995,
      "backward_entropy": 0.007120681305726369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0484087624718086e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325050324201584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07453889846801758,
      "backward_entropy": 0.007120484279261695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.89108469234634e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033250536769628525,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07453771829605102,
      "backward_entropy": 0.004471416274706523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.714059163139609e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03325057029724121,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.07453657388687134,
      "backward_entropy": 0.005521280070145925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.452481440850534e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0332506000995636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07453546524047852,
      "backward_entropy": 0.00711997432841195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603781000398158e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033250629901885986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0745343804359436,
      "backward_entropy": 0.007119833595222897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.18982846592553e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033250659704208374,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07453333139419556,
      "backward_entropy": 0.004471181167496575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.732874678367807e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03325068578124046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07453230023384094,
      "backward_entropy": 0.004471125702063243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.895898193055473e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325071185827255,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07453132271766663,
      "backward_entropy": 0.007119389043913947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.029884727671742e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03325074166059494,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07453036308288574,
      "backward_entropy": 0.004471006078852547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.840183578380675e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325077146291733,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452942132949829,
      "backward_entropy": 0.007119100126955245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.028047098676325e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325079753994942,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452852725982666,
      "backward_entropy": 0.007118970155715942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.255877226773009e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325081989169121,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452764511108398,
      "backward_entropy": 0.007118845979372661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9303552057390334e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033250842243433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452678680419922,
      "backward_entropy": 0.007118716835975647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.734997389732598e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325086459517479,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452595829963685,
      "backward_entropy": 0.007118605077266693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5272876175440615e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03325088694691658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07452515959739685,
      "backward_entropy": 0.0044707175758149885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.010450425084855e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03325090557336807,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0745243787765503,
      "backward_entropy": 0.004470672044489119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1809454387475853e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033250924199819565,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07452362775802612,
      "backward_entropy": 0.004470625271399816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.117085043413681e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033250946551561356,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.07452288866043091,
      "backward_entropy": 0.004470590915944841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.594599379790452e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325096517801285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452218532562256,
      "backward_entropy": 0.0071180711189905805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.469740761374851e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03325098380446434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0745215117931366,
      "backward_entropy": 0.004470518065823449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1015704848869063e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325100243091583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452083826065063,
      "backward_entropy": 0.0071178823709487915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5267874548262625e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033251021057367325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.07452019453048705,
      "backward_entropy": 0.0071177805463473005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4404960186075186e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03325103968381882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0745195746421814,
      "backward_entropy": 0.007117682033114963,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.712388613697158e-05,
    "avg_log_Z": 0.033247987180948256,
    "success_rate": 1.0,
    "avg_reward": 53.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.06,
      "1": 0.26,
      "2": 0.68
    },
    "avg_forward_entropy": 0.07462021869421005,
    "avg_backward_entropy": 0.006346045935319528,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}