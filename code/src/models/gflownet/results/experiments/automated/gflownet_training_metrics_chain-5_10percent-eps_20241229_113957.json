{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.13857634067535402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385568380355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.559015274047852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299714724222818,
      "backward_entropy": 0.1385643720626831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.655019760131836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299301465352377,
      "backward_entropy": 0.1385718584060669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.651811599731445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00020001709344796836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829889416694641,
      "backward_entropy": 0.13856709003448486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.304496765136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00030003924621269107,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298478921254477,
      "backward_entropy": 0.13853923082351685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.055651664733887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00039998278953135014,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829806168874105,
      "backward_entropy": 0.13853297233581544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955397605895996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000499822897836566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297656377156576,
      "backward_entropy": 0.13855156898498536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.855990409851074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005995635874569416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297247091929117,
      "backward_entropy": 0.13853740692138672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.047005653381348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000699202180840075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296831846237183,
      "backward_entropy": 0.1385403871536255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.53690242767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007988416473381221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18296406666437784,
      "backward_entropy": 0.1385273814201355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.876391410827637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008986136526800692,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829594373703003,
      "backward_entropy": 0.13852887153625487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.203744888305664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009985860669985414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182954470316569,
      "backward_entropy": 0.13852283954620362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.623847007751465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010982176754623652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294980128606161,
      "backward_entropy": 0.138511323928833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.114140510559082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011980176204815507,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294483423233032,
      "backward_entropy": 0.13850568532943724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.276880264282227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012980897445231676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829395294189453,
      "backward_entropy": 0.13849990367889403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.14298152923584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013981317169964314,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829340656598409,
      "backward_entropy": 0.1384939432144165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.9518461227417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001498443423770368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18292832374572754,
      "backward_entropy": 0.1384878158569336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76218318939209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015989006496965885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292230367660522,
      "backward_entropy": 0.13848621845245362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.037630081176758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016993996687233448,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291612466176352,
      "backward_entropy": 0.13847967386245727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.188149452209473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018000483978539705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290968736012778,
      "backward_entropy": 0.1384730577468872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.092536926269531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019008564995601773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290303150812784,
      "backward_entropy": 0.13846629858016968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.504156112670898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020017570350319147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289623657862344,
      "backward_entropy": 0.1384593963623047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.501335144042969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021025349851697683,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18288938204447427,
      "backward_entropy": 0.13839683532714844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.264963150024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002203205367550254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828825076421102,
      "backward_entropy": 0.13844010829925538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.354207038879395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00230406504124403,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18287535508473715,
      "backward_entropy": 0.13837647438049316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.819031715393066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024044185411185026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828683614730835,
      "backward_entropy": 0.13842378854751586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.073262214660645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0025044595822691917,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828614870707194,
      "backward_entropy": 0.13842183351516724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.6670503616333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002604698296636343,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828544537226359,
      "backward_entropy": 0.13834420442581177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.655909538269043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002704979619011283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828471819559733,
      "backward_entropy": 0.13839753866195678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.420533180236816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028049033135175705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18284004926681519,
      "backward_entropy": 0.1383883237838745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.991981506347656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029052114114165306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182832400004069,
      "backward_entropy": 0.13838796615600585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.811279296875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030056796967983246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828244924545288,
      "backward_entropy": 0.13836921453475953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.737703323364258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031061985064297915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281646569569907,
      "backward_entropy": 0.13836965560913086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.717219352722168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003206757828593254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280816078186035,
      "backward_entropy": 0.1383490204811096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.644035339355469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033073080703616142,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827998956044515,
      "backward_entropy": 0.13835036754608154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.378450393676758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00340824481099844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279147148132324,
      "backward_entropy": 0.1383277177810669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.303043365478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035093859769403934,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278308709462485,
      "backward_entropy": 0.13823211193084717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.3714017868042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036098777782171965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827750007311503,
      "backward_entropy": 0.1383053779602051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.791732788085938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037106280215084553,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276679515838623,
      "backward_entropy": 0.1382045030593872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.946562767028809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038109570741653442,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18275888760884604,
      "backward_entropy": 0.13829832077026366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.782919883728027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003911382053047419,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275105953216553,
      "backward_entropy": 0.13817571401596068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.704216003417969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004011840559542179,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274319171905518,
      "backward_entropy": 0.1382577896118164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.776750564575195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004112321883440018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18273494640986124,
      "backward_entropy": 0.13826563358306884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.773635864257812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004212826024740934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18272666136423746,
      "backward_entropy": 0.1382542371749878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.677275657653809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004313348792493343,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18271833658218384,
      "backward_entropy": 0.13811661005020143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.521468162536621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0044142622500658035,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18270977338155112,
      "backward_entropy": 0.13810105323791505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.339515686035156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004515042528510094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18270117044448853,
      "backward_entropy": 0.13821864128112793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.682740211486816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004616038873791695,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18269246816635132,
      "backward_entropy": 0.1380687952041626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.016168594360352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004716976545751095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18268340826034546,
      "backward_entropy": 0.13805220127105713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.837617874145508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004817531444132328,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18267476558685303,
      "backward_entropy": 0.1381805419921875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260591506958008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004918128252029419,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266594409942627,
      "backward_entropy": 0.13816710710525512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.582493782043457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005018515512347221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826570232709249,
      "backward_entropy": 0.1381197452545166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51686954498291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0051188236102461815,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18264840046564737,
      "backward_entropy": 0.1381392240524292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.006596565246582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00521860970184207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826401154200236,
      "backward_entropy": 0.13808791637420653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.2485990524292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005318174138665199,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18263161182403564,
      "backward_entropy": 0.13810992240905762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.448977470397949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005417643114924431,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18262292941411337,
      "backward_entropy": 0.13809468746185302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.813882827758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005516218952834606,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826146443684896,
      "backward_entropy": 0.1379029393196106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.506025314331055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005615065339952707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18260602156321207,
      "backward_entropy": 0.13806307315826416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.89079761505127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005713552236557007,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18259771664937338,
      "backward_entropy": 0.1378609538078308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.723525047302246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005812333431094885,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18258927265803018,
      "backward_entropy": 0.13803024291992189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.154351234436035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005911318585276604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825805107752482,
      "backward_entropy": 0.13801343441009523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.577287673950195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006010195706039667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825727621714274,
      "backward_entropy": 0.1379469156265259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.549263000488281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006108755711466074,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18256493409474692,
      "backward_entropy": 0.1377704381942749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89687728881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0062074908055365086,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825565497080485,
      "backward_entropy": 0.13774662017822265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14641284942627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006306077353656292,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182547926902771,
      "backward_entropy": 0.13794293403625488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.294363975524902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006404605228453875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18254009882609049,
      "backward_entropy": 0.13786847591400148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.407217979431152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006503208540380001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18253159523010254,
      "backward_entropy": 0.13790562152862548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.885666847229004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006601431872695684,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825235684712728,
      "backward_entropy": 0.13764576911926268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.715961456298828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006699566729366779,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18251526355743408,
      "backward_entropy": 0.1378666043281555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.821373462677002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006797563284635544,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825064222017924,
      "backward_entropy": 0.1378462553024292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.199576377868652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006895017810165882,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249736229578653,
      "backward_entropy": 0.1377561330795288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15119743347168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0069926283322274685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824879248936971,
      "backward_entropy": 0.13780369758605956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.515348434448242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007089865859597921,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824789047241211,
      "backward_entropy": 0.13778176307678222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.113048553466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007187442854046822,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18246930837631226,
      "backward_entropy": 0.13747818470001222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.109986305236816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007285121362656355,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18245959281921387,
      "backward_entropy": 0.13773641586303711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.182726860046387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007382891606539488,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18244977792104086,
      "backward_entropy": 0.13763076066970825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.857739448547363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007480790838599205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18243960539499918,
      "backward_entropy": 0.13760387897491455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.2508544921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007578649092465639,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242923418680826,
      "backward_entropy": 0.13734939098358154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.626910209655762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007676674518734217,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18241824706395468,
      "backward_entropy": 0.13731507062911988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94544792175293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007774509023874998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824080546696981,
      "backward_entropy": 0.1375230073928833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.189370155334473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007872332818806171,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239843845367432,
      "backward_entropy": 0.13759444952011107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.841461181640625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007970258593559265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238921960194907,
      "backward_entropy": 0.1375693678855896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37900447845459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008068145252764225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823794643084208,
      "backward_entropy": 0.13754353523254395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.734624862670898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008166289888322353,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18236815929412842,
      "backward_entropy": 0.13712868690490723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.046318054199219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008264349773526192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823558807373047,
      "backward_entropy": 0.1373764991760254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929482460021973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008361948654055595,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18234465519587198,
      "backward_entropy": 0.1370491862297058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.143319129943848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008459568955004215,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18233398596445718,
      "backward_entropy": 0.13700757026672364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.283295631408691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008557343855500221,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18232274055480957,
      "backward_entropy": 0.13740460872650145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.849530220031738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008655346930027008,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18231030305226645,
      "backward_entropy": 0.13724880218505858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42389965057373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008753285743296146,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18229893843332926,
      "backward_entropy": 0.1372152090072632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.315526962280273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00885098334401846,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18228795131047568,
      "backward_entropy": 0.13683137893676758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.806185722351074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00894844252616167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18227638800938925,
      "backward_entropy": 0.1371462821960449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.237527847290039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009045918472111225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18226454655329385,
      "backward_entropy": 0.1372504711151123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.293661117553711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009143135510385036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182252566019694,
      "backward_entropy": 0.13707528114318848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.359626770019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00924062728881836,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18224056561787924,
      "backward_entropy": 0.13663971424102783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47426700592041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009338408708572388,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18222816785176596,
      "backward_entropy": 0.13659062385559081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.699637413024902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009436015039682388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18221577008565268,
      "backward_entropy": 0.136963152885437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.595609664916992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009533056989312172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18220486243565878,
      "backward_entropy": 0.13708349466323852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.395320892333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009630555287003517,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18219359715779623,
      "backward_entropy": 0.13643791675567626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.544008255004883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00972786732017994,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821826696395874,
      "backward_entropy": 0.137013578414917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.97519302368164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009825621731579304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821699539820353,
      "backward_entropy": 0.13680431842803956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700563430786133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009923494420945644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18215576807657877,
      "backward_entropy": 0.13694019317626954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26008415222168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010021300986409187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821418603261312,
      "backward_entropy": 0.13671574592590333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.504252433776855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010119324550032616,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821285287539164,
      "backward_entropy": 0.13616762161254883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.258898735046387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010217659175395966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821156938870748,
      "backward_entropy": 0.1368256092071533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.808176517486572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010315683670341969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18210198481877646,
      "backward_entropy": 0.13678613901138306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.565533638000488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010413185693323612,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820889711380005,
      "backward_entropy": 0.1367459774017334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74244499206543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010511615313589573,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18207430839538574,
      "backward_entropy": 0.13670514822006224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.867961883544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010609958320856094,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820594072341919,
      "backward_entropy": 0.13587379455566406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.226344108581543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010708306916058064,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820432742436727,
      "backward_entropy": 0.13662482500076295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231744766235352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010806290432810783,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18202908833821616,
      "backward_entropy": 0.13658442497253417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.285382270812988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010903995484113693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18201422691345215,
      "backward_entropy": 0.13625048398971557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100767135620117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011001967824995518,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819990078608195,
      "backward_entropy": 0.13650135993957518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.709798812866211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011099624447524548,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18198221921920776,
      "backward_entropy": 0.13555225133895873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.018988609313965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011197749525308609,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.181966503461202,
      "backward_entropy": 0.13548403978347778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.518938064575195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011295933276414871,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195273478825888,
      "backward_entropy": 0.13637137413024902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.518103122711182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011393971741199493,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18193848927815756,
      "backward_entropy": 0.13534278869628907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.695618629455566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011491314508020878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1819272836049398,
      "backward_entropy": 0.13587372303009032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.752605438232422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011588680557906628,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18191564083099365,
      "backward_entropy": 0.13623509407043458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.562753677368164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011686107143759727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18190308411916098,
      "backward_entropy": 0.13618788719177247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.990910530090332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01178346760571003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18189126253128052,
      "backward_entropy": 0.13566675186157226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.746392726898193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011881008744239807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18187872568766275,
      "backward_entropy": 0.13559448719024658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9906907081604,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01197806652635336,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18186686436335245,
      "backward_entropy": 0.13485945463180543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.555618762969971,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01207481324672699,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18185611565907797,
      "backward_entropy": 0.13477120399475098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.793444633483887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01217104122042656,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18184798955917358,
      "backward_entropy": 0.13593931198120118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.419285297393799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01226696465164423,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1818395455678304,
      "backward_entropy": 0.13458354473114015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469673156738281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012362413108348846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18183183670043945,
      "backward_entropy": 0.13521617650985718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.396238327026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01245796773582697,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18182520071665445,
      "backward_entropy": 0.13438699245452881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.390884399414062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012553613632917404,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818173130353292,
      "backward_entropy": 0.13505493402481078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002279281616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01264934241771698,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18180827299753824,
      "backward_entropy": 0.13418320417404175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.833418846130371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012745467945933342,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18179742495218912,
      "backward_entropy": 0.13407905101776124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.639130592346191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012841303832828999,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1817887822786967,
      "backward_entropy": 0.1339722156524658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.119573593139648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012936796993017197,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18178117275238037,
      "backward_entropy": 0.13549044132232665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.931893348693848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013032265938818455,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18177209297815958,
      "backward_entropy": 0.13375229835510255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.664371490478516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013128085993230343,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18176486094792685,
      "backward_entropy": 0.13363888263702392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.355739593505859,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013224132359027863,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18175597985585532,
      "backward_entropy": 0.13530421257019043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.032341957092285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01331972237676382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1817449927330017,
      "backward_entropy": 0.13434281349182128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.894168853759766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013415729627013206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18173464139302573,
      "backward_entropy": 0.13424575328826904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.750176429748535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013512064702808857,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18172319730122885,
      "backward_entropy": 0.13510665893554688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.018449783325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013609138317406178,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18171030282974243,
      "backward_entropy": 0.13503379821777345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.451632499694824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013705974444746971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18169709046681723,
      "backward_entropy": 0.13394036293029785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.808780670166016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013802805915474892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18168489138285318,
      "backward_entropy": 0.13488287925720216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.629776000976562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013899832963943481,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18167245388031006,
      "backward_entropy": 0.13480496406555176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.374444007873535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013996916823089123,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18166198333104452,
      "backward_entropy": 0.1325298070907593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.65913724899292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01409392710775137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18165294329325357,
      "backward_entropy": 0.13350038528442382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417238235473633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01419056300073862,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18163859844207764,
      "backward_entropy": 0.1322489619255066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.551926612854004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014287207275629044,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18162510792414346,
      "backward_entropy": 0.1344568371772766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.210612297058105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014383405447006226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18161322673161825,
      "backward_entropy": 0.1331478476524353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.755338668823242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014479568228125572,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18160086870193481,
      "backward_entropy": 0.13180670738220215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.747007369995117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014575985260307789,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815878947575887,
      "backward_entropy": 0.1328967809677124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.027527809143066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014672626741230488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18157442410786948,
      "backward_entropy": 0.1314995765686035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.866579055786133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014768563210964203,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18156196673711142,
      "backward_entropy": 0.13263239860534667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.024308204650879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01486482098698616,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18155086040496826,
      "backward_entropy": 0.13117998838424683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.161510467529297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014961476437747478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18153860171635947,
      "backward_entropy": 0.13375306129455566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.234917640686035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015058034099638462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18152620395024618,
      "backward_entropy": 0.1322115659713745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.693543434143066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015154514461755753,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18151617050170898,
      "backward_entropy": 0.133531391620636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.491786003112793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015251198783516884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18150538206100464,
      "backward_entropy": 0.13191680908203124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16811466217041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015347974374890327,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814927856127421,
      "backward_entropy": 0.133300256729126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.376118183135986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015445167198777199,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1814802885055542,
      "backward_entropy": 0.1301408290863037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.395893096923828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015541812404990196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18146701653798422,
      "backward_entropy": 0.1330591320991516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.343424797058105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015637939795851707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18145678440729776,
      "backward_entropy": 0.13129117488861083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.141356468200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015734128654003143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18144619464874268,
      "backward_entropy": 0.12957518100738524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.061674118041992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015830280259251595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18143421411514282,
      "backward_entropy": 0.13096251487731933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.896153450012207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015926862135529518,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18142290910085043,
      "backward_entropy": 0.129180645942688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.056535720825195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016024276614189148,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18141156435012817,
      "backward_entropy": 0.13061692714691162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.379926681518555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016121475026011467,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813997427622477,
      "backward_entropy": 0.13228471279144288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417654037475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016219180077314377,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18138734499613443,
      "backward_entropy": 0.12854278087615967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.620290756225586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016316808760166168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18137685457865396,
      "backward_entropy": 0.13006837368011476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.95897912979126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01641451008617878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18136471509933472,
      "backward_entropy": 0.12987712621688843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89312744140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016511909663677216,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18135305245717367,
      "backward_entropy": 0.12968182563781738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.042529106140137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016609560698270798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18133930365244547,
      "backward_entropy": 0.12948217391967773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.520892143249512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016706978902220726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18132450183232626,
      "backward_entropy": 0.1292794704437256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.668883800506592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01680387184023857,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18131270011266074,
      "backward_entropy": 0.12907419204711915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.793349742889404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016900401562452316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813002030054728,
      "backward_entropy": 0.13110630512237548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.287843704223633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016996651887893677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812895933787028,
      "backward_entropy": 0.13094692230224608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.844829082489014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017093438655138016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18128178517023721,
      "backward_entropy": 0.13078514337539673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.798100471496582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017190005630254745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1812699834505717,
      "backward_entropy": 0.12821919918060304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312945365905762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01728687435388565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18125585714975992,
      "backward_entropy": 0.13045032024383546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7525529861450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017383189871907234,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18124252557754517,
      "backward_entropy": 0.12558696269989014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.648419380187988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01747928000986576,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812267303466797,
      "backward_entropy": 0.13010270595550538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.939908981323242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01757562905550003,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18121063709259033,
      "backward_entropy": 0.12730329036712645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.137971878051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017672905698418617,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18119406700134277,
      "backward_entropy": 0.12474777698516845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.539237022399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017770051956176758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18117662270863852,
      "backward_entropy": 0.12681471109390258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.355367660522461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017866749316453934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1811596949895223,
      "backward_entropy": 0.12936360836029054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.510201454162598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01796402782201767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18114256858825684,
      "backward_entropy": 0.129164719581604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31411361694336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018060827627778053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18112595876057944,
      "backward_entropy": 0.12605159282684325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5104522705078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01815764419734478,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18110879262288412,
      "backward_entropy": 0.12324726581573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.969599723815918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0182539951056242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810962955156962,
      "backward_entropy": 0.1285470724105835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.107932090759277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01835017092525959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18108850717544556,
      "backward_entropy": 0.1252504587173462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.191925048828125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018446294590830803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18108208974202475,
      "backward_entropy": 0.1281215190887451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.260813236236572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018542977049946785,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18107515573501587,
      "backward_entropy": 0.12791067361831665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02839469909668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018639085814356804,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810705065727234,
      "backward_entropy": 0.12769713401794433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.366035461425781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01873514987528324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18106273810068765,
      "backward_entropy": 0.12411580085754395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.513775825500488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018831877037882805,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1810547113418579,
      "backward_entropy": 0.12090228796005249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.689335346221924,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01892876625061035,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18104358514149985,
      "backward_entropy": 0.12702882289886475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.391460418701172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019025340676307678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810305913289388,
      "backward_entropy": 0.12320975065231324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.832576751708984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019121969118714333,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18102077643076578,
      "backward_entropy": 0.11982133388519287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.476359844207764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019218379631638527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810106635093689,
      "backward_entropy": 0.12632374763488768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.202753067016602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01931438222527504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18100150426228842,
      "backward_entropy": 0.12226334810256959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.544573783874512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019410422071814537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1809928814570109,
      "backward_entropy": 0.12193882465362549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.914279460906982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019506152719259262,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1809830665588379,
      "backward_entropy": 0.11833432912826539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.108199119567871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019601836800575256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18096959590911865,
      "backward_entropy": 0.12128057479858398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.049052238464355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019698094576597214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1809569994608561,
      "backward_entropy": 0.12505747079849244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.202184677124023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019794316962361336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18094209829966226,
      "backward_entropy": 0.1247899055480957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.339344501495361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01989058032631874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18092628320058188,
      "backward_entropy": 0.12027146816253662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.210578918457031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019986381754279137,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18091177940368652,
      "backward_entropy": 0.1199267864227295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.855559825897217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02008228562772274,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18089532852172852,
      "backward_entropy": 0.11597461700439453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.83972454071045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020178070291876793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18087873856226602,
      "backward_entropy": 0.12367545366287232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.532295227050781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02027430571615696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18086111545562744,
      "backward_entropy": 0.12338498830795289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6257853507995605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020370200276374817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1808441678682963,
      "backward_entropy": 0.11849112510681152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709842681884766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020465249195694923,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18083121379216513,
      "backward_entropy": 0.12279368638992309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.228048324584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02056018076837063,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1808187166849772,
      "backward_entropy": 0.11385563611984253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.158552169799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020655356347560883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1808011531829834,
      "backward_entropy": 0.1173707365989685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.345545768737793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020750662311911583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18078394730885824,
      "backward_entropy": 0.1218723177909851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.273249626159668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020846230909228325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18076338370641074,
      "backward_entropy": 0.12155380249023437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95075511932373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020941946655511856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18074448903401694,
      "backward_entropy": 0.1161921739578247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.885721683502197,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021038223057985306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1807230512301127,
      "backward_entropy": 0.12090266942977905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.964711666107178,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021134378388524055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18070054054260254,
      "backward_entropy": 0.12056910991668701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.343132495880127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021230492740869522,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18067578474680582,
      "backward_entropy": 0.12022989988327026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.447998046875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02132619172334671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.180651326974233,
      "backward_entropy": 0.11452933549880981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.611557960510254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021422192454338074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18062337239583334,
      "backward_entropy": 0.11953634023666382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.535326957702637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021517964079976082,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18059434493382773,
      "backward_entropy": 0.11366729736328125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.502520561218262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021613433957099915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18056917190551758,
      "backward_entropy": 0.11882333755493164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2041215896606445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02170865796506405,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18054354190826416,
      "backward_entropy": 0.10822427272796631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879504203796387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02180352620780468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18051437536875406,
      "backward_entropy": 0.1123381495475769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.307541847229004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02189902774989605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804834802945455,
      "backward_entropy": 0.1177133560180664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.229697227478027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021994194015860558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804506778717041,
      "backward_entropy": 0.11733062267303467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.512667655944824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02208896353840828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1804210146268209,
      "backward_entropy": 0.11095654964447021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.534615516662598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022184165194630623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18039021889368692,
      "backward_entropy": 0.11048275232315063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5027241706848145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022279173135757446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18035986026128134,
      "backward_entropy": 0.11000396013259887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.576123237609863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022373992949724197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18032999833424887,
      "backward_entropy": 0.10952014923095703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.181378364562988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02246866375207901,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18030222256978354,
      "backward_entropy": 0.11534883975982665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.786365985870361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022562943398952484,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1802790363629659,
      "backward_entropy": 0.10349147319793701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.114461421966553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022656654939055443,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18025881052017212,
      "backward_entropy": 0.11453020572662354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.313179969787598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02275007963180542,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18023852507273355,
      "backward_entropy": 0.11411421298980713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.100369453430176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02284274622797966,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18022076288859049,
      "backward_entropy": 0.10179930925369263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.67645788192749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02293523959815502,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18020168940226236,
      "backward_entropy": 0.10652881860733032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.235665798187256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023027917370200157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18018178145090738,
      "backward_entropy": 0.1060139536857605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603088855743408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02312050387263298,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1801608403523763,
      "backward_entropy": 0.10006078481674194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2087178230285645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023213226348161697,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18013914426167807,
      "backward_entropy": 0.09946810007095337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.678617000579834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023305213078856468,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18011911710103354,
      "backward_entropy": 0.09887146949768066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.989602088928223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023396842181682587,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18009883165359497,
      "backward_entropy": 0.11106269359588623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9504923820495605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023488324135541916,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18007938067118326,
      "backward_entropy": 0.1106067419052124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.52236270904541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023580297827720642,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18005716800689697,
      "backward_entropy": 0.10281975269317627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.630397796630859,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023671811446547508,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18003580967585245,
      "backward_entropy": 0.10226927995681763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.307880878448486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023762967437505722,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18001621961593628,
      "backward_entropy": 0.09581304788589477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.151522159576416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02385363169014454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17999611298243204,
      "backward_entropy": 0.10115903615951538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.18473482131958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023944390937685966,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17997384071350098,
      "backward_entropy": 0.09455973505973816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.828329563140869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024034613743424416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.179952343304952,
      "backward_entropy": 0.10003201961517334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.67818546295166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02412477321922779,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17992969353993735,
      "backward_entropy": 0.09329174757003784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.507481575012207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024214135482907295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799087921778361,
      "backward_entropy": 0.10675495862960815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3972296714782715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024303317070007324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17988761266072592,
      "backward_entropy": 0.10624846220016479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.94152307510376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024392208084464073,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17987114191055298,
      "backward_entropy": 0.10574018955230713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.910299777984619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02448122762143612,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17985492944717407,
      "backward_entropy": 0.09715251922607422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.843040943145752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024569708853960037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17983982960383096,
      "backward_entropy": 0.09656355381011963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.308689117431641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024657703936100006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17982272307078043,
      "backward_entropy": 0.095974600315094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.741771697998047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02474554255604744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17980480194091797,
      "backward_entropy": 0.09538096189498901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.698894500732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024832844734191895,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17978918552398682,
      "backward_entropy": 0.08804107904434204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.003101825714111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02492033690214157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1797705888748169,
      "backward_entropy": 0.09418303966522217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.886231899261475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02500753477215767,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17975135644276938,
      "backward_entropy": 0.08669505715370178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.801051616668701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025094421580433846,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1797294020652771,
      "backward_entropy": 0.10149475336074829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.290996551513672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02518162690103054,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1797040899594625,
      "backward_entropy": 0.08534492254257202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.194241523742676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02526876889169216,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17967760562896729,
      "backward_entropy": 0.08466514348983764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.952023983001709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025355780497193336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17965110143025717,
      "backward_entropy": 0.09110753536224366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.811252117156982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025442561134696007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17962157726287842,
      "backward_entropy": 0.0904797911643982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.498721599578857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0255296528339386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17959221204121908,
      "backward_entropy": 0.08984159231185913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.170002460479736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02561611495912075,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17956697940826416,
      "backward_entropy": 0.08920298218727112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.966609477996826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025702549144625664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17953685919443765,
      "backward_entropy": 0.08856024742126464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.418623447418213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02578878588974476,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17950654029846191,
      "backward_entropy": 0.08052222728729248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.411122798919678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025874441489577293,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17947922150293985,
      "backward_entropy": 0.09628472328186036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.877499103546143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025959625840187073,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17945065100987753,
      "backward_entropy": 0.07912160158157348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.506154537200928,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026044700294733047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17942063013712564,
      "backward_entropy": 0.09507123231887818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.953999042510986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026130100712180138,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17938923835754395,
      "backward_entropy": 0.09445706605911255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4511919021606445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026214705780148506,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.179360032081604,
      "backward_entropy": 0.07700763344764709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9804253578186035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026298992335796356,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1793283224105835,
      "backward_entropy": 0.07630348205566406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.213202953338623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026382599025964737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17929983139038086,
      "backward_entropy": 0.08334768414497376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.750770568847656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02646573819220066,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17927497625350952,
      "backward_entropy": 0.08269214630126953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.759804725646973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026548903435468674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17924807469050089,
      "backward_entropy": 0.0820313572883606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.862155437469482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026632070541381836,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1792211333910624,
      "backward_entropy": 0.08136449456214905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.271987438201904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026715360581874847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17919119199117026,
      "backward_entropy": 0.08069195747375488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2283525466918945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02679838053882122,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17915687958399454,
      "backward_entropy": 0.08944617509841919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.336577415466309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026881083846092224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17912153402964273,
      "backward_entropy": 0.08880243301391602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.400637626647949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026963578537106514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17908507585525513,
      "backward_entropy": 0.08815556764602661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.752316474914551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02704519033432007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.179050346215566,
      "backward_entropy": 0.08750819563865661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.927976131439209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02712702378630638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17901299397150675,
      "backward_entropy": 0.07733609676361083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.184426784515381,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027208419516682625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1789767344792684,
      "backward_entropy": 0.08620457053184509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7262067794799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027289606630802155,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17894113063812256,
      "backward_entropy": 0.06780750155448914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.028949737548828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027370290830731392,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1789055864016215,
      "backward_entropy": 0.06710374355316162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.077064514160156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027450714260339737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17887153228123984,
      "backward_entropy": 0.07463732361793518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.626365661621094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02753102220594883,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1788339614868164,
      "backward_entropy": 0.06569652557373047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.034714221954346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027610810473561287,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1787983775138855,
      "backward_entropy": 0.07328503131866455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.724164009094238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027689656242728233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17876728375752768,
      "backward_entropy": 0.07261676192283631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1531267166137695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027768272906541824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17873344818751016,
      "backward_entropy": 0.08161275386810303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5722527503967285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02784697525203228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17869832118352255,
      "backward_entropy": 0.07127511501312256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756206035614014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027925333008170128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17866174379984537,
      "backward_entropy": 0.0706030011177063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.892356872558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028003506362438202,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17862441142400107,
      "backward_entropy": 0.06152412891387939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.270572185516357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028081638738512993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17858511209487915,
      "backward_entropy": 0.06925300359725953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.316784381866455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02815920114517212,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17854773998260498,
      "backward_entropy": 0.060150301456451415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8624067306518555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028236323967576027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1785100301106771,
      "backward_entropy": 0.06790927052497864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.445760250091553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028313498944044113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17846999565760294,
      "backward_entropy": 0.06723489761352539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.526480674743652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028390413150191307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17842753728230795,
      "backward_entropy": 0.06656193733215332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.28991174697876,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02846715971827507,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1783825159072876,
      "backward_entropy": 0.07562360763549805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.943413257598877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02854354865849018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17833640178044638,
      "backward_entropy": 0.06521660685539246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6476402282714844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028620164841413498,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17828710873921713,
      "backward_entropy": 0.05610615015029907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5165810585021973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028695860877633095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1782408356666565,
      "backward_entropy": 0.06387044191360473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.633354663848877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02877063862979412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17819658915201822,
      "backward_entropy": 0.07293687462806701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0539960861206055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028845570981502533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17814894517262778,
      "backward_entropy": 0.06254846453666688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5629007816314697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02892010472714901,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17810181776682535,
      "backward_entropy": 0.07160038352012635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.069097995758057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028993789106607437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17805971701939902,
      "backward_entropy": 0.06123182773590088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.431023359298706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02906721644103527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17801713943481445,
      "backward_entropy": 0.06057692170143127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9288153648376465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02913983166217804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1779773235321045,
      "backward_entropy": 0.059929704666137694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0468335151672363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02921222150325775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17793510357538858,
      "backward_entropy": 0.06897512674331666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.064582586288452,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029283544048666954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17789727449417114,
      "backward_entropy": 0.06832725405693055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6056573390960693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029354002326726913,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17786006132761636,
      "backward_entropy": 0.04967118501663208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4833946228027344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294241551309824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17782139778137207,
      "backward_entropy": 0.057404184341430665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6881868839263916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029493946582078934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17778082688649496,
      "backward_entropy": 0.06639082431793213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.084442138671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029563553631305695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17773914337158203,
      "backward_entropy": 0.05616735816001892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5808300971984863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02963346242904663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17769118150075278,
      "backward_entropy": 0.06510340571403503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.193918228149414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029703080654144287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17764268318812051,
      "backward_entropy": 0.06446176767349243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5817418098449707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029772084206342697,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17759486039479574,
      "backward_entropy": 0.06382391452789307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.376265287399292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02984100580215454,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17754238843917847,
      "backward_entropy": 0.06318420171737671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0883796215057373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029909642413258553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17748695611953735,
      "backward_entropy": 0.05308520197868347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9757251739501953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02997768484055996,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17743178208669028,
      "backward_entropy": 0.06190912127494812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.137061834335327,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03004510886967182,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17737642923990884,
      "backward_entropy": 0.043748697638511656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.527677059173584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0301121287047863,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17731992403666177,
      "backward_entropy": 0.0431892067193985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2834906578063965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030178174376487732,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17726564407348633,
      "backward_entropy": 0.06002282500267029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.35370135307312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030244123190641403,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1772083838780721,
      "backward_entropy": 0.04209359586238861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.199833631515503,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0303101297467947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1771460771560669,
      "backward_entropy": 0.05877653956413269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.047109365463257,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030376039445400238,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17707969745000204,
      "backward_entropy": 0.04101793766021729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.937471628189087,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030441589653491974,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17701297998428345,
      "backward_entropy": 0.05753449201583862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.287994146347046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030506731942296028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17694552739461264,
      "backward_entropy": 0.047844767570495605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3609139919281006,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03057076968252659,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17688224713007608,
      "backward_entropy": 0.05631582140922546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4690747261047363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03063395991921425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1768204172452291,
      "backward_entropy": 0.04673949778079987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5726215839385986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030697613954544067,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17675218979517618,
      "backward_entropy": 0.03842820525169373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.765503168106079,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030760621652007103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17668519417444864,
      "backward_entropy": 0.04563475549221039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.552598237991333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03082335740327835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17661577463150024,
      "backward_entropy": 0.053933078050613405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7567574977874756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030885567888617516,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17654617627461752,
      "backward_entropy": 0.05334781408309937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.370604991912842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030947580933570862,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1764738162358602,
      "backward_entropy": 0.03645473122596741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2561497688293457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031009074300527573,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1763995885848999,
      "backward_entropy": 0.052183645963668826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7817707061767578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031069787219166756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17632752656936646,
      "backward_entropy": 0.042959564924240114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0855515003204346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03112926334142685,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17626037200291952,
      "backward_entropy": 0.05104618072509766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4481894969940186,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031187962740659714,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17619518438975015,
      "backward_entropy": 0.050489777326583864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1888949871063232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031246429309248924,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1761279503504435,
      "backward_entropy": 0.03415010869503021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9970247745513916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130427747964859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17606226603190103,
      "backward_entropy": 0.040964603424072266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.168677568435669,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031361427158117294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17599761486053467,
      "backward_entropy": 0.048859035968780516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.060230016708374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03141811862587929,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1759328842163086,
      "backward_entropy": 0.039998230338096616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.146068572998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03147434815764427,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1758671005566915,
      "backward_entropy": 0.03240858316421509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5763734579086304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031530242413282394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17579964796702066,
      "backward_entropy": 0.039038974046707156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.185529947280884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031585074961185455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17573575178782144,
      "backward_entropy": 0.0467673271894455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.049429416656494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03163972869515419,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17566949129104614,
      "backward_entropy": 0.04625817239284515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.259993553161621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031694114208221436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17560080687204996,
      "backward_entropy": 0.04575232863426208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9202569723129272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174855187535286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17552749315897623,
      "backward_entropy": 0.03716999292373657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8401864767074585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03180260583758354,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.175452450911204,
      "backward_entropy": 0.029949852824211122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6358987092971802,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185609355568886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17537752787272134,
      "backward_entropy": 0.03624260127544403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4645729064941406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03190901130437851,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17530186971028647,
      "backward_entropy": 0.043761125206947325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3254204988479614,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03196103125810623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17522847652435303,
      "backward_entropy": 0.04327577352523804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9507243633270264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03201192989945412,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1751594344774882,
      "backward_entropy": 0.028418457508087157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.741005539894104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03206287696957588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17508564392725626,
      "backward_entropy": 0.034487184882164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4139747619628906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032113462686538696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17501036326090494,
      "backward_entropy": 0.03405850827693939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3809411525726318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03216322883963585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17493693033854166,
      "backward_entropy": 0.03363841772079468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5476839542388916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032212208956480026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17486470937728882,
      "backward_entropy": 0.03322659730911255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8569515943527222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03226080536842346,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1747908592224121,
      "backward_entropy": 0.0405021071434021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6851575374603271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0323096364736557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1747108300526937,
      "backward_entropy": 0.03240962028503418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3478878736495972,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03235833719372749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17462738355000815,
      "backward_entropy": 0.03200153112411499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5862505435943604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0324065126478672,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1745434602101644,
      "backward_entropy": 0.03916829824447632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5112043619155884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03245444595813751,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1744558016459147,
      "backward_entropy": 0.03873164653778076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4375187158584595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03250208497047424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17436601718266806,
      "backward_entropy": 0.030809879302978516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1672908067703247,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03254937380552292,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1742744247118632,
      "backward_entropy": 0.02464729845523834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1179426908493042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03259572759270668,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17418531576792398,
      "backward_entropy": 0.024334943294525145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2211288213729858,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03264111652970314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17409880956013998,
      "backward_entropy": 0.03704621195793152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9915143847465515,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032685935497283936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17401206493377686,
      "backward_entropy": 0.036645108461380006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3375626802444458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03272979333996773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17392800251642862,
      "backward_entropy": 0.03625281751155853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1311346292495728,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032773457467556,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17384092013041177,
      "backward_entropy": 0.023148371279239653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.949267566204071,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0328165665268898,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17375353972117105,
      "backward_entropy": 0.022864702343940734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9238758087158203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03285885974764824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17366800705591837,
      "backward_entropy": 0.02790987491607666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0959380865097046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0329003669321537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17358416318893433,
      "backward_entropy": 0.027580419182777406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9874656796455383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032941464334726334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17349904775619507,
      "backward_entropy": 0.027254778146743774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9615284204483032,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032982032746076584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17341367403666177,
      "backward_entropy": 0.02693496346473694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8895148038864136,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03302207589149475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17332800229390463,
      "backward_entropy": 0.0336625874042511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8363379836082458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03306150436401367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17324280738830566,
      "backward_entropy": 0.026313284039497377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9938435554504395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03310020640492439,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17315868536631265,
      "backward_entropy": 0.03297420144081116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0125285387039185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03313854709267616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17307247718175253,
      "backward_entropy": 0.03263888359069824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9430927038192749,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03317660093307495,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17298370599746704,
      "backward_entropy": 0.02056506872177124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.637639045715332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0332142598927021,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17289328575134277,
      "backward_entropy": 0.02033081352710724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8234897255897522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033250875771045685,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17280622323354086,
      "backward_entropy": 0.024832433462142943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6666933298110962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03328702971339226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17271836598714194,
      "backward_entropy": 0.024551324546337128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.504358172416687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03332240507006645,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17263227701187134,
      "backward_entropy": 0.031050747632980345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7644267082214355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03335665538907051,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17255043983459473,
      "backward_entropy": 0.030754953622817993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7004541754722595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033390436321496964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17246703306833902,
      "backward_entropy": 0.030465060472488405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6874484419822693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033423762768507004,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17238306999206543,
      "backward_entropy": 0.019049347937107088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6155813932418823,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03345653414726257,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17229831218719482,
      "backward_entropy": 0.029900017380714416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.727514922618866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033488720655441284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17221399148305258,
      "backward_entropy": 0.02300715297460556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7245025634765625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03352070227265358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17212748527526855,
      "backward_entropy": 0.02276432514190674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7934148907661438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033552415668964386,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17203847567240396,
      "backward_entropy": 0.018274779617786407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7125054001808167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03358412906527519,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17194541295369467,
      "backward_entropy": 0.02228216528892517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35748904943466187,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03361569344997406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17185000578562418,
      "backward_entropy": 0.02855658531188965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6981471180915833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03364609554409981,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17175974448521933,
      "backward_entropy": 0.017722034454345705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.559006929397583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033676568418741226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17166666189829508,
      "backward_entropy": 0.02804597020149231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.441662073135376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03370647132396698,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17157300313313803,
      "backward_entropy": 0.027796480059623718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4668354392051697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03373551368713379,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1714810530344645,
      "backward_entropy": 0.027554482221603394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5715429186820984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03376388177275658,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17138981819152832,
      "backward_entropy": 0.020937816798686983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46713608503341675,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033792078495025635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17129677534103394,
      "backward_entropy": 0.02708460986614227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5142298340797424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03381984308362007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17120444774627686,
      "backward_entropy": 0.02685420513153076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4900493025779724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03384717181324959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17111031214396158,
      "backward_entropy": 0.020325484871864318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40922990441322327,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03387416526675224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17101534207661948,
      "backward_entropy": 0.026406437158584595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3918158710002899,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03390054032206535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17092108726501465,
      "backward_entropy": 0.026189613342285156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5018802881240845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033926259726285934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1708274483680725,
      "backward_entropy": 0.01974923461675644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29806503653526306,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033951833844184875,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17073140541712442,
      "backward_entropy": 0.01599944829940796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36387163400650024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033976368606090546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1706372300783793,
      "backward_entropy": 0.019386179745197296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40293416380882263,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034000374376773834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17054355144500732,
      "backward_entropy": 0.01921324133872986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4286964535713196,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03402401879429817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17044878005981445,
      "backward_entropy": 0.025182089209556578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40040040016174316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03404754772782326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17035253842671713,
      "backward_entropy": 0.02499159425497055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.350754976272583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034070707857608795,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17025446891784668,
      "backward_entropy": 0.015368016064167022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3442085385322571,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0340934582054615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17015647888183594,
      "backward_entropy": 0.015249606966972352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35620832443237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03411586210131645,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17005866765975952,
      "backward_entropy": 0.015133775770664215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3332802653312683,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034137990325689316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16996026039123535,
      "backward_entropy": 0.02426462769508362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2217695564031601,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03415961191058159,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1698606014251709,
      "backward_entropy": 0.018072766065597535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37030479311943054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034180428832769394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16976376374562582,
      "backward_entropy": 0.017925438284873963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25153112411499023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03420122712850571,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16966487963994345,
      "backward_entropy": 0.01470016986131668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2811621129512787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03422143682837486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16956738630930582,
      "backward_entropy": 0.02359870970249176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3694256842136383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03424118086695671,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1694693366686503,
      "backward_entropy": 0.02344180941581726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2510544955730438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0342608317732811,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1693671147028605,
      "backward_entropy": 0.023286917805671693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2582903206348419,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034280043095350266,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16926594575246176,
      "backward_entropy": 0.01722243130207062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27244022488594055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034298788756132126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16916443904240927,
      "backward_entropy": 0.017090457677841186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1711847484111786,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0343172661960125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1690624157587687,
      "backward_entropy": 0.02284315079450607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18781577050685883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034334901720285416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16896257797876993,
      "backward_entropy": 0.016837085783481597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31839719414711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034351982176303864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16886470715204874,
      "backward_entropy": 0.02257009446620941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3283047378063202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034369200468063354,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16876335938771567,
      "backward_entropy": 0.016597682237625123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.251275897026062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034386683255434036,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16865867376327515,
      "backward_entropy": 0.01647512912750244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13319726288318634,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03440389037132263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16855271657307944,
      "backward_entropy": 0.016354528069496155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25572651624679565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034420181065797806,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16844973961512247,
      "backward_entropy": 0.016240859031677247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2188512533903122,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03443652763962746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16834580898284912,
      "backward_entropy": 0.021914127469062804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1096406802535057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03445275500416756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1682424545288086,
      "backward_entropy": 0.01601429730653763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23280537128448486,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03446817398071289,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16814343134562174,
      "backward_entropy": 0.02166924923658371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1304168850183487,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034483496099710464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16804218292236328,
      "backward_entropy": 0.021550969779491426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18030701577663422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0344981849193573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16794357697168985,
      "backward_entropy": 0.015701235830783845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24128659069538116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03451259434223175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16784483194351196,
      "backward_entropy": 0.015602229535579682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1961444914340973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03452729806303978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1677442193031311,
      "backward_entropy": 0.021212996542453767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21495698392391205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03454203903675079,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16764398415883383,
      "backward_entropy": 0.01540015935897827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17249181866645813,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03455668315291405,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16754100720087686,
      "backward_entropy": 0.01302429437637329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19113387167453766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03457110747694969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16743830839792886,
      "backward_entropy": 0.02087937146425247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17418114840984344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03458534553647041,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16733376185099283,
      "backward_entropy": 0.020771773159503938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13614244759082794,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03459932655096054,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16722822189331055,
      "backward_entropy": 0.012833447754383087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14139221608638763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03461281210184097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1671234369277954,
      "backward_entropy": 0.014913833141326905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1685742884874344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0346260704100132,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16702020168304443,
      "backward_entropy": 0.02046508193016052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16399423778057098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03463928773999214,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16691641012827554,
      "backward_entropy": 0.012657934427261352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1969243586063385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03465239703655243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16681170463562012,
      "backward_entropy": 0.01464279443025589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09824948757886887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03466576710343361,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1667048136393229,
      "backward_entropy": 0.014551234245300294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1414521187543869,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03467846289277077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16660003860791525,
      "backward_entropy": 0.02007436454296112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15545019507408142,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03469087928533554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16649436950683594,
      "backward_entropy": 0.014379452168941497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05959341675043106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03470313921570778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1663865645726522,
      "backward_entropy": 0.014295241236686707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11224351823329926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03471427783370018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1662809650103251,
      "backward_entropy": 0.019808894395828246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12124603241682053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03472510352730751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1661758522192637,
      "backward_entropy": 0.014143982529640197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0754239484667778,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03473595529794693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16607214013735452,
      "backward_entropy": 0.01964801549911499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1198178306221962,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034746166318655014,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16597041487693787,
      "backward_entropy": 0.012203036993741988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12324370443820953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03475617617368698,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16586720943450928,
      "backward_entropy": 0.019497807323932647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10283487290143967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03476608172059059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16576250394185385,
      "backward_entropy": 0.013861836493015289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09468300640583038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03477584198117256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16565857330958048,
      "backward_entropy": 0.01379435509443283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09591788053512573,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03478531539440155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16555508971214294,
      "backward_entropy": 0.013728746771812439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13638368248939514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03479468449950218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16545278827349344,
      "backward_entropy": 0.01366398185491562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0902693122625351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03480420261621475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16534709930419922,
      "backward_entropy": 0.013597869873046875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09397987276315689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03481357917189598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16524283091227213,
      "backward_entropy": 0.013532915711402893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09452344477176666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03482286259531975,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16513927777608237,
      "backward_entropy": 0.013468649983406068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07503724843263626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034831929951906204,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650350590546926,
      "backward_entropy": 0.01894157975912094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09032024443149567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03484082221984863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16493324438730875,
      "backward_entropy": 0.013344126939773559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07852105051279068,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03484946861863136,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16483020782470703,
      "backward_entropy": 0.01881401240825653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05641862004995346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03485792875289917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16472800572713217,
      "backward_entropy": 0.013225102424621582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06265180557966232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03486591950058937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1646279295285543,
      "backward_entropy": 0.013169345259666444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0831214189529419,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03487345948815346,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16452831029891968,
      "backward_entropy": 0.018639186024665834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0722651332616806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034880753606557846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16442647576332092,
      "backward_entropy": 0.013064773380756378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06654941290616989,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03488786146044731,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1643241544564565,
      "backward_entropy": 0.013014167547225952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061166517436504364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034894708544015884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16422114769617716,
      "backward_entropy": 0.01848369538784027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06757906079292297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034901220351457596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16411797205607095,
      "backward_entropy": 0.012918278574943542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051128022372722626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034907739609479904,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16401551167170206,
      "backward_entropy": 0.011569592356681823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04012087360024452,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03491395339369774,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16391448179880777,
      "backward_entropy": 0.011547309160232545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061267025768756866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03491963446140289,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1638149917125702,
      "backward_entropy": 0.012784963846206665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0453437864780426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03492521867156029,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16371527314186096,
      "backward_entropy": 0.012743958830833435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06281282007694244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03493044897913933,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1636164387067159,
      "backward_entropy": 0.011491791903972625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06554023176431656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03493580222129822,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16351763407389322,
      "backward_entropy": 0.011473701894283294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.057242996990680695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03494112566113472,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16341725985209146,
      "backward_entropy": 0.018141347169876098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05416245386004448,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034946292638778687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16331595182418823,
      "backward_entropy": 0.0181031659245491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04022681713104248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03495119884610176,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16321351130803427,
      "backward_entropy": 0.01806671917438507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03875797614455223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03495591878890991,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16311333576838175,
      "backward_entropy": 0.018031594157218934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05278407782316208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03496033325791359,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16301443179448447,
      "backward_entropy": 0.012480200827121734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04273426532745361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034964751452207565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16291518012682596,
      "backward_entropy": 0.012446129322052002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044513680040836334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03496912866830826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16281686226526895,
      "backward_entropy": 0.017932984232902526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04619591310620308,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0349733792245388,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16271779934565225,
      "backward_entropy": 0.011354852467775345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04638822004199028,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03497742861509323,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16261721650759378,
      "backward_entropy": 0.017870883643627166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03916456922888756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034981515258550644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16251655419667563,
      "backward_entropy": 0.012315477430820464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0400758720934391,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03498553857207298,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16241701443990073,
      "backward_entropy": 0.01131870448589325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03509403020143509,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03498956561088562,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1623185078303019,
      "backward_entropy": 0.012252356112003326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044178884476423264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034993454813957214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16222103436787924,
      "backward_entropy": 0.017751435935497283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04473916068673134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03499740734696388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16212318340937296,
      "backward_entropy": 0.017722126841545106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027916204184293747,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0350014753639698,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16202507416407266,
      "backward_entropy": 0.01126856803894043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03212762251496315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035005275160074234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16192859411239624,
      "backward_entropy": 0.01212901622056961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04333361238241196,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035008907318115234,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16183284918467203,
      "backward_entropy": 0.017636939883232117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035922687500715256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03501259163022041,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16173560420672098,
      "backward_entropy": 0.017609605193138124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020323673263192177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035016387701034546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1616395910580953,
      "backward_entropy": 0.012040778994560242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03896549344062805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03501973673701286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1615453859170278,
      "backward_entropy": 0.012013665586709976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02996017597615719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03502316400408745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1614502271016439,
      "backward_entropy": 0.017531144618988036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025622403249144554,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03502647951245308,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1613555351893107,
      "backward_entropy": 0.011191270500421523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026918333023786545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035029586404561996,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1612618366877238,
      "backward_entropy": 0.017483118176460265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028764689341187477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035032644867897034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1611694892247518,
      "backward_entropy": 0.011908118426799775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036171384155750275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03503577411174774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16107829411824545,
      "backward_entropy": 0.011882537603378296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024628523737192154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035039085894823074,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16098624467849731,
      "backward_entropy": 0.017412492632865907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031668975949287415,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03504231572151184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16089552640914917,
      "backward_entropy": 0.017388662695884703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023202721029520035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03504548966884613,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16080335776011148,
      "backward_entropy": 0.011803802847862244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01968512125313282,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03504848852753639,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16071192423502603,
      "backward_entropy": 0.011123757809400558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019055427983403206,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03505132719874382,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.160622368256251,
      "backward_entropy": 0.011115478724241257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024392450228333473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03505410999059677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16053539514541626,
      "backward_entropy": 0.01730102300643921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021085558459162712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03505672514438629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16044666369756064,
      "backward_entropy": 0.01170991063117981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02481304295361042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035059187561273575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16035719712575278,
      "backward_entropy": 0.017262743413448335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025485368445515633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0350617878139019,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16026786963144937,
      "backward_entropy": 0.011666464805603027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019632548093795776,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035064540803432465,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16017844279607138,
      "backward_entropy": 0.017222853004932405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02388904057443142,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03506718575954437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600895325342814,
      "backward_entropy": 0.017203164100646973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01325208880007267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035069964826107025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16000076134999594,
      "backward_entropy": 0.011598172038793564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019511882215738297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03507241606712341,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15991340080897012,
      "backward_entropy": 0.017164289951324463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01725260727107525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03507479652762413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15982596079508463,
      "backward_entropy": 0.011556608229875564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012325741350650787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03507709503173828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15973923603693643,
      "backward_entropy": 0.011536596715450287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013866395689547062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03507933393120766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1596557597319285,
      "backward_entropy": 0.01711231768131256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020074965432286263,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03508151322603226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15957419077555338,
      "backward_entropy": 0.011498253792524338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020190050825476646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035083819180727005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15949233373006186,
      "backward_entropy": 0.01147855818271637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01332179270684719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03508612886071205,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15940898656845093,
      "backward_entropy": 0.01101214364171028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018502486869692802,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03508825972676277,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15932647387186685,
      "backward_entropy": 0.011005959659814834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01309587899595499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03509056195616722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15924437840779623,
      "backward_entropy": 0.01142043098807335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013573155738413334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03509272634983063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15916313727696738,
      "backward_entropy": 0.01140168085694313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01521255262196064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035094860941171646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15908302863438925,
      "backward_entropy": 0.011383150517940522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013526818715035915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03509707748889923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1590037147204081,
      "backward_entropy": 0.011364223808050156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008657361380755901,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035099346190690994,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15892579158147177,
      "backward_entropy": 0.010970034450292588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01184250507503748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03510133549571037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15884930888811746,
      "backward_entropy": 0.011327736824750901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015608877874910831,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03510329872369766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15877379973729452,
      "backward_entropy": 0.01693398654460907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010794964618980885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03510541841387749,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15869808197021484,
      "backward_entropy": 0.01691837012767792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01529510598629713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035107504576444626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1586237152417501,
      "backward_entropy": 0.011274793744087219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010331913828849792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035109683871269226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15854831536610922,
      "backward_entropy": 0.011256406456232071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008309238590300083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035111743956804276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15847358107566833,
      "backward_entropy": 0.011238807439804077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01000293530523777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03511377051472664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15840144952138266,
      "backward_entropy": 0.011221590638160705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008801371790468693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03511577844619751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15833034118016562,
      "backward_entropy": 0.011204540729522705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007890003733336926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03511775657534599,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15826077262560526,
      "backward_entropy": 0.011187795549631119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010981566272675991,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0351196750998497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15819295247395834,
      "backward_entropy": 0.016813942790031434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010034543462097645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035121578723192215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15812436739603677,
      "backward_entropy": 0.01680004894733429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0071372683160007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035123441368341446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15805542469024658,
      "backward_entropy": 0.01113925501704216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007782947737723589,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03512519225478172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1579878330230713,
      "backward_entropy": 0.016773435473442077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007633563596755266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03512684255838394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15792073806126913,
      "backward_entropy": 0.011109353601932525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008615327998995781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03512844443321228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1578544278939565,
      "backward_entropy": 0.011095087975263596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006235603243112564,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03513007238507271,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15778844555219015,
      "backward_entropy": 0.016737200319767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005956771317869425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03513169288635254,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15772451957066855,
      "backward_entropy": 0.011066456139087678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005907176528126001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03513321653008461,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15766181548436484,
      "backward_entropy": 0.01085318922996521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00815644208341837,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03513463959097862,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1575999657313029,
      "backward_entropy": 0.016703489422798156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006716573145240545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03513609617948532,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1575376788775126,
      "backward_entropy": 0.01669267416000366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0058530778624117374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0351376011967659,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1574764053026835,
      "backward_entropy": 0.011013485491275787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0053829895332455635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03513909876346588,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15741636355717978,
      "backward_entropy": 0.010833059251308442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006397890392690897,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03514047712087631,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15735676884651184,
      "backward_entropy": 0.010828414559364319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006081976927816868,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035141874104738235,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15729751189549765,
      "backward_entropy": 0.010823571681976318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006049451883882284,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03514324873685837,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15723837415377298,
      "backward_entropy": 0.01663980484008789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005816198885440826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0351446308195591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15717947483062744,
      "backward_entropy": 0.01095041111111641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003987881820648909,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03514601290225983,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15712085366249084,
      "backward_entropy": 0.010809321701526643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004569421987980604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03514730930328369,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15706376234690347,
      "backward_entropy": 0.010926209390163422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0053320699371397495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03514851629734039,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15700711806615195,
      "backward_entropy": 0.010914974659681321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035477918572723866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03514975681900978,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1569507916768392,
      "backward_entropy": 0.010903582721948624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036564073525369167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0351509228348732,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15689597527186075,
      "backward_entropy": 0.010793045908212662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004787561483681202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03515196964144707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.156841774781545,
      "backward_entropy": 0.010882611572742461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003943379502743483,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035153087228536606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15678811073303223,
      "backward_entropy": 0.016566072404384614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003255315590649843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035154178738594055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1567351520061493,
      "backward_entropy": 0.01086183488368988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003520221682265401,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035155221819877625,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1566834350426992,
      "backward_entropy": 0.01077941656112671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032938458025455475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035156283527612686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15663292010625204,
      "backward_entropy": 0.016542074084281922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026942479889839888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035157304257154465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15658318996429443,
      "backward_entropy": 0.010832339525222778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036117422860115767,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03515826165676117,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1565346916516622,
      "backward_entropy": 0.016527265310287476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025618195068091154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03515923023223877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1564864714940389,
      "backward_entropy": 0.01651999056339264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003509265836328268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035160135477781296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15643927454948425,
      "backward_entropy": 0.01080510914325714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002162578050047159,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03516106680035591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15639221668243408,
      "backward_entropy": 0.010796190798282623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031674106139689684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03516189754009247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15634618202845255,
      "backward_entropy": 0.0107574924826622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026713486295193434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035162705928087234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15629995862642923,
      "backward_entropy": 0.01077980101108551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002187137259170413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03516347333788872,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1562541127204895,
      "backward_entropy": 0.016487748920917512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020120921544730663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03516421094536781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15620940923690796,
      "backward_entropy": 0.010764312744140626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023264868650585413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03516490384936333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15616577863693237,
      "backward_entropy": 0.010757049173116684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022847780492156744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03516561910510063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15612304210662842,
      "backward_entropy": 0.010749711096286774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018009674968197942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03516634926199913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15608108043670654,
      "backward_entropy": 0.0107423335313797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021081860177218914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03516708314418793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15604050954182944,
      "backward_entropy": 0.010735032707452774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018651337595656514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03516782447695732,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15600057442982992,
      "backward_entropy": 0.010739968717098236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001955925254151225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035168565809726715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15596153338750204,
      "backward_entropy": 0.01644916981458664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001866257400251925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03516928851604462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15592285990715027,
      "backward_entropy": 0.010713388025760651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002045298460870981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035170018672943115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15588479240735373,
      "backward_entropy": 0.010706278681755065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015674158930778503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035170745104551315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15584673484166464,
      "backward_entropy": 0.010699209570884705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018355041975155473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035171426832675934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.155809223651886,
      "backward_entropy": 0.010692459344863892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001644688774831593,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03517213463783264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1557721495628357,
      "backward_entropy": 0.01642247140407562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001738875056616962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03517283499240875,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15573553244272867,
      "backward_entropy": 0.01067880317568779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012734073679894209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03517356887459755,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15569939215977988,
      "backward_entropy": 0.010719884186983109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016793907852843404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03517429903149605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15566440423329672,
      "backward_entropy": 0.016406303644180296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012778707314282656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03517504781484604,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15562951564788818,
      "backward_entropy": 0.010714198648929595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013823884073644876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03517577052116394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1555953025817871,
      "backward_entropy": 0.010651279985904694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008393843891099095,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035176508128643036,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15556167562802634,
      "backward_entropy": 0.016389958560466766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010140156373381615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03517715260386467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15552894274393717,
      "backward_entropy": 0.010638327151536942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001099281245842576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03517775610089302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15549693504969278,
      "backward_entropy": 0.010632441937923431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010844293283298612,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035178374499082565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1554657220840454,
      "backward_entropy": 0.016376157104969025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010695962700992823,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03517898544669151,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1554349660873413,
      "backward_entropy": 0.016371677815914153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009810631163418293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035179562866687775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15540438890457153,
      "backward_entropy": 0.010615051537752152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006510475068353117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035180117934942245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15537420908610025,
      "backward_entropy": 0.010609558969736099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008210348896682262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03518059849739075,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15534486373265585,
      "backward_entropy": 0.010693538933992386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007577469805255532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518107533454895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15531624356905618,
      "backward_entropy": 0.010599689185619354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007514155586250126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518153727054596,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15528833866119385,
      "backward_entropy": 0.010594920814037323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007473917794413865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03518196567893028,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15526082118352255,
      "backward_entropy": 0.016349327564239503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006978668970987201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0351824052631855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1552339792251587,
      "backward_entropy": 0.010585825145244598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008187441271729767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518282622098923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15520764390627542,
      "backward_entropy": 0.010581395030021668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006101195467635989,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518327325582504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15518162647883096,
      "backward_entropy": 0.010576874017715454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000612048024777323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035183705389499664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15515623490015665,
      "backward_entropy": 0.010572440922260284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005514979129657149,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035184118896722794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15513132015864053,
      "backward_entropy": 0.0105681911110878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006661090301349759,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035184506326913834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1551069219907125,
      "backward_entropy": 0.01056411862373352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005621061427518725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518490865826607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1550828218460083,
      "backward_entropy": 0.01055997759103775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006027186173014343,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0351853109896183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15505926807721457,
      "backward_entropy": 0.016324572265148163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005303098587319255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035185717046260834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15503594279289246,
      "backward_entropy": 0.010551768541336059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003761171246878803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035186104476451874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15501290559768677,
      "backward_entropy": 0.010547807812690735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000547430943697691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518643230199814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15499037504196167,
      "backward_entropy": 0.010544206947088242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003052286629099399,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518678620457649,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1549681822458903,
      "backward_entropy": 0.010540498048067093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005240208702161908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518711403012276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15494693319002786,
      "backward_entropy": 0.010536997020244599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005093874060548842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03518746793270111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15492590268452963,
      "backward_entropy": 0.010533341765403747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003096817818004638,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035187844187021255,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15490506092707315,
      "backward_entropy": 0.016305753588676454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004844568611588329,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035188183188438416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15488479534784952,
      "backward_entropy": 0.01630324125289917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034495166619308293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035188548266887665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15486464897791544,
      "backward_entropy": 0.01630055606365204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035178670077584684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03518890216946602,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15484495957692465,
      "backward_entropy": 0.010663918405771255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034604620304889977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03518924117088318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15482556819915771,
      "backward_entropy": 0.016295464336872102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003576366580091417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03518956899642944,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1548064649105072,
      "backward_entropy": 0.010661397129297256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003490603412501514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035189881920814514,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1547874410947164,
      "backward_entropy": 0.010660278052091599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034104890073649585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03519020602107048,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.154768705368042,
      "backward_entropy": 0.010659044981002808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033617758890613914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519054502248764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1547502875328064,
      "backward_entropy": 0.010502345860004425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023459580552298576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035190895199775696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15473203857739767,
      "backward_entropy": 0.010498955845832825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023773321299813688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035191234201192856,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1547144055366516,
      "backward_entropy": 0.010495679080486297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025519338669255376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519154712557793,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1546971003214518,
      "backward_entropy": 0.010492578148841858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018258110503666103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519187122583389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1546802520751953,
      "backward_entropy": 0.01627577990293503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021825321891810745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519216552376747,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15466390053431192,
      "backward_entropy": 0.010486502945423127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019444929785095155,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519245609641075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15464794635772705,
      "backward_entropy": 0.016271476447582246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015794436330907047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519272059202194,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15463221073150635,
      "backward_entropy": 0.01626953184604645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020969539764337242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035192959010601044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15461697181065878,
      "backward_entropy": 0.010478389263153077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015608900866936892,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035193197429180145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15460191170374551,
      "backward_entropy": 0.01626596450805664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001936822955030948,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035193417221307755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15458720922470093,
      "backward_entropy": 0.010473497211933136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017635575204622,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035193637013435364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1545726458231608,
      "backward_entropy": 0.016262681782245637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001272048830287531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035193853080272675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1545582910378774,
      "backward_entropy": 0.010468824952840804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013605810818262398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035194046795368195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15454435348510742,
      "backward_entropy": 0.01625957041978836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012946622155141085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035194240510463715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15453081329663595,
      "backward_entropy": 0.010464516282081605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001358264998998493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035194430500268936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15451767047246298,
      "backward_entropy": 0.01046241819858551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010767774801934138,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035194627940654755,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15450486540794373,
      "backward_entropy": 0.010642289370298385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010252425272483379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519481047987938,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15449238816897073,
      "backward_entropy": 0.010458331555128098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014617883425671607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03519497811794281,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1544802486896515,
      "backward_entropy": 0.010641027987003327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28766351332888e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035195160657167435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15446817874908447,
      "backward_entropy": 0.01625140756368637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.578199387760833e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035195328295230865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15445653597513834,
      "backward_entropy": 0.016250193119049072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011155800893902779,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0351954884827137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1544451912244161,
      "backward_entropy": 0.016249041259288787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.676133438711986e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035195644944906235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15443390607833862,
      "backward_entropy": 0.010449115931987763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.685578697826713e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03519579768180847,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15442293882369995,
      "backward_entropy": 0.010638050734996796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.445266237482429e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519595414400101,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15441217025121054,
      "backward_entropy": 0.010445669293403625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.452540739905089e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519609943032265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15440169970194498,
      "backward_entropy": 0.010444045811891556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.738222145941108e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519623726606369,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15439148743947348,
      "backward_entropy": 0.010442465543746948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.89869630150497e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519636392593384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1543815235296885,
      "backward_entropy": 0.010440974682569503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.094542550272308e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035196494311094284,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15437185764312744,
      "backward_entropy": 0.016241709887981414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.606126746395603e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03519661724567413,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15436244010925293,
      "backward_entropy": 0.010635095834732055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.785876030335203e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519674390554428,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15435314178466797,
      "backward_entropy": 0.016239918768405914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.990139809204265e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519687429070473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1543440024058024,
      "backward_entropy": 0.016238963603973387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.60366063634865e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519700840115547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1543349822362264,
      "backward_entropy": 0.010433722287416458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.352543666958809e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519713133573532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15432623028755188,
      "backward_entropy": 0.01043236330151558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7452205510344356e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035197243094444275,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15431761741638184,
      "backward_entropy": 0.010632757097482681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3981119233649224e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519735857844353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15430917342503866,
      "backward_entropy": 0.016235432028770445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.33942477684468e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035197462886571884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15430088837941489,
      "backward_entropy": 0.016234660148620607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.990368688595481e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519756346940994,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15429283181826273,
      "backward_entropy": 0.016233912110328673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.569683369481936e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0351976715028286,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15428491433461508,
      "backward_entropy": 0.01042611375451088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3610347600188106e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519777953624725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1542771259943644,
      "backward_entropy": 0.010424904525279999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.579071562853642e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519788011908531,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1542695959409078,
      "backward_entropy": 0.01623159199953079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.459446816123091e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519798070192337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15426228443781534,
      "backward_entropy": 0.010422623157501221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9906377676525153e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03519807010889053,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15425509214401245,
      "backward_entropy": 0.010629811882972717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7671312636812218e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0351981595158577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15424815813700357,
      "backward_entropy": 0.016229569911956787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.755640343821142e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035198237746953964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15424136320749918,
      "backward_entropy": 0.010419550538063049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7369676899979822e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035198308527469635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15423476696014404,
      "backward_entropy": 0.010418619215488433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.740600575634744e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519837185740471,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15422827005386353,
      "backward_entropy": 0.01041777729988098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2088326659286395e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519843518733978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1542219122250875,
      "backward_entropy": 0.016227562725543977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.801751204766333e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519849479198456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15421577294667563,
      "backward_entropy": 0.010416100174188614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4185968868550844e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519854322075844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15420985221862793,
      "backward_entropy": 0.01622675210237503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1220143025857396e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519859164953232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1542040010293325,
      "backward_entropy": 0.010414637625217438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.011997094086837e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0351986326277256,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15419826904932657,
      "backward_entropy": 0.010628189146518707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0481738829403184e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035198669880628586,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15419262647628784,
      "backward_entropy": 0.010628163814544678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.818737837311346e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519871085882187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15418712298075357,
      "backward_entropy": 0.010412677377462386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8329068552702665e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519875556230545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15418177843093872,
      "backward_entropy": 0.010412013530731202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7539961845614016e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035198796540498734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1541765034198761,
      "backward_entropy": 0.010411377996206284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3193522136134561e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035198841243982315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15417137742042542,
      "backward_entropy": 0.010410766303539275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.442896063963417e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0351988784968853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15416638056437174,
      "backward_entropy": 0.010627798736095428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.892825801216532e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519891947507858,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15416155258814493,
      "backward_entropy": 0.010409574955701828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2130053619330283e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519894927740097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15415692329406738,
      "backward_entropy": 0.010409042239189148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1219975021958817e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519897907972336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1541524132092794,
      "backward_entropy": 0.010408508032560349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2640571185329463e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03519900515675545,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15414798259735107,
      "backward_entropy": 0.010627620667219163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1207516763533931e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035199034959077835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15414369106292725,
      "backward_entropy": 0.01622316688299179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1167103366460651e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519906476140022,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15413951873779297,
      "backward_entropy": 0.010407069325447082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1290490874671377e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519909828901291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1541354457537333,
      "backward_entropy": 0.01040654331445694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.784826033865102e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035199131816625595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15413143237431845,
      "backward_entropy": 0.010406052321195602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225470992329065e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519916534423828,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15412751833597818,
      "backward_entropy": 0.01622220277786255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.68953213992063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519919887185097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15412373344103494,
      "backward_entropy": 0.010405078530311584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.74987052459619e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519922494888306,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15412002801895142,
      "backward_entropy": 0.010404639691114426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.035362952796277e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519924730062485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15411648154258728,
      "backward_entropy": 0.010404232889413834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.960263362998376e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519927337765694,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15411301453908285,
      "backward_entropy": 0.016221445798873902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.575762083433801e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519929572939873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15410963694254556,
      "backward_entropy": 0.010403435677289963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.004467079241294e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519932180643082,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15410631895065308,
      "backward_entropy": 0.010403028130531311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.928828613832593e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035199347883462906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15410309036572775,
      "backward_entropy": 0.010402636975049973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.062911663524574e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035199373960494995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15409996112187704,
      "backward_entropy": 0.010402242839336395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.526392785919597e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519940376281738,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15409688154856363,
      "backward_entropy": 0.010401828587055207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.751805474574212e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519942983984947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15409388144810995,
      "backward_entropy": 0.01040145754814148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4059760259406175e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519945964217186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15409099062283835,
      "backward_entropy": 0.016220112144947053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.792815500171855e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519948944449425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15408815940221152,
      "backward_entropy": 0.016219884157180786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5591654068412026e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035199519246816635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15408535798390707,
      "backward_entropy": 0.016219663619995116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.666759195970371e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519954904913902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15408267577489218,
      "backward_entropy": 0.010399921238422394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.609315849142149e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519957885146141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15408005317052206,
      "backward_entropy": 0.016219261288642883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.434827587829204e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0351996123790741,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15407746036847433,
      "backward_entropy": 0.010399160534143448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4597740068420535e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519964590668678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15407492717107138,
      "backward_entropy": 0.01039876788854599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.685899400807102e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519967943429947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15407246351242065,
      "backward_entropy": 0.010398399829864503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1374561331176665e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035199712961912155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1540700594584147,
      "backward_entropy": 0.01621829569339752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1656454666517675e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519974648952484,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1540677547454834,
      "backward_entropy": 0.016218049824237822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6524669465288753e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519977629184723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1540654997030894,
      "backward_entropy": 0.010397301614284515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.515478854547837e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03519980609416962,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15406332413355509,
      "backward_entropy": 0.016217614710330962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9169884783186717e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035199832171201706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1540611982345581,
      "backward_entropy": 0.01621742844581604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.25227813643869e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035199858248233795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15405911207199097,
      "backward_entropy": 0.010396314412355423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4887970084819244e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035199884325265884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15405710538228354,
      "backward_entropy": 0.016217026114463805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2692286165693076e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.035199910402297974,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15405515829722086,
      "backward_entropy": 0.010624802857637405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0186482743156375e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03519993647933006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1540532410144806,
      "backward_entropy": 0.01039542183279991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2837045889900764e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.035199958831071854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15405136346817017,
      "backward_entropy": 0.010395141690969468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1196622128627496e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035199981182813644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15404953559239706,
      "backward_entropy": 0.01621633917093277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.880075274129922e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.035200007259845734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1540477474530538,
      "backward_entropy": 0.016216157376766203,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 6.541227734828681e-05,
    "avg_log_Z": 0.03519717082381248,
    "success_rate": 1.0,
    "avg_reward": 45.1,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.14,
      "1": 0.33,
      "2": 0.53
    },
    "avg_forward_entropy": 0.15429174780845642,
    "avg_backward_entropy": 0.012373320542275907,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}