{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07683323489295112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07694898711310492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869379997253418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981312990188599,
      "backward_entropy": 0.07693625821007623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.108509063720703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981354713439942,
      "backward_entropy": 0.07682511541578504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753312110900879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0002000302920350805,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981330871582032,
      "backward_entropy": 0.07693729135725233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.100787162780762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00029999628895893693,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098130226135254,
      "backward_entropy": 0.07691933711369832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.018248558044434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004000141052529216,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981247425079346,
      "backward_entropy": 0.07691333029005262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.307707786560059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000499785179272294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098126769065857,
      "backward_entropy": 0.07679082949956258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.846698760986328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005997519474476576,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981260538101197,
      "backward_entropy": 0.07690081331464979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.298611640930176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006997210439294577,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981240272521972,
      "backward_entropy": 0.07690352201461792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839140892028809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007998274522833526,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981199741363526,
      "backward_entropy": 0.07689577341079712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.789785385131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00089989323168993,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981147289276123,
      "backward_entropy": 0.07688768704732259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621345520019531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009995833970606327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981128215789795,
      "backward_entropy": 0.07687318325042725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.48011589050293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010992452735081315,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981090068817138,
      "backward_entropy": 0.07686565981970893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719966888427734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001198856276459992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981049537658691,
      "backward_entropy": 0.07672353585561116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167926788330078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001298500457778573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980993509292603,
      "backward_entropy": 0.07671284675598145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.609737396240234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013983318349346519,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980911254882812,
      "backward_entropy": 0.07670185301038954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.056565284729004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014981090789660811,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980813503265381,
      "backward_entropy": 0.07683232095506456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.19332218170166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001598007627762854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980689525604248,
      "backward_entropy": 0.07667885224024455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.01168155670166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016980379587039351,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980530977249145,
      "backward_entropy": 0.07666681872473823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.943218231201172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017977666575461626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980393886566162,
      "backward_entropy": 0.07665450043148464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.121026992797852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018975783605128527,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980232954025268,
      "backward_entropy": 0.07679586940341526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.591828346252441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001997480634599924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980029106140136,
      "backward_entropy": 0.07662869824303521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.520353317260742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020973088685423136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979822874069214,
      "backward_entropy": 0.07661523421605428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.901230812072754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002197414869442582,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979583263397216,
      "backward_entropy": 0.07660139931572808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.65417766571045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022978722117841244,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979299545288086,
      "backward_entropy": 0.07675425211588542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.435824394226074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023985470179468393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978986024856567,
      "backward_entropy": 0.07674320538838704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.388002395629883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002499708905816078,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978634357452392,
      "backward_entropy": 0.0767319467332628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730842590332031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026012968737632036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978254079818725,
      "backward_entropy": 0.07654249668121338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.517566680908203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027026485186070204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977890491485595,
      "backward_entropy": 0.07652709219190809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.446430206298828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002804429968819022,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977489948272705,
      "backward_entropy": 0.07669634289211696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.583498001098633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002906192559748888,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977078676223755,
      "backward_entropy": 0.07665057977040608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.399544715881348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003007970517501235,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976650714874267,
      "backward_entropy": 0.07663492361704509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.430817604064941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031100623309612274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976195335388184,
      "backward_entropy": 0.07646180523766412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.989279747009277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003212074749171734,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109757399559021,
      "backward_entropy": 0.07644455962710911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.647123336791992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0033138226717710495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975289344787598,
      "backward_entropy": 0.07642694314320882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.654814720153809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034151924774050713,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974853038787842,
      "backward_entropy": 0.07656763659583198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.792153358459473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003516650525853038,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974401235580444,
      "backward_entropy": 0.0765494770473904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.971610069274902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036182207986712456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973941087722779,
      "backward_entropy": 0.07658664385477702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.349658966064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037195601034909487,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973489284515381,
      "backward_entropy": 0.0765116744571262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.345154762268066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003820825833827257,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973020792007446,
      "backward_entropy": 0.07633278104994032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.105453491210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003922023344784975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972537994384765,
      "backward_entropy": 0.07647165324952868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.954154014587402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00402349466457963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972019433975219,
      "backward_entropy": 0.07629190550910102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569108963012695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004124727100133896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971510410308838,
      "backward_entropy": 0.07627078559663561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.421574592590332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004225535783916712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971019268035889,
      "backward_entropy": 0.07624914911058214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.273426055908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0043263682164251804,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970540046691894,
      "backward_entropy": 0.0763847827911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.222804069519043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004427544306963682,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970015525817871,
      "backward_entropy": 0.07636166943444146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.549616813659668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004528587684035301,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969486236572265,
      "backward_entropy": 0.07617790169186062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.213387489318848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004629658535122871,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968937873840331,
      "backward_entropy": 0.07631373405456543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.727005958557129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004730601795017719,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096841812133789,
      "backward_entropy": 0.07612572775946723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.95718765258789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0048316833563148975,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967835187911987,
      "backward_entropy": 0.07637177573310004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.996135711669922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004932979121804237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967216491699219,
      "backward_entropy": 0.0760710636774699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.522112846374512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005034520756453276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096659779548645,
      "backward_entropy": 0.07604269186655681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.265880584716797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005136012099683285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965968370437622,
      "backward_entropy": 0.07630260785420735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.762068748474121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005237805191427469,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965301990509033,
      "backward_entropy": 0.0761545631620619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.267101287841797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0053391526453197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096464991569519,
      "backward_entropy": 0.07595290078057183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.264724731445312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005440430715680122,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964014530181884,
      "backward_entropy": 0.07592154873741998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.540580749511719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005541572812944651,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963377952575684,
      "backward_entropy": 0.07588937547471789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.928048133850098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0056426809169352055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962721109390258,
      "backward_entropy": 0.0758563412560357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24763298034668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0057435124181210995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962080955505371,
      "backward_entropy": 0.07582252555423313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.241787910461426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005844248458743095,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096142053604126,
      "backward_entropy": 0.07596382167604235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.559534072875977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0059448969550430775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960752964019775,
      "backward_entropy": 0.0757523775100708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.461180686950684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006045617628842592,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960066318511963,
      "backward_entropy": 0.07589361402723524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.378312110900879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006146345287561417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959362983703613,
      "backward_entropy": 0.07567874590555827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.987004280090332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006247472018003464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958600044250488,
      "backward_entropy": 0.07599078284369574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.900992393493652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0063483514823019505,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957851409912109,
      "backward_entropy": 0.07595829168955485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.434076309204102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0064494069665670395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957064628601074,
      "backward_entropy": 0.07592513826158312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.511162757873535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0065504154190421104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095625638961792,
      "backward_entropy": 0.07589113712310791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.24117374420166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006650976836681366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109554922580719,
      "backward_entropy": 0.07547896438174778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.138409614562988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006751955486834049,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10954610109329224,
      "backward_entropy": 0.07581984334521824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.269115447998047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006852793041616678,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10953733921051026,
      "backward_entropy": 0.07539284229278564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.896169662475586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006953999865800142,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952792167663575,
      "backward_entropy": 0.07574449645148383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.93270206451416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007055384572595358,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951817035675049,
      "backward_entropy": 0.07570535606808132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.884294509887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007156913168728352,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950789451599122,
      "backward_entropy": 0.0754279957877265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.003955841064453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007258046884089708,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949786901473998,
      "backward_entropy": 0.07520140541924371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.634881019592285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0073593975976109505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948734283447266,
      "backward_entropy": 0.07515015204747517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.98423957824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007460790686309338,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109476637840271,
      "backward_entropy": 0.07526968585120307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.213761329650879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007562361191958189,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946544408798217,
      "backward_entropy": 0.07504647970199585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.205483436584473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007663730066269636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10945428609848022,
      "backward_entropy": 0.07499285538991292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46585464477539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007764915004372597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10944277048110962,
      "backward_entropy": 0.07493809858957927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.96670150756836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007866095751523972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943108797073364,
      "backward_entropy": 0.07488229539659289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.685733795166016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007967003621160984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941965579986572,
      "backward_entropy": 0.07482575045691596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.320712089538574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008068469353020191,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10940705537796021,
      "backward_entropy": 0.07526830832163493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.470711708068848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008170279674232006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939366817474365,
      "backward_entropy": 0.07521888282563952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.852438926696777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00827198475599289,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938016176223755,
      "backward_entropy": 0.0747838020324707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.361452102661133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008373724296689034,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936609506607056,
      "backward_entropy": 0.07457837793562147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.262480735778809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008475299924612045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935194492340088,
      "backward_entropy": 0.07450957430733575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.863306999206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008576668798923492,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933777093887329,
      "backward_entropy": 0.07457246383031209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.714407920837402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008678155019879341,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932304859161376,
      "backward_entropy": 0.07436656951904297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.318663597106934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008779620751738548,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10930781364440918,
      "backward_entropy": 0.07490117020077175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.825265884399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008881441317498684,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10929179191589355,
      "backward_entropy": 0.07434748940997654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.416253089904785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008983309380710125,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10927531719207764,
      "backward_entropy": 0.07426932122972277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.438125610351562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009085515514016151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10925793647766113,
      "backward_entropy": 0.07405205567677815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.245745658874512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009188003838062286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10923975706100464,
      "backward_entropy": 0.07396823167800903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.717967987060547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009290625341236591,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10922048091888428,
      "backward_entropy": 0.07460629940032959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860937118530273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009393108077347279,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10920095443725586,
      "backward_entropy": 0.07393830352359348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.342727661132812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009495069272816181,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10918210744857788,
      "backward_entropy": 0.07385075092315674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.277283668518066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009596308693289757,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10916447639465332,
      "backward_entropy": 0.0736148820983039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.563213348388672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009697423316538334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10914713144302368,
      "backward_entropy": 0.07352470027075873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.200732231140137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009797981008887291,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10913043022155762,
      "backward_entropy": 0.073432723681132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.596694946289062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009898903779685497,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10911259651184083,
      "backward_entropy": 0.07333818409177992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.908499717712402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010000335052609444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10909323692321778,
      "backward_entropy": 0.07413829697502984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.742457389831543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010101362131536007,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10907419919967651,
      "backward_entropy": 0.07406402296490139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260725975036621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010202488861978054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109054696559906,
      "backward_entropy": 0.07398607995775011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.60946273803711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0103034358471632,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10903512239456177,
      "backward_entropy": 0.07294521729151408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.60805606842041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010404910892248154,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10901389122009278,
      "backward_entropy": 0.07297341028849284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.391176223754883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010506357997655869,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1089923620223999,
      "backward_entropy": 0.07374182012346056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.887585639953613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010607678443193436,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10897085666656495,
      "backward_entropy": 0.07275356186760797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67600154876709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010709105059504509,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10894837379455566,
      "backward_entropy": 0.07264012760586208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860838890075684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01081005297601223,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10892699956893921,
      "backward_entropy": 0.07252450784047444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.080565452575684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010910660959780216,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1089064598083496,
      "backward_entropy": 0.0724065833621555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854291915893555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011010563932359219,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10888785123825073,
      "backward_entropy": 0.07216836346520318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.752203941345215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011110208928585052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10886930227279663,
      "backward_entropy": 0.07204723358154297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.2136869430542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011209561489522457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10885013341903686,
      "backward_entropy": 0.07310672601064046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80829906463623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011308889836072922,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10883004665374756,
      "backward_entropy": 0.07192126909891765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.952156066894531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011408002115786076,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10880999565124512,
      "backward_entropy": 0.07290917634963989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.055469512939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011506467126309872,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10879154205322265,
      "backward_entropy": 0.07166486316257054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.681631088256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011604944244027138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10877232551574707,
      "backward_entropy": 0.07140121195051405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.916207313537598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011703778058290482,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10875127315521241,
      "backward_entropy": 0.07126335302988689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502337455749512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011802534572780132,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1087300419807434,
      "backward_entropy": 0.07246165143118964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.070796966552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011901048943400383,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10871018171310425,
      "backward_entropy": 0.07112918297449748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.429218292236328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011999040842056274,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10869176387786865,
      "backward_entropy": 0.07098929749594794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.658191680908203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01209730003029108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10867174863815307,
      "backward_entropy": 0.0706910490989685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.201395988464355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012195423245429993,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10865204334259033,
      "backward_entropy": 0.07054031557506985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80885124206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01229369267821312,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10863128900527955,
      "backward_entropy": 0.07055350144704182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.53118896484375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012391902506351471,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10861053466796874,
      "backward_entropy": 0.07172498438093397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.967774391174316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012490415014326572,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10858784914016724,
      "backward_entropy": 0.07006749841901991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.30098819732666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012588894926011562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10856442451477051,
      "backward_entropy": 0.06990283727645874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.912459373474121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01268753968179226,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10853972434997558,
      "backward_entropy": 0.07132446765899658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.174664497375488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01278614066541195,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10851467847824096,
      "backward_entropy": 0.07118570142322117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.220528602600098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012884311378002167,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10849072933197021,
      "backward_entropy": 0.07104450464248657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.325089454650879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012982672080397606,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10846527814865112,
      "backward_entropy": 0.0693921446800232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47413158416748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013080677948892117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1084402084350586,
      "backward_entropy": 0.07075381278991699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.011008262634277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013178468681871891,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10841525793075561,
      "backward_entropy": 0.07060492038726807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42387580871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013275823555886745,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10839166641235351,
      "backward_entropy": 0.06882090700997247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7035813331604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013373038731515408,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1083685040473938,
      "backward_entropy": 0.07029926776885986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.166365623474121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013469738885760307,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10834790468215942,
      "backward_entropy": 0.06842560238308376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.1404390335083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013566761277616024,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10832477807998657,
      "backward_entropy": 0.06809186935424805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.164578437805176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013664060272276402,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10829862356185913,
      "backward_entropy": 0.06981890069113837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.084677696228027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013761073350906372,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10827263593673705,
      "backward_entropy": 0.06965279579162598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630850791931152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013858368620276451,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10824493169784546,
      "backward_entropy": 0.06948224703470866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.667764663696289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013955647125840187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1082162618637085,
      "backward_entropy": 0.06930625438690186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.390780448913574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014052378945052624,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10818984508514404,
      "backward_entropy": 0.0691228707631429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.114689826965332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014148467220366001,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10816642045974731,
      "backward_entropy": 0.06685860289467706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.262129306793213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014243797399103642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10814605951309204,
      "backward_entropy": 0.06664790709813435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.331778526306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014338552951812744,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10812827348709106,
      "backward_entropy": 0.0664797027905782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.225300788879395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0144334202632308,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1081092357635498,
      "backward_entropy": 0.06621906492445204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.610014915466309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014528892934322357,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10808584690093995,
      "backward_entropy": 0.06599730915493435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7563018798828125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014624550938606262,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10806028842926026,
      "backward_entropy": 0.06577013598548041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.138922691345215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014719933271408081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10803667306900025,
      "backward_entropy": 0.06554374429914686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.857351303100586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014815256930887699,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10801234245300292,
      "backward_entropy": 0.06531676318910387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.574735641479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01491097453981638,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10798550844192505,
      "backward_entropy": 0.06503400537702772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.224776268005371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015006858855485916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10795649290084838,
      "backward_entropy": 0.06484892633226183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.617654800415039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01510273851454258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10792782306671142,
      "backward_entropy": 0.06460968653361003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.523070335388184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01519822794944048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10790060758590699,
      "backward_entropy": 0.06662234995100233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.450623512268066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015294428914785385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10786679983139039,
      "backward_entropy": 0.06411895487043592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.612537860870361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01539071835577488,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10783131122589111,
      "backward_entropy": 0.06386697292327881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.418519973754883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015486590564250946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10779750347137451,
      "backward_entropy": 0.06361297766367595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.940483570098877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015581958927214146,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10776557922363281,
      "backward_entropy": 0.06563366121715969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9950408935546875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01567717082798481,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10773262977600098,
      "backward_entropy": 0.06309662262598674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.035292625427246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015772316604852676,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.107699453830719,
      "backward_entropy": 0.06262409024768406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.530571460723877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015867412090301514,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10766518115997314,
      "backward_entropy": 0.06233698129653931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.125899314880371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01596216671168804,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1076318621635437,
      "backward_entropy": 0.062046044402652316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.624243259429932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01605699583888054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10759742259979248,
      "backward_entropy": 0.06202050712373522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.972686767578125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01615159399807453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10756391286849976,
      "backward_entropy": 0.061743080615997314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.086066722869873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016246190294623375,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10752917528152466,
      "backward_entropy": 0.06375853882895575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.805678367614746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016340237110853195,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10749661922454834,
      "backward_entropy": 0.060846845308939614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849844455718994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01643482781946659,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10745794773101806,
      "backward_entropy": 0.06086893876393636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.435142517089844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016529332846403122,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10741758346557617,
      "backward_entropy": 0.060560802618662514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.296831130981445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016623523086309433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10737758874893188,
      "backward_entropy": 0.060249023967319064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.804547309875488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01671796292066574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10733386278152465,
      "backward_entropy": 0.05993096033732096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.228630542755127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01681233011186123,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10728864669799805,
      "backward_entropy": 0.059249944157070585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.939101696014404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016906246542930603,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10724351406097413,
      "backward_entropy": 0.058917608526017934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.106016159057617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017000241205096245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10719592571258545,
      "backward_entropy": 0.058948881096310086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.97578239440918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017093827947974205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10715123414993286,
      "backward_entropy": 0.06104372607337104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.35402250289917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017186935991048813,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.107108473777771,
      "backward_entropy": 0.06072028477986654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.123301982879639,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017279833555221558,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10706459283828736,
      "backward_entropy": 0.06039378378126356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.279051303863525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017372453585267067,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10702288150787354,
      "backward_entropy": 0.05714281400044759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.719021320343018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017464904114603996,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10698045492172241,
      "backward_entropy": 0.05677018562952677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.457738876342773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017557470127940178,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10693411827087403,
      "backward_entropy": 0.05938722689946493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.47200345993042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017649980261921883,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10688188076019287,
      "backward_entropy": 0.05600928597980075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0177531242370605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017741873860359192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10683770179748535,
      "backward_entropy": 0.05617975526385837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.576317310333252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017833521589636803,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10679172277450562,
      "backward_entropy": 0.05834608607821994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.977482318878174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01792469248175621,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10674901008605957,
      "backward_entropy": 0.054847121238708496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.82087516784668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018015660345554352,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10670340061187744,
      "backward_entropy": 0.054451551702287465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.30735969543457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018106384202837944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10665796995162964,
      "backward_entropy": 0.05726593732833862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.522704601287842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018197206780314445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10660851001739502,
      "backward_entropy": 0.054345935583114624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.801082134246826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018287615850567818,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10656110048294068,
      "backward_entropy": 0.05396971437666151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.521325588226318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018377836793661118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10651257038116455,
      "backward_entropy": 0.05359013875325521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.426445007324219,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018468350172042847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10645666122436523,
      "backward_entropy": 0.05577487415737576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.889735221862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01855841651558876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10640196800231934,
      "backward_entropy": 0.05281416575113932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.233198165893555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01864839531481266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10634413957595826,
      "backward_entropy": 0.05241964923010932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.194549083709717,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018737899139523506,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10629062652587891,
      "backward_entropy": 0.05116044150458442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.678520679473877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018827620893716812,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10623228549957275,
      "backward_entropy": 0.050735155741373696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.076663017272949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018917186185717583,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10617231130599976,
      "backward_entropy": 0.053832285934024386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.262411117553711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01900690421462059,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10610814094543457,
      "backward_entropy": 0.05081457561916775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.508651256561279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01909620128571987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10604616403579711,
      "backward_entropy": 0.050405429469214544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.485024929046631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019185293465852737,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10598305463790894,
      "backward_entropy": 0.04999177323447333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.692481994628906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019274218007922173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10592026710510254,
      "backward_entropy": 0.04957499768998888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.934518814086914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019362440332770348,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10586436986923217,
      "backward_entropy": 0.05179217126634386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1795806884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01945015788078308,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10580811500549317,
      "backward_entropy": 0.047678967316945396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.85659646987915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01953834854066372,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1057426929473877,
      "backward_entropy": 0.04832217428419325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1564621925354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01962597854435444,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10567635297775269,
      "backward_entropy": 0.04678563939200507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.040779113769531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019713375717401505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10560891628265381,
      "backward_entropy": 0.04747218555874295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.893614292144775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01979975402355194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1055505633354187,
      "backward_entropy": 0.04704970121383667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.324636936187744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0198858343064785,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10549042224884034,
      "backward_entropy": 0.0492737160788642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.128332138061523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019971277564764023,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10543721914291382,
      "backward_entropy": 0.046202136410607234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.145720958709717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02005675435066223,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10538187026977539,
      "backward_entropy": 0.048419959015316434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.794073104858398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02014152519404888,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10533313751220703,
      "backward_entropy": 0.04535308149125841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.03645658493042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020226141437888145,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10528173446655273,
      "backward_entropy": 0.043628944291008845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.827307224273682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020310068503022194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10523669719696045,
      "backward_entropy": 0.04450319210688273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.679373264312744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020394034683704376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10519242286682129,
      "backward_entropy": 0.04407799243927002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.938501358032227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02047787792980671,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10514514446258545,
      "backward_entropy": 0.046248548560672335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.137248992919922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020561061799526215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10510402917861938,
      "backward_entropy": 0.04322484466764662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2386794090271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02064380794763565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10506497621536255,
      "backward_entropy": 0.04279976089795431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.772120952606201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020726248621940613,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1050260305404663,
      "backward_entropy": 0.04093143343925476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.298642635345459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02080882340669632,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10497826337814331,
      "backward_entropy": 0.04048120975494385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.813894748687744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020891161635518074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10492769479751587,
      "backward_entropy": 0.04151099589135912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.927449703216553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02097286656498909,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1048762321472168,
      "backward_entropy": 0.04359707236289978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.428649425506592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02105414867401123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10482589006423951,
      "backward_entropy": 0.040647503402498036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.197052955627441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0211346298456192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10478018522262574,
      "backward_entropy": 0.040219012233946055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2607808113098145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02121422439813614,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10474250316619874,
      "backward_entropy": 0.03822950522104899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.597533702850342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02129392884671688,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10469939708709716,
      "backward_entropy": 0.039368129438824125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.516231536865234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02137318253517151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10465871095657349,
      "backward_entropy": 0.038942558897866145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.49608850479126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02145199105143547,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10462205410003662,
      "backward_entropy": 0.03851922684245639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.434810161590576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021530352532863617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10458518266677856,
      "backward_entropy": 0.03809656368361579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.291565418243408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021608268842101097,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10454798936843872,
      "backward_entropy": 0.03600869907273187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5971269607543945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021685678511857986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10451233386993408,
      "backward_entropy": 0.039630628294414945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.513574600219727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021762901917099953,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10447232723236084,
      "backward_entropy": 0.03919001420338949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1877007484436035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021839914843440056,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443041324615479,
      "backward_entropy": 0.03469216823577881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.282156467437744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021916436031460762,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10438880920410157,
      "backward_entropy": 0.0342554317580329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.551578998565674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02199259214103222,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1043433666229248,
      "backward_entropy": 0.037869764698876276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.847615957260132,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0220686886459589,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10429072380065918,
      "backward_entropy": 0.035116460588243276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.005305290222168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022144120186567307,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10424296855926514,
      "backward_entropy": 0.034693002700805664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.364334583282471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02221916988492012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10420180559158325,
      "backward_entropy": 0.03427344891760084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.075062274932861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022294120863080025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10415115356445312,
      "backward_entropy": 0.03611859348085192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.677396535873413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022368747740983963,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10409755706787109,
      "backward_entropy": 0.03568297955724928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.928741693496704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02244272083044052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10404694080352783,
      "backward_entropy": 0.033013214667638145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8078501224517822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022516373544931412,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10399539470672607,
      "backward_entropy": 0.03259746895896064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3826751708984375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02258962020277977,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10394293069839478,
      "backward_entropy": 0.034387701087527804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9817535877227783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022662067785859108,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10389342308044433,
      "backward_entropy": 0.029937916331821017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7378084659576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022734444588422775,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10383913516998292,
      "backward_entropy": 0.02952013413111369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7794106006622314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02280651219189167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1037822961807251,
      "backward_entropy": 0.03095670872264438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0648157596588135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022878380492329597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10372326374053956,
      "backward_entropy": 0.030550006363126967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4510679244995117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022949323058128357,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10367165803909302,
      "backward_entropy": 0.030149989657931857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8718085289001465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02301989495754242,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10362327098846436,
      "backward_entropy": 0.027885337670644123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.27433180809021,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023089416325092316,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10357712507247925,
      "backward_entropy": 0.029362635480033025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6271493434906006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023158535361289978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10353361368179322,
      "backward_entropy": 0.028975248336791992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9898293018341064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023227661848068237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10348291397094726,
      "backward_entropy": 0.028587874439027574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.808689832687378,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02329612337052822,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10343743562698364,
      "backward_entropy": 0.026315722200605605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3073980808258057,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023363716900348663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10339232683181762,
      "backward_entropy": 0.029815442032284208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7904598712921143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023431088775396347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10333582162857055,
      "backward_entropy": 0.027447539899084303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1554651260375977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023497721180319786,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1032804012298584,
      "backward_entropy": 0.02902994884385003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2647926807403564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023564130067825317,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10321857929229736,
      "backward_entropy": 0.024799906545215182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.653709650039673,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023630451411008835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10314545631408692,
      "backward_entropy": 0.028256893157958984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6977500915527344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023696042597293854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10307693481445312,
      "backward_entropy": 0.02787380748324924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.461000680923462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023761041462421417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10301080942153931,
      "backward_entropy": 0.025595032506518893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2990729808807373,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023825181648135185,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10294647216796875,
      "backward_entropy": 0.027119977606667414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5105130672454834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023888377472758293,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10288779735565186,
      "backward_entropy": 0.022989412148793537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4282004833221436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02395094558596611,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10282442569732667,
      "backward_entropy": 0.024538743827078078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6194963455200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02401292510330677,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10276286602020264,
      "backward_entropy": 0.022297981712553237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.713165044784546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024074604734778404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10269536972045898,
      "backward_entropy": 0.023854101697603863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.051542282104492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024136250838637352,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1026272177696228,
      "backward_entropy": 0.023514623443285625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.390460252761841,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024196894839406013,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10256272554397583,
      "backward_entropy": 0.023181945085525513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.033088207244873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024257147684693336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10249656438827515,
      "backward_entropy": 0.022852533393436007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.069401979446411,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02431655302643776,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10243413448333741,
      "backward_entropy": 0.02428099513053894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0451853275299072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02437525801360607,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10237329006195069,
      "backward_entropy": 0.022210982110765245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.212129831314087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024433370679616928,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10231833457946778,
      "backward_entropy": 0.02002284096346961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.246657133102417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024491174146533012,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10226109027862548,
      "backward_entropy": 0.02327629758252038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1428089141845703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024548742920160294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10219795703887939,
      "backward_entropy": 0.022946731911765203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7388732433319092,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024606002494692802,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10213345289230347,
      "backward_entropy": 0.022619517313109502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.043400764465332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02466236613690853,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1020746111869812,
      "backward_entropy": 0.02067495882511139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0612943172454834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024718400090932846,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10201220512390137,
      "backward_entropy": 0.018538503183258906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6770739555358887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024774212390184402,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10194675922393799,
      "backward_entropy": 0.01825448539521959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7104672193527222,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024829206988215446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10188515186309814,
      "backward_entropy": 0.019795255528555974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5601989030838013,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024883508682250977,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10182315111160278,
      "backward_entropy": 0.017701890733506944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3649383783340454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024936934933066368,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10176224708557129,
      "backward_entropy": 0.020748222867647808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6127041578292847,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024989301338791847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1017109990119934,
      "backward_entropy": 0.01896089149845971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5871517658233643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02504110150039196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10165886878967285,
      "backward_entropy": 0.018692841132481892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2549715042114258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025092432275414467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10160837173461915,
      "backward_entropy": 0.018428602152400546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.418776035308838,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025142710655927658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10156357288360596,
      "backward_entropy": 0.019604100121392146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4009459018707275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025192324072122574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10151655673980713,
      "backward_entropy": 0.019331037998199463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4986118078231812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025241363793611526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1014702558517456,
      "backward_entropy": 0.019061952829360962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3486825227737427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025290029123425484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1014169692993164,
      "backward_entropy": 0.017421500550376043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.322553038597107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02533815987408161,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10136487483978271,
      "backward_entropy": 0.017178250683678523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2121284008026123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025385713204741478,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1013094425201416,
      "backward_entropy": 0.015233352780342102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4886155128479004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02543259784579277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10125689506530762,
      "backward_entropy": 0.016703615585962932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2892358303070068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025479348376393318,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10119065046310424,
      "backward_entropy": 0.01646884282430013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3596240282058716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025525659322738647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10112112760543823,
      "backward_entropy": 0.016237086719936795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1820145845413208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025571750476956367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10104569196701049,
      "backward_entropy": 0.016007049216164485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.128757119178772,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025617294013500214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1009696364402771,
      "backward_entropy": 0.01705034739441342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0739573240280151,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025662193074822426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10089088678359985,
      "backward_entropy": 0.01681662764814165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0672072172164917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02570650540292263,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10081638097763061,
      "backward_entropy": 0.01658629046546088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.030631184577942,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025750277563929558,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10074334144592285,
      "backward_entropy": 0.016359392139646742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1052848100662231,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025793375447392464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10066509246826172,
      "backward_entropy": 0.016138070159488253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.952240526676178,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025836126878857613,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10058178901672363,
      "backward_entropy": 0.015920052925745647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8699867725372314,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025878218933939934,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10049829483032227,
      "backward_entropy": 0.012977484199735854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8277415633201599,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025919562205672264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10041804313659668,
      "backward_entropy": 0.015497267246246338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6918401718139648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025960082188248634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10033844709396363,
      "backward_entropy": 0.01411488652229309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7256268858909607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0259996484965086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10027022361755371,
      "backward_entropy": 0.013928176628218757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7802262902259827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038354262709618,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1002046823501587,
      "backward_entropy": 0.013746637437078688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6494097113609314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026076454669237137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1001389503479004,
      "backward_entropy": 0.01356875565316942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8352859616279602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026113569736480713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10007269382476806,
      "backward_entropy": 0.014521463049782647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48616257309913635,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026150483638048172,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10000487565994262,
      "backward_entropy": 0.014338067836231656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6223872900009155,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026186222210526466,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09994885325431824,
      "backward_entropy": 0.014160109890831841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6824421286582947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02622126042842865,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09989438652992248,
      "backward_entropy": 0.013986143800947402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.680452287197113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02625579759478569,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0998349130153656,
      "backward_entropy": 0.012741569015714858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5457031726837158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026289980858564377,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09977368712425232,
      "backward_entropy": 0.011224997540314993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6721396446228027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026323489844799042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09971818327903748,
      "backward_entropy": 0.012433499925666384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6552982330322266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635672688484192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09965746402740479,
      "backward_entropy": 0.012282975845866732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5658789277076721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026389645412564278,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0995901346206665,
      "backward_entropy": 0.01316218740410275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48270395398139954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026422016322612762,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09952086210250854,
      "backward_entropy": 0.011987893117798699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5017955303192139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0264535341411829,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09944969415664673,
      "backward_entropy": 0.010565405918492211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37425753474235535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02648450806736946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09938040971755982,
      "backward_entropy": 0.011707272794511583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42914220690727234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02651449851691723,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09931679964065551,
      "backward_entropy": 0.01256567570898268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4899309277534485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026543818414211273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09925484657287598,
      "backward_entropy": 0.011444136500358582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43159255385398865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026572810485959053,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09919124841690063,
      "backward_entropy": 0.012289464473724365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36085745692253113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02660130150616169,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09912847876548767,
      "backward_entropy": 0.01215515285730362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3685617744922638,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026629092171788216,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0990700900554657,
      "backward_entropy": 0.012024157577090792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39961785078048706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02665622904896736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09901236295700074,
      "backward_entropy": 0.0109524205327034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33353012800216675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02668294496834278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09895340204238892,
      "backward_entropy": 0.010836838020218743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38455677032470703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026708874851465225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09889224171638489,
      "backward_entropy": 0.01072482019662857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.343528151512146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026734448969364166,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.098828786611557,
      "backward_entropy": 0.01061457892258962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2912524938583374,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026759488508105278,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09876354932785034,
      "backward_entropy": 0.00939266218079461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36951377987861633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026783866807818413,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09870051145553589,
      "backward_entropy": 0.01040254533290863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33658888936042786,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026807991787791252,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0986330270767212,
      "backward_entropy": 0.009214648769961463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3360608220100403,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026831816881895065,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0985642671585083,
      "backward_entropy": 0.009127989411354065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33018895983695984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02685536816716194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09849312305450439,
      "backward_entropy": 0.010097276833322313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24380798637866974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026878610253334045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09841834306716919,
      "backward_entropy": 0.00999829669793447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24337202310562134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026901209726929665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09834681749343872,
      "backward_entropy": 0.00990261220269733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2535422146320343,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02692309580743313,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0982742190361023,
      "backward_entropy": 0.008801120022932688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2286757528781891,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02694445662200451,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0982004463672638,
      "backward_entropy": 0.01058280716339747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25612586736679077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026965070515871048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09812378883361816,
      "backward_entropy": 0.009633196724785699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24632567167282104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026985421776771545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09804670214653015,
      "backward_entropy": 0.00954761521683799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20538006722927094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027005497366189957,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09796923398971558,
      "backward_entropy": 0.009463452630572848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24649867415428162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02702483721077442,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09788897037506103,
      "backward_entropy": 0.010229920347531637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2136055827140808,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027044005692005157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09780652523040771,
      "backward_entropy": 0.00930206643210517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20797152817249298,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027062781155109406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09772340059280396,
      "backward_entropy": 0.009223576221201155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14620789885520935,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02708122320473194,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09764015078544616,
      "backward_entropy": 0.009986216823259989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16360273957252502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027098841965198517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09755922555923462,
      "backward_entropy": 0.00907332201798757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20490846037864685,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02711593545973301,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09747995138168335,
      "backward_entropy": 0.009836845927768283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18852363526821136,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027132943272590637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09739916920661926,
      "backward_entropy": 0.009763997462060716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14882613718509674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027149559929966927,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09731447696685791,
      "backward_entropy": 0.0088632603486379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1693982630968094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027165524661540985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09722919464111328,
      "backward_entropy": 0.008797095881568061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13411878049373627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027181150391697884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09714198112487793,
      "backward_entropy": 0.008732318878173828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11260876804590225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027196232229471207,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0970562219619751,
      "backward_entropy": 0.007880901296933493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19102245569229126,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027210555970668793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09697198271751403,
      "backward_entropy": 0.009435784485605028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11400341242551804,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027225172147154808,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09688531160354615,
      "backward_entropy": 0.007789586153295305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11604046076536179,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027239220216870308,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09680088758468627,
      "backward_entropy": 0.009315662913852267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1355120688676834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027252767235040665,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09671755433082581,
      "backward_entropy": 0.008437179856830172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12129005789756775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02726598083972931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0966319739818573,
      "backward_entropy": 0.008382836977640787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09810545295476913,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027279002591967583,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09654816389083862,
      "backward_entropy": 0.009149527384175194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1176874190568924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729140594601631,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09646514058113098,
      "backward_entropy": 0.008278609977828132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11778879910707474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027303678914904594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09638277292251587,
      "backward_entropy": 0.008228438595930735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10871617496013641,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027315638959407806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09629809856414795,
      "backward_entropy": 0.008997233377562629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11460616439580917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732720598578453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09621163606643676,
      "backward_entropy": 0.008131881554921469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11485741287469864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733861468732357,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09612367749214172,
      "backward_entropy": 0.008085132473044924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09250431507825851,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027350038290023804,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09603556394577026,
      "backward_entropy": 0.007411672837204403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09445421397686005,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027361365035176277,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09595084190368652,
      "backward_entropy": 0.008809987869527604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09439262747764587,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027372317388653755,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09586511850357056,
      "backward_entropy": 0.008765378759966956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0822002962231636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027383089065551758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0957793951034546,
      "backward_entropy": 0.007903228203455607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06794404983520508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027393704280257225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09569621086120605,
      "backward_entropy": 0.007860071957111359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07787946611642838,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02740401402115822,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09561693668365479,
      "backward_entropy": 0.008636318975024752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07573137432336807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027413975447416306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09553751945495606,
      "backward_entropy": 0.007778004639678531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06575579196214676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02742355689406395,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09545744657516479,
      "backward_entropy": 0.007739095224274529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0754389762878418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0274327602237463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09537858963012695,
      "backward_entropy": 0.007701872951454586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07382344454526901,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744181826710701,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09529882669448853,
      "backward_entropy": 0.008482230206330618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06614953279495239,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027450891211628914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09521973133087158,
      "backward_entropy": 0.007628188365035587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06829878687858582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02745959535241127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.095139878988266,
      "backward_entropy": 0.007592812180519104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06912476569414139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02746809646487236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09505914449691773,
      "backward_entropy": 0.007558198438750373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05514707788825035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027476588264107704,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0949780821800232,
      "backward_entropy": 0.007049621807204353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0586560033261776,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02748461253941059,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09489720463752746,
      "backward_entropy": 0.00749090313911438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06562142074108124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02749241702258587,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09481632709503174,
      "backward_entropy": 0.007459044456481934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05573981627821922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027500318363308907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09473474025726318,
      "backward_entropy": 0.00824622478750017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046087026596069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0275082029402256,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09465429186820984,
      "backward_entropy": 0.006963749726613362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05358298122882843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02751586213707924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0945762038230896,
      "backward_entropy": 0.007364214294486576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05638200044631958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02752351574599743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09449875354766846,
      "backward_entropy": 0.007333610620763566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04313131421804428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027530934661626816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09441924691200257,
      "backward_entropy": 0.007303733792569902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04454329237341881,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027538038790225983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09434109926223755,
      "backward_entropy": 0.007275064786275228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04418250545859337,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027544936165213585,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09426344633102417,
      "backward_entropy": 0.008068894346555075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044709496200084686,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02755148336291313,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09418461322784424,
      "backward_entropy": 0.008042950597074296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04269014671444893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02755800262093544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09410582780838013,
      "backward_entropy": 0.007194063729710049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0418759249150753,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027564309537410736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09402658939361572,
      "backward_entropy": 0.007168351776070065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03977051004767418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757064253091812,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0939478874206543,
      "backward_entropy": 0.006796829402446747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03722473606467247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027576588094234467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09386832118034363,
      "backward_entropy": 0.007118201090229882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03039463236927986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027582375332713127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09378941655158997,
      "backward_entropy": 0.007094414697753059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031041888520121574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027587754651904106,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09371219873428345,
      "backward_entropy": 0.007900078263547685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04003627598285675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027593061327934265,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09363697767257691,
      "backward_entropy": 0.0070503221617804635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028131794184446335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027598341926932335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09356001615524293,
      "backward_entropy": 0.007028428216775258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03147690370678902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027603356167674065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09348479509353638,
      "backward_entropy": 0.007007623712221782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02630746178328991,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760797180235386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0934091329574585,
      "backward_entropy": 0.006988307668103112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028743231669068336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027612367644906044,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09333527088165283,
      "backward_entropy": 0.006694750653372871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030997466295957565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027616560459136963,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09326177835464478,
      "backward_entropy": 0.006952083773083157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026950864121317863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02762056700885296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931873857975006,
      "backward_entropy": 0.006934930466943317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02698737382888794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027624614536762238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09311404228210449,
      "backward_entropy": 0.006917705552445518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023177223280072212,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027628544718027115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09304096698760986,
      "backward_entropy": 0.007739007472991943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02140743099153042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02763235755264759,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09296944141387939,
      "backward_entropy": 0.006884613384803136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023362386971712112,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0276360921561718,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09289989471435547,
      "backward_entropy": 0.007709042893515693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022902166470885277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02763975039124489,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09283097386360169,
      "backward_entropy": 0.0068530138168070055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020449470728635788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027643173933029175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09276219606399536,
      "backward_entropy": 0.00683822813961241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021481875330209732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027646398171782494,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09269446134567261,
      "backward_entropy": 0.006824226015143924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01820170320570469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027649421244859695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09262692928314209,
      "backward_entropy": 0.006810944113466475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018739400431513786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027652572840452194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09256134033203126,
      "backward_entropy": 0.00679728885491689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019515905529260635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02765548788011074,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09249651432037354,
      "backward_entropy": 0.006784530563486947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01708933711051941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027658216655254364,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09243184328079224,
      "backward_entropy": 0.006772486699952019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016857078298926353,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027661046013236046,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09236871600151061,
      "backward_entropy": 0.0065951889587773215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015726804733276367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027663705870509148,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09230654239654541,
      "backward_entropy": 0.006748368342717488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015166162513196468,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02766619622707367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09224559664726258,
      "backward_entropy": 0.007587455213069916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017628882080316544,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027668680995702744,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09218600988388062,
      "backward_entropy": 0.007577243778440688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015886712819337845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027670929208397865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0921258270740509,
      "backward_entropy": 0.006715947141249974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01441650465130806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027673080563545227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09206589460372924,
      "backward_entropy": 0.006706114444467757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01732114516198635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027675215154886246,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0920068383216858,
      "backward_entropy": 0.006572959323724111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013930701650679111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027677327394485474,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09194660782814026,
      "backward_entropy": 0.006686667187346352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0096236951649189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027679432183504105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09188716411590576,
      "backward_entropy": 0.006677000886864132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011249496601521969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027681559324264526,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09183099269866943,
      "backward_entropy": 0.006563687904013528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014935016632080078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027683712542057037,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09177652597427369,
      "backward_entropy": 0.007514771487977769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010035894811153412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027685675770044327,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09172097444534302,
      "backward_entropy": 0.006557383057143953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010190105065703392,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02768775075674057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09166759252548218,
      "backward_entropy": 0.006639481832583745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010506385006010532,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027689751237630844,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09161576032638549,
      "backward_entropy": 0.007489693661530812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010595712810754776,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02769179455935955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09156489372253418,
      "backward_entropy": 0.006621389339367549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008660138584673405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027693795040249825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09151462316513062,
      "backward_entropy": 0.006612483412027359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01036838348954916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02769574336707592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09146612882614136,
      "backward_entropy": 0.0066038672294881605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009347636252641678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027697576209902763,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09141789674758911,
      "backward_entropy": 0.0065957605838775635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008433128707110882,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027699410915374756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09137052297592163,
      "backward_entropy": 0.006587490853336122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008152752183377743,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02770122140645981,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09132444858551025,
      "backward_entropy": 0.0074419983559184605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0076507749035954475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02770300582051277,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09127952456474304,
      "backward_entropy": 0.006529010418388579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009111719205975533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02770479954779148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0912358283996582,
      "backward_entropy": 0.00742705331908332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009562394581735134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027706487104296684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09119179844856262,
      "backward_entropy": 0.006555926468637254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007109709084033966,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027708062902092934,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09114605188369751,
      "backward_entropy": 0.006521063960260815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008256301283836365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027709579095244408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09110120534896851,
      "backward_entropy": 0.006541821277803845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008209829218685627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027710966765880585,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09105607867240906,
      "backward_entropy": 0.006517423937718074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006628553848713636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771228924393654,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.091010582447052,
      "backward_entropy": 0.006529133352968428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006609383504837751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027713662013411522,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09096601605415344,
      "backward_entropy": 0.006514447430769603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006786596495658159,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771504409611225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09092211723327637,
      "backward_entropy": 0.006516361816061867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005317476112395525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027716409415006638,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09087852239608765,
      "backward_entropy": 0.007377360430028703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0051631988026201725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771790325641632,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09083635807037353,
      "backward_entropy": 0.00650331833296352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005934867076575756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771942876279354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079557657241821,
      "backward_entropy": 0.006496541202068329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006306461989879608,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02772090584039688,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0907551646232605,
      "backward_entropy": 0.006503499216503567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007689334452152252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02772228606045246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09071457386016846,
      "backward_entropy": 0.0073527875873777605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0063307094387710094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02772349864244461,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09067230820655822,
      "backward_entropy": 0.007347576320171356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005569797474890947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027724657207727432,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09062975645065308,
      "backward_entropy": 0.006498841775788201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038449501153081656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027725815773010254,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09058760404586792,
      "backward_entropy": 0.006497587594721053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005028394982218742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027727004140615463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09054753184318542,
      "backward_entropy": 0.006461394329865773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0055907717905938625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02772810310125351,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09050800204277039,
      "backward_entropy": 0.0064561884436342455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004856008570641279,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027729086577892303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09046814441680909,
      "backward_entropy": 0.007323368555969662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005818708334118128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027730043977499008,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09042854309082031,
      "backward_entropy": 0.006446658737129635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004014322534203529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027730898931622505,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09038791656494141,
      "backward_entropy": 0.007315208514531453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003642560448497534,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027731744572520256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09034847021102906,
      "backward_entropy": 0.00731135325299369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031548701226711273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027732636779546738,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09031033515930176,
      "backward_entropy": 0.00730735311905543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033434361685067415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027733581140637398,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09027391076087951,
      "backward_entropy": 0.006491897834671868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026235163677483797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02773452363908291,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09023873805999756,
      "backward_entropy": 0.007299002673890855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00340238306671381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027735555544495583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09020534157752991,
      "backward_entropy": 0.006419694672028224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036670693662017584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027736525982618332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09017271995544433,
      "backward_entropy": 0.007290268109904395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037633730098605156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027737431228160858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09014019966125489,
      "backward_entropy": 0.0064108843604723615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002933219773694873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027738293632864952,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09010733366012573,
      "backward_entropy": 0.0072823646995756365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002012124052271247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02773919329047203,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09007511138916016,
      "backward_entropy": 0.006402499145931668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031694730278104544,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02774019166827202,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09004473686218262,
      "backward_entropy": 0.006397988233301375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003370411694049835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02774117887020111,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09001408815383911,
      "backward_entropy": 0.006483126845624711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026312193367630243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027742115780711174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08998283147811889,
      "backward_entropy": 0.006389167159795761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032661696895956993,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027743050828576088,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08995211124420166,
      "backward_entropy": 0.006480605651934941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029732463881373405,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027743887156248093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08992092609405518,
      "backward_entropy": 0.007258242203129662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002072094939649105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027744650840759277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08988974690437317,
      "backward_entropy": 0.006377214772833718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022961855866014957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027745431289076805,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08985989093780518,
      "backward_entropy": 0.007251395119561089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00222777109593153,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027746165171265602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08983093500137329,
      "backward_entropy": 0.0072480978237258065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018423233414068818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027746884152293205,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08980255126953125,
      "backward_entropy": 0.006477227641476525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001740112784318626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027747618034482002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08977528810501098,
      "backward_entropy": 0.006362877786159515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022692710626870394,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027748389169573784,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08974892497062684,
      "backward_entropy": 0.007238167855474684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002115823095664382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027749106287956238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08972245454788208,
      "backward_entropy": 0.0063558949364556205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002203718526288867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027749795466661453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08969594240188598,
      "backward_entropy": 0.006352600538068348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015356459189206362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027750421315431595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08966929912567138,
      "backward_entropy": 0.006349518067306942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011169671779498458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02775109000504017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08964340686798096,
      "backward_entropy": 0.0064733562370141344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014266945654526353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02775181457400322,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08961931467056275,
      "backward_entropy": 0.006343007915549808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001371671911329031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02775254286825657,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08959605693817138,
      "backward_entropy": 0.006339691579341888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001408588606864214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027753273025155067,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08957358598709106,
      "backward_entropy": 0.006336393455664317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001419215346686542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027753988280892372,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08955175280570984,
      "backward_entropy": 0.006333158661921819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014706712681800127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02775469422340393,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08953014016151428,
      "backward_entropy": 0.006330002513196733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012756776995956898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02775537595152855,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08950859308242798,
      "backward_entropy": 0.007207163506084018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012943155597895384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027756044641137123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08948752880096436,
      "backward_entropy": 0.006323842538727654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012477744603529572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02775668166577816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0894669234752655,
      "backward_entropy": 0.006320935156610277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012971204705536366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02775728888809681,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08944675326347351,
      "backward_entropy": 0.006318151950836182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010547689162194729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027757856994867325,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08942679166793824,
      "backward_entropy": 0.006315523551570045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008645670022815466,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027758410200476646,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08940761089324951,
      "backward_entropy": 0.006464082333776686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001295869704335928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027758978307247162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08938947916030884,
      "backward_entropy": 0.006310402933094237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009561954066157341,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027759499847888947,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08937084674835205,
      "backward_entropy": 0.006307971974213918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009506603237241507,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027760010212659836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08935283422470093,
      "backward_entropy": 0.007186087469259898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013061627978459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027760513126850128,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08933513164520264,
      "backward_entropy": 0.00630328721470303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008124597952701151,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027760948985815048,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08931671380996704,
      "backward_entropy": 0.006461896830134922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008388162241317332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027761394158005714,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08929883241653443,
      "backward_entropy": 0.007179517712857988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012670863652601838,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027761833742260933,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08928145170211792,
      "backward_entropy": 0.006461366597149108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007084712269715965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02776218391954899,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08926351070404052,
      "backward_entropy": 0.0064614783558580614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009201533976010978,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02776254713535309,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08924638032913208,
      "backward_entropy": 0.006461494084861543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000895672244951129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027762873098254204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08922947645187378,
      "backward_entropy": 0.006291581938664119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008865402778610587,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02776316925883293,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08921266198158265,
      "backward_entropy": 0.007170495887597402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007013055146671832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027763420715928078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08919644355773926,
      "backward_entropy": 0.006288638131486045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008019907982088625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027763668447732925,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08918097615242004,
      "backward_entropy": 0.006287284195423126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008098358521237969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027763893827795982,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08916542530059815,
      "backward_entropy": 0.006285991105768416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005416320054791868,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027764087542891502,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08914994597434997,
      "backward_entropy": 0.0064638906882868875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042565129115246236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027764305472373962,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08913509845733643,
      "backward_entropy": 0.006283582912551032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004987157881259918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027764562517404556,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08912119865417481,
      "backward_entropy": 0.0071620891491572065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007354397093877196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027764836326241493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08910787105560303,
      "backward_entropy": 0.006280859725342857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006705599371343851,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02776506543159485,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08909435272216797,
      "backward_entropy": 0.007159219847785102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005634539993479848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027765264734625816,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.089080548286438,
      "backward_entropy": 0.007157978084352281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005019953823648393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027765456587076187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08906689882278443,
      "backward_entropy": 0.006277412176132202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048275970038957894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027765650302171707,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08905365467071533,
      "backward_entropy": 0.006276293347279231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039462826680392027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027765845879912376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08904072046279907,
      "backward_entropy": 0.006275205976433224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041282977326773107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027766060084104538,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08902847766876221,
      "backward_entropy": 0.0071530987819035845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004916292964480817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027766281738877296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08901643753051758,
      "backward_entropy": 0.006272897952132755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041363632772117853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027766484767198563,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08900463581085205,
      "backward_entropy": 0.00646779230899281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039592033135704696,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02776668779551983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08899348974227905,
      "backward_entropy": 0.006270770811372333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003806312452070415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027766888961195946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08898265361785888,
      "backward_entropy": 0.006269728144009908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023224075266625732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027767090126872063,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08897210359573364,
      "backward_entropy": 0.0071469735768106245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003542147169355303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027767328545451164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08896229267120362,
      "backward_entropy": 0.0062675368454721235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028473453130573034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027767563238739967,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08895285129547119,
      "backward_entropy": 0.006266426708963182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023494288325309753,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027767805382609367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08894346952438355,
      "backward_entropy": 0.006265285942289565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043436893611215055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027768071740865707,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08893493413925171,
      "backward_entropy": 0.00714161495367686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003259574295952916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027768293395638466,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08892620801925659,
      "backward_entropy": 0.006468694243166182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004048267437610775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02776850201189518,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08891756534576416,
      "backward_entropy": 0.007139147983656989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030160072492435575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02776867337524891,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08890883922576905,
      "backward_entropy": 0.0062612129582299125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019528604752849787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02776883728802204,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0889002501964569,
      "backward_entropy": 0.0071370162897639805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026373376022093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027769029140472412,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08889246582984925,
      "backward_entropy": 0.007135863105456035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026992446510121226,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027769217267632484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0888850212097168,
      "backward_entropy": 0.006258643335766262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022168675786815584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02776939608156681,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08887770175933837,
      "backward_entropy": 0.0071336204806963606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016491732094436884,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027769578620791435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0888705849647522,
      "backward_entropy": 0.006256927632623249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022232317132875323,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02776978351175785,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08886401653289795,
      "backward_entropy": 0.007131333980295394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001630243204999715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02776998095214367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08885754346847534,
      "backward_entropy": 0.006255144874254863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011605787585722283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027770191431045532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08885126709938049,
      "backward_entropy": 0.006254238386948903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014824095705989748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027770429849624634,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08884565830230713,
      "backward_entropy": 0.006253245390123791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002381607046118006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777068316936493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08884073495864868,
      "backward_entropy": 0.006252225074503157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019241614791098982,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027770906686782837,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08883556127548217,
      "backward_entropy": 0.0071252187093098955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002607055357657373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027771120890975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08883062601089478,
      "backward_entropy": 0.006250430312421586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011983017611782998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777129039168358,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08882506489753723,
      "backward_entropy": 0.0062496790455447305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019324799359310418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277714766561985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08881995677947999,
      "backward_entropy": 0.006248900045951207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017173205560538918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027771644294261932,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08881471753120422,
      "backward_entropy": 0.006248176925712162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017942026897799224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777179889380932,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08880939483642578,
      "backward_entropy": 0.0062474873330858015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001245001913048327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777193672955036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08880401849746704,
      "backward_entropy": 0.006246863140000237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014981826825533062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027772080153226852,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08879883289337158,
      "backward_entropy": 0.006246224045753479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012317014625295997,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027772221714258194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08879398107528687,
      "backward_entropy": 0.006245622618330849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014667412324342877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027772361412644386,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08878914117813111,
      "backward_entropy": 0.006469756778743532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013162451796233654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027772491797804832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08878439664840698,
      "backward_entropy": 0.006244420177406735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014188046043273062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777261845767498,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08877989053726196,
      "backward_entropy": 0.0062438373764355974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001331350504187867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027772732079029083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08877522349357606,
      "backward_entropy": 0.006243300934632619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001299980067415163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027772830799221992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08877036571502686,
      "backward_entropy": 0.006242812093761232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.211844007950276e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027772918343544006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08876539468765259,
      "backward_entropy": 0.00711268103784985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.545672269770876e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027773013338446617,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08876070380210876,
      "backward_entropy": 0.007112008002069261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95795674296096e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027773117646574974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08875614404678345,
      "backward_entropy": 0.006241396897368961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010980429942719638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777322195470333,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08875164985656739,
      "backward_entropy": 0.006240900605916977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.789311348460615e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027773313224315643,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08874702453613281,
      "backward_entropy": 0.006240435772471958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919032552512363e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027773410081863403,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08874261975288392,
      "backward_entropy": 0.006239965558052063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.207905582617968e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027773505076766014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0887382984161377,
      "backward_entropy": 0.006239501138528188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.355025784112513e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027773603796958923,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0887341856956482,
      "backward_entropy": 0.007108108037047916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.214886813424528e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027773700654506683,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08873017430305481,
      "backward_entropy": 0.0071074871553315055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.614292942686006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027773786336183548,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08872610330581665,
      "backward_entropy": 0.006472061077753703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.46315238554962e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777387760579586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08872231245040893,
      "backward_entropy": 0.006237754805220498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.726489613763988e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777397446334362,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08871880769729615,
      "backward_entropy": 0.006237316048807568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.392899715341628e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774056419730186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08871514797210693,
      "backward_entropy": 0.0062369294464588165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.94615552877076e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774130925536156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08871150016784668,
      "backward_entropy": 0.006236563126246135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6466760725015774e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027774199843406677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08870793581008911,
      "backward_entropy": 0.007104071478048961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.248908564681187e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0277742687612772,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08870444297790528,
      "backward_entropy": 0.006472972118192249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.96122268284671e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777433767914772,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0887009859085083,
      "backward_entropy": 0.006235554814338684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.636432954110205e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774419635534286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08869782090187073,
      "backward_entropy": 0.0062351880802048575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3008425058797e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027774492278695107,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08869464993476868,
      "backward_entropy": 0.0064733682407273185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.709759014076553e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777455560863018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08869144916534424,
      "backward_entropy": 0.006234536154402627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.957201599609107e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027774620801210403,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08868836760520935,
      "backward_entropy": 0.006473693168825573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.686935426434502e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774684131145477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08868533968925477,
      "backward_entropy": 0.006233923137187958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.620336378342472e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027774745598435402,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08868233561515808,
      "backward_entropy": 0.007100145022074382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5465090554207563e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777479588985443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08867924809455871,
      "backward_entropy": 0.006233352753851149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2854142520809546e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027774833142757416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0886759638786316,
      "backward_entropy": 0.007099383407168918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4800104913301766e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774866670370102,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08867266178131103,
      "backward_entropy": 0.0062329280707571245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.885025580530055e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774902060627937,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08866943717002869,
      "backward_entropy": 0.006232701241970062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4130549465771765e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027774939313530922,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08866633176803589,
      "backward_entropy": 0.007098394135634105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.350895713083446e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027774978429079056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08866336345672607,
      "backward_entropy": 0.006232263313399421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3034197258530185e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775021269917488,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08866056203842163,
      "backward_entropy": 0.0062320248948203195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.649139034678228e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775058522820473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08865767121315002,
      "backward_entropy": 0.006231798893875546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.048033067898359e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027775095775723457,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08865488171577454,
      "backward_entropy": 0.006475841419564353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6118725145352073e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777513675391674,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0886522650718689,
      "backward_entropy": 0.007096709476576911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4106331440852955e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777518332004547,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0886498212814331,
      "backward_entropy": 0.006231137447886997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8778829801012762e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027775226160883904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08864740133285523,
      "backward_entropy": 0.007096017400423686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.143037611152977e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775269001722336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08864509463310241,
      "backward_entropy": 0.006230721043215858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6769772375700995e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777530811727047,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08864279985427856,
      "backward_entropy": 0.007095361749331157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2869406166137196e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775343507528305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08864052891731262,
      "backward_entropy": 0.006230342719289992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.71382559731137e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777538262307644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08863836526870728,
      "backward_entropy": 0.006230131619506412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2339112547342665e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027775418013334274,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08863621354103088,
      "backward_entropy": 0.007094434565967984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4979352272348478e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777545340359211,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08863412141799927,
      "backward_entropy": 0.006229763643609153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.730555752350483e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775492519140244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08863211870193481,
      "backward_entropy": 0.006229573239882787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1704795724654105e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777552418410778,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08863006830215454,
      "backward_entropy": 0.006229403532213635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5879606507951394e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775565162301064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08862819671630859,
      "backward_entropy": 0.006229208989275826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8224685845780186e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775609865784645,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08862643241882324,
      "backward_entropy": 0.006228995819886525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5203404473140836e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027775652706623077,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0886246919631958,
      "backward_entropy": 0.007092617452144623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9758253984036855e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027775699272751808,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0886230707168579,
      "backward_entropy": 0.0070922937658098005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.306155991187552e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777574397623539,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08862152099609374,
      "backward_entropy": 0.006228395634227329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3040098565397784e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777579054236412,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08862003087997436,
      "backward_entropy": 0.006228196952078078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4439879123528954e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027775838971138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08861860036849975,
      "backward_entropy": 0.007091355820496877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2459423487598542e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777589112520218,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08861731290817261,
      "backward_entropy": 0.006227794206804699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2929707736475393e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775948867201805,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08861624002456665,
      "backward_entropy": 0.006227559927437041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6634148778393865e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02777600847184658,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08861525058746338,
      "backward_entropy": 0.006477880809042189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2736341886920854e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776066213846207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08861432075500489,
      "backward_entropy": 0.006227119515339534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2273693755560089e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027776116505265236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08861329555511474,
      "backward_entropy": 0.007089639703432719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0652800483512692e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776170521974564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08861238956451416,
      "backward_entropy": 0.006226712216933568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.872532245935872e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777622453868389,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0886115550994873,
      "backward_entropy": 0.007088967495494419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.168087237601867e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777627855539322,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08861073851585388,
      "backward_entropy": 0.007088645464844174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1852142961288337e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277763269841671,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08860988616943359,
      "backward_entropy": 0.006226119895776113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.992051673179958e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777636982500553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08860895037651062,
      "backward_entropy": 0.006225951843791538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1364320926077198e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027776410803198814,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08860806226730347,
      "backward_entropy": 0.006477880809042189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1779175110859796e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027776449918746948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08860717415809631,
      "backward_entropy": 0.007087512148751153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.647294973547105e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776485309004784,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08860628008842468,
      "backward_entropy": 0.006225504395034578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.596719792170916e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02777651697397232,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08860535025596619,
      "backward_entropy": 0.0064780087106757695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.927016667963471e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027776546776294708,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08860446214675903,
      "backward_entropy": 0.006478071212768555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.615761205670424e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027776576578617096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0886036217212677,
      "backward_entropy": 0.007086555990907881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919166248233523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776606380939484,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0886027991771698,
      "backward_entropy": 0.006225003136528863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7178782551782206e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027776632457971573,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08860193490982056,
      "backward_entropy": 0.006478243403964573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.453063062712317e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776658535003662,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0886011004447937,
      "backward_entropy": 0.006224795348114437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.06314063386526e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277766864746809,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08860031962394714,
      "backward_entropy": 0.006224678622351753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.594063506781822e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776718139648438,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859964609146118,
      "backward_entropy": 0.006224561482667923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.754940270388033e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776744216680527,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859890699386597,
      "backward_entropy": 0.006224450137880113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.181604243873153e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027776766568422318,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08859815597534179,
      "backward_entropy": 0.007085108094745212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.454742677102331e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777678333222866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0885973334312439,
      "backward_entropy": 0.00708494418197208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0614582909911405e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776796370744705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859646320343018,
      "backward_entropy": 0.006224209235774146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.335012479510624e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0277768075466156,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08859559297561645,
      "backward_entropy": 0.0070846544371710885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.860216333530843e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027776824310421944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0885948359966278,
      "backward_entropy": 0.007084507081243727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.344573310139822e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027776839211583138,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08859410285949706,
      "backward_entropy": 0.0070843564139472116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.699281705848989e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777685411274433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859338760375976,
      "backward_entropy": 0.006223929425080617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.517438694369048e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776869013905525,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859267234802246,
      "backward_entropy": 0.006223866095145543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.791115659623756e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777688205242157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859198093414307,
      "backward_entropy": 0.006223801109525893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7202744351816364e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027776896953582764,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08859132528305054,
      "backward_entropy": 0.006479188799858093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9200766675785417e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776911854743958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859069347381592,
      "backward_entropy": 0.006223670310444302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.73366788153362e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777693048119545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08859013319015503,
      "backward_entropy": 0.006223607808351517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.216327281232225e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777695097029209,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858966827392578,
      "backward_entropy": 0.006223519643147786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1199517707136692e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027776969596743584,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08858920335769653,
      "backward_entropy": 0.006479372994767295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1789247714186786e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027776991948485374,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08858880996704102,
      "backward_entropy": 0.006479399071799384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3630706184339942e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777010574936867,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858837485313416,
      "backward_entropy": 0.006223311026891072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.699376975419e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777702733874321,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858791589736939,
      "backward_entropy": 0.00708274460501141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.106132680841256e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777044102549553,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858749866485596,
      "backward_entropy": 0.007082597249084049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3633025395829463e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777059003710747,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858706951141357,
      "backward_entropy": 0.00622310737768809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.707411113078706e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777707390487194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858664631843567,
      "backward_entropy": 0.00622306184636222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4475350528518902e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777088806033134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858623504638671,
      "backward_entropy": 0.006223005967007743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.78709853773762e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777710370719433,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858585357666016,
      "backward_entropy": 0.00708207819196913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7739386041503167e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777118608355522,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858550190925599,
      "backward_entropy": 0.007081958982679579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8533661432229565e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777131646871567,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858516216278076,
      "backward_entropy": 0.006222831706206004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.514677134968224e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777714654803276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858482241630554,
      "backward_entropy": 0.007081713941362169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.160443500542897e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777161449193954,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858449459075927,
      "backward_entropy": 0.007081594732072618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9642066035885364e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777717635035515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858422040939332,
      "backward_entropy": 0.006222668207354016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5740127966855653e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777191251516342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858393430709839,
      "backward_entropy": 0.006222609430551529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9989099655504106e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777204290032387,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0885836660861969,
      "backward_entropy": 0.006222558518250783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4448870615524356e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777721732854843,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858336210250854,
      "backward_entropy": 0.007081127001179589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5613849200235563e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777230367064476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858309984207154,
      "backward_entropy": 0.006222473664416207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9856865947076585e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777724340558052,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858284950256348,
      "backward_entropy": 0.007080902655919393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.208089654232026e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777254581451416,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858256936073303,
      "backward_entropy": 0.006222381360001034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4973524002925842e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777263894677162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858227133750915,
      "backward_entropy": 0.006222352385520935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9256913219578564e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777727320790291,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858200907707214,
      "backward_entropy": 0.0070806195338567095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0824602415814297e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777280658483505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0885817289352417,
      "backward_entropy": 0.006222286572058995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4279153219831642e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777286246418953,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0885814070701599,
      "backward_entropy": 0.007080448998345269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4293927961261943e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777728997170925,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858106732368469,
      "backward_entropy": 0.007080383598804474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.572912879055366e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777729369699955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858072757720947,
      "backward_entropy": 0.006222223656045066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.099884229915915e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277772955596447,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858038187026977,
      "backward_entropy": 0.006222200062539842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2477700011004345e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777729742228985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08858003616333007,
      "backward_entropy": 0.006222188472747803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2199195680295816e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027777301147580147,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857974410057068,
      "backward_entropy": 0.006480541494157579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.718385409636539e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777306735515594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857949376106262,
      "backward_entropy": 0.007080045011308458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.057901143525669e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777312323451042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857923746109009,
      "backward_entropy": 0.006222128868103027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.596762318622496e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777731977403164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857902884483337,
      "backward_entropy": 0.00622209327088462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706534799785004e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777327224612236,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857882022857666,
      "backward_entropy": 0.0062220705052216845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.276062448596349e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777334675192833,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857861757278443,
      "backward_entropy": 0.006222030768791835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.026164454742684e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02777734212577343,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0885784387588501,
      "backward_entropy": 0.006480737692779965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0165081221202854e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777349576354027,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857825994491578,
      "backward_entropy": 0.00622199061844084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.505232133553363e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777357026934624,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857806324958802,
      "backward_entropy": 0.006221957504749298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.307798111673037e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02777736447751522,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857791423797608,
      "backward_entropy": 0.006480823788377974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.323351501829165e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777371928095818,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857775926589966,
      "backward_entropy": 0.007079404261377122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.619923513222602e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777379378676414,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0885776162147522,
      "backward_entropy": 0.006221879687574174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.723585551706492e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777738869190216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857752084732055,
      "backward_entropy": 0.006221844090355767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.984088602417614e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777396142482758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857738971710205,
      "backward_entropy": 0.0062218209107716875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.604725513170706e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777403593063354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0885772705078125,
      "backward_entropy": 0.006221789452764723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.363473398276255e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02777741104364395,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857715725898743,
      "backward_entropy": 0.006480935961008072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.648767106933519e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0277774166315794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857702016830445,
      "backward_entropy": 0.00707897875044081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.412792916104081e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777422219514847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857687711715698,
      "backward_entropy": 0.006221723639302784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.079683316784212e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777427807450294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857674598693847,
      "backward_entropy": 0.0062217116355896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.529398319798929e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777431532740593,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857659101486207,
      "backward_entropy": 0.006221700873639848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.912052477517136e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777743525803089,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857642412185669,
      "backward_entropy": 0.006221693009138107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.863215394834697e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777743898332119,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857628107070922,
      "backward_entropy": 0.006221668587790595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5005225501881796e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777744270861149,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857613801956177,
      "backward_entropy": 0.0070786674817403155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.721653172306105e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027777446433901787,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857600092887878,
      "backward_entropy": 0.0064811743795871735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.121453400784958e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777452021837234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857588768005371,
      "backward_entropy": 0.0062216342323356206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4573185442022805e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027777457609772682,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857578039169312,
      "backward_entropy": 0.00648120790719986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1750263335416093e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02777746319770813,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857567310333252,
      "backward_entropy": 0.006481236881679959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3808620969466574e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777468785643578,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857557773590088,
      "backward_entropy": 0.007078423268265194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8450068018391903e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777472510933876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857547044754029,
      "backward_entropy": 0.006221556001239353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.985941023325722e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777476236224174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857536315917969,
      "backward_entropy": 0.0062215423418415915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.952089855374652e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777479961514473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857526183128357,
      "backward_entropy": 0.006221528682443831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.084129502894939e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748368680477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857516646385193,
      "backward_entropy": 0.006221519162257512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.743579727848555e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748741209507,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857506513595581,
      "backward_entropy": 0.006221497224436866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1249288074141077e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777749113738537,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857496976852416,
      "backward_entropy": 0.006221487290329403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.574757331785804e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777493000030518,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857484459877014,
      "backward_entropy": 0.007078125245041317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0759451280791836e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857471942901611,
      "backward_entropy": 0.006221474044852787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4553983735131624e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857457637786866,
      "backward_entropy": 0.0062214719752470655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.347047001194369e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857444524765015,
      "backward_entropy": 0.006221468249956767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.503326126974571e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857431411743164,
      "backward_entropy": 0.006221464524666469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.450885006055614e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857417106628418,
      "backward_entropy": 0.00707798699537913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6149402287956036e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857402801513672,
      "backward_entropy": 0.00622146079937617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6184559942521446e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0885738730430603,
      "backward_entropy": 0.006221462868981891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.473092794412878e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777493000030518,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857371807098388,
      "backward_entropy": 0.006221462868981891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.42321078758323e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027777493000030518,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857357501983643,
      "backward_entropy": 0.006481679777304332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8509626897866838e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777749113738537,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857342004776,
      "backward_entropy": 0.006221462868981891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2858752995725808e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857327699661255,
      "backward_entropy": 0.006221462868981891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.436107481822546e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857314586639405,
      "backward_entropy": 0.006221462868981891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6735509689169703e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857303261756896,
      "backward_entropy": 0.007077823082605998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3716417868181452e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857290148735046,
      "backward_entropy": 0.006221462868981891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.861643852407724e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857277631759644,
      "backward_entropy": 0.006221458729770448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.049351112669683e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08857263922691345,
      "backward_entropy": 0.007077765133645799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.781777355830855e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857251405715942,
      "backward_entropy": 0.006221458729770448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.597380219209299e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857240676879882,
      "backward_entropy": 0.00622145500448015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.411508017365122e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857228755950927,
      "backward_entropy": 0.00622145500448015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0874070710542583e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857216835021972,
      "backward_entropy": 0.0062214529348744285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1714553949104811e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777748927474022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857205510139465,
      "backward_entropy": 0.006221451279189851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.780759941373617e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777749113738537,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857197165489197,
      "backward_entropy": 0.006221435136265225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.607172302139588e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777493000030518,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857188224792481,
      "backward_entropy": 0.0062214309970537824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.436913390141854e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777494862675667,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857179284095765,
      "backward_entropy": 0.0062214235464731855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0902383706934415e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777496725320816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0885717213153839,
      "backward_entropy": 0.006221419407261742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671251805481006e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777498587965965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857164382934571,
      "backward_entropy": 0.006221416095892589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.616068759512927e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027777500450611115,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08857156038284301,
      "backward_entropy": 0.006482111083136665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.351183401420712e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777502313256264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0885714828968048,
      "backward_entropy": 0.007077539960543315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13998894955148e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777504175901413,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857141733169556,
      "backward_entropy": 0.006221406161785126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.628801685337748e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777506038546562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0885713517665863,
      "backward_entropy": 0.006221402850415971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.846509847946436e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02777750790119171,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08857128620147706,
      "backward_entropy": 0.006221396227677663,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.1391234643554072e-06,
    "avg_log_Z": 0.02777733838185668,
    "success_rate": 1.0,
    "avg_reward": 52.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.12,
      "1": 0.21,
      "2": 0.67
    },
    "avg_forward_entropy": 0.08857857018709182,
    "avg_backward_entropy": 0.006433221110039288,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}