{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06274100867184726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06278003345836293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988605499267578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154999256134033,
      "backward_entropy": 0.06283206289464777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.247252464294434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154969453811646,
      "backward_entropy": 0.06282592903483998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.982162475585938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00020003263489343226,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154934684435527,
      "backward_entropy": 0.06276745145971124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.240324020385742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003000281867571175,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154890974362691,
      "backward_entropy": 0.06281341747804121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.497936248779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00040005965274758637,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154840310414632,
      "backward_entropy": 0.06270798228003761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.593255043029785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005001669633202255,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154785672823589,
      "backward_entropy": 0.06280046159570868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.229859352111816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006003529415465891,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154723087946574,
      "backward_entropy": 0.06269075653769753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.966208457946777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007004952058196068,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154653549194336,
      "backward_entropy": 0.06273471767252142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.742600440979004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008005367126315832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154576063156128,
      "backward_entropy": 0.06278019601648505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.67564868927002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009007062180899084,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154494603474934,
      "backward_entropy": 0.06272095441818237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.956665992736816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0010009764228016138,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154405196507771,
      "backward_entropy": 0.06265456026250665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.114344596862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011011038441210985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09154305855433147,
      "backward_entropy": 0.06275880336761475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.82383918762207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012011518701910973,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09154203534126282,
      "backward_entropy": 0.0626989711414684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.205354690551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001301361946389079,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09154096245765686,
      "backward_entropy": 0.0626256682656028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.362325668334961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00140151206869632,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09153985977172852,
      "backward_entropy": 0.06268341974778609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.425707817077637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00150164810474962,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09153870741526286,
      "backward_entropy": 0.06267543272538618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.486705780029297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001601491472683847,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09153750538825989,
      "backward_entropy": 0.06272021748802879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.191638946533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017014627810567617,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09153621395428975,
      "backward_entropy": 0.0625846494327892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.028260231018066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001801412203349173,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09153484304745992,
      "backward_entropy": 0.06265075098384511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.378013610839844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001901303417980671,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0915334125359853,
      "backward_entropy": 0.06269551407207143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.572275161743164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020012722816318274,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09153189261754353,
      "backward_entropy": 0.06263362277637828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.274016380310059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021010003983974457,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09153034289677937,
      "backward_entropy": 0.06262484463778409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.406949043273926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002200786955654621,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152875343958537,
      "backward_entropy": 0.06266945058649237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.618158340454102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002300313673913479,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152716398239136,
      "backward_entropy": 0.06260685487227007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.327205657958984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024000622797757387,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152546525001526,
      "backward_entropy": 0.06259764324535023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.697566509246826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002499863738194108,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0915237267812093,
      "backward_entropy": 0.06264193491502242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.255849838256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025991129223257303,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152207771937053,
      "backward_entropy": 0.06263248486952348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.678218841552734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026984906289726496,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0915203591187795,
      "backward_entropy": 0.06256902759725397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.644805908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027978005819022655,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151861071586609,
      "backward_entropy": 0.06245699253949252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.310315132141113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0028969994746148586,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0915168325106303,
      "backward_entropy": 0.0625494122505188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.684591293334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002996334806084633,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151500463485718,
      "backward_entropy": 0.06243134628642689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.905572891235352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030959828291088343,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151302774747212,
      "backward_entropy": 0.06258285045623779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.27733325958252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031959444750100374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09151097138722737,
      "backward_entropy": 0.06257214871319858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.990434646606445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032963703852146864,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150872627894084,
      "backward_entropy": 0.0625070496038957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.172887802124023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003397054737433791,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09150638182957967,
      "backward_entropy": 0.06237681345506148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.568416595458984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034980587661266327,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150388836860657,
      "backward_entropy": 0.06248401511799206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.806614875793457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003599101211875677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150129556655884,
      "backward_entropy": 0.06247258728200739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.970317840576172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036998840514570475,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149866302808125,
      "backward_entropy": 0.06246117570183494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.992486000061035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0038008703850209713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149594108263652,
      "backward_entropy": 0.06250267679041083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.801410675048828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0039020839612931013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149306019147237,
      "backward_entropy": 0.062437610192732376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.232723236083984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004003393929451704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149006009101868,
      "backward_entropy": 0.062477642839605156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.194186210632324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004104980733245611,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148691097895305,
      "backward_entropy": 0.06246471946889704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.942474365234375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00420596357434988,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148384133974712,
      "backward_entropy": 0.062451806935397064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.505036354064941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004306711256504059,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148080150286357,
      "backward_entropy": 0.06238779696551236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.434494018554688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004407447297126055,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147780140240987,
      "backward_entropy": 0.06222346695986661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930815696716309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004508172161877155,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09147473176320393,
      "backward_entropy": 0.062361430038105355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.949371337890625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004608682822436094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147163232167561,
      "backward_entropy": 0.06239727952263572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.403801918029785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004709458909928799,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146832426389058,
      "backward_entropy": 0.06233337792483243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.736675262451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004809333011507988,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146532416343689,
      "backward_entropy": 0.06215344775806774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890832901000977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004908979870378971,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146239360173543,
      "backward_entropy": 0.06213506785306064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.176844596862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005008476320654154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145951271057129,
      "backward_entropy": 0.06233895908702503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930743217468262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0051084598526358604,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145638346672058,
      "backward_entropy": 0.06227389248934659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.241315841674805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0052083577029407024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145316481590271,
      "backward_entropy": 0.06230805136940696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.989020347595215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005308280698955059,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144985675811768,
      "backward_entropy": 0.06229225071993741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.322025299072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005408120341598988,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144651889801025,
      "backward_entropy": 0.062038389119234955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.800790786743164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005508041474968195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144312143325806,
      "backward_entropy": 0.0622607252814553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.896036148071289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005607770290225744,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143972396850586,
      "backward_entropy": 0.06218983910300515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.724285125732422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00570785254240036,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143608808517456,
      "backward_entropy": 0.06217184933749112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85727596282959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00580771965906024,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143245220184326,
      "backward_entropy": 0.061955896290865814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.632704734802246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005907394457608461,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142894546190898,
      "backward_entropy": 0.06219467249783603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.94276237487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0060073211789131165,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142530957857768,
      "backward_entropy": 0.061912005597894844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86447525024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0061075747944414616,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142147501309712,
      "backward_entropy": 0.06216031854802912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.685715675354004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006207638420164585,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141767024993896,
      "backward_entropy": 0.06186626716093584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.925111770629883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0063079046085476875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141369660695393,
      "backward_entropy": 0.06212439320304177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49911880493164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006407975684851408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140978256861369,
      "backward_entropy": 0.062105769460851494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.669114112854004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006508138962090015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140577912330627,
      "backward_entropy": 0.062086641788482666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.40095043182373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006608487572520971,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140159686406453,
      "backward_entropy": 0.06206706437197598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.418096542358398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006708839908242226,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139738480250041,
      "backward_entropy": 0.06204699386249889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.146215438842773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006808761041611433,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139337142308553,
      "backward_entropy": 0.06202667409723455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.897441864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006908622104674578,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138938784599304,
      "backward_entropy": 0.061689019203186035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.727296829223633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007008320186287165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138542413711548,
      "backward_entropy": 0.06198470700870861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.460785865783691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00710830045863986,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138120214144389,
      "backward_entropy": 0.061632736162705856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.194818496704102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007208370137959719,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137687087059021,
      "backward_entropy": 0.061847892674532806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.311043739318848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007308357395231724,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09137256940205891,
      "backward_entropy": 0.06191816655072299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.443134307861328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00740842567756772,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136807918548584,
      "backward_entropy": 0.06189588525078513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.143138885498047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007508567534387112,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136345982551575,
      "backward_entropy": 0.061514756896279076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621464729309082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007608172949403524,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135911862055461,
      "backward_entropy": 0.06174370375546542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.597947120666504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007707518525421619,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135487675666809,
      "backward_entropy": 0.061716231432828034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.37136173248291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007807120215147734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135039647420247,
      "backward_entropy": 0.06168670004064387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.671487808227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007906349375844002,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09134612480799358,
      "backward_entropy": 0.06138914281671697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167505264282227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00800589844584465,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09134149551391602,
      "backward_entropy": 0.06135632775046609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.031950950622559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008105459623038769,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09133680661519368,
      "backward_entropy": 0.06173085624521429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.241362571716309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00820448249578476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09133244554201762,
      "backward_entropy": 0.06170576810836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.244585037231445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00830362644046545,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09132790565490723,
      "backward_entropy": 0.06125345013358376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.990571975708008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008402332663536072,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09132368365923564,
      "backward_entropy": 0.0612173622304743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.882071495056152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0085010826587677,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131936232248943,
      "backward_entropy": 0.06118101423436945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.216904640197754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008599765598773956,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131505091985066,
      "backward_entropy": 0.06142012639479204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.685955047607422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008698603138327599,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913105309009552,
      "backward_entropy": 0.061573906378312546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.356391906738281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008797796443104744,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130566318829854,
      "backward_entropy": 0.06134552305394953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.51924991607666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008897140622138977,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130057692527771,
      "backward_entropy": 0.06130707263946533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.596781730651855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008996725082397461,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09129520257314046,
      "backward_entropy": 0.061267701062289154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9474458694458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009096574038267136,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09128951032956441,
      "backward_entropy": 0.06094814430583607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02520751953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0091963279992342,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128379821777344,
      "backward_entropy": 0.06142316623167558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.168862342834473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009296049363911152,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127797683080037,
      "backward_entropy": 0.060865499756552956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.058629035949707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009395794942975044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09127201636632283,
      "backward_entropy": 0.061350800774314186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.600139617919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009496482089161873,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09126522143681844,
      "backward_entropy": 0.060779820788990364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.145170211791992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009596806019544601,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125859538714091,
      "backward_entropy": 0.06100949374112216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.753745079040527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009697075933218002,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912518600622813,
      "backward_entropy": 0.060963554815812546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.746421813964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009797568432986736,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09124477704366048,
      "backward_entropy": 0.06064486503601074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.320514678955078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009897815063595772,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123785297075908,
      "backward_entropy": 0.060868935151533646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.892000198364258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009997569024562836,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123132626215617,
      "backward_entropy": 0.060820162296295166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.483316421508789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01009769830852747,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122432271639506,
      "backward_entropy": 0.06106011975895275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.317719459533691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010197940282523632,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121706088383992,
      "backward_entropy": 0.06045211445201527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.663835525512695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01029773149639368,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121012687683105,
      "backward_entropy": 0.06096731532703747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.390399932861328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010396734811365604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120391805966695,
      "backward_entropy": 0.06092022765766491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.902233123779297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010495960712432861,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119733174641927,
      "backward_entropy": 0.0602976842360063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.224782943725586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010595111176371574,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119070569674174,
      "backward_entropy": 0.060244159264998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.967159271240234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010694406926631927,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09118382136027019,
      "backward_entropy": 0.060449838638305664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.894532203674316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01079366635531187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09117682774861653,
      "backward_entropy": 0.06072103977203369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.802777290344238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010892888531088829,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116974472999573,
      "backward_entropy": 0.06066884777762673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.401128768920898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010992019437253475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116265177726746,
      "backward_entropy": 0.060615685853091156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.247130393981934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011090848594903946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115578730901082,
      "backward_entropy": 0.06056168404492465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38344955444336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011189348064363003,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0911492109298706,
      "backward_entropy": 0.06014828248457475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.675729751586914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011287606321275234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114282329877217,
      "backward_entropy": 0.06045136668465354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.660468101501465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011385262943804264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113709131876628,
      "backward_entropy": 0.06039516492323442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.889532089233398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011483419686555862,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113065401713054,
      "backward_entropy": 0.05995167927308516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.409516334533691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011581636033952236,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09112465381622314,
      "backward_entropy": 0.05961077863519842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.275147438049316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011679630726575851,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111889203389485,
      "backward_entropy": 0.05981435559012673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002190589904785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011777964420616627,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09111252427101135,
      "backward_entropy": 0.05946602604605935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.233948707580566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011876383796334267,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09110590815544128,
      "backward_entropy": 0.05967125025662509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.064611434936523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011975036934018135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09109882513682048,
      "backward_entropy": 0.06002939289266413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.824983596801758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012073242105543613,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109220902125041,
      "backward_entropy": 0.05951891162178733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.893975257873535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012171478942036629,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09108538428942363,
      "backward_entropy": 0.059159446846355095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.640881538391113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012269793078303337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09107832113901775,
      "backward_entropy": 0.059357643127441406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.727433204650879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012368010357022285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09107119838396709,
      "backward_entropy": 0.05975988778201016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.795361518859863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012466241605579853,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09106395641962688,
      "backward_entropy": 0.05891420624472878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.986818313598633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012564534321427345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105637669563293,
      "backward_entropy": 0.059615828774192116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.752080917358398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012662936002016068,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910482406616211,
      "backward_entropy": 0.05954171852632002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51779556274414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012761319056153297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910399357477824,
      "backward_entropy": 0.059464638883417305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.504683494567871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012859571725130081,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09103167057037354,
      "backward_entropy": 0.05882650071924383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5308356285095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012957701459527016,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0910236934820811,
      "backward_entropy": 0.05847272005948154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.958824157714844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013055222108960152,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910167396068573,
      "backward_entropy": 0.059216423468156296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.139361381530762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013152414001524448,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09101022283236186,
      "backward_entropy": 0.05827562375502153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35502815246582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013249959796667099,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09100288152694702,
      "backward_entropy": 0.059035116975957695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9968719482421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013347333297133446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099562962849934,
      "backward_entropy": 0.05832716009833596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73219108581543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013444429263472557,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098864595095317,
      "backward_entropy": 0.058844013647599655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54533863067627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01354170497506857,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090981125831604,
      "backward_entropy": 0.05811254544691606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.198216438293457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013638978824019432,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09097339709599812,
      "backward_entropy": 0.05800194090062922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.579892635345459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013736623339354992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096487363179524,
      "backward_entropy": 0.058539715680209076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420644760131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013833769597113132,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09095744291941325,
      "backward_entropy": 0.05752859332344749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.689498424530029,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013930855318903923,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09094980359077454,
      "backward_entropy": 0.0576568679376082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.247801780700684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014027545228600502,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09094279011090596,
      "backward_entropy": 0.05753780495036732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231253623962402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01412415225058794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09093568722407024,
      "backward_entropy": 0.05810690468007868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.717092037200928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014220679178833961,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09092846512794495,
      "backward_entropy": 0.057993747971274635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.855480194091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014316899701952934,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09092175960540771,
      "backward_entropy": 0.05693771080537276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052228927612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014413444325327873,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09091417988141377,
      "backward_entropy": 0.0568154129115018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.537812232971191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014510381035506725,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09090552727381389,
      "backward_entropy": 0.05669093132019043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.152312278747559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014607932418584824,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09089535474777222,
      "backward_entropy": 0.05656463449651545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.627988815307617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014705810695886612,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09088436762491862,
      "backward_entropy": 0.056643968278711494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.965884685516357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014803700149059296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09087309241294861,
      "backward_entropy": 0.057261981747367165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.160759925842285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014901259914040565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09086219469706218,
      "backward_entropy": 0.05636893619190563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.060165405273438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014999168924987316,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09085024396578471,
      "backward_entropy": 0.056039409203962845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259187698364258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01509674172848463,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0908386508623759,
      "backward_entropy": 0.05590238896283237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.953906536102295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015194159932434559,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09082704782485962,
      "backward_entropy": 0.0559408881447532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0170979499816895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01529126800596714,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09081578254699707,
      "backward_entropy": 0.05562083287672563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.129976272583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015387596562504768,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09080684185028076,
      "backward_entropy": 0.055470623753287575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.108415603637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015483863651752472,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907979706923167,
      "backward_entropy": 0.055318252606825394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876949787139893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015580067411065102,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09078880151112874,
      "backward_entropy": 0.055163968693126335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.762917518615723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015676094219088554,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09077971180280049,
      "backward_entropy": 0.056004578416997734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.107150077819824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015772443264722824,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09076931079228719,
      "backward_entropy": 0.05502442880110307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.946996212005615,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015868697315454483,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09075870116551717,
      "backward_entropy": 0.05486272139982744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10290813446045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015964796766638756,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09074807167053223,
      "backward_entropy": 0.05469847809184681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.481386661529541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01606139726936817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073567390441895,
      "backward_entropy": 0.05538352511145852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.907404899597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016157520934939384,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907241702079773,
      "backward_entropy": 0.054187238216400146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262595176696777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016254018992185593,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09071119626363118,
      "backward_entropy": 0.054191665215925736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.826401233673096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016350509598851204,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0906977653503418,
      "backward_entropy": 0.05384074557911266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.822022438049316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016446763649582863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09068455298741658,
      "backward_entropy": 0.054717302322387695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251581192016602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01654333993792534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09066998958587646,
      "backward_entropy": 0.05454270948063244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.015809059143066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016639914363622665,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09065486987431844,
      "backward_entropy": 0.053302125497297806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.791633605957031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01673632115125656,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09063974022865295,
      "backward_entropy": 0.053117118098519066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.896629333496094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01683250069618225,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09062480926513672,
      "backward_entropy": 0.053112907843156296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.406264305114746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016928520053625107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09060983856519063,
      "backward_entropy": 0.053818496790799225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.503705978393555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017024699598550797,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09059385458628337,
      "backward_entropy": 0.052730809558521614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.686299800872803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0171204824000597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09057857592900594,
      "backward_entropy": 0.0534404841336337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.92199182510376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017216090112924576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09056355555852254,
      "backward_entropy": 0.05324831875887784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.479500770568848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017311058938503265,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905501941839854,
      "backward_entropy": 0.05213606357574463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.053457260131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017406348139047623,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09053515394528706,
      "backward_entropy": 0.05175109343095259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.959330081939697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017501693218946457,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09051938851674397,
      "backward_entropy": 0.05154585838317871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.133023262023926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01759706623852253,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09050311644872029,
      "backward_entropy": 0.05151299996809526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.12700080871582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01769188977777958,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09048797686894734,
      "backward_entropy": 0.05112801356749101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.888381004333496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017785625532269478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09047599633534749,
      "backward_entropy": 0.052047111771323464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.019638061523438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017878927290439606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0904650588830312,
      "backward_entropy": 0.0508732795715332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.600365161895752,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017972473055124283,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09045310815175374,
      "backward_entropy": 0.05065458471124822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.92296028137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018066005781292915,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09044124682744344,
      "backward_entropy": 0.0502583384513855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.303645133972168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01815909706056118,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09043035904566447,
      "backward_entropy": 0.05020899122411555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.693979740142822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01825266145169735,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09041720628738403,
      "backward_entropy": 0.04998173496939919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.576746940612793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018346309661865234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09040319919586182,
      "backward_entropy": 0.050751751119440254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4192376136779785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018439337611198425,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09039078156153361,
      "backward_entropy": 0.049350180409171364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.071454048156738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018531732261180878,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09038013219833374,
      "backward_entropy": 0.04928515174172141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.921534061431885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018623333424329758,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09037178754806519,
      "backward_entropy": 0.05007393793626265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6367034912109375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01871473900973797,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09036354223887126,
      "backward_entropy": 0.04984623735601252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9813642501831055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018805794417858124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09035593271255493,
      "backward_entropy": 0.049616905775937165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.320248126983643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018896697089076042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09034813443819682,
      "backward_entropy": 0.04938444766131314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.345794677734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018987108021974564,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09034154812494914,
      "backward_entropy": 0.04792950370094993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.621495246887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01907770149409771,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09033353130022685,
      "backward_entropy": 0.04768382419239391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.53085994720459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019168609753251076,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0903234879175822,
      "backward_entropy": 0.047585552388971504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.555940628051758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019259138032794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09031414985656738,
      "backward_entropy": 0.04842523011294278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.074791431427002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019349355250597,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.090305229028066,
      "backward_entropy": 0.04692854664542458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.543327331542969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01943960227072239,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09029534459114075,
      "backward_entropy": 0.04682550647042014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.116610527038574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01952957548201084,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09028571844100952,
      "backward_entropy": 0.04656745087016712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.679466724395752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019619660452008247,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0902747909228007,
      "backward_entropy": 0.04614971984516491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.158527851104736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019710233435034752,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09026118119557698,
      "backward_entropy": 0.04588593678040938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.390980243682861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01980087347328663,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09024638930956523,
      "backward_entropy": 0.0457733002575961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.990665912628174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01989111676812172,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09023229281107585,
      "backward_entropy": 0.04662036353891546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598648548126221,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019980762153863907,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09021979570388794,
      "backward_entropy": 0.04507977854121815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.509035587310791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02006959542632103,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09020984172821045,
      "backward_entropy": 0.04608294096860019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.83079195022583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020158305764198303,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09019952019055684,
      "backward_entropy": 0.04453290592540394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.193588733673096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020247068256139755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0901879072189331,
      "backward_entropy": 0.04553623632951216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6801838874816895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020336152985692024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09017399946848552,
      "backward_entropy": 0.04525602405721491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5086846351623535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020425189286470413,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09015914797782898,
      "backward_entropy": 0.043692569841038094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7025675773620605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02051473595201969,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09014115730921428,
      "backward_entropy": 0.044683635234832764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7926554679870605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02060423232614994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09012227257092793,
      "backward_entropy": 0.04439172148704529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.756570816040039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020693080499768257,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.090105007092158,
      "backward_entropy": 0.04409976439042525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.224175453186035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02078128606081009,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09008936087290446,
      "backward_entropy": 0.0438075065612793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.329580307006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02086924947798252,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0900735855102539,
      "backward_entropy": 0.042248346588828346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.197466850280762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020956391468644142,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09006032347679138,
      "backward_entropy": 0.04210474274375222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1959991455078125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021044116467237473,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09004348516464233,
      "backward_entropy": 0.04292003133080222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.535898208618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021131664514541626,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09002620975176494,
      "backward_entropy": 0.04136031053282998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.435036659240723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02121860533952713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09001048405965169,
      "backward_entropy": 0.04231649095361883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.998953819274902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021305609494447708,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0899931788444519,
      "backward_entropy": 0.04090614752335982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.130159378051758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021392378956079483,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08997563521067302,
      "backward_entropy": 0.04170369018207897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.849082946777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021478332579135895,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08996051549911499,
      "backward_entropy": 0.040146811441941696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.527145862579346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021564053371548653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08994505802790324,
      "backward_entropy": 0.041089166294444694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.966521739959717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021649368107318878,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08993018666903178,
      "backward_entropy": 0.039681025526740334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.020289897918701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021734610199928284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08991418282190959,
      "backward_entropy": 0.040467934174971146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.95992374420166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02181985415518284,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08989667892456055,
      "backward_entropy": 0.03890316052870317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.705780029296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021904338151216507,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08988121151924133,
      "backward_entropy": 0.03874516216191379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.026627063751221,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021988682448863983,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0898648997147878,
      "backward_entropy": 0.03827210448004983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8151164054870605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02207309566438198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08984639247258504,
      "backward_entropy": 0.03920318321748213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.500133991241455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02215742878615856,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08982646465301514,
      "backward_entropy": 0.03779741850766269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.447876930236816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022241493687033653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08980617920557658,
      "backward_entropy": 0.03855689005418257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0379157066345215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022325284779071808,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08978556593259175,
      "backward_entropy": 0.03716000372713262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.494992256164551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022408531978726387,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08976612488428752,
      "backward_entropy": 0.03684022751721469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.789614677429199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02249162644147873,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08974566062291463,
      "backward_entropy": 0.036519326946952126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.736024856567383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022573992609977722,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08972678581873576,
      "backward_entropy": 0.036201287399638786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.529144763946533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022656487300992012,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08970532814661662,
      "backward_entropy": 0.03568675301291726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.784167289733887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022738996893167496,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08968226114908855,
      "backward_entropy": 0.03535978089679371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.342609882354736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02282091975212097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08966042598088582,
      "backward_entropy": 0.036263460462743584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.971188068389893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02290201559662819,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08964169025421143,
      "backward_entropy": 0.035935732451352204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1967692375183105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022982805967330933,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08962247769037883,
      "backward_entropy": 0.03438207507133484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.433569431304932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02306276001036167,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0896064043045044,
      "backward_entropy": 0.03423988277261907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.141903400421143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023142091929912567,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08959145347277324,
      "backward_entropy": 0.033913289958780464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.238401412963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023221490904688835,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08957435687383015,
      "backward_entropy": 0.033408015966415405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.981719017028809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023300237953662872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08955927689870198,
      "backward_entropy": 0.0343046405098655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.646732330322266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02337898313999176,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08954214056332906,
      "backward_entropy": 0.0327609045939012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.190141677856445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02345743402838707,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08952430884043376,
      "backward_entropy": 0.03259345076300881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3536481857299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02353605069220066,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08950292070706685,
      "backward_entropy": 0.032111251896077934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.657480239868164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023614196106791496,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0894823968410492,
      "backward_entropy": 0.031927932392467155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.782955169677734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023692967370152473,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08945586284001668,
      "backward_entropy": 0.03159214149821888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8339643478393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023771587759256363,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0894277294476827,
      "backward_entropy": 0.031134646047245373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.530880451202393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023849304765462875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0894026259581248,
      "backward_entropy": 0.03197809241034768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.820131301879883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023926787078380585,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08937636017799377,
      "backward_entropy": 0.03164396231824702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.585598945617676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024004368111491203,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0893477201461792,
      "backward_entropy": 0.031307407400824806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5410306453704834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024081794545054436,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0893174409866333,
      "backward_entropy": 0.02984347939491272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.995833158493042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024158168584108353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08929085731506348,
      "backward_entropy": 0.030635421926325016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.943908929824829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02423405461013317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08926524718602498,
      "backward_entropy": 0.030303502624685116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8829259872436523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024309370666742325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08923977613449097,
      "backward_entropy": 0.029972975904291325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5784077644348145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024384215474128723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08921510974566142,
      "backward_entropy": 0.029644107276743107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.206693172454834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02445838414132595,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08919272820154826,
      "backward_entropy": 0.02826010368087075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.64093017578125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02453150786459446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08917353550593059,
      "backward_entropy": 0.027925984425978226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.631037473678589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024604102596640587,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08915443221728007,
      "backward_entropy": 0.028677693822167137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6038618087768555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024676183238625526,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0891348918279012,
      "backward_entropy": 0.02835913137956099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.062309265136719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02474788762629032,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08911556005477905,
      "backward_entropy": 0.026962748982689598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4930169582366943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024819670245051384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08909313877423604,
      "backward_entropy": 0.027722453529184513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4085021018981934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02489101141691208,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08907117446263631,
      "backward_entropy": 0.026412836529991844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.773928165435791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024961818009614944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08904929955800374,
      "backward_entropy": 0.027089181271466343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9361228942871094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02503250353038311,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08902485171953838,
      "backward_entropy": 0.025809298862110485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.066749095916748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510327845811844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08899693687756856,
      "backward_entropy": 0.026454532688314266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3715803623199463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02517424337565899,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08896445234616597,
      "backward_entropy": 0.0252091261473569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.392144203186035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025244712829589844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08893188834190369,
      "backward_entropy": 0.025815589861436325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4776856899261475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02531474269926548,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08889861901601155,
      "backward_entropy": 0.025498926639556885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.657351493835449,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025384478271007538,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08886375029881795,
      "backward_entropy": 0.02411820942705328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.682938575744629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025454185903072357,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.088826189438502,
      "backward_entropy": 0.023808712309057064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.406608819961548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025522857904434204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08879383405049641,
      "backward_entropy": 0.024556864391673695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9705255031585693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02559131570160389,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08875920375188191,
      "backward_entropy": 0.023447711359370838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6662657260894775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02565912716090679,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08872487147649129,
      "backward_entropy": 0.023161481727253307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3189001083374023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025726087391376495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0886932114760081,
      "backward_entropy": 0.023639085617932407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5346975326538086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025792982429265976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08865836262702942,
      "backward_entropy": 0.023337310010736637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7556867599487305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025858964771032333,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08862699071566264,
      "backward_entropy": 0.023040706461126156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.70308518409729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025924336165189743,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0885960062344869,
      "backward_entropy": 0.02204102413220839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0547006130218506,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025989102199673653,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08856500188509624,
      "backward_entropy": 0.021441080353476784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.296905279159546,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026053758338093758,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08853070934613545,
      "backward_entropy": 0.021157419139688664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.319911003112793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026117386296391487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08849898974100749,
      "backward_entropy": 0.020879645239223133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1477694511413574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026181314140558243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08846076329549153,
      "backward_entropy": 0.021593171087178318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.707855224609375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624420076608658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08842649062474568,
      "backward_entropy": 0.02131191302429546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8355562686920166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026306794956326485,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0883902112642924,
      "backward_entropy": 0.020421334288337013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4840617179870605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02636927179992199,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08835038542747498,
      "backward_entropy": 0.020752413706345993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1418874263763428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026431238278746605,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0883100430170695,
      "backward_entropy": 0.019897531379352917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0704941749572754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026492340490221977,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08827204505602519,
      "backward_entropy": 0.019259695302356373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2919058799743652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026552563533186913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08823621273040771,
      "backward_entropy": 0.019937108863483776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2656409740448,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02661231905221939,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08820004264513652,
      "backward_entropy": 0.019137669693339954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.245163679122925,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026671642437577248,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08816347519556682,
      "backward_entropy": 0.018489962274377995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.158933401107788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026730449870228767,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08812533815701802,
      "backward_entropy": 0.01823942227797075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.567110538482666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026788726449012756,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08808642625808716,
      "backward_entropy": 0.018405269492756237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.127359628677368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026847131550312042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08804267644882202,
      "backward_entropy": 0.018639273264191368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.035982131958008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026905061677098274,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08799833059310913,
      "backward_entropy": 0.018385150215842506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2675789594650269,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026962416246533394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08795350790023804,
      "backward_entropy": 0.017260193824768066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.537121295928955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02701818384230137,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08791639407475789,
      "backward_entropy": 0.01702592047778043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0513501167297363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027072859928011894,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08788235982259114,
      "backward_entropy": 0.016797025095332752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7013258934020996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027127385139465332,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08784574270248413,
      "backward_entropy": 0.017021020705049687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8998286724090576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027181167155504227,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08780909578005473,
      "backward_entropy": 0.016345671632073143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6218206882476807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0272346381098032,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08777020374933879,
      "backward_entropy": 0.016124423254619945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7033028602600098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027287432923913002,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08773217598597209,
      "backward_entropy": 0.016718964685093273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6452447175979614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339711785316467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08769299586613973,
      "backward_entropy": 0.01649283008141951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8245041370391846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027391498908400536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08765364686648051,
      "backward_entropy": 0.015478688207539644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3274672031402588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027443120256066322,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08761120835940044,
      "backward_entropy": 0.015736547383395107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2100459337234497,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02749374508857727,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08757092555363973,
      "backward_entropy": 0.015532596544785933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1278506517410278,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754334919154644,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08753442764282227,
      "backward_entropy": 0.015618699518117037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2547016143798828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027591921389102936,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08750225106875102,
      "backward_entropy": 0.015413362871516834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3915960788726807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027639713138341904,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08747106790542603,
      "backward_entropy": 0.014467705379832874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3870208263397217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027687063440680504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08743870258331299,
      "backward_entropy": 0.015013037757440046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.304770827293396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027733972296118736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.087404469648997,
      "backward_entropy": 0.014816070144826715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4167550802230835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02778036892414093,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0873694618542989,
      "backward_entropy": 0.014621745456348766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1318728923797607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027826523408293724,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08733169237772624,
      "backward_entropy": 0.01371773671020161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0421751737594604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027871975675225258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08729520440101624,
      "backward_entropy": 0.014239408753134987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2376128435134888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027916641905903816,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08726087212562561,
      "backward_entropy": 0.014054530046202919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1789244413375854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027960924431681633,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08722436428070068,
      "backward_entropy": 0.013688560236584057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7591460347175598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02800472266972065,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0871859888235728,
      "backward_entropy": 0.013520093126730486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.049838900566101,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028047244995832443,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08715174595514934,
      "backward_entropy": 0.012845907698978077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.862545907497406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028089206665754318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08711620171864827,
      "backward_entropy": 0.013345202261751348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0436187982559204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028130318969488144,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08708232641220093,
      "backward_entropy": 0.013032975521954622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0653828382492065,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0281709935516119,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08704602718353271,
      "backward_entropy": 0.012366999279369007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1456921100616455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028211312368512154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08700658877690633,
      "backward_entropy": 0.012848913669586182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8210848569869995,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028251484036445618,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08696251114209493,
      "backward_entropy": 0.012567144903269682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0830769538879395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028290899470448494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08691970507303874,
      "backward_entropy": 0.012526108459992842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7525832653045654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02833014354109764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08687259753545125,
      "backward_entropy": 0.011764783750880848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9123084545135498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028368530794978142,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08682690064112346,
      "backward_entropy": 0.011621337045322765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8322875499725342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028406575322151184,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08677988251050313,
      "backward_entropy": 0.01198042793707414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.68409264087677,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028444012627005577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08673134446144104,
      "backward_entropy": 0.011909669095819647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7732305526733398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028480609878897667,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08668409784634908,
      "backward_entropy": 0.011703909798101946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6813391447067261,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028516702353954315,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08663633465766907,
      "backward_entropy": 0.011570163748481056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8499546647071838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028552182018756866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08658997217814128,
      "backward_entropy": 0.011478952386162498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7514054775238037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02858743444085121,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08654028177261353,
      "backward_entropy": 0.011339184235442768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5885953307151794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028622286394238472,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0864894191424052,
      "backward_entropy": 0.011201382360675118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8207098841667175,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028656328096985817,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08644036451975505,
      "backward_entropy": 0.01106112856756557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5327392220497131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02869025431573391,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08638740579287212,
      "backward_entropy": 0.010933871973644604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7474460601806641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02872338704764843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0863370696703593,
      "backward_entropy": 0.010804329406131397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5987637042999268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02875637076795101,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08628394206364949,
      "backward_entropy": 0.010703535242514177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5435200929641724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02878892607986927,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08623196681340535,
      "backward_entropy": 0.010549017651514574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2925449013710022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028820808976888657,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08618048826853435,
      "backward_entropy": 0.010425662452524359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5310793519020081,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028851306065917015,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08613429466883342,
      "backward_entropy": 0.01037148047577251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42633259296417236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028881246224045753,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0860869288444519,
      "backward_entropy": 0.010193989358165047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34318047761917114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02891044318675995,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0860412319501241,
      "backward_entropy": 0.010082695971835743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4247191548347473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028938710689544678,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08599863449732463,
      "backward_entropy": 0.009975604712963104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4590624272823334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028966356068849564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08595622579256694,
      "backward_entropy": 0.00987114892764525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3934938311576843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028993461281061172,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08591192960739136,
      "backward_entropy": 0.009768683801997791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5718038082122803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029019931331276894,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08586780230204265,
      "backward_entropy": 0.009269226003776897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5791577100753784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02904645726084709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0858193039894104,
      "backward_entropy": 0.009568541564724663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.470664381980896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029073035344481468,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08576589822769165,
      "backward_entropy": 0.009467756206339056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31655773520469666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029099280014634132,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08571020762125652,
      "backward_entropy": 0.009368259798396717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36478134989738464,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029124710708856583,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08565627535184224,
      "backward_entropy": 0.0094415775754235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3437858819961548,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029149606823921204,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08560254176457723,
      "backward_entropy": 0.00935933535749262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5333521962165833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029173869639635086,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08554853995641072,
      "backward_entropy": 0.00927954302592711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4398787319660187,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029198436066508293,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08549006779988606,
      "backward_entropy": 0.009199384938586842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4151270091533661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029222937300801277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08542967836062114,
      "backward_entropy": 0.008902708237821405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27855461835861206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029247192665934563,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08536690473556519,
      "backward_entropy": 0.008811565962704744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3649749159812927,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029270658269524574,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08530535300572713,
      "backward_entropy": 0.00841009955514561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23925474286079407,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029293807223439217,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0852423111597697,
      "backward_entropy": 0.00833254104310816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3174709677696228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029316142201423645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.085181325674057,
      "backward_entropy": 0.008553880182179537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3017283082008362,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029338069260120392,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08511934677759807,
      "backward_entropy": 0.008753324096853083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3608939051628113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02935948595404625,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0850559671719869,
      "backward_entropy": 0.008113646371798082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30669426918029785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02938084676861763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08498997489611308,
      "backward_entropy": 0.008313051678917625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2166125625371933,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029401885345578194,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08492273092269897,
      "backward_entropy": 0.0085548304698684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2606298625469208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029422173276543617,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08485671877861023,
      "backward_entropy": 0.008492506363175133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23824787139892578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029441891238093376,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08478917678197224,
      "backward_entropy": 0.00808644023808566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28632497787475586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029461106285452843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08472155531247456,
      "backward_entropy": 0.008374143730510365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18932892382144928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294802263379097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08465262254079182,
      "backward_entropy": 0.007944429462606257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2460833340883255,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02949870377779007,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08458518981933594,
      "backward_entropy": 0.008261014114726673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24075762927532196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951681613922119,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08451609810193379,
      "backward_entropy": 0.007809287445111709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15246081352233887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02953471802175045,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08444631099700928,
      "backward_entropy": 0.007542647421360016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26752227544784546,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0295517947524786,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0843779444694519,
      "backward_entropy": 0.008103752678090876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24397850036621094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029568858444690704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08430662751197815,
      "backward_entropy": 0.007617296143011613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1391083002090454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02958579733967781,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08423326412836711,
      "backward_entropy": 0.007379377430135553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17422530055046082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02960212156176567,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08416272203127544,
      "backward_entropy": 0.007327399470589377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15444275736808777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02961811237037182,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08409301439921062,
      "backward_entropy": 0.007435977458953857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2871798872947693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02963358163833618,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08402396241823833,
      "backward_entropy": 0.00722741809758273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1799333691596985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02964949607849121,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0839496652285258,
      "backward_entropy": 0.007320797578854995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17329303920269012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02966499514877796,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08387369910875957,
      "backward_entropy": 0.007776758210225539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15564219653606415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029680170118808746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0837970773379008,
      "backward_entropy": 0.00720799443396655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1504758894443512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029694950208067894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08372044563293457,
      "backward_entropy": 0.007153678346763958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16516730189323425,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029709260910749435,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0836432973543803,
      "backward_entropy": 0.007652438499710776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1992121785879135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02972336672246456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08356531461079915,
      "backward_entropy": 0.006946600296280601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14318621158599854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0297375600785017,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08348464965820312,
      "backward_entropy": 0.006996887651356784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1373148262500763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029751429334282875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08340403437614441,
      "backward_entropy": 0.00694596835158088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1233799010515213,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029765000566840172,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0833238164583842,
      "backward_entropy": 0.006818221373991532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12135027348995209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02977818064391613,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08324427902698517,
      "backward_entropy": 0.006847959350455891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12299609184265137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029790828004479408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08316424489021301,
      "backward_entropy": 0.006801465018229051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08726342767477036,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029803158715367317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0830842653910319,
      "backward_entropy": 0.006756091659719294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12338090687990189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029814867302775383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08300591508547465,
      "backward_entropy": 0.0067129216410897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0800594761967659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029826290905475616,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08292649686336517,
      "backward_entropy": 0.006629930301146073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07176896184682846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02983718551695347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08284901579221089,
      "backward_entropy": 0.006630249321460724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06939404457807541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02984744869172573,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08277317881584167,
      "backward_entropy": 0.00656494295055216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10771283507347107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029857121407985687,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08269882202148438,
      "backward_entropy": 0.006535184654322537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12418167293071747,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029866594821214676,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08262292544047038,
      "backward_entropy": 0.007230715995485132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07510446012020111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029876315966248512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08254547913869222,
      "backward_entropy": 0.006483212790705941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09568112343549728,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02988556958734989,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08246866861979167,
      "backward_entropy": 0.006447722966020758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0529010109603405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029894646257162094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08239089449246724,
      "backward_entropy": 0.006413530219684948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04860508441925049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0299031063914299,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0823150376478831,
      "backward_entropy": 0.006393922323530371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08012961596250534,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029911082237958908,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08224170406659444,
      "backward_entropy": 0.006350525400855325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06782148778438568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029918912798166275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08216789364814758,
      "backward_entropy": 0.006320396607572382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0839935839176178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02992645837366581,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08209429184595744,
      "backward_entropy": 0.006291190331632441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06808023154735565,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029934002086520195,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0820197065671285,
      "backward_entropy": 0.006299187513914975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06447562575340271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029941314831376076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08194504678249359,
      "backward_entropy": 0.0062334049831737175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05720863863825798,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029948445037007332,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08187074462572734,
      "backward_entropy": 0.006254912777380509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04378172382712364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029955359175801277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08179724216461182,
      "backward_entropy": 0.006178540262308988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05236252397298813,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02996186353266239,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08172520995140076,
      "backward_entropy": 0.006213912909681147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03978424519300461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02996804006397724,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08165326714515686,
      "backward_entropy": 0.006998258558186618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05805709585547447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029973894357681274,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08158305287361145,
      "backward_entropy": 0.006105246869000522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056706611067056656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02997969090938568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08151260018348694,
      "backward_entropy": 0.006082178516821427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04775957390666008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02998540736734867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08144177993138631,
      "backward_entropy": 0.006059341809966348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05239840969443321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02999093383550644,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08137133717536926,
      "backward_entropy": 0.0060371614315293054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035930562764406204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029996398836374283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08130079011122386,
      "backward_entropy": 0.0060151849280704155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05045431852340698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03000149503350258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08123127619425456,
      "backward_entropy": 0.005994500761682337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0513501837849617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030006645247340202,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08116183678309123,
      "backward_entropy": 0.00607752190394835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039784230291843414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030011752620339394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08109169205029805,
      "backward_entropy": 0.006062006408518011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04736650362610817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030016696080565453,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08102220296859741,
      "backward_entropy": 0.005932782861319455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03365596383810043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030021609738469124,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08095221718152364,
      "backward_entropy": 0.006032130934975364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032750654965639114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030026206746697426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08088282744089763,
      "backward_entropy": 0.005893852223049511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042139116674661636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0300306286662817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08081452051798503,
      "backward_entropy": 0.005875609815120697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040663547813892365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030035054311156273,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08074604471524556,
      "backward_entropy": 0.005991501564329321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033132851123809814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030039474368095398,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08067746460437775,
      "backward_entropy": 0.005839115516705947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04228615015745163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030043717473745346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0806093414624532,
      "backward_entropy": 0.005821489474990151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030840126797556877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03004804067313671,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08054067691167195,
      "backward_entropy": 0.0068497000770135355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018589112907648087,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030052179470658302,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08047256867090861,
      "backward_entropy": 0.005939797921614213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03350432962179184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030055852606892586,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08040607472260793,
      "backward_entropy": 0.005928684364665638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024633286520838737,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030059557408094406,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08033973972002666,
      "backward_entropy": 0.005917511880397797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03189105540513992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03006301261484623,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08027411003907521,
      "backward_entropy": 0.005907062102447857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02014990523457527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030066480860114098,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08020833631356557,
      "backward_entropy": 0.0057252435521645976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026266107335686684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030069708824157715,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08014396329720815,
      "backward_entropy": 0.005886863578449596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030952095985412598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030072879046201706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08008001248041789,
      "backward_entropy": 0.005697453563863581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019401229918003082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030076179653406143,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08001596728960673,
      "backward_entropy": 0.006809656592932614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021114131435751915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030079295858740807,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07995321849981944,
      "backward_entropy": 0.00585804744200273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025648433715105057,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030082250013947487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07989099621772766,
      "backward_entropy": 0.00584917583248832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026450779289007187,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03008522465825081,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07982782026131947,
      "backward_entropy": 0.00584025884216482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019741516560316086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030088325962424278,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07976450522740682,
      "backward_entropy": 0.005630386146632108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016667015850543976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030091309919953346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07970175643761952,
      "backward_entropy": 0.005617435682903637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022281866520643234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094102025032043,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07963983217875163,
      "backward_entropy": 0.006785348057746887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01837296411395073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009689599275589,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07957779864470164,
      "backward_entropy": 0.005592919208786704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01782747358083725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030099643394351006,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0795164704322815,
      "backward_entropy": 0.005580865524031899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015428722836077213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030102256685495377,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0794554054737091,
      "backward_entropy": 0.006774795326319608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01300794817507267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030104737728834152,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07939515511194865,
      "backward_entropy": 0.005558145655827088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02069532498717308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03010709397494793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07933632532755534,
      "backward_entropy": 0.005547505210746418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011168837547302246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030109599232673645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07927738626797994,
      "backward_entropy": 0.0055364041843197565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015724841505289078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03011186234652996,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0792195995648702,
      "backward_entropy": 0.005760755051266064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01816513203084469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030114127323031425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07916221022605896,
      "backward_entropy": 0.005515940487384796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01714630052447319,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030116470530629158,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07910460233688354,
      "backward_entropy": 0.005747068334709515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011862026527523994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03011889010667801,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07904708882172902,
      "backward_entropy": 0.005494808270172639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009554454125463963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03012124076485634,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07899076739947002,
      "backward_entropy": 0.0054844343526796865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01517973281443119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030123408883810043,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07893571257591248,
      "backward_entropy": 0.005474716424942017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011510899290442467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030125653371214867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07888072729110718,
      "backward_entropy": 0.0054647800597277555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01374624203890562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03012785129249096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07882659633954366,
      "backward_entropy": 0.005455052988095717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009931579232215881,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03013012185692787,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07877278327941895,
      "backward_entropy": 0.005445112558928403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012318810448050499,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03013230673968792,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07871996859709422,
      "backward_entropy": 0.006735748865387656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010676998645067215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03013450838625431,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07866739233334859,
      "backward_entropy": 0.005693934857845306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01052646990865469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03013666160404682,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07861527303854625,
      "backward_entropy": 0.005687626925381747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011109844781458378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030138809233903885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07856371502081554,
      "backward_entropy": 0.005407078699632125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010089362971484661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03014100342988968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07851259410381317,
      "backward_entropy": 0.005397600883787329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007429418619722128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03014320693910122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0784620742003123,
      "backward_entropy": 0.005388126793232831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00800259318202734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030145270749926567,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07841251293818156,
      "backward_entropy": 0.00537915290756659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008042436093091965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030147258192300797,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07836368680000305,
      "backward_entropy": 0.005660487508231943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009542153216898441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030149202793836594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07831550637880962,
      "backward_entropy": 0.005361958660862662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005584805738180876,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03015124425292015,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0782677431901296,
      "backward_entropy": 0.005650722845034165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006482346914708614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030153142288327217,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782212217648824,
      "backward_entropy": 0.005344940518791025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005811645649373531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03015497885644436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07817559440930684,
      "backward_entropy": 0.005336938933892684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00592573918402195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030156737193465233,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078130970398585,
      "backward_entropy": 0.005329242145473307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005254183895885944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030158396810293198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07808694243431091,
      "backward_entropy": 0.005321883342482827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003908467013388872,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030159994959831238,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07804393768310547,
      "backward_entropy": 0.0056306990710171785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006200969219207764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030161434784531593,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07800209522247314,
      "backward_entropy": 0.005308217623017051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005316488910466433,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030162904411554337,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07796066999435425,
      "backward_entropy": 0.0056245371022007684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005377274472266436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030164357274770737,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07791991035143535,
      "backward_entropy": 0.006686186925931411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004763578996062279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030165812000632286,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07787964741388957,
      "backward_entropy": 0.006684155626730485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004596829880028963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030167212709784508,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07783992091814677,
      "backward_entropy": 0.005282234739173542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0052463579922914505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030168598517775536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07780090967814128,
      "backward_entropy": 0.005612373013388027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0042307814583182335,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03017001785337925,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07776224613189697,
      "backward_entropy": 0.005609281022440304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032951754983514547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030171412974596024,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.077724223335584,
      "backward_entropy": 0.005263629962097515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032963769044727087,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030172698199748993,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07768701513608296,
      "backward_entropy": 0.005603548477996479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003866060171276331,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030173907056450844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07765063146750133,
      "backward_entropy": 0.005252609537406402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034141072537750006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03017512522637844,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07761492828528087,
      "backward_entropy": 0.006671994924545288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028040690813213587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030176304280757904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07757986585299174,
      "backward_entropy": 0.005241820419376547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033965068869292736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030177421867847443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07754569252332051,
      "backward_entropy": 0.0052366879853335295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003023872384801507,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030178546905517578,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07751211524009705,
      "backward_entropy": 0.0055914866653355684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002685570390895009,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03017963469028473,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07747905949751537,
      "backward_entropy": 0.006666502491994338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002446823986247182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030180674046278,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07744665443897247,
      "backward_entropy": 0.006665349006652832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002502831630408764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030181648209691048,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07741488019625346,
      "backward_entropy": 0.005216906693848697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019434214336797595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03018260933458805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773838460445404,
      "backward_entropy": 0.005212302912365307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003324826480820775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03018348291516304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773535172144572,
      "backward_entropy": 0.00520806150002913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024475434329360723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030184471979737282,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732346653938293,
      "backward_entropy": 0.005579489875923504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020704660564661026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03018546849489212,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07729395727316539,
      "backward_entropy": 0.005199003625999798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00227553304284811,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030186442658305168,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07726511359214783,
      "backward_entropy": 0.006659066812558608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018253728048875928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030187416821718216,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0772366722424825,
      "backward_entropy": 0.006657796827229587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020635060500353575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03018834814429283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07720878223578136,
      "backward_entropy": 0.005185996944254095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018115732818841934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030189279466867447,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0771813044945399,
      "backward_entropy": 0.005181804299354553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017513299826532602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030190201476216316,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07715438803037007,
      "backward_entropy": 0.005177688192237507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018122781766578555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03019111044704914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0771280179421107,
      "backward_entropy": 0.005173626948486675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017235585255548358,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03019203618168831,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0771021842956543,
      "backward_entropy": 0.005563297054984353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018504176987335086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03019297495484352,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07707687218983968,
      "backward_entropy": 0.005165456370873885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001692319056019187,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030193939805030823,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0770518829425176,
      "backward_entropy": 0.005559007891199805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001232984708622098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03019491210579872,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07702724138895671,
      "backward_entropy": 0.0051571195098486814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011403930839151144,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030195830389857292,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07700314124425252,
      "backward_entropy": 0.006645872511646964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010989451548084617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03019670583307743,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07697967191537221,
      "backward_entropy": 0.005149316042661667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010013548890128732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030197536572813988,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07695674896240234,
      "backward_entropy": 0.005145739425312389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010887482203543186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03019833378493786,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0769344965616862,
      "backward_entropy": 0.005142278291962363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010262541472911835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030199117958545685,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0769127607345581,
      "backward_entropy": 0.005547224459323016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006932199466973543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030199889093637466,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07689159115155537,
      "backward_entropy": 0.005135484039783478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009622551151551306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030200600624084473,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07687115669250488,
      "backward_entropy": 0.00513231483372775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007363161421380937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030201315879821777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07685122887293498,
      "backward_entropy": 0.005129141563718969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009856843389570713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030201992020010948,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07683188716570537,
      "backward_entropy": 0.0055409690195863896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007968185236677527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03020268678665161,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07681281367937724,
      "backward_entropy": 0.005123066631230441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007968581630848348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03020336851477623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07679418722788493,
      "backward_entropy": 0.005120096558874304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008036966901272535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0302040483802557,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07677595814069112,
      "backward_entropy": 0.005536417392167178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006061891326680779,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030204731971025467,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07675804694493611,
      "backward_entropy": 0.006632493978196924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006523936754092574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030205383896827698,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07674059271812439,
      "backward_entropy": 0.005111408504572782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005443673580884933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030206020921468735,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07672351598739624,
      "backward_entropy": 0.005108647725798867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007819141610525548,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030206630006432533,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0767068862915039,
      "backward_entropy": 0.005530643192204562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000541163026355207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030207272619009018,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07669043044249217,
      "backward_entropy": 0.005103272809223695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005779190105386078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03020790033042431,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07667441169420879,
      "backward_entropy": 0.00510060651735826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043379812268540263,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0302085280418396,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07665872573852539,
      "backward_entropy": 0.005526277490637519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005088838515803218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030209125950932503,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07664347191651662,
      "backward_entropy": 0.005095452070236206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047012901632115245,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030209723860025406,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07662861545880635,
      "backward_entropy": 0.005523543127558448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023886786948423833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030210310593247414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07661407192548116,
      "backward_entropy": 0.005090446973388845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036415536305867136,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021082654595375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07660003999869029,
      "backward_entropy": 0.005088207057931207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032661372097209096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030211327597498894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07658642033735912,
      "backward_entropy": 0.005086032165722413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004195713554508984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030211808159947395,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07657318313916524,
      "backward_entropy": 0.005083949051120065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025794387329369783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030212296172976494,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07656015952428182,
      "backward_entropy": 0.006619628857482563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002995839458890259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030212750658392906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07654752333958943,
      "backward_entropy": 0.005079864778301932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003016430709976703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030213190242648125,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07653521001338959,
      "backward_entropy": 0.006618249822746624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002840165689121932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030213622376322746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652318974335988,
      "backward_entropy": 0.00507607717405666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002809509460348636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021404705941677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651143272717793,
      "backward_entropy": 0.005074229430068623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029668238130398095,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030214469879865646,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0764999787012736,
      "backward_entropy": 0.005512955175204711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025249793543480337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021490015089512,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07648873329162598,
      "backward_entropy": 0.005070580000227148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028290573391132057,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030215326696634293,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07647779583930969,
      "backward_entropy": 0.005511008880355142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021408205793704838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030215760692954063,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07646700739860535,
      "backward_entropy": 0.0050669461488723755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000213190185604617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021618165075779,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07645650207996368,
      "backward_entropy": 0.005065171217376535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014362888759933412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021659515798092,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07644624511400859,
      "backward_entropy": 0.005063435570760207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002331365249119699,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03021698072552681,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07643635074297588,
      "backward_entropy": 0.005507166751406409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016064629016909748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030217377468943596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07642660041650136,
      "backward_entropy": 0.005060142752799121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015141928452067077,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03021775744855404,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07641712824503581,
      "backward_entropy": 0.0066102377393028955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016080119530670345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021812252700329,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07640789945920308,
      "backward_entropy": 0.005057016556913202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016677363601047546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021848015487194,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.076398899157842,
      "backward_entropy": 0.005055504089052027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011645651829894632,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030218839645385742,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07639008263746898,
      "backward_entropy": 0.005502823401581158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001337432477157563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021918050944805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0763815591732661,
      "backward_entropy": 0.005052571608261628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011706217628670856,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030219515785574913,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07637324432531993,
      "backward_entropy": 0.006607005541974848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011226769129280001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03021984174847603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07636516292889912,
      "backward_entropy": 0.005049800669605082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011153786181239411,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022015653550625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07635728518168132,
      "backward_entropy": 0.00504847683689811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012154786963947117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022046387195587,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07634961605072021,
      "backward_entropy": 0.00660523230379278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011361533688614145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030220774933695793,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07634209096431732,
      "backward_entropy": 0.00504590401595289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.715715714264661e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030221087858080864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07633472979068756,
      "backward_entropy": 0.005044600503011184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.12733342172578e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030221395194530487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07632756233215332,
      "backward_entropy": 0.005496812137690457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.553056250093505e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030221691355109215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07632059355576833,
      "backward_entropy": 0.005042108961127021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.977336645126343e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030221981927752495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07631380359331767,
      "backward_entropy": 0.005040914497592233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.280872185016051e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030222268775105476,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0763071874777476,
      "backward_entropy": 0.006601547653024847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.012100832071155e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030222540721297264,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07630078494548798,
      "backward_entropy": 0.0066009712490168486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.253744529909454e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030222807079553604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07629453639189403,
      "backward_entropy": 0.005037534643303265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.670478665502742e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022305853664875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07628849148750305,
      "backward_entropy": 0.005036483095450835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.229233283898793e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030223293229937553,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0762826402982076,
      "backward_entropy": 0.005035507746718146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.139189670444466e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022351861000061,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07627696295579274,
      "backward_entropy": 0.005034564232284372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1532868383219466e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022373840212822,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07627145449320476,
      "backward_entropy": 0.005033637989651073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.280336725059897e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022395446896553,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07626607517401378,
      "backward_entropy": 0.006598116999322718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.152187804924324e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030224163085222244,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07626085480054219,
      "backward_entropy": 0.005490405654365366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.822451981250197e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030224373564124107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0762557586034139,
      "backward_entropy": 0.005030989308248867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.564789949450642e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030224574729800224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07625079651673634,
      "backward_entropy": 0.005030152133919976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.524843486957252e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030224768444895744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07624596854050954,
      "backward_entropy": 0.005029333586042578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1509549444308504e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030224956572055817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07624126474062602,
      "backward_entropy": 0.005488600581884384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7600266548688523e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030225135385990143,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07623669505119324,
      "backward_entropy": 0.0050277994437651205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6084182536578737e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030225304886698723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07623225450515747,
      "backward_entropy": 0.005027080801400271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.250006921007298e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030225466936826706,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07622794310251872,
      "backward_entropy": 0.006595143540339036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7960126317339018e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030225630849599838,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07622372607390086,
      "backward_entropy": 0.00502570549195463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.969955858134199e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022579289972782,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07621962328751881,
      "backward_entropy": 0.005025031214410608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0959098037565127e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030225956812500954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07621561487515767,
      "backward_entropy": 0.005024356598203833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2664080461254343e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022611327469349,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07621174554030101,
      "backward_entropy": 0.005023696205832742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5323357729357667e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030226267874240875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07620797057946523,
      "backward_entropy": 0.005023049359971827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7941136320587248e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030226411297917366,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07620433966318767,
      "backward_entropy": 0.0050224516202103005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7591502910363488e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03022654913365841,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07620079318682353,
      "backward_entropy": 0.005484986034306613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7976981325773522e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030226683244109154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07619736591974895,
      "backward_entropy": 0.005021301860159094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2416306162776891e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022681549191475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07619402805964152,
      "backward_entropy": 0.005020746453241868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2939020962221548e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030226940289139748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07619077463944753,
      "backward_entropy": 0.0050202174620194865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1465469469840173e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022705763578415,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07618765036265056,
      "backward_entropy": 0.006592037325555628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4174966054270044e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030227169394493103,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07618460555871327,
      "backward_entropy": 0.005019239742647518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.105272167478688e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030227281153202057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07618164519468944,
      "backward_entropy": 0.0050187750973484735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0327631571271922e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030227389186620712,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07617876927057902,
      "backward_entropy": 0.0054831508208404885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65684160089586e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022749349474907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07617597778638203,
      "backward_entropy": 0.005017864433201877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100741069938522e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022759221494198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07617328564325969,
      "backward_entropy": 0.005017453635280783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.788640116108581e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022768348455429,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07617067297299702,
      "backward_entropy": 0.005017044192010706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.398695288429735e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030227772891521454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07616814970970154,
      "backward_entropy": 0.005482360381971706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.549348538304912e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022785857319832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07616569598515828,
      "backward_entropy": 0.005016297101974487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.030607321212301e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030227942392230034,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07616332670052846,
      "backward_entropy": 0.005482016639275985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4264392019831575e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0302280243486166,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07616103688875835,
      "backward_entropy": 0.006590204482728785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.363450782169821e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022810071706772,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07615881164868672,
      "backward_entropy": 0.005015245892784812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.942868028796511e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022817149758339,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07615665594736735,
      "backward_entropy": 0.0050149285657839346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.853937182109803e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022824227809906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07615456978480022,
      "backward_entropy": 0.005014622753316706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.866231054416858e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022831305861473,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07615253825982411,
      "backward_entropy": 0.005014315247535706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.004214133601636e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030228378251194954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07615057627360027,
      "backward_entropy": 0.00501402501355518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.104407253180398e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03022843971848488,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07614868879318237,
      "backward_entropy": 0.005481050095774911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.407876076584216e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030228499323129654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0761468509833018,
      "backward_entropy": 0.005013495683670044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3976868962781737e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03022855892777443,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.076145072778066,
      "backward_entropy": 0.005480825223705985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.847273890438373e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030228614807128906,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07614335417747498,
      "backward_entropy": 0.00658915869214318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6517843707551947e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030228666961193085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07614170014858246,
      "backward_entropy": 0.005480622026053342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6768688005395234e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030228715389966965,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07614010075728099,
      "backward_entropy": 0.0065889866514639425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5807350994000444e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030228767544031143,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07613853613535564,
      "backward_entropy": 0.0054804330522363835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1381088117777836e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030228815972805023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07613703608512878,
      "backward_entropy": 0.005012076009403576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0806778593396302e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030228862538933754,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07613558570543925,
      "backward_entropy": 0.005480258302255111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.369371713939472e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030228905379772186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07613417506217957,
      "backward_entropy": 0.005011675371365113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2681056179862935e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03022894822061062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0761328140894572,
      "backward_entropy": 0.005480108951980417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.801808593882015e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022899106144905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07613150278727214,
      "backward_entropy": 0.005011294375766407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.610503545634856e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229032039642334,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07613023618857066,
      "backward_entropy": 0.005479954860427163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5693939303673687e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229071155190468,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07612900932629903,
      "backward_entropy": 0.00501093708656051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2095280226276373e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229108408093452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07612781723340352,
      "backward_entropy": 0.005010766400532289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6472687320856494e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022914193570614,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07612667481104533,
      "backward_entropy": 0.006588238206776706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.322981347584573e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229175463318825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07612556715806325,
      "backward_entropy": 0.005010458556088534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4674611747977906e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022920899093151,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07612449924151103,
      "backward_entropy": 0.006588113578883084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.412208234796708e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229242518544197,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07612344622612,
      "backward_entropy": 0.005010163242166693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1398857395761297e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030229276046156883,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07612243294715881,
      "backward_entropy": 0.006587977436455813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.308515700467979e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022930957376957,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07612145443757375,
      "backward_entropy": 0.005009865218942816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469023669022135e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229341238737106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07612050573031108,
      "backward_entropy": 0.0050097250125624914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.273636578654987e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229371041059494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611959179242452,
      "backward_entropy": 0.005009587854146957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.059136007432244e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03022940084338188,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07611870765686035,
      "backward_entropy": 0.005479300902648406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.143392508623947e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022943064570427,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611786325772603,
      "backward_entropy": 0.005009329454465346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.630841878381034e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030229458585381508,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07611703375975291,
      "backward_entropy": 0.006587587296962738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.206435045896797e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229486525058746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611624399820964,
      "backward_entropy": 0.005009084939956665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.076024649497413e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229514464735985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07611547410488129,
      "backward_entropy": 0.005479099398309534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.584543944474717e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229540541768074,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611473401387532,
      "backward_entropy": 0.00500885701992295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.128023872202903e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229564756155014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611402869224548,
      "backward_entropy": 0.005008754405108365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.748492870021437e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229587107896805,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0761133333047231,
      "backward_entropy": 0.00500865483825857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.346935267880326e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229609459638596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611267268657684,
      "backward_entropy": 0.005008557642048056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8635749888271675e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229631811380386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611202200253804,
      "backward_entropy": 0.005008460784500296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5820781363327114e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229652300477028,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07611141105492909,
      "backward_entropy": 0.005478859625079415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5015702337659604e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022967278957367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611080010732015,
      "backward_entropy": 0.005008284002542496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1741683415020816e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022969327867031,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07611023386319478,
      "backward_entropy": 0.005008193918249824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1778000675330986e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229711905121803,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610967755317688,
      "backward_entropy": 0.005008106881921942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.638919056607847e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229730531573296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610913117726643,
      "backward_entropy": 0.005008033392104236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1526303700957214e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229749158024788,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610861460367839,
      "backward_entropy": 0.005007950081066651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.205981672886992e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022976778447628,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07610811789830525,
      "backward_entropy": 0.006586895070292733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.756988297074713e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030229784548282623,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07610762119293213,
      "backward_entropy": 0.006586855108087713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7507926486359793e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229801312088966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610715428988139,
      "backward_entropy": 0.005007720806381919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2037067165238113e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022981621325016,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610670725504558,
      "backward_entropy": 0.005007659847086126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3666331710737722e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229829251766205,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07610627015431722,
      "backward_entropy": 0.005478556521914222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4641173606833036e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022984229028225,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610586285591125,
      "backward_entropy": 0.005007550459016453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1768879915052821e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229855328798294,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610546549161275,
      "backward_entropy": 0.005007498643615029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2179862096672878e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022986650466919,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0761050929625829,
      "backward_entropy": 0.005007447844201868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.487889940373861e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229877680540085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07610473036766052,
      "backward_entropy": 0.00547848032279448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.452157373994851e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03022988885641098,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0761043777068456,
      "backward_entropy": 0.005478470840237357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.058005900897115e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229898169636726,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0761040449142456,
      "backward_entropy": 0.005478460680354725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.134344480798973e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229907482862473,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07610371708869934,
      "backward_entropy": 0.005478443408554251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.280403562821448e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022991679608822,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.076103409131368,
      "backward_entropy": 0.005007219246842645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.030825344145342e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229926109313965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0761031061410904,
      "backward_entropy": 0.00547842342745174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.658054729768992e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022993542253971,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610282301902771,
      "backward_entropy": 0.005007135258479552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.727245960291839e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229942873120308,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610254486401875,
      "backward_entropy": 0.0050071044401689005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.442841199965187e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229950323700905,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.076102281610171,
      "backward_entropy": 0.005478386851874265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0276859181176405e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229957774281502,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610202829043071,
      "backward_entropy": 0.005007029595700177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.821915038950465e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0302299652248621,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610178987185161,
      "backward_entropy": 0.005007003518668088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.572038747596707e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030229972675442696,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0761015514532725,
      "backward_entropy": 0.006586467677896673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3745782107862397e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229980126023293,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07610132296880086,
      "backward_entropy": 0.005478346889669245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.679923210597735e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03022998757660389,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610110441843669,
      "backward_entropy": 0.005006905983794819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3485936750944347e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030229993164539337,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610089083512624,
      "backward_entropy": 0.005006874149495905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2276098238526174e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030229998752474785,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07610069712003072,
      "backward_entropy": 0.005478321489962665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.914435981438146e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230004340410233,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610050837198894,
      "backward_entropy": 0.005006823350082745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.501417384337401e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03023000992834568,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07610032459100087,
      "backward_entropy": 0.005478316748684103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7170939276288664e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023001365363598,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07610014081001282,
      "backward_entropy": 0.005006778307936408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.895746931130816e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230017378926277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609997193018596,
      "backward_entropy": 0.005006761036135934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9905890269455995e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230022966861725,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609980305035909,
      "backward_entropy": 0.005006735297766599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.000731669227207e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230026692152023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0760996441046397,
      "backward_entropy": 0.005006720057942651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9596642530927966e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230030417442322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609949012597401,
      "backward_entropy": 0.0050066939809105615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.633636337317057e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03023003414273262,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609935104846954,
      "backward_entropy": 0.005478278818455609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1631582808036e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023003786802292,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609920700391133,
      "backward_entropy": 0.0050066614692861385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4270763237789197e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230041593313217,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609908282756805,
      "backward_entropy": 0.005006636069579558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.41543541332112e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230045318603516,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609894871711731,
      "backward_entropy": 0.006586313247680664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.614467444407637e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230049043893814,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609882454077403,
      "backward_entropy": 0.005478252064098011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0099711289512925e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230052769184113,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609871029853821,
      "backward_entropy": 0.005478249354795976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.435911524884432e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023005649447441,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609860102335612,
      "backward_entropy": 0.005006576464934783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.82702613832953e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023006021976471,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609849174817403,
      "backward_entropy": 0.005006562918424606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.705953126129316e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230063945055008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609839240709941,
      "backward_entropy": 0.005006539550694552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.430969617416849e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230067670345306,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609830300013225,
      "backward_entropy": 0.005478230728344483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1038854798644024e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230071395635605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609820862611134,
      "backward_entropy": 0.005006519908254797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5222528771992074e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230075120925903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609811425209045,
      "backward_entropy": 0.005006498911164023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.005791419738671e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230076983571053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609802484512329,
      "backward_entropy": 0.005006489767269654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.339653969509527e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230078846216202,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609795033931732,
      "backward_entropy": 0.005006478930061514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.434984018393152e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023008070886135,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609787583351135,
      "backward_entropy": 0.005006470802155408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.436351730419119e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0302300825715065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609779636065166,
      "backward_entropy": 0.0050064514983784066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.904517598130042e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03023008443415165,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609772682189941,
      "backward_entropy": 0.005478200587359342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.802597348112613e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0302300862967968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609766225020091,
      "backward_entropy": 0.005006432871926914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.763489075936377e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230088159441948,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609759271144867,
      "backward_entropy": 0.0050064271146600895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6039153883393737e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230090022087097,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609753807385762,
      "backward_entropy": 0.006586185910485007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.133436621283181e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230091884732246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609746853510539,
      "backward_entropy": 0.0050064034082672815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1941559680271894e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230093747377396,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609741886456807,
      "backward_entropy": 0.005478181960907849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.288402356498409e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230095610022545,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0760973592599233,
      "backward_entropy": 0.005478179251605814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.331908888209e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230097472667694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609730462233226,
      "backward_entropy": 0.005006380379199982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.997364051931072e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230099335312843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609724998474121,
      "backward_entropy": 0.005006377331235192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1042083631073183e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230101197957993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0760972003142039,
      "backward_entropy": 0.005006371235305613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6593162399658468e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230103060603142,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609716057777405,
      "backward_entropy": 0.006586143916303461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7662600271250994e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023010492324829,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609711090723674,
      "backward_entropy": 0.005006349899552085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4151595451039611e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023010678589344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609706620375316,
      "backward_entropy": 0.005006343803622506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5263168506862712e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03023010864853859,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0760970264673233,
      "backward_entropy": 0.005006340416994962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1984937486886338e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03023011051118374,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609698176383972,
      "backward_entropy": 0.006586134433746338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0265495120620471e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230112373828888,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609695196151733,
      "backward_entropy": 0.0050063309344378385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0109815207215433e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230114236474037,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609690725803375,
      "backward_entropy": 0.005006328225135803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.252651812450495e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230116099119186,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609687248865764,
      "backward_entropy": 0.006586128337816758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.937757118270383e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230117961764336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609683771928151,
      "backward_entropy": 0.005006320774555206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.381544264717377e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230119824409485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609681288401286,
      "backward_entropy": 0.005006305534731258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.909104399710486e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230121687054634,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609677811463673,
      "backward_entropy": 0.0054781518199227075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.444054179155501e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230123549699783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609674831231435,
      "backward_entropy": 0.005006299100138925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.407177011169551e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230125412344933,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0760967234770457,
      "backward_entropy": 0.0050062980841506614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.750706577600795e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609670360883077,
      "backward_entropy": 0.00658610463142395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.93287188874092e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609667380650838,
      "backward_entropy": 0.005006293004209345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.133084985369351e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609664897123973,
      "backward_entropy": 0.0050062899562445555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.354774318926502e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0760966291030248,
      "backward_entropy": 0.005006288262930783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.072617798556166e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609660426775615,
      "backward_entropy": 0.006586100567470898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6343550391393364e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609658439954121,
      "backward_entropy": 0.006586100567470898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1734259664517595e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0760965645313263,
      "backward_entropy": 0.0065860985354943705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.639453100528044e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609653969605763,
      "backward_entropy": 0.005478150126608935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3038637664285488e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609652479489644,
      "backward_entropy": 0.005006278103048151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.381383978899976e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07609650989373525,
      "backward_entropy": 0.0065860985354943705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0116885934839956e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609649499257405,
      "backward_entropy": 0.005478148771957917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4281376909129904e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609647512435913,
      "backward_entropy": 0.005006275055083362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0099122366445954e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609646022319794,
      "backward_entropy": 0.005006273023106835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.866169441200327e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609644532203674,
      "backward_entropy": 0.005006273023106835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6328982610502862e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609643538792928,
      "backward_entropy": 0.005006273023106835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.553459583192307e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609642545382182,
      "backward_entropy": 0.005478148771957917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2155965123383794e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07609641055266063,
      "backward_entropy": 0.0050062581219456415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4516388091578847e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030230127274990082,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07609639565149943,
      "backward_entropy": 0.005478148771957917,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.352288437623145e-08,
    "avg_log_Z": 0.030229991246014835,
    "success_rate": 1.0,
    "avg_reward": 50.2,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.13,
      "1": 0.24,
      "2": 0.63
    },
    "avg_forward_entropy": 0.07610082636276881,
    "avg_backward_entropy": 0.005325373255393723,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}