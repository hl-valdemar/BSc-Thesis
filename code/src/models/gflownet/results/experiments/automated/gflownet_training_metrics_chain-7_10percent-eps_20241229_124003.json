{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0990022165434701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.09896295411246163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.445924758911133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698194921016693,
      "backward_entropy": 0.0989823511668614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.040082931518555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369917392730713,
      "backward_entropy": 0.09895999942507062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.138663291931152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019993301248177886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700121641159058,
      "backward_entropy": 0.09897835765566144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.632253646850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0002998761192429811,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370105743408203,
      "backward_entropy": 0.0989537239074707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.531404495239258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003996883751824498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137019544839859,
      "backward_entropy": 0.09899563448769706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.527287483215332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004996652132831514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370285451412201,
      "backward_entropy": 0.09899382931845528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.71662425994873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005997475236654282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370374858379364,
      "backward_entropy": 0.098991973059518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.711727142333984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006999352481216192,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704638183116913,
      "backward_entropy": 0.0989671094076974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.219951629638672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008001970709301531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370552033185959,
      "backward_entropy": 0.09896472522190639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.304835319519043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009003987070173025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706380128860474,
      "backward_entropy": 0.09898602962493896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.196565628051758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010008557001128793,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370723843574524,
      "backward_entropy": 0.09895981209618705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.502252578735352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011014710180461407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708092272281647,
      "backward_entropy": 0.09898178918021065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.185746192932129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012020099675282836,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13708928227424622,
      "backward_entropy": 0.09895474570138114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.888625144958496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013026879169046879,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370975822210312,
      "backward_entropy": 0.09891806329999651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.695916175842285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001403394271619618,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371057629585266,
      "backward_entropy": 0.09891416345323835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.48546314239502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015040800208225846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13711370527744293,
      "backward_entropy": 0.09897252491542272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.957859992980957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016046564560383558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712146878242493,
      "backward_entropy": 0.09896999597549438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.766392707824707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017052689800038934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712914288043976,
      "backward_entropy": 0.09894102811813354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.256719589233398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018058663699775934,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713666796684265,
      "backward_entropy": 0.09889750821249825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.756789207458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0019066283712163568,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13714413344860077,
      "backward_entropy": 0.09889312301363264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.855313301086426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002007344039157033,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715144991874695,
      "backward_entropy": 0.09888861860547747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.106775283813477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021080649457871914,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715867698192596,
      "backward_entropy": 0.09892883471080235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.001654624938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0022081604693084955,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137165367603302,
      "backward_entropy": 0.0988790648324149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.920307159423828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023076629731804132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717153668403625,
      "backward_entropy": 0.0989217758178711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.982131958007812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024073459208011627,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371777057647705,
      "backward_entropy": 0.09886842114584786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.34133529663086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0025068973191082478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718360662460327,
      "backward_entropy": 0.09891416345323835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485767364501953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002606429625302553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718941807746887,
      "backward_entropy": 0.09893898453031268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.766972541809082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00270564341917634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719487190246582,
      "backward_entropy": 0.09890597207205636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.612909317016602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028046835213899612,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720011711120605,
      "backward_entropy": 0.09884539672306605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.222687721252441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029038789216428995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720539212226868,
      "backward_entropy": 0.09892657824925014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.373499870300293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003003054764121771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721056282520294,
      "backward_entropy": 0.09889256102698189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.318714141845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031019023153930902,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721540570259094,
      "backward_entropy": 0.09882634026663643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.088462829589844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003200833685696125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722020387649536,
      "backward_entropy": 0.09891266482216972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.77462100982666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032993610948324203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722455501556396,
      "backward_entropy": 0.09887765986578805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.794960021972656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0033986568450927734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722912967205048,
      "backward_entropy": 0.09890251500265938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.953251838684082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034981993958353996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137233704328537,
      "backward_entropy": 0.09886717796325684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.125405311584473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003597642295062542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723808526992798,
      "backward_entropy": 0.09889182022639684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.018438339233398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003697047708556056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724233210086823,
      "backward_entropy": 0.0988560404096331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.292956352233887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003796363016590476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724645972251892,
      "backward_entropy": 0.09888032504490443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.185458183288574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003895707195624709,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725051283836365,
      "backward_entropy": 0.09887427943093437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.181636810302734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003995019011199474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372544765472412,
      "backward_entropy": 0.0988680464880807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.797240257263184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004094303119927645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372583508491516,
      "backward_entropy": 0.098831193787711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.314159393310547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004193010274320841,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372617930173874,
      "backward_entropy": 0.09882421152932304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.311071395874023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004291892517358065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372651755809784,
      "backward_entropy": 0.09881711006164551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.961177825927734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004390930291265249,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726848363876343,
      "backward_entropy": 0.09872416087559291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.853102684020996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004490383900702,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13727182149887085,
      "backward_entropy": 0.09871493067060198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753646850585938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004590144380927086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13727521896362305,
      "backward_entropy": 0.0987945454461234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.118021011352539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00468973396345973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13727831840515137,
      "backward_entropy": 0.09881889820098877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.437538146972656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004789725411683321,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372816264629364,
      "backward_entropy": 0.09877831595284599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.925963401794434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004889332689344883,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13728463649749756,
      "backward_entropy": 0.09867616210665021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66273307800293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0049896687269210815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728785514831543,
      "backward_entropy": 0.09879468168531146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41293716430664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005090155638754368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729096949100494,
      "backward_entropy": 0.09878617525100708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.344131469726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005190581548959017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372939944267273,
      "backward_entropy": 0.09864563601357597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.88086986541748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00529096182435751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372969001531601,
      "backward_entropy": 0.09876842158181327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.082221984863281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00539152417331934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13729974627494812,
      "backward_entropy": 0.09872347967965263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.627106666564941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005492366850376129,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730253279209137,
      "backward_entropy": 0.09871353421892438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.022258758544922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005592831876128912,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730503618717194,
      "backward_entropy": 0.09860551357269287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.88998031616211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005694050341844559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373075395822525,
      "backward_entropy": 0.09872998510088239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.783485412597656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005794954020529985,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730981945991516,
      "backward_entropy": 0.09858460085732597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.83339786529541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005895514506846666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1373118758201599,
      "backward_entropy": 0.09867077214377266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.983686447143555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005995286628603935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137313574552536,
      "backward_entropy": 0.09865907260349818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.937689781188965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0060949670150876045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731509447097778,
      "backward_entropy": 0.09864698137555804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14040470123291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006194490939378738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373165249824524,
      "backward_entropy": 0.09867475714002337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.24201774597168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006294001825153828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731783628463745,
      "backward_entropy": 0.09866256373269218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.662761688232422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006394030526280403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373191475868225,
      "backward_entropy": 0.09865002121244158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.762592315673828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006493745371699333,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732029497623444,
      "backward_entropy": 0.09859499761036464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700737953186035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0065932441502809525,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13732129335403442,
      "backward_entropy": 0.0984851632799421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.284337043762207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006692563183605671,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732218742370605,
      "backward_entropy": 0.09860960074833461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.261191368103027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00679194089025259,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732300698757172,
      "backward_entropy": 0.09855185236249651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.276796340942383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006891927216202021,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373237669467926,
      "backward_entropy": 0.09844134535108294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31653881072998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006991895381361246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732445240020752,
      "backward_entropy": 0.09856562955038888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31253433227539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007091921288520098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1373250037431717,
      "backward_entropy": 0.09850588015147618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.901248931884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007191997487097979,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373254656791687,
      "backward_entropy": 0.098395117691585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.250025749206543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007291861809790134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732585310935974,
      "backward_entropy": 0.0985180139541626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35852336883545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007392188999801874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732615113258362,
      "backward_entropy": 0.09850125653403145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527874946594238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007492516655474901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732635974884033,
      "backward_entropy": 0.09848402227674212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625931739807129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007592419162392616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373264491558075,
      "backward_entropy": 0.09846627712249756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.345251083374023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007692006416618824,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373264342546463,
      "backward_entropy": 0.09830258573804583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.556376457214355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007791673764586449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732630014419556,
      "backward_entropy": 0.09842934778758458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.31583023071289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007891451008617878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732607662677765,
      "backward_entropy": 0.09835946559906006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.871413230895996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007991758175194263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732567429542542,
      "backward_entropy": 0.09833885090691703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.943485260009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008092837408185005,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13732510805130005,
      "backward_entropy": 0.09821747030530657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.220096588134766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00819411687552929,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373242884874344,
      "backward_entropy": 0.09835147857666016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.774855613708496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0082952119410038,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137323260307312,
      "backward_entropy": 0.09827572107315063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08443832397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008396447636187077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373220682144165,
      "backward_entropy": 0.098150406564985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76325798034668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008496969938278198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732081651687622,
      "backward_entropy": 0.09823083877563477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.098700523376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008597691543400288,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731935620307922,
      "backward_entropy": 0.09810238225119454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.953469276428223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008698215708136559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373177319765091,
      "backward_entropy": 0.0982466425214495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730491638183594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008799063041806221,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731592893600464,
      "backward_entropy": 0.09822227273668561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372476577758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008899605832993984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1373140513896942,
      "backward_entropy": 0.09813281467982701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.271393775939941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008999694138765335,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731223344802856,
      "backward_entropy": 0.09799948760441371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.081177711486816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009099219925701618,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731037080287933,
      "backward_entropy": 0.09807922158922468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.608457565307617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00919922161847353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373082399368286,
      "backward_entropy": 0.09811796460832868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.968493461608887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009298381395637989,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730625808238983,
      "backward_entropy": 0.09791426147733416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.557215690612793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009397990070283413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730400800704956,
      "backward_entropy": 0.09799386773790632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.903919219970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009497277438640594,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373017430305481,
      "backward_entropy": 0.09785398415156774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09910774230957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009596457704901695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729938864707947,
      "backward_entropy": 0.09800480093274798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.595705509185791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009695671498775482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372969150543213,
      "backward_entropy": 0.0979748112814767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.386740684509277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009794124402105808,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13729466497898102,
      "backward_entropy": 0.0978711588042123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.985027313232422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009893342852592468,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13729198276996613,
      "backward_entropy": 0.09783984933580671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.825776100158691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009992523118853569,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13728922605514526,
      "backward_entropy": 0.097807662827628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.819276809692383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01009207870811224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728618621826172,
      "backward_entropy": 0.09784915617534093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.168466567993164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010191966779530048,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13728280365467072,
      "backward_entropy": 0.0976109334400722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.074565887451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010291867889463902,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372794359922409,
      "backward_entropy": 0.09757272686277117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.947650909423828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010391252115368843,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13727639615535736,
      "backward_entropy": 0.09766920123781477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447471618652344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010491032153367996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13727280497550964,
      "backward_entropy": 0.09771119696753365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.328194618225098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01059093326330185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726890087127686,
      "backward_entropy": 0.09767493179866246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74603271484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010691425763070583,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726451992988586,
      "backward_entropy": 0.09741107906614031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495594024658203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01079159788787365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726019859313965,
      "backward_entropy": 0.09760008539472308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.735218048095703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010891365818679333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725602626800537,
      "backward_entropy": 0.09756146158490862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.458353042602539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010990886949002743,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372515857219696,
      "backward_entropy": 0.09743965523583549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092142105102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011089528910815716,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724759221076965,
      "backward_entropy": 0.09722702843802315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.060346603393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011187761090695858,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724385201931,
      "backward_entropy": 0.09717731816428048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.736268997192383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011286088265478611,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723982870578766,
      "backward_entropy": 0.09712621995380946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.21314811706543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011384857818484306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723526895046234,
      "backward_entropy": 0.0972672871180943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21854019165039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011484247632324696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722997903823853,
      "backward_entropy": 0.0973114286150251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.472415924072266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011583193205296993,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137224942445755,
      "backward_entropy": 0.09696630069187709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.645590782165527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011682393960654736,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372196525335312,
      "backward_entropy": 0.09712472983769008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.417461395263672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011781413108110428,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372145712375641,
      "backward_entropy": 0.0968536649431501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.40732192993164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011881128884851933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720862567424774,
      "backward_entropy": 0.09712118761880058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.007164001464844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011981025338172913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720247149467468,
      "backward_entropy": 0.0970696210861206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.958126068115234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012080821208655834,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719616830348969,
      "backward_entropy": 0.09667912551334926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.581279754638672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012180540710687637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371898502111435,
      "backward_entropy": 0.09696290322712489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.511146545410156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012280561961233616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718335330486298,
      "backward_entropy": 0.09690787962504796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.075794219970703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012380233034491539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371770203113556,
      "backward_entropy": 0.09685163838522774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.971949577331543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012479880824685097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717050850391388,
      "backward_entropy": 0.09668324674878802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.255542755126953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012579972855746746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716334104537964,
      "backward_entropy": 0.09635981491633824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.192268371582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012680118903517723,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715606927871704,
      "backward_entropy": 0.09629198483058385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.903159141540527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012779694981873035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714927434921265,
      "backward_entropy": 0.09649337189538139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471036911010742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012879728339612484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371418535709381,
      "backward_entropy": 0.09654666696275983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.230588912963867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012979392893612385,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713467121124268,
      "backward_entropy": 0.09635983194623675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262839317321777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013078611344099045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712796568870544,
      "backward_entropy": 0.09641537496021815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.411420822143555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013177411630749702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712146878242493,
      "backward_entropy": 0.0962197014263698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.843129634857178,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01327598374336958,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711538910865784,
      "backward_entropy": 0.09585753508976527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.498435974121094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013374057598412037,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13711044192314148,
      "backward_entropy": 0.09607035773141044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56314754486084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013472456485033035,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13710445165634155,
      "backward_entropy": 0.09570155824933733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.499903678894043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013570692390203476,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709834218025208,
      "backward_entropy": 0.09562046187264579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.855424880981445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013669328764081001,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709169626235962,
      "backward_entropy": 0.09598961898258754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827869415283203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013768479228019714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370840221643448,
      "backward_entropy": 0.0957553471837725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.81911563873291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013867572881281376,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707640767097473,
      "backward_entropy": 0.09536586488996233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.81020450592041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01396661251783371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706879317760468,
      "backward_entropy": 0.09575465747288295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41756820678711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014065600000321865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137061208486557,
      "backward_entropy": 0.0956730842590332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.467937469482422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014164278283715248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705366849899292,
      "backward_entropy": 0.09558980805533272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.010695457458496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014262759126722813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704638183116913,
      "backward_entropy": 0.09550491401127406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.318510055541992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014361348934471607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703885674476624,
      "backward_entropy": 0.09541811261858259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.481501579284668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014459696598351002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370319426059723,
      "backward_entropy": 0.09513306617736816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.336945533752441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014558365568518639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370238959789276,
      "backward_entropy": 0.0952378341129848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.327452659606934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014656759798526764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370162069797516,
      "backward_entropy": 0.09493764809199742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.448755264282227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014755414798855782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370077133178711,
      "backward_entropy": 0.09483603068760463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.17835807800293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014853835105895996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136999249458313,
      "backward_entropy": 0.09494480064937047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61814022064209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014951949007809162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699141144752502,
      "backward_entropy": 0.09462074722562518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.245466232299805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015050007030367851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698357343673706,
      "backward_entropy": 0.09473931789398193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.317605972290039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015148363076150417,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369749903678894,
      "backward_entropy": 0.09439468383789062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55141830444336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01524754986166954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13696451485157013,
      "backward_entropy": 0.09427836963108607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.747785568237305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015346572734415531,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13695459067821503,
      "backward_entropy": 0.09380561113357544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.100737571716309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01544605940580368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694347441196442,
      "backward_entropy": 0.09430669886725289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.563907623291016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01554560661315918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13693195581436157,
      "backward_entropy": 0.09391348702566964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.294622421264648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015645403414964676,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691911101341248,
      "backward_entropy": 0.09343063831329346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.211548805236816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01574532501399517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690561056137085,
      "backward_entropy": 0.09395171914781843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.732303619384766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015844782814383507,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689285516738892,
      "backward_entropy": 0.09316618101937431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.437514305114746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01594410464167595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687999546527863,
      "backward_entropy": 0.09369911466326032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79883861541748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016043106094002724,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13686686754226685,
      "backward_entropy": 0.09289351531437465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721009254455566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016142072156071663,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13685354590415955,
      "backward_entropy": 0.09275313786097936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.904836177825928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016240915283560753,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683955371379852,
      "backward_entropy": 0.09261024849755424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.310481071472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016339292749762535,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136827290058136,
      "backward_entropy": 0.09246523891176496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.339734077453613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016437942162156105,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13681340217590332,
      "backward_entropy": 0.09231735127312797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.3258638381958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016536330804228783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13679982721805573,
      "backward_entropy": 0.09288614988327026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.176285743713379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01663448102772236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678643107414246,
      "backward_entropy": 0.09274271556309291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.684921264648438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016731780022382736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677489757537842,
      "backward_entropy": 0.09259818281446185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.521780014038086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016829783096909523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367623209953308,
      "backward_entropy": 0.09244969912937709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.294004440307617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016927655786275864,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674892485141754,
      "backward_entropy": 0.0915356022971017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.464847564697266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01702529564499855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136735200881958,
      "backward_entropy": 0.09214353561401367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.78099536895752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017122849822044373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672122359275818,
      "backward_entropy": 0.09120115212031774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.803285598754883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017221050336956978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670489192008972,
      "backward_entropy": 0.09182119369506836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.509829998016357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01731877215206623,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13668985664844513,
      "backward_entropy": 0.09084972313472203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.81564998626709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017415275797247887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366775631904602,
      "backward_entropy": 0.09148781640189034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.004693984985352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017511997371912003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366637945175171,
      "backward_entropy": 0.09090195383344378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.971343040466309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017609013244509697,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13664814829826355,
      "backward_entropy": 0.0902915256364005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.234621047973633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017705729231238365,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366327852010727,
      "backward_entropy": 0.09054608004433769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.821589469909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017802365124225616,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13661763072013855,
      "backward_entropy": 0.08990034035273961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.313823699951172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01789981685578823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365998387336731,
      "backward_entropy": 0.09017447062901088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.587944030761719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017997687682509422,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658013939857483,
      "backward_entropy": 0.08949398994445801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.177973747253418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0180949904024601,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656222820281982,
      "backward_entropy": 0.08928493942533221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.439431190490723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018192091956734657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13654404878616333,
      "backward_entropy": 0.08999145030975342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.937653541564941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018289202824234962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13652583956718445,
      "backward_entropy": 0.08978605270385742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.798555374145508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018386008217930794,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13650797307491302,
      "backward_entropy": 0.0886351295879909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.003406524658203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01848304271697998,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13648873567581177,
      "backward_entropy": 0.08894239153180804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.43032169342041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018579799681901932,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13646917045116425,
      "backward_entropy": 0.08818259409495763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.635723114013672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018677176907658577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364474892616272,
      "backward_entropy": 0.08849317686898368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.827320575714111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018774624913930893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13642458617687225,
      "backward_entropy": 0.08825927121298653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.78243350982666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018871717154979706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13640335202217102,
      "backward_entropy": 0.08846246344702584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.698739051818848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018968990072607994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13637980818748474,
      "backward_entropy": 0.0882258415222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.24411678314209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01906580477952957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635680079460144,
      "backward_entropy": 0.08798602649143764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.934376239776611,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01916256733238697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13633409142494202,
      "backward_entropy": 0.0872718436377389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.864087104797363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019259104505181313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13631218671798706,
      "backward_entropy": 0.08749399866376605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603203773498535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01935596764087677,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13628827035427094,
      "backward_entropy": 0.08621501922607422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.28141975402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019452402368187904,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13626593351364136,
      "backward_entropy": 0.08595035757337298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.250462532043457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01954941637814045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362401396036148,
      "backward_entropy": 0.08671895946775164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.185497283935547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019646933302283287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362113207578659,
      "backward_entropy": 0.08588298729487828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.067829132080078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01974431984126568,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13618329167366028,
      "backward_entropy": 0.08558229889188494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.200557231903076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019841475412249565,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13615480065345764,
      "backward_entropy": 0.08484747580119542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.362776756286621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019937977194786072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13613037765026093,
      "backward_entropy": 0.08560011216572352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.980550765991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02003394439816475,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13610753417015076,
      "backward_entropy": 0.0842687657901219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3114471435546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020129820331931114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13608479499816895,
      "backward_entropy": 0.08397197723388672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.294127464294434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02022516541182995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13606229424476624,
      "backward_entropy": 0.08470382860728673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438617706298828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020321248099207878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360350102186203,
      "backward_entropy": 0.08439127036503383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.769980430603027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020417477935552597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13600541651248932,
      "backward_entropy": 0.08407192570822579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.655894756317139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020513461902737617,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13597624003887177,
      "backward_entropy": 0.08273335865565709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9771904945373535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020608583465218544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13595201075077057,
      "backward_entropy": 0.08261418342590332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.195530891418457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020703671500086784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13592565059661865,
      "backward_entropy": 0.0822575432913644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.442580223083496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02079946920275688,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13589346408843994,
      "backward_entropy": 0.08175402879714966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.253884315490723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020895492285490036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585951924324036,
      "backward_entropy": 0.08152418477194649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1631011962890625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020991012454032898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13582834601402283,
      "backward_entropy": 0.08114744084221977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.187492370605469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02108537219464779,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358020305633545,
      "backward_entropy": 0.08163340602602277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.628602981567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021179331466555595,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.135776549577713,
      "backward_entropy": 0.08037490504128593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902614116668701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021272549405694008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13575226068496704,
      "backward_entropy": 0.07999453374317714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.912759780883789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02136593870818615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13572591543197632,
      "backward_entropy": 0.08051128898348127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.105197906494141,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021458877250552177,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13570141792297363,
      "backward_entropy": 0.07923780168805804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.933250427246094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021550938487052917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13568294048309326,
      "backward_entropy": 0.07974159717559814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.23514986038208,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02164275199174881,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13566726446151733,
      "backward_entropy": 0.07837555238178798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.111536026000977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02173447795212269,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13565048575401306,
      "backward_entropy": 0.07795425823756627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50420618057251,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021826039999723434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13563251495361328,
      "backward_entropy": 0.07752789769853864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.544389724731445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021917805075645447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135615736246109,
      "backward_entropy": 0.0770951509475708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.33350133895874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022009722888469696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13559728860855103,
      "backward_entropy": 0.07772767543792725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.622323989868164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022101623937487602,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13557687401771545,
      "backward_entropy": 0.07730518920081002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.500617980957031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022193066775798798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13555771112442017,
      "backward_entropy": 0.07576461349214826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.875881195068359,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02228465862572193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13553565740585327,
      "backward_entropy": 0.0764442767415728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.255204200744629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022376008331775665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13551419973373413,
      "backward_entropy": 0.0760045051574707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.13308572769165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02246672473847866,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354951411485672,
      "backward_entropy": 0.07461225986480713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.584409713745117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022556785494089127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13547813892364502,
      "backward_entropy": 0.07511585099356514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.09000015258789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022646557539701462,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354609727859497,
      "backward_entropy": 0.07367525781903948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.389822006225586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022737082093954086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13543784618377686,
      "backward_entropy": 0.0729322178023202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3400092124938965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02282780036330223,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354108452796936,
      "backward_entropy": 0.07243707350322179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.486085891723633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022918665781617165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13538026809692383,
      "backward_entropy": 0.07193583250045776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.83668327331543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023009121417999268,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13535071909427643,
      "backward_entropy": 0.07172765050615583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.549910068511963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023099474608898163,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13532157242298126,
      "backward_entropy": 0.07122515780585152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.20919132232666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02318951115012169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352926343679428,
      "backward_entropy": 0.07169466359274727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.762635231018066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023279715329408646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352602243423462,
      "backward_entropy": 0.07117619684764318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.098884105682373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023369785398244858,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1352268010377884,
      "backward_entropy": 0.06967908995492118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.345624923706055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023459957912564278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13519008457660675,
      "backward_entropy": 0.07012176939419337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.369112968444824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023549748584628105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13515529036521912,
      "backward_entropy": 0.06958715404782977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.546249866485596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02363922819495201,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1351223886013031,
      "backward_entropy": 0.06808406114578247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.654867172241211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023728521540760994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13508827984333038,
      "backward_entropy": 0.06715653623853411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.984186172485352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02381707727909088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13505958020687103,
      "backward_entropy": 0.06796206746782575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.977167129516602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023905158042907715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350315660238266,
      "backward_entropy": 0.06603973252432686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.727405071258545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023993508890271187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349981129169464,
      "backward_entropy": 0.06686249801090785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.530481338500977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024081245064735413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13496701419353485,
      "backward_entropy": 0.06490575415747506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.762566089630127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024168267846107483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13493776321411133,
      "backward_entropy": 0.0657525360584259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.520460605621338,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024254869669675827,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13491085171699524,
      "backward_entropy": 0.06423031432288033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.522110462188721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024341564625501633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348775327205658,
      "backward_entropy": 0.0646294185093471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.896503448486328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02442839927971363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13484027981758118,
      "backward_entropy": 0.06260637726102557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.25623083114624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024514127522706985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13480646908283234,
      "backward_entropy": 0.0634860098361969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.114389419555664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02459920197725296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13477647304534912,
      "backward_entropy": 0.06291653428758893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.801880359649658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024684341624379158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13474498689174652,
      "backward_entropy": 0.060862575258527486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.989449501037598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024768531322479248,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13471820950508118,
      "backward_entropy": 0.060276925563812256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.240533351898193,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024852799251675606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1346895396709442,
      "backward_entropy": 0.059684583118983676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6573166847229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02493656799197197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13466286659240723,
      "backward_entropy": 0.06061030285699027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.262612819671631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02502022124826908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13463544845581055,
      "backward_entropy": 0.06002672229494367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.660444736480713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025103451684117317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13460834324359894,
      "backward_entropy": 0.05789004053388323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.806005954742432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025185855105519295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13458576798439026,
      "backward_entropy": 0.057290102754320414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.342135429382324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02526840940117836,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13455912470817566,
      "backward_entropy": 0.05728213701929365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.156671047210693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025350745767354965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345314085483551,
      "backward_entropy": 0.05767888682229178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.63585901260376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02543272264301777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345023512840271,
      "backward_entropy": 0.05708405801228115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.148798942565918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025514714419841766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1344660222530365,
      "backward_entropy": 0.054848590067454746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.291832447052002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025596413761377335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13442933559417725,
      "backward_entropy": 0.05587047338485718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.844677448272705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025677936151623726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13439036905765533,
      "backward_entropy": 0.055258759430476596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.270364284515381,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02575894631445408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13435301184654236,
      "backward_entropy": 0.053000565086092265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.455842971801758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025839874520897865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13431262969970703,
      "backward_entropy": 0.054031742470605035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5036845207214355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025920065119862556,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13427531719207764,
      "backward_entropy": 0.05176622952733721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.189897537231445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025999663397669792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13424085080623627,
      "backward_entropy": 0.05114978126117161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.011954307556152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026079274713993073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13420122861862183,
      "backward_entropy": 0.0505316470350538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.351485729217529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026158733293414116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13415654003620148,
      "backward_entropy": 0.04991469212940761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.568663120269775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026238368824124336,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1341046243906021,
      "backward_entropy": 0.04929585116250174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.129419326782227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026317501440644264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13405169546604156,
      "backward_entropy": 0.050334112984793525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.287866115570068,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02639584429562092,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13400274515151978,
      "backward_entropy": 0.04898113438061306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.292844772338867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0264736358076334,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13395598530769348,
      "backward_entropy": 0.049102996076856344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.393818378448486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026550916954874992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13390938937664032,
      "backward_entropy": 0.04848781653812954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.943474769592285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026627840474247932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13386142253875732,
      "backward_entropy": 0.04623094201087952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.854167938232422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704031974077225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13381503522396088,
      "backward_entropy": 0.047262034245899746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.905900716781616,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026779524981975555,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1337718665599823,
      "backward_entropy": 0.04606036628995623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.116196632385254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026854433119297028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1337299793958664,
      "backward_entropy": 0.04441996131624494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9150004386901855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026929005980491638,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13368582725524902,
      "backward_entropy": 0.04545112592833383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3353207111358643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027003061026334763,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1336398869752884,
      "backward_entropy": 0.044339392866407125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.910996437072754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027076097205281258,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13359731435775757,
      "backward_entropy": 0.0426358027117593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6477534770965576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027147885411977768,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13356488943099976,
      "backward_entropy": 0.04320850542613438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.211383104324341,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027219228446483612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13353082537651062,
      "backward_entropy": 0.04310165984289987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.007080078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027289776131510735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13350065052509308,
      "backward_entropy": 0.04209409015519278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5720362663269043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02736038714647293,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1334635615348816,
      "backward_entropy": 0.041541257074901035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.915045738220215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027430657297372818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13342538475990295,
      "backward_entropy": 0.04138217227799552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6825380325317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027499916031956673,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13339175283908844,
      "backward_entropy": 0.040446502821786065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8369131088256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027569040656089783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13335098326206207,
      "backward_entropy": 0.04025283030101231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4033055305480957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02763720415532589,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13331443071365356,
      "backward_entropy": 0.039365679025650024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4798061847686768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027705026790499687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1332707703113556,
      "backward_entropy": 0.03753893290247236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.734013557434082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027772681787610054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13322074711322784,
      "backward_entropy": 0.03858173745019095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3449840545654297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027839448302984238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13317570090293884,
      "backward_entropy": 0.03803249767848423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.508840322494507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027906032279133797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13312436640262604,
      "backward_entropy": 0.03748329196657453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.95072603225708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0279726330190897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1330638825893402,
      "backward_entropy": 0.03539473244122097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.655734062194824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02803870663046837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13300380110740662,
      "backward_entropy": 0.03638629402433123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5393612384796143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028105109930038452,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13293421268463135,
      "backward_entropy": 0.035695880651474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9464120864868164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028170542791485786,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1328691840171814,
      "backward_entropy": 0.035296495471681864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.062735080718994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02823551744222641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13279931247234344,
      "backward_entropy": 0.03475705427782876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.456641912460327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028300251811742783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13272327184677124,
      "backward_entropy": 0.03421900953565325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.748568058013916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028364039957523346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13264840841293335,
      "backward_entropy": 0.03369017371109554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.855771780014038,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02842738851904869,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1325712502002716,
      "backward_entropy": 0.03178618635450091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8732335567474365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02849051170051098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13249066472053528,
      "backward_entropy": 0.03129019907542637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6091368198394775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02855345606803894,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13240480422973633,
      "backward_entropy": 0.03225468099117279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2477784156799316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028615938499569893,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13231736421585083,
      "backward_entropy": 0.031784508909497945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.057950735092163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028677519410848618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13223177194595337,
      "backward_entropy": 0.031101437551634654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1876187324523926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02873803675174713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13214966654777527,
      "backward_entropy": 0.029354844774518694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0488815307617188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028797760605812073,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13206696510314941,
      "backward_entropy": 0.030414858034678867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8703428506851196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028856661170721054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1319880485534668,
      "backward_entropy": 0.02964273520878383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8659684658050537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028914570808410645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1319141983985901,
      "backward_entropy": 0.029175724302019392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.007169723510742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028971614316105843,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13184534013271332,
      "backward_entropy": 0.029107447181429182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8802732229232788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02902808226644993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13177719712257385,
      "backward_entropy": 0.027114670191492354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1619873046875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029083874076604843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1317117065191269,
      "backward_entropy": 0.027821840984480723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5402264595031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02913939580321312,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13163866102695465,
      "backward_entropy": 0.027850180864334106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9791734218597412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029193758964538574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.131569504737854,
      "backward_entropy": 0.026949073587145125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.857195496559143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029247768223285675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1314949095249176,
      "backward_entropy": 0.026521872196878706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5496443510055542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029301300644874573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13141724467277527,
      "backward_entropy": 0.026099498782839094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.669704794883728,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02935393899679184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13134218752384186,
      "backward_entropy": 0.025686349187578474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4937975406646729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029405968263745308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13126572966575623,
      "backward_entropy": 0.02527929629598345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5829702615737915,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029457204043865204,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13119220733642578,
      "backward_entropy": 0.02548703338418688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3197017908096313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029507797211408615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13111470639705658,
      "backward_entropy": 0.023489628519330705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6585792303085327,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029557395726442337,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13103915750980377,
      "backward_entropy": 0.024744391441345215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3489198684692383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029606681317090988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13095635175704956,
      "backward_entropy": 0.02372430052076067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0423778295516968,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02965525910258293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13087692856788635,
      "backward_entropy": 0.02241104415484837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2459940910339355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029702624306082726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13080573081970215,
      "backward_entropy": 0.02299105269568307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1256842613220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029749222099781036,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13073396682739258,
      "backward_entropy": 0.02333794747080122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.371168613433838,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029794970527291298,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13066595792770386,
      "backward_entropy": 0.02300504275730678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9995924830436707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029840361326932907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13059166073799133,
      "backward_entropy": 0.021951121943337575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1966795921325684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029884804040193558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13052310049533844,
      "backward_entropy": 0.020754367113113403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1836544275283813,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029928680509328842,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13044960796833038,
      "backward_entropy": 0.020442668880735124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.083838939666748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029972059652209282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13037189841270447,
      "backward_entropy": 0.020968415907451084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0830857753753662,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030014801770448685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13029199838638306,
      "backward_entropy": 0.019836651427405223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.163266658782959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030057020485401154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13021054863929749,
      "backward_entropy": 0.02033935913017818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7134035229682922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009895049035549,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1301242709159851,
      "backward_entropy": 0.02003020261015211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.75178062915802,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030139721930027008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13004808127880096,
      "backward_entropy": 0.0189650867666517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8548715114593506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030179549008607864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12997941672801971,
      "backward_entropy": 0.019443724836621965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9530413150787354,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030218712985515594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12991201877593994,
      "backward_entropy": 0.01916115837437766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.613020658493042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030257467180490494,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12983988225460052,
      "backward_entropy": 0.019738061087472097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6981319785118103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030295060947537422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1297733187675476,
      "backward_entropy": 0.018613474709647044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6894311308860779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030331827700138092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12970857322216034,
      "backward_entropy": 0.018352031707763672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9236677885055542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030367860570549965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12964580953121185,
      "backward_entropy": 0.018097068582262312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6002825498580933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030403781682252884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12957456707954407,
      "backward_entropy": 0.017842821776866913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9664791822433472,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030438752844929695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1295047253370285,
      "backward_entropy": 0.016910001635551453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6777203679084778,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030473804101347923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12942169606685638,
      "backward_entropy": 0.016676104494503567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5697928071022034,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030508285388350487,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12933871150016785,
      "backward_entropy": 0.018045725567000254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7597331404685974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030541865155100822,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.129256010055542,
      "backward_entropy": 0.01622485156570162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6187307834625244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030575193464756012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12916618585586548,
      "backward_entropy": 0.016639350780418942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.442474901676178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030607920140028,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12907442450523376,
      "backward_entropy": 0.016411565244197845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4979442358016968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030639704316854477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12898990511894226,
      "backward_entropy": 0.01619207113981247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5044503211975098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030670693144202232,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12890593707561493,
      "backward_entropy": 0.015384915683950697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4199627935886383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070107288658619,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12882328033447266,
      "backward_entropy": 0.016788316624505178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41276779770851135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030730538070201874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1287418156862259,
      "backward_entropy": 0.014998888330800193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43402183055877686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030759191140532494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12866175174713135,
      "backward_entropy": 0.015376056943620955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5850422382354736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030787203460931778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1285816729068756,
      "backward_entropy": 0.015186783458505358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5482242107391357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030815064907073975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12849228084087372,
      "backward_entropy": 0.014460906386375427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3880556523799896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030842749401926994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12839651107788086,
      "backward_entropy": 0.014287182262965612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5072481632232666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030869759619235992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12830214202404022,
      "backward_entropy": 0.014629060668604714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4658682644367218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030896566808223724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1282019317150116,
      "backward_entropy": 0.01444873000894274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3598073720932007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030923085287213326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12809833884239197,
      "backward_entropy": 0.014270612171718053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40297067165374756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030948907136917114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12799465656280518,
      "backward_entropy": 0.013627820781299047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33866041898727417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03097432292997837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12788881361484528,
      "backward_entropy": 0.013471904609884535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.290336936712265,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030999137088656425,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1277836263179779,
      "backward_entropy": 0.014924072793551854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35998550057411194,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031023139134049416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12767913937568665,
      "backward_entropy": 0.0131741464138031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3344644606113434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03104681521654129,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12757301330566406,
      "backward_entropy": 0.013030554567064558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29711249470710754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031070007011294365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1274641752243042,
      "backward_entropy": 0.013295315206050873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2467103749513626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031092582270503044,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12735363841056824,
      "backward_entropy": 0.012755542993545532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3169157803058624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031114408746361732,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12724438309669495,
      "backward_entropy": 0.014234972851616996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32322439551353455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031135916709899902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1271318793296814,
      "backward_entropy": 0.012863072965826308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2897583544254303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03115719184279442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12701569497585297,
      "backward_entropy": 0.012723774782248906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22901089489459991,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031178083270788193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12689684331417084,
      "backward_entropy": 0.012587290789399828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23165903985500336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031198393553495407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12677937746047974,
      "backward_entropy": 0.012455100459711892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22391526401042938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03121813014149666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12666113674640656,
      "backward_entropy": 0.012326863195214952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24496088922023773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03123735822737217,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12654270231723785,
      "backward_entropy": 0.011903288108961923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2797938287258148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125625103712082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12642188370227814,
      "backward_entropy": 0.01207990518638066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22354096174240112,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031275078654289246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1262962371110916,
      "backward_entropy": 0.011958054133823939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16091351211071014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129350021481514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12616866827011108,
      "backward_entropy": 0.011839007692677634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17910966277122498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131123632192612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12604396045207977,
      "backward_entropy": 0.011724784970283508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19481708109378815,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132845461368561,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1259196251630783,
      "backward_entropy": 0.011380493640899658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1634065955877304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03134525194764137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257929652929306,
      "backward_entropy": 0.011506110429763794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1453518271446228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031361524015665054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1256665289402008,
      "backward_entropy": 0.011401658611638206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1606162041425705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031377241015434265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1255415976047516,
      "backward_entropy": 0.011104803000177656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1849260777235031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03139255568385124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12541596591472626,
      "backward_entropy": 0.011202923953533173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06712326407432556,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031407680362463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12528693675994873,
      "backward_entropy": 0.011106068534510476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15989309549331665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03142179176211357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12516462802886963,
      "backward_entropy": 0.010855413973331451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10731805860996246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03143570199608803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12503980100154877,
      "backward_entropy": 0.010927087494305201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12051241844892502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03144906088709831,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12491728365421295,
      "backward_entropy": 0.010842014636312212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1238863617181778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03146197646856308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12479456514120102,
      "backward_entropy": 0.010759612279278892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1187562420964241,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03147454187273979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12467103451490402,
      "backward_entropy": 0.010679275861808233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12099218368530273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03148676082491875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12454688549041748,
      "backward_entropy": 0.010495576475347792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08677072823047638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03149875998497009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12442196905612946,
      "backward_entropy": 0.010524146258831024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10431604832410812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031510237604379654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12429901957511902,
      "backward_entropy": 0.01036679425409862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1067938506603241,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03152141347527504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1241755411028862,
      "backward_entropy": 0.010378400129931313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06437201052904129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031532347202301025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12405078113079071,
      "backward_entropy": 0.010307808007512773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08558312803506851,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031542617827653885,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12392881512641907,
      "backward_entropy": 0.011864034192902701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08663895726203918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03155256807804108,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12380717694759369,
      "backward_entropy": 0.011814081243106298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1235501766204834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03156233951449394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12368609011173248,
      "backward_entropy": 0.010112876338618142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05931747704744339,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031572286039590836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12356001883745193,
      "backward_entropy": 0.010048164853027888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07308783382177353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03158169239759445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12343692779541016,
      "backward_entropy": 0.009987005165645055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08847692608833313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03159073740243912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12331414222717285,
      "backward_entropy": 0.009929011975015913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05979178845882416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03159971535205841,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12318993359804153,
      "backward_entropy": 0.011578187346458435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06359793990850449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03160838037729263,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12306840717792511,
      "backward_entropy": 0.011535055935382843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056138694286346436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031616728752851486,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12294761091470718,
      "backward_entropy": 0.0114937105349132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04596585035324097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03162473440170288,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1228284239768982,
      "backward_entropy": 0.009744998599801744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07911702990531921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163229674100876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12271176278591156,
      "backward_entropy": 0.009653946118695396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0576508492231369,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03163991868495941,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12259279191493988,
      "backward_entropy": 0.009662855948720659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05116046965122223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031647294759750366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12247427552938461,
      "backward_entropy": 0.009623063462121146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05451283976435661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165439888834953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12235678732395172,
      "backward_entropy": 0.009507113269397191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04225526750087738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166138008236885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1222398430109024,
      "backward_entropy": 0.009460496050970895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04031689465045929,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03166809305548668,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12212513387203217,
      "backward_entropy": 0.011243956429617745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04232637211680412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167441114783287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12201157957315445,
      "backward_entropy": 0.009477843131337847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04159747064113617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031680524349212646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12189918756484985,
      "backward_entropy": 0.009331992694309779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030498571693897247,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03168640658259392,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12178753316402435,
      "backward_entropy": 0.009414089577538627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032697465270757675,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03169184923171997,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12167792022228241,
      "backward_entropy": 0.011133053473063878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03390779718756676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03169702738523483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12157010287046432,
      "backward_entropy": 0.009219432515757424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03748200088739395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03170188516378403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12146298587322235,
      "backward_entropy": 0.009185777178832464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029279163107275963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031706638634204865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12135626375675201,
      "backward_entropy": 0.009152673184871674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030462749302387238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171105310320854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1212506890296936,
      "backward_entropy": 0.009121490376336234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028024030849337578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171519562602043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12114572525024414,
      "backward_entropy": 0.009091849837984358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031503066420555115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171912208199501,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12104200571775436,
      "backward_entropy": 0.009063457804066795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025471622124314308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031722914427518845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12093845009803772,
      "backward_entropy": 0.009035806570734297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02386433444917202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03172643482685089,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12083594501018524,
      "backward_entropy": 0.009009716766221183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032728929072618484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031729817390441895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12073563039302826,
      "backward_entropy": 0.010972065585000175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02429879456758499,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031733233481645584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12063485383987427,
      "backward_entropy": 0.009163361574922289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025026287883520126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03173653408885002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12053540349006653,
      "backward_entropy": 0.008934444614819117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03507276251912117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031739674508571625,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12043650448322296,
      "backward_entropy": 0.010933057538100652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028080042451620102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174300119280815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12033611536026001,
      "backward_entropy": 0.008885664599282401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024863706901669502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031746331602334976,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1202356368303299,
      "backward_entropy": 0.010906060891492026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028625719249248505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174956142902374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12013541162014008,
      "backward_entropy": 0.00883640136037554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021884730085730553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031752850860357285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12003456801176071,
      "backward_entropy": 0.008811708007540022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023282989859580994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175606206059456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11993467807769775,
      "backward_entropy": 0.008787738957575389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02368590421974659,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175919130444527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11983488500118256,
      "backward_entropy": 0.008764232375792094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019637638702988625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176233917474747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11973521113395691,
      "backward_entropy": 0.00874068375144686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014344890601933002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176538646221161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11963652074337006,
      "backward_entropy": 0.008717810469014304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015006618574261665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031768083572387695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11953958868980408,
      "backward_entropy": 0.008975136492933546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014489080756902695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03177061304450035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11944448947906494,
      "backward_entropy": 0.00867717553462301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015389902517199516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031773049384355545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11935144662857056,
      "backward_entropy": 0.008658111627612795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01749829202890396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031775347888469696,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925947666168213,
      "backward_entropy": 0.010792907859597887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016198130324482918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03177766501903534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11916802823543549,
      "backward_entropy": 0.008621517036642348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015829887241125107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03177989646792412,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11907700449228287,
      "backward_entropy": 0.008911886385508947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01621944084763527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03178209438920021,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1189865916967392,
      "backward_entropy": 0.010768789265836989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015045909211039543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03178427368402481,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1188964769244194,
      "backward_entropy": 0.008888158947229385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011143948882818222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03178644925355911,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1188071072101593,
      "backward_entropy": 0.00887629549418177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011132505722343922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03178847208619118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11871951818466187,
      "backward_entropy": 0.008535098816667284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01469893753528595,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03179038688540459,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11863352358341217,
      "backward_entropy": 0.010739825665950775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011457700282335281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031792402267456055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1185479387640953,
      "backward_entropy": 0.008503028324672155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011614554561674595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03179435431957245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11846353113651276,
      "backward_entropy": 0.008487192647797721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01057856809347868,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03179622069001198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11837981641292572,
      "backward_entropy": 0.008823065353291375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011044821701943874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03179797902703285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1182970404624939,
      "backward_entropy": 0.008457128490720476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011130742728710175,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03179978206753731,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11821533739566803,
      "backward_entropy": 0.008803435202155794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009793139062821865,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03180159628391266,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11813423037528992,
      "backward_entropy": 0.010700541947569166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009441647678613663,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03180340677499771,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11805424839258194,
      "backward_entropy": 0.010693950312478202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00782851967960596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031805165112018585,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1179751604795456,
      "backward_entropy": 0.010687657764979772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00832399819046259,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031806837767362595,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11789754778146744,
      "backward_entropy": 0.008764849177428655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007260938640683889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03180839493870735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11782074719667435,
      "backward_entropy": 0.008756293782166072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006740182638168335,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031809840351343155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11774519830942154,
      "backward_entropy": 0.008748362639120646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007197350263595581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031811151653528214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11767089366912842,
      "backward_entropy": 0.008347295224666595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007215370889753103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03181241825222969,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1175975650548935,
      "backward_entropy": 0.008336057088204793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007430482190102339,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03181366249918938,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11752477288246155,
      "backward_entropy": 0.010661385953426361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005293860565871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03181495890021324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11745166778564453,
      "backward_entropy": 0.008313707475151335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006983791012316942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031816184520721436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11737983673810959,
      "backward_entropy": 0.008302949368953705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005581030156463385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03181741386651993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11730821430683136,
      "backward_entropy": 0.00870662076132638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004582242574542761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03181856870651245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11723750829696655,
      "backward_entropy": 0.008281808878694261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004817711655050516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031819626688957214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11716821789741516,
      "backward_entropy": 0.008694310273442949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004812667146325111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03182057663798332,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11709985882043839,
      "backward_entropy": 0.008263003613267626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004430602304637432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03182156756520271,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11703282594680786,
      "backward_entropy": 0.008253863347428185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004114085342735052,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031822510063648224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11696693301200867,
      "backward_entropy": 0.008678346872329712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004421227145940065,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03182338923215866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11690236628055573,
      "backward_entropy": 0.008673492286886488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034674094058573246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03182423487305641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11683879047632217,
      "backward_entropy": 0.008668792034898485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038282498717308044,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03182501345872879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11677655577659607,
      "backward_entropy": 0.00822074179138456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003491535782814026,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031825724989175797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11671510338783264,
      "backward_entropy": 0.008660511246749334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003421148983761668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03182638809084892,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11665463447570801,
      "backward_entropy": 0.010628435228552138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003541977144777775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03182702511548996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11659520864486694,
      "backward_entropy": 0.008199664098875863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003195718163624406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03182772174477577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1165369376540184,
      "backward_entropy": 0.008192689823252814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035350897815078497,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03182840719819069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11647973209619522,
      "backward_entropy": 0.008185794310910361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002624279586598277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031829096376895905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1164231151342392,
      "backward_entropy": 0.008641629878963743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030759316869080067,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03182974457740784,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11636774241924286,
      "backward_entropy": 0.01062180953366416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028862874023616314,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03183038532733917,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11631303280591965,
      "backward_entropy": 0.010620554643017905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002318427199497819,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031831044703722,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11625920236110687,
      "backward_entropy": 0.010619136903967177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002270464552566409,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031831659376621246,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11620654910802841,
      "backward_entropy": 0.010617915008749281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026125104632228613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0318322516977787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11615504324436188,
      "backward_entropy": 0.008623729859079634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018795749638229609,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03183289244771004,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11610440909862518,
      "backward_entropy": 0.01061517745256424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027196239680051804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318334624171257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11605493724346161,
      "backward_entropy": 0.008134930793728148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018045870820060372,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183412924408913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11600605398416519,
      "backward_entropy": 0.008128651550837926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019332646625116467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03183475136756897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1159583106637001,
      "backward_entropy": 0.008609662630728312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020548002794384956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183535113930702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11591141670942307,
      "backward_entropy": 0.008116877504757472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001697734696790576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03183596581220627,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11586526036262512,
      "backward_entropy": 0.010607559766088213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019043795764446259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183654323220253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11581999063491821,
      "backward_entropy": 0.008105431284223284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015689380234107375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183716535568237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11577548086643219,
      "backward_entropy": 0.008099655487707682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013887722743675113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183776140213013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11573184281587601,
      "backward_entropy": 0.008094075002840586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012065257178619504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031838323920965195,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1156892403960228,
      "backward_entropy": 0.01060137471982411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011685265926644206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183882310986519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11564762890338898,
      "backward_entropy": 0.00808378734758922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001260671648196876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183930739760399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11560718715190887,
      "backward_entropy": 0.008078981190919876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012753455666825175,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0318397618830204,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11556747555732727,
      "backward_entropy": 0.008581081671374184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011789778945967555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031840238720178604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11552867293357849,
      "backward_entropy": 0.00806971692613193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013259383849799633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0318407267332077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11549068987369537,
      "backward_entropy": 0.010595919830458505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000901232473552227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184126690030098,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11545337736606598,
      "backward_entropy": 0.008060147719723838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008474622736684978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184175491333008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11541696637868881,
      "backward_entropy": 0.008055554436785834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009665380348451436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031842224299907684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11538165807723999,
      "backward_entropy": 0.008051139967782157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011217324063181877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184269741177559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11534717679023743,
      "backward_entropy": 0.008046751043626241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007350554806180298,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031843218952417374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11531320214271545,
      "backward_entropy": 0.008042118379047938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007262849831022322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03184371441602707,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11528018116950989,
      "backward_entropy": 0.010586923786572047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006535476422868669,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03184418007731438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11524796485900879,
      "backward_entropy": 0.008556204182761056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006819553673267365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031844612210989,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11521656811237335,
      "backward_entropy": 0.008029453456401825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006318779196590185,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184502571821213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11518588662147522,
      "backward_entropy": 0.008025578090122767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000622887397184968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184542804956436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11515595763921738,
      "backward_entropy": 0.00802182885152953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005861425888724625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0318458117544651,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11512666940689087,
      "backward_entropy": 0.008547031453677587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006920385640114546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031846169382333755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11509798467159271,
      "backward_entropy": 0.00801476463675499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004809889942407608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184657171368599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11506994813680649,
      "backward_entropy": 0.008011097354548318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042970056529156864,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03184695169329643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11504267901182175,
      "backward_entropy": 0.008540561688797814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004273403319530189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184729442000389,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1150161400437355,
      "backward_entropy": 0.00800432903426034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041001487988978624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03184761106967926,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11499026417732239,
      "backward_entropy": 0.010575559522424425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005095519591122866,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03184793144464493,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11496514081954956,
      "backward_entropy": 0.01057464416537966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003801482089329511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03184828162193298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11494050174951553,
      "backward_entropy": 0.007995019001620156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039735581958666444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031848616898059845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11491650342941284,
      "backward_entropy": 0.00799193446125303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033275046735070646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031848933547735214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11489292234182358,
      "backward_entropy": 0.008529381028243474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002968577900901437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031849246472120285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11487002670764923,
      "backward_entropy": 0.007986140038285936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002672591945156455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031849537044763565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11484774947166443,
      "backward_entropy": 0.007983415786709105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002638269797898829,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031849805265665054,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11482614278793335,
      "backward_entropy": 0.010569003011499132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025500336778350174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031850047409534454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11480509489774704,
      "backward_entropy": 0.008523179484265191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002489507314749062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031850263476371765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11478453874588013,
      "backward_entropy": 0.007976230766092027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022394786356016994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185047581791878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11476457118988037,
      "backward_entropy": 0.007974032312631607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025341540458612144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185068070888519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11474515497684479,
      "backward_entropy": 0.007971928587981634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020903705444652587,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185088932514191,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11472620069980621,
      "backward_entropy": 0.008518409516130174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001686320174485445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031851086765527725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11470776051282883,
      "backward_entropy": 0.007967797773224967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018651288701221347,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185126185417175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11468987166881561,
      "backward_entropy": 0.008516282907554082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001733348472043872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031851429492235184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1146724596619606,
      "backward_entropy": 0.007964096963405609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017569038027431816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031851597130298615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11465553939342499,
      "backward_entropy": 0.008514361722128732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018506543710827827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031851768493652344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11463908851146698,
      "backward_entropy": 0.007960517491613115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012952249380759895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185194730758667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11462296545505524,
      "backward_entropy": 0.007958721369504929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015725901175756007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031852107495069504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11460733413696289,
      "backward_entropy": 0.007957040199211665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012379117833916098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185226768255234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.114592045545578,
      "backward_entropy": 0.007955371269157954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001375766732962802,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185242414474487,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11457724124193192,
      "backward_entropy": 0.00850965189082282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013679394032806158,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185258060693741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11456280946731567,
      "backward_entropy": 0.007952156343630381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011452516628196463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185274451971054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11454874277114868,
      "backward_entropy": 0.00795053584235055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001364651252515614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031852904707193375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11453504860401154,
      "backward_entropy": 0.007948965898581914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.230816795025021e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031853087246418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11452164500951767,
      "backward_entropy": 0.00794730388692447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.171255805995315e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185324743390083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11450859904289246,
      "backward_entropy": 0.008505001664161682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.608774416847154e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185339272022247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11449587345123291,
      "backward_entropy": 0.007944317268473762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010047735122498125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031853530555963516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11448344588279724,
      "backward_entropy": 0.007942925606455122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.992011134978384e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031853679567575455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11447130143642426,
      "backward_entropy": 0.007941513721432005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753354632062837e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185382857918739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11445948481559753,
      "backward_entropy": 0.008501657950026649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.81055714469403e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185398504137993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11444796621799469,
      "backward_entropy": 0.008500753768852778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.203818677226081e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031854141503572464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11443674564361572,
      "backward_entropy": 0.007937234427247728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.711197056574747e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031854297965765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11442584544420242,
      "backward_entropy": 0.007935840104307448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.063860539346933e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031854450702667236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.114415243268013,
      "backward_entropy": 0.007934465472187315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5941545724635944e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03185460343956947,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11440489441156387,
      "backward_entropy": 0.010557334337915694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4882406402612105e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185474872589111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11439483612775803,
      "backward_entropy": 0.007931797632149287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.524747055256739e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185489401221275,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11438505351543427,
      "backward_entropy": 0.008495584662471498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4733045797329396e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031855031847953796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11437559127807617,
      "backward_entropy": 0.007929302219833647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5670421968679875e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185516595840454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11436645686626434,
      "backward_entropy": 0.0079281319464956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4526459532789886e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031855300068855286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.114357590675354,
      "backward_entropy": 0.007926973381212779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.119436925975606e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185543417930603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434897035360336,
      "backward_entropy": 0.007925819605588913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4280608815606683e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185557201504707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143406331539154,
      "backward_entropy": 0.00792465784720012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.165730231557973e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185569867491722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433252692222595,
      "backward_entropy": 0.007923562079668045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9716162316617556e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185581788420677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1143246740102768,
      "backward_entropy": 0.008490449083702905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.931063500000164e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031855929642915726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11431705951690674,
      "backward_entropy": 0.008489828024591719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9537717637140304e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185603767633438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11430966854095459,
      "backward_entropy": 0.00792060632790838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6393114239908755e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031856145709753036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11430250108242035,
      "backward_entropy": 0.00791967979499272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4227845642599277e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031856246292591095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11429551243782043,
      "backward_entropy": 0.007918780403477805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3909153242129833e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031856343150138855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11428874731063843,
      "backward_entropy": 0.00848755772624697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2368352802004665e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031856440007686615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11428218334913254,
      "backward_entropy": 0.007917071027415139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.234307066828478e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031856536865234375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11427582055330276,
      "backward_entropy": 0.007916233901466643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1829057004651986e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185662999749184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11426961421966553,
      "backward_entropy": 0.007915434028421129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8809661924024113e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318567231297493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11426357924938202,
      "backward_entropy": 0.007914618189845766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9529588826117106e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185681253671646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11425769329071045,
      "backward_entropy": 0.008484955877065659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.794197851268109e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031856898218393326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11425194144248962,
      "backward_entropy": 0.007913079644952501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3134413165971637e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185698390007019,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11424634605646133,
      "backward_entropy": 0.00791233777999878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3524919268093072e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185705840587616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11424091458320618,
      "backward_entropy": 0.0079116624380861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0637721970851999e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03185712918639183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11423563957214355,
      "backward_entropy": 0.01054876297712326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.964107448467985e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031857192516326904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11423053592443466,
      "backward_entropy": 0.008482804255826133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2390650226734579e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185724839568138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1142256110906601,
      "backward_entropy": 0.008482477494648524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0876826308958698e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185730054974556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11422081291675568,
      "backward_entropy": 0.007909323487962996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1508468560350593e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185735270380974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.114216148853302,
      "backward_entropy": 0.008481864950486593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.077455615624785e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185740485787392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11421160399913788,
      "backward_entropy": 0.007908309144633157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.482690074946731e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318574532866478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1142071932554245,
      "backward_entropy": 0.00790782698563167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.091466042969842e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185750171542168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11420291662216187,
      "backward_entropy": 0.007907329393284661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.602981324656866e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185755014419556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11419878900051117,
      "backward_entropy": 0.007906847766467504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.723350790911354e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185759857296944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11419478058815002,
      "backward_entropy": 0.007906384766101837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.577261046913918e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031857650727033615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11419089138507843,
      "backward_entropy": 0.007905907396759306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.352990112645784e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031857702881097794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11418713629245758,
      "backward_entropy": 0.007905438542366028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.656395387632074e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031857751309871674,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11418349295854568,
      "backward_entropy": 0.01054721006325313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.468163064710097e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031857796013355255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11417996883392334,
      "backward_entropy": 0.007904554052012307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7574753807566594e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031857844442129135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11417652666568756,
      "backward_entropy": 0.008479014039039612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.19150626132614e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185788542032242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11417318880558014,
      "backward_entropy": 0.007903737681252616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.585525519156363e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318579263985157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11416995525360107,
      "backward_entropy": 0.0079033263027668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.69262340629939e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031857967376708984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11416685581207275,
      "backward_entropy": 0.007902969739266805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.13456200476503e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185800835490227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1141638457775116,
      "backward_entropy": 0.00790259667805263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.62841001333436e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185804933309555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1141609251499176,
      "backward_entropy": 0.008477843765701567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0555465855286457e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858086585998535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11415807902812958,
      "backward_entropy": 0.00790188621197428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.976513542307657e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185812383890152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1141553446650505,
      "backward_entropy": 0.007901539227792196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.946115728263976e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858157366514206,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1141526997089386,
      "backward_entropy": 0.01054601903472628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.498137291695457e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185819089412689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11415012180805206,
      "backward_entropy": 0.007900922426155635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.854797230611439e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185822442173958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11414767056703568,
      "backward_entropy": 0.007900622274194444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5234367058146745e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858257949352264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11414527893066406,
      "backward_entropy": 0.007900321590048926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.296636921528261e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185829147696495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11414296925067902,
      "backward_entropy": 0.007900042193276542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9074145711783785e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185832500457764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11414074152708054,
      "backward_entropy": 0.007899744170052665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6988742572721094e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185835853219032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11413857340812683,
      "backward_entropy": 0.007899457854884011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7010770534398034e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03185838833451271,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11413650214672089,
      "backward_entropy": 0.010545258011136736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.993981868508854e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318584181368351,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11413449048995972,
      "backward_entropy": 0.007898924606187003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6859962670423556e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858447939157486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11413255333900452,
      "backward_entropy": 0.00789867980139596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5907021406746935e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858477741479874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1141306608915329,
      "backward_entropy": 0.007898426481655665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3473652415996185e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185850754380226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11412881314754486,
      "backward_entropy": 0.00847535952925682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5182733932306292e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185853362083435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1141270250082016,
      "backward_entropy": 0.007897927292755671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1405559234844986e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185855969786644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11412529647350311,
      "backward_entropy": 0.007897703775337763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.053979758580681e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185858577489853,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11412361264228821,
      "backward_entropy": 0.00789749569126538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1227994036744349e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185860812664032,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11412197351455688,
      "backward_entropy": 0.007897284414087023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.006001411951729e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185863047838211,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11412039399147034,
      "backward_entropy": 0.007897075797830309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.949794730346184e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318586528301239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411885917186737,
      "backward_entropy": 0.007896890597684043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2738282597129e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185867518186569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411736905574799,
      "backward_entropy": 0.007896702204431807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841102274142031e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858693808317184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411593854427338,
      "backward_entropy": 0.007896528180156435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.221472972356423e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185871243476868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411455273628235,
      "backward_entropy": 0.007896360542093004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.290981104939419e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185872733592987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1141132116317749,
      "backward_entropy": 0.007896203015531813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.381442858582886e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858742237091064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411191523075104,
      "backward_entropy": 0.007896057197025843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.18010915331979e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185875713825226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11411065608263016,
      "backward_entropy": 0.007895908185413905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.386805810303485e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858768314123154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11410944908857346,
      "backward_entropy": 0.008473878992455346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5006197524344316e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185877948999405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11410825699567795,
      "backward_entropy": 0.00847382630620684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.56746420240961e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858790665864944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11410711705684662,
      "backward_entropy": 0.007895537785121374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1272778616985306e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185880184173584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11410601437091827,
      "backward_entropy": 0.007895431880440031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.698866350987373e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858813017606735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11410495638847351,
      "backward_entropy": 0.010543944580214364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4384308378321293e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185882046818733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11410392820835114,
      "backward_entropy": 0.007895213152681078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.457024604358594e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185882791876793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11410292983055115,
      "backward_entropy": 0.007895119488239288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.126417311705154e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858835369348526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11410197615623474,
      "backward_entropy": 0.007895013051373618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7318128559272736e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03185884281992912,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11410103738307953,
      "backward_entropy": 0.010543896683624812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.908744818341802e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185885027050972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11410015821456909,
      "backward_entropy": 0.007894845413310187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.601383357614395e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185885772109032,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11409929394721985,
      "backward_entropy": 0.008473348936864309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.471063282882824e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858865171670914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1140984445810318,
      "backward_entropy": 0.007894694805145264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9107353921299364e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185886889696121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11409763991832733,
      "backward_entropy": 0.00789462508899825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9006844809155155e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185887262225151,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11409686505794525,
      "backward_entropy": 0.007894555372851235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7573408683801972e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185887634754181,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11409610509872437,
      "backward_entropy": 0.008473203650542669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4069588871734595e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185888007283211,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11409538984298706,
      "backward_entropy": 0.007894437227930342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6763759447258053e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858883798122406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11409468948841095,
      "backward_entropy": 0.00789437017270497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6423192050751823e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858887523412704,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11409401893615723,
      "backward_entropy": 0.010543912649154663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5432857480845996e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858891248703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11409337818622589,
      "backward_entropy": 0.007894238190991538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1945850530992175e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0318588949739933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11409274488687515,
      "backward_entropy": 0.00847305463893073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2069376964518597e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318588986992836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1140921413898468,
      "backward_entropy": 0.007894134415047509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1203592720221422e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318589024245739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11409154534339905,
      "backward_entropy": 0.007894073746034078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0360185598301541e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318589061498642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11409099400043488,
      "backward_entropy": 0.007894035428762436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.393461570221916e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858909875154495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1140904426574707,
      "backward_entropy": 0.008472953523908342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.824848242104053e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858913600444794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408992111682892,
      "backward_entropy": 0.007893923137869154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.91670365426944e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03185891732573509,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11408941447734833,
      "backward_entropy": 0.008472900837659836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.419237763566343e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185892105102539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408893018960953,
      "backward_entropy": 0.007893841181482588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.148611302909558e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185892477631569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408846080303192,
      "backward_entropy": 0.007893817233187812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.943058312141147e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185892850160599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1140880286693573,
      "backward_entropy": 0.007893765611307961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.126605984173693e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11408758908510208,
      "backward_entropy": 0.008472822606563568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5802097165269515e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408717930316925,
      "backward_entropy": 0.00789369216987065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1356891244959115e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408677697181702,
      "backward_entropy": 0.007893669818128859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.166259515159254e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11408638954162598,
      "backward_entropy": 0.010543978640011378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.736329290404683e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408601701259613,
      "backward_entropy": 0.007893608616931098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1387163918216174e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11408568173646927,
      "backward_entropy": 0.008472771516868047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4865742293277435e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408533155918121,
      "backward_entropy": 0.007893550608839308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0261873007475515e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408500373363495,
      "backward_entropy": 0.007893528257097517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8620425140957195e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408469080924988,
      "backward_entropy": 0.007893509098461695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.561347045570983e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408437788486481,
      "backward_entropy": 0.007893473442111696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7769642585440124e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408410966396332,
      "backward_entropy": 0.007893454815660204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9091707770257926e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408381164073944,
      "backward_entropy": 0.007893435124840056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.742057520459639e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408355832099915,
      "backward_entropy": 0.007893414901835578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4857732821837999e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408329755067825,
      "backward_entropy": 0.007893379777669907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.958164119741923e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408305168151855,
      "backward_entropy": 0.007893364876508713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.788421855053457e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11408281326293945,
      "backward_entropy": 0.010544043566499437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5610169157298515e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408258974552155,
      "backward_entropy": 0.00789331751210349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3190813774599519e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408238112926483,
      "backward_entropy": 0.007893305804048265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2528083459528716e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11408217251300812,
      "backward_entropy": 0.008472629955836706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.731564887260902e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.114081971347332,
      "backward_entropy": 0.007893281323569161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.054944931411228e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11408177018165588,
      "backward_entropy": 0.008472601217882974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.608967843632854e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11408159881830215,
      "backward_entropy": 0.010544059532029288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.621736131113721e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408142745494843,
      "backward_entropy": 0.007893225444214684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.84444154078301e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1140812486410141,
      "backward_entropy": 0.010544078690665109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.982673994571087e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408108472824097,
      "backward_entropy": 0.007893201495919908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.917691225931776e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408093571662903,
      "backward_entropy": 0.007893191916601998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.001993651556404e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11408078670501709,
      "backward_entropy": 0.01054408507687705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.322636636468815e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11408065259456635,
      "backward_entropy": 0.00847255757876805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.793385409764596e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1140805184841156,
      "backward_entropy": 0.007893144020012446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5722927666247415e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11408037692308426,
      "backward_entropy": 0.010544087205614363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.14310016797026e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1140802651643753,
      "backward_entropy": 0.01054409146308899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.794617953190027e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11408014595508575,
      "backward_entropy": 0.007893117410796029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5557476962821966e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1140800267457962,
      "backward_entropy": 0.007893108363662447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.338438941431377e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407992243766785,
      "backward_entropy": 0.007893086544104986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9113920163581497e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1140798032283783,
      "backward_entropy": 0.008472507553441184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6973765443472075e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407971382141113,
      "backward_entropy": 0.007893066321100508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.731169956859958e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11407960951328278,
      "backward_entropy": 0.008472500102860587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.449461078413151e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11407952755689621,
      "backward_entropy": 0.008472497441938944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.769475315744785e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407943814992905,
      "backward_entropy": 0.007893048226833344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8396804080111906e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407934874296188,
      "backward_entropy": 0.00789304290499006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0940902345500945e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11407926678657532,
      "backward_entropy": 0.010544096784932273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8412293911751476e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11407919228076935,
      "backward_entropy": 0.008472484137330736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6188295148822363e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407911777496338,
      "backward_entropy": 0.007893031196934836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7554384612594731e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.114079050719738,
      "backward_entropy": 0.007893007780824388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4857377550470119e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407898366451263,
      "backward_entropy": 0.007893002458981105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2523102554951038e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407892405986786,
      "backward_entropy": 0.007892998201506478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3860699255019426e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11407884955406189,
      "backward_entropy": 0.01054411062172481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.500435910718807e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407880485057831,
      "backward_entropy": 0.007892992879663194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0711360687309934e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11407873779535294,
      "backward_entropy": 0.010544112750462123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.999023748401669e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407868564128876,
      "backward_entropy": 0.007892977978502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.33255250856746e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407864093780518,
      "backward_entropy": 0.007892977978502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85457041022164e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1140785813331604,
      "backward_entropy": 0.007892975849764687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.652030037912482e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407853662967682,
      "backward_entropy": 0.007892973721027374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.093951926937734e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407849192619324,
      "backward_entropy": 0.00789296839918409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.011351499386365e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11407846212387085,
      "backward_entropy": 0.008472431983266557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.350671017367858e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407842487096786,
      "backward_entropy": 0.007892960948603494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.15589340718725e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407837271690369,
      "backward_entropy": 0.00789295881986618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.032738835732744e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1140783429145813,
      "backward_entropy": 0.007892956691128867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.426716936402954e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11407830566167831,
      "backward_entropy": 0.010544119136674064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3649350800478715e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407827585935593,
      "backward_entropy": 0.007892932742834091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.065619118089671e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407825350761414,
      "backward_entropy": 0.007892927953175135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.381934897741303e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11407822370529175,
      "backward_entropy": 0.008472418678658349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.289759658604453e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407817900180817,
      "backward_entropy": 0.007892927953175135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.028795158068533e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11407814919948578,
      "backward_entropy": 0.010544122329780034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.829256911558332e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407813429832458,
      "backward_entropy": 0.007892923163516181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3525537901368807e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1140781044960022,
      "backward_entropy": 0.010544125522886003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7982772482791916e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11407807469367981,
      "backward_entropy": 0.008472416549921036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.185860464327561e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407804489135742,
      "backward_entropy": 0.007892918373857225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.887219352487591e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407802253961563,
      "backward_entropy": 0.007892918373857225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.142588411719771e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407800763845444,
      "backward_entropy": 0.007892918373857225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.629576556500979e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11407797783613205,
      "backward_entropy": 0.01054414255278451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.113438313244842e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407795548439026,
      "backward_entropy": 0.007892915712935584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7673329466560972e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407792568206787,
      "backward_entropy": 0.007892915712935584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.569109369687794e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031858932226896286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11407791078090668,
      "backward_entropy": 0.007892913584198271,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.599119397459162e-08,
    "avg_log_Z": 0.031858917772769925,
    "success_rate": 1.0,
    "avg_reward": 51.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.17,
      "1": 0.17,
      "2": 0.66
    },
    "avg_forward_entropy": 0.11408453457057476,
    "avg_backward_entropy": 0.008442564569413662,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}