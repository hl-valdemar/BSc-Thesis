{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301262161948464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06300783157348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.236921310424805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152897198994954,
      "backward_entropy": 0.06301288713108409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.23465633392334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152734279632568,
      "backward_entropy": 0.06300667199221524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.329065322875977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019999983487650752,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152564406394958,
      "backward_entropy": 0.06301315264268355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.580979347229004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003000232973136008,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152388572692871,
      "backward_entropy": 0.06300400603901256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.928730964660645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004001072666142136,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09152206778526306,
      "backward_entropy": 0.06301331520080566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.925588607788086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005003041587769985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09152021010716756,
      "backward_entropy": 0.06300086866725575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.92242431640625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006005727918818593,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151828289031982,
      "backward_entropy": 0.0630133802240545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41229248046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007008889806456864,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151631593704224,
      "backward_entropy": 0.0630133802240545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.820659637451172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008011120953597128,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09151426951090495,
      "backward_entropy": 0.06301337480545044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.564676284790039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009013606468215585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151220321655273,
      "backward_entropy": 0.06301320682872426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.20301628112793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010015603620558977,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09151009718577068,
      "backward_entropy": 0.06301304968920621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.306814193725586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011013158364221454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150805075963338,
      "backward_entropy": 0.0630128492008556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.610175132751465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012010583886876702,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09150596459706624,
      "backward_entropy": 0.06301258368925615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.356145858764648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001300561474636197,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09150389830271403,
      "backward_entropy": 0.06301274624737827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.299782752990723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013997911009937525,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09150188167889912,
      "backward_entropy": 0.06298171390186656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.699105262756348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014991149073466659,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149979551633199,
      "backward_entropy": 0.06297903711145575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.453761100769043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015983200864866376,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149768948554993,
      "backward_entropy": 0.06301173296841708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.040717124938965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016976675251498818,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09149551391601562,
      "backward_entropy": 0.06301028078252618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.852294921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001797017059288919,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09149328867594402,
      "backward_entropy": 0.06301070885224776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.195335388183594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001896285219117999,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09149106343587239,
      "backward_entropy": 0.06296680190346458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.815482139587402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019956117030233145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148883819580078,
      "backward_entropy": 0.06296331232244318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.687567710876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002095239469781518,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148648381233215,
      "backward_entropy": 0.06300855766643178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.189067840576172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021947019267827272,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148409962654114,
      "backward_entropy": 0.06300766901536421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.500019073486328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022941953502595425,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148166577021281,
      "backward_entropy": 0.06300474838777022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.024770736694336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023934526834636927,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147929151852925,
      "backward_entropy": 0.062947923486883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.336777687072754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024927302729338408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147681792577107,
      "backward_entropy": 0.06294380534778941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.592947959899902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025917564053088427,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147438406944275,
      "backward_entropy": 0.06300313906236128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.655003547668457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026910167653113604,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09147201975186665,
      "backward_entropy": 0.06300171938809482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673891067504883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027901194989681244,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146974484125774,
      "backward_entropy": 0.0630001805045388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671981811523438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002889132359996438,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146733085314433,
      "backward_entropy": 0.06292559883811256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513856887817383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029880686197429895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146487712860107,
      "backward_entropy": 0.06292059204795143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260213851928711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030872647184878588,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09146228432655334,
      "backward_entropy": 0.06299159201708707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23575210571289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031865958590060472,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145957231521606,
      "backward_entropy": 0.06290983611887152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.57463550567627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003285619430243969,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145692984263103,
      "backward_entropy": 0.06298704580827193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823829650878906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003384518902748823,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145426750183105,
      "backward_entropy": 0.06289830532940952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.752421379089355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034834081307053566,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145158529281616,
      "backward_entropy": 0.0629817626693032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569170951843262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003582673380151391,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914487640062968,
      "backward_entropy": 0.06297883662310513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729758262634277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036817858926951885,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144595265388489,
      "backward_entropy": 0.06298047846013849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.565469741821289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037808159831911325,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914431909720103,
      "backward_entropy": 0.06297248060053046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.240532875061035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003879723371937871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144040942192078,
      "backward_entropy": 0.0628651272166859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.738978385925293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0039788200519979,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143748879432678,
      "backward_entropy": 0.06296539848501032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722702980041504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004078282508999109,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143441915512085,
      "backward_entropy": 0.06296722455458208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.633635520935059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004177622497081757,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143144885698955,
      "backward_entropy": 0.06295746023004706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.979997634887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0042768060229718685,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142863750457764,
      "backward_entropy": 0.06295922669497403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.401055335998535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004376048222184181,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142566720644633,
      "backward_entropy": 0.0629487471147017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.724318504333496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004475541412830353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142241875330608,
      "backward_entropy": 0.06281626766378229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.049083709716797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004575361497700214,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141905109087627,
      "backward_entropy": 0.06294582648710771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719908714294434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004675168078392744,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141570329666138,
      "backward_entropy": 0.06294090097600763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.459541320800781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004774854052811861,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141223629315694,
      "backward_entropy": 0.06278754364360463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.882986068725586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004874284379184246,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0914088785648346,
      "backward_entropy": 0.06277743252840909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.459230422973633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004974150098860264,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914052426815033,
      "backward_entropy": 0.06291675567626953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.455986976623535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005074198357760906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140147765477498,
      "backward_entropy": 0.06275591525164517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.203874588012695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0051744068041443825,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139760335286458,
      "backward_entropy": 0.06290392984043468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.86733341217041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005274651106446981,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09139363964398702,
      "backward_entropy": 0.06273297830061479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198652267456055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005375232547521591,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138941764831543,
      "backward_entropy": 0.06272097067399458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.777397155761719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005475335754454136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138535459836324,
      "backward_entropy": 0.06270875172181563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.187154769897461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005575277376919985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138135115305583,
      "backward_entropy": 0.06287478316913951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775147438049316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0056757437996566296,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137701988220215,
      "backward_entropy": 0.06286670403047041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5214204788208,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0057760439813137054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913725197315216,
      "backward_entropy": 0.06285831061276523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.601873397827148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005876047071069479,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913681189219157,
      "backward_entropy": 0.06286046721718529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.837347984313965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005975834559649229,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136370817820232,
      "backward_entropy": 0.06284065680070357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.59592056274414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006075968034565449,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09135931730270386,
      "backward_entropy": 0.06283132596449419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.427756309509277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00617586774751544,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135490655899048,
      "backward_entropy": 0.06261232766238126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.166472434997559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006275499705225229,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09135044614473979,
      "backward_entropy": 0.06282307343049483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.410155296325684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00637521967291832,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134588638941447,
      "backward_entropy": 0.06280130689794367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827454566955566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006475124973803759,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134121735890706,
      "backward_entropy": 0.06256496906280518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.070252418518066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0065749650821089745,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09133629004160564,
      "backward_entropy": 0.06254838813434947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.892990112304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006674855016171932,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09133109450340271,
      "backward_entropy": 0.06277982755140825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.820291519165039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006775126326829195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0913258691628774,
      "backward_entropy": 0.06251440806822343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569787979125977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006875247694551945,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132065375645955,
      "backward_entropy": 0.06274341995065863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.553987503051758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006975123658776283,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131546815236409,
      "backward_entropy": 0.0627306808124889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730297088623047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007075222674757242,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131032228469849,
      "backward_entropy": 0.0627175352790139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986920356750488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007175137288868427,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130531549453735,
      "backward_entropy": 0.0627165057442405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.240815162658691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007274551782757044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09130040804545085,
      "backward_entropy": 0.06269013339822943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.96689510345459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0073735979385674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129596749941508,
      "backward_entropy": 0.0624013597315008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.627130508422852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007472687400877476,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09129159649213155,
      "backward_entropy": 0.06267350912094116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.77672004699707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007571687921881676,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912870466709137,
      "backward_entropy": 0.0626461614261974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.603912353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00767112011089921,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09128248691558838,
      "backward_entropy": 0.06264247677542946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.198226928710938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00777087127789855,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127777814865112,
      "backward_entropy": 0.06261396949941461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.211092948913574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007870696485042572,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912731687227885,
      "backward_entropy": 0.06228870695287531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.68092155456543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007970135658979416,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0912686288356781,
      "backward_entropy": 0.06259145519950172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.170845985412598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008069906383752823,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09126418828964233,
      "backward_entropy": 0.062238552353598854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.200562477111816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008169776760041714,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125942985216777,
      "backward_entropy": 0.06253899769349532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.365256309509277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008269250392913818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125473101933797,
      "backward_entropy": 0.062185417522083626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.948390483856201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008368435315787792,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09125023086865743,
      "backward_entropy": 0.06251471151005138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.602327346801758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008467181585729122,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09124582012494405,
      "backward_entropy": 0.06213029948147861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.71076774597168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008565831929445267,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.091241588195165,
      "backward_entropy": 0.06210181929848411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.21640396118164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008664975874125957,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123680988947551,
      "backward_entropy": 0.06242981824007901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.530046463012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008764330297708511,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123152494430542,
      "backward_entropy": 0.062428431077436966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73552131652832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008864032104611397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122566382090251,
      "backward_entropy": 0.062009703029285775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26242733001709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008963623084127903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121986230214436,
      "backward_entropy": 0.06197713180021806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.241170883178711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009062855504453182,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09121449788411458,
      "backward_entropy": 0.062327027320861816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32809829711914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009162782691419125,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120859702428182,
      "backward_entropy": 0.06232971494848078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.957634925842285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009262357838451862,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120298425356548,
      "backward_entropy": 0.06230240518396551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.466045379638672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009361942298710346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911973516146342,
      "backward_entropy": 0.06183771111748435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776740074157715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009461303241550922,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119173884391785,
      "backward_entropy": 0.062207818031311035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.697447776794434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009560625068843365,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09118600686391194,
      "backward_entropy": 0.0622151873328469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93386459350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009659863077104092,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09118024508158366,
      "backward_entropy": 0.06218427961522883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.169770240783691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009759139269590378,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09117446343104045,
      "backward_entropy": 0.061683275482871315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.090715408325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009858561679720879,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09116872151692708,
      "backward_entropy": 0.062119462273337624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.914605140686035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009958066046237946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116309881210327,
      "backward_entropy": 0.061599438840692695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69196891784668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010057573206722736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115741650263469,
      "backward_entropy": 0.06155587326396595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.552391052246094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01015693973749876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115219116210938,
      "backward_entropy": 0.06151132691990246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.277960777282715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010256617330014706,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114702542622884,
      "backward_entropy": 0.061977489428086716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.431922912597656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01035647839307785,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09114140272140503,
      "backward_entropy": 0.06141812692989002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.838947296142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010456036776304245,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113621711730957,
      "backward_entropy": 0.06190017136660489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.897441864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010556036606431007,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09113095204035442,
      "backward_entropy": 0.061859846115112305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.962334632873535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010655944235622883,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09112606445948283,
      "backward_entropy": 0.06173624775626443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.308182716369629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010756338946521282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0911206603050232,
      "backward_entropy": 0.06121640855615789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.324003219604492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01085633784532547,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09111529588699341,
      "backward_entropy": 0.06173210794275457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05656623840332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010956485755741596,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09110977252324422,
      "backward_entropy": 0.061107348312031136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.921273231506348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0110561428591609,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09110430876413982,
      "backward_entropy": 0.061641167510639534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51567554473877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011156298220157623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09109832843144734,
      "backward_entropy": 0.060993400487032806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.135802268981934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011256183497607708,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09109246730804443,
      "backward_entropy": 0.06093432686545632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.040715217590332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011356647126376629,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09108611941337585,
      "backward_entropy": 0.06137866323644465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.795917510986328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01145707443356514,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09107967217763265,
      "backward_entropy": 0.06132159991697832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.935399055480957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011557349935173988,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09107311566670735,
      "backward_entropy": 0.06074587865309282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870484352111816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0116580780595541,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106593330701192,
      "backward_entropy": 0.06067781014875932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.626567840576172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011758633889257908,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09105902910232544,
      "backward_entropy": 0.061140374703840775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.614781379699707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011858916841447353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105239311854045,
      "backward_entropy": 0.060537229884754525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.815597534179688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01195844728499651,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09104633331298828,
      "backward_entropy": 0.06115557930686257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.687121391296387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012057943269610405,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910399357477824,
      "backward_entropy": 0.06039206006310203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.423684120178223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012157788500189781,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09103375673294067,
      "backward_entropy": 0.06031640551306985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.875303268432617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012257350608706474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910276969273885,
      "backward_entropy": 0.06023926084691828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.371164321899414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012356881983578205,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09102161725362141,
      "backward_entropy": 0.060896136543967506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.920802116394043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012456676922738552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09101474285125732,
      "backward_entropy": 0.06007882139899514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.344839096069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012556450441479683,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09100770950317383,
      "backward_entropy": 0.06075591390783137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.986780166625977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012656450271606445,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099995096524556,
      "backward_entropy": 0.06050346114418723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65450382232666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012756416574120522,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09099242091178894,
      "backward_entropy": 0.0604228214784102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.711551666259766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012856213375926018,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09098480145136516,
      "backward_entropy": 0.060340063138441605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71895980834961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012956369668245316,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0909770925839742,
      "backward_entropy": 0.05964042923667214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231278419494629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013056344352662563,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09096960226694743,
      "backward_entropy": 0.0595459829677235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16425895690918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013155948370695114,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09096191326777141,
      "backward_entropy": 0.06008063663135876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.541023254394531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013255617581307888,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095484018325806,
      "backward_entropy": 0.05935215950012207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.159990310668945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013355046510696411,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09094826380411784,
      "backward_entropy": 0.05925254388289018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.492415428161621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013454639352858067,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09094097216924031,
      "backward_entropy": 0.059805420312014496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.118806838989258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013554010540246964,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09093367060025533,
      "backward_entropy": 0.059046116742220794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.62523365020752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013652972877025604,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09092682600021362,
      "backward_entropy": 0.05894045396284624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29427719116211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01375239621847868,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09091893831888835,
      "backward_entropy": 0.05883142081173984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.674623489379883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013851528987288475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09091099103291829,
      "backward_entropy": 0.05872058868408203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.434942245483398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013951108790934086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09090238809585571,
      "backward_entropy": 0.05860634825446389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46585750579834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014050406403839588,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0908943514029185,
      "backward_entropy": 0.05849027633666992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.249897956848145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014150075614452362,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090885063012441,
      "backward_entropy": 0.05907447229732166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65365219116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014249371364712715,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09087632099787395,
      "backward_entropy": 0.05923386053605513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.914959907531738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014348573051393032,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0908670723438263,
      "backward_entropy": 0.059123743664134636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417092323303223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014447304420173168,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09085806210835774,
      "backward_entropy": 0.05800110101699829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.599506378173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014545847661793232,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09084940950075786,
      "backward_entropy": 0.058896292339671745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.361392974853516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014644883573055267,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09083985288937886,
      "backward_entropy": 0.058474985035983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991147994995117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014744238927960396,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09082950154940288,
      "backward_entropy": 0.05865788459777832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.912881851196289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014843669719994068,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09081883231798808,
      "backward_entropy": 0.0585344596342607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.161561012268066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01494258176535368,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09080882867177327,
      "backward_entropy": 0.05840848792682995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.875831604003906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015041705220937729,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09079831838607788,
      "backward_entropy": 0.05718817494132302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115386009216309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015140323899686337,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09078917900721233,
      "backward_entropy": 0.05814802646636963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.546623706817627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015239164233207703,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090779443581899,
      "backward_entropy": 0.057665651494806465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.107329368591309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015337381511926651,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09077027440071106,
      "backward_entropy": 0.056748168034987015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.768596649169922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015435286797583103,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09076178073883057,
      "backward_entropy": 0.05659762295809659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.58024263381958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015533302910625935,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09075271089871724,
      "backward_entropy": 0.05759494954889471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589524269104004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01563074439764023,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09074487288792928,
      "backward_entropy": 0.05744966593655673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4622578620910645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015728231519460678,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073676665623982,
      "backward_entropy": 0.05613021417097612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986197471618652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015825161710381508,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09072951475779216,
      "backward_entropy": 0.057147963480515915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.235097885131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01592189073562622,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0907222330570221,
      "backward_entropy": 0.056992850520394066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538142204284668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01601858250796795,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0907145341237386,
      "backward_entropy": 0.05644659562544389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.46391773223877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01611483097076416,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09070765972137451,
      "backward_entropy": 0.05628165331753818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56918716430664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016211194917559624,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09070030848185222,
      "backward_entropy": 0.056114153428511185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.215548515319824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016307741403579712,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09069210290908813,
      "backward_entropy": 0.05634937503121116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.650341033935547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016404807567596436,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09068240722020467,
      "backward_entropy": 0.05495278401808305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.419967174530029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016502615064382553,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09067046642303467,
      "backward_entropy": 0.05476987361907959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.920476913452148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016599800437688828,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09065963824590047,
      "backward_entropy": 0.05458578196438876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.236912727355957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016697322949767113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0906474490960439,
      "backward_entropy": 0.05439741503108631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.870974540710449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016794167459011078,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09063645203908284,
      "backward_entropy": 0.05420811067927967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.828476905822754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016890792176127434,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0906253457069397,
      "backward_entropy": 0.054016275839372116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.319031715393066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016987770795822144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09061276912689209,
      "backward_entropy": 0.05381963469765403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698169708251953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01708531752228737,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09059849381446838,
      "backward_entropy": 0.05443990230560303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145832061767578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01718304120004177,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09058319528897603,
      "backward_entropy": 0.05423380569978194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.565555572509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01728060655295849,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09056769808133443,
      "backward_entropy": 0.054515968669544564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91547679901123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017378266900777817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09055150548617046,
      "backward_entropy": 0.05381039055910977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75153923034668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01747620478272438,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905342698097229,
      "backward_entropy": 0.05359338630329479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.741698741912842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017574315890669823,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0905160903930664,
      "backward_entropy": 0.05390002510764382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538299083709717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017671404406428337,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09050037463506062,
      "backward_entropy": 0.052327719601717865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.134754180908203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01776806078851223,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09048511584599812,
      "backward_entropy": 0.052918098189614036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2813334465026855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017864670604467392,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09046940008799235,
      "backward_entropy": 0.052684225819327614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6899495124816895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017960723489522934,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09045470754305522,
      "backward_entropy": 0.051640228791670365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.601274490356445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01805655099451542,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09043988585472107,
      "backward_entropy": 0.05220693349838257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.493266582489014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018151549622416496,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09042668342590332,
      "backward_entropy": 0.051962332292036575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.079305648803711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018246302381157875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09041352073351543,
      "backward_entropy": 0.0509318004954945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.571755409240723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01834053546190262,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09040149052937825,
      "backward_entropy": 0.051466589624231514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.757217884063721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018434099853038788,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09039092063903809,
      "backward_entropy": 0.051214212721044365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9630937576293945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01852775737643242,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09037915865580241,
      "backward_entropy": 0.050956899469549004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.74284029006958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018621627241373062,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09036596616109212,
      "backward_entropy": 0.05069446563720703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.275360107421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018715566024184227,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0903518299261729,
      "backward_entropy": 0.05042701417749578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.834936141967773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018809255212545395,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09033779303232829,
      "backward_entropy": 0.05015648495067249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.805694103240967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018903054296970367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09032281239827473,
      "backward_entropy": 0.04917732693932273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.750054359436035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018997007980942726,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0903066595395406,
      "backward_entropy": 0.04891012473539873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.125317573547363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01909100078046322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.090289702018102,
      "backward_entropy": 0.048637563532049004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6734089851379395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019185293465852737,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09027099609375,
      "backward_entropy": 0.04835653846914118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.501310348510742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019279619678854942,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09025126695632935,
      "backward_entropy": 0.04807101596485485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.114501953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01937382109463215,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09023110071818034,
      "backward_entropy": 0.048443377017974854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.414026737213135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019467724487185478,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09021102388699849,
      "backward_entropy": 0.048981227658011696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.362202167510986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019561534747481346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09019033114115398,
      "backward_entropy": 0.04719348387284712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.202104568481445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019655199721455574,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09016919136047363,
      "backward_entropy": 0.046893889253789726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.266386032104492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01974865421652794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09014785289764404,
      "backward_entropy": 0.04659115726297552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7092461585998535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01984195038676262,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09012608726819356,
      "backward_entropy": 0.04781410910866477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399968147277832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01993473991751671,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09010513623555501,
      "backward_entropy": 0.04659246314655651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.785178184509277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020028164610266685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09008113543192546,
      "backward_entropy": 0.04565815492109819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.237109661102295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020121783018112183,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09005538622538249,
      "backward_entropy": 0.04594973542473533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.465866565704346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020214581862092018,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0900315244992574,
      "backward_entropy": 0.04501399939710444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.069638252258301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02030680701136589,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09000863631566365,
      "backward_entropy": 0.0446913946758617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.69403076171875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020398886874318123,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0899851123491923,
      "backward_entropy": 0.0443647097457539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.694308757781982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02049064263701439,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08996163805325826,
      "backward_entropy": 0.044033944606781006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.440991401672363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020582089200615883,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08993812402089436,
      "backward_entropy": 0.0436980507590554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.844846248626709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020673751831054688,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08991252382596333,
      "backward_entropy": 0.04395364631306042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0590410232543945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020764537155628204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08988918860753377,
      "backward_entropy": 0.04301460764624856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.165485858917236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020854691043496132,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08986711502075195,
      "backward_entropy": 0.04429058595137163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.904776573181152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02094437927007675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0898456871509552,
      "backward_entropy": 0.04232775081287731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6530561447143555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021033475175499916,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08982547124226888,
      "backward_entropy": 0.04255268790505149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.615893363952637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021123236045241356,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08980124195416768,
      "backward_entropy": 0.04325121912089261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.403450012207031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021212896332144737,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08977603912353516,
      "backward_entropy": 0.04127258062362671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.895806312561035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02130233496427536,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08975038925806682,
      "backward_entropy": 0.0409132567319003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.033315181732178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021391915157437325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08972269296646118,
      "backward_entropy": 0.04054825685241006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.925370216369629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021480994299054146,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08969545364379883,
      "backward_entropy": 0.04069183360446583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.648739814758301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021569542586803436,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08966876069704692,
      "backward_entropy": 0.041475095532157204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.339602470397949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021658169105648994,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08964009086290996,
      "backward_entropy": 0.039443002505735916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.844095230102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021746642887592316,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0896103282769521,
      "backward_entropy": 0.040746667168357155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.971222877502441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021834591403603554,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08958094318707784,
      "backward_entropy": 0.03869337385351008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2840704917907715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02192293107509613,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08954812089602153,
      "backward_entropy": 0.03878491033207287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.513611793518066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022011125460267067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08951423565546672,
      "backward_entropy": 0.03792815858667547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.468059062957764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022098639979958534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08948148290316264,
      "backward_entropy": 0.037542947314002297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.076005935668945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022186271846294403,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08944637576738994,
      "backward_entropy": 0.03715362332083962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.776731491088867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022273704409599304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0894100268681844,
      "backward_entropy": 0.036760368130423805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7548065185546875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022360768169164658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08937340974807739,
      "backward_entropy": 0.03636657649820501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.638596057891846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02244746685028076,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08933623631795247,
      "backward_entropy": 0.037748889489607376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.132516860961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022533781826496124,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08929882446924846,
      "backward_entropy": 0.03736830028620633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.672725200653076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022619357332587242,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08926275372505188,
      "backward_entropy": 0.03518338095058094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.303776741027832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022704709321260452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08922544121742249,
      "backward_entropy": 0.03478884155100042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.594679832458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02278955839574337,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08918661872545879,
      "backward_entropy": 0.036221547560258346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.293105602264404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022873446345329285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08915079633394878,
      "backward_entropy": 0.034482059153643524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.846798896789551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022956980392336845,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08911377191543579,
      "backward_entropy": 0.03360720927065069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.192008972167969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02303987368941307,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08907770117123921,
      "backward_entropy": 0.03321547128937461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.630363464355469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023122461512684822,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08904032905896504,
      "backward_entropy": 0.034685844724828545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.410122871398926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02320435829460621,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0890045960744222,
      "backward_entropy": 0.03430145437067205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3844523429870605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023285429924726486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08897080024083455,
      "backward_entropy": 0.032039436427029694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.826152324676514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023365750908851624,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08893867333730061,
      "backward_entropy": 0.03353250297633084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.755794525146484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02344578132033348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08890538414319356,
      "backward_entropy": 0.03126635605638677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.45967960357666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023525498807430267,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08887102206548055,
      "backward_entropy": 0.03276445919817144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6144537925720215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023604679852724075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08883668979008992,
      "backward_entropy": 0.03094886378808455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.430314540863037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02368353307247162,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08880131443341573,
      "backward_entropy": 0.030559864911166103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9271318912506104,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023761950433254242,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08876573046048482,
      "backward_entropy": 0.030171226371418346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.547097206115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023839514702558517,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08873218297958374,
      "backward_entropy": 0.031234654513272373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.12009859085083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023916887119412422,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08869656920433044,
      "backward_entropy": 0.029402367093346336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.193252086639404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023993702605366707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.088660995165507,
      "backward_entropy": 0.028580562634901566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4423980712890625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024070093408226967,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08862453699111938,
      "backward_entropy": 0.028640294616872616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.294966697692871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024146312847733498,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.088584303855896,
      "backward_entropy": 0.027816750786521217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7427797317504883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024222271516919136,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08854163686434428,
      "backward_entropy": 0.02743415669961409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3385303020477295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02429751306772232,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08850027124087016,
      "backward_entropy": 0.028963140465996483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7414004802703857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02437175065279007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08846289912859599,
      "backward_entropy": 0.026683300733566284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7044661045074463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024445459246635437,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08842543760935466,
      "backward_entropy": 0.02677340399135243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2397046089172363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02451867237687111,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08838777740796407,
      "backward_entropy": 0.02594602649862116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3157246112823486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02459106221795082,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08835442860921223,
      "backward_entropy": 0.027481452985243363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.383357524871826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024662727490067482,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08832257986068726,
      "backward_entropy": 0.02522737600586631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3763010501861572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024733781814575195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0882904330889384,
      "backward_entropy": 0.02487260103225708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.367546558380127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02480430342257023,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08825780948003133,
      "backward_entropy": 0.024520180442116478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6593775749206543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024874363094568253,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08822453022003174,
      "backward_entropy": 0.024169959805228493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9437334537506104,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02494431659579277,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08818769454956055,
      "backward_entropy": 0.0242462158203125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1752238273620605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025013426318764687,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0881527562936147,
      "backward_entropy": 0.023470277136022396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3034653663635254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02508201077580452,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08811664581298828,
      "backward_entropy": 0.023552336476065895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.837533712387085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025150293484330177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08807815114657085,
      "backward_entropy": 0.022776980291713367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.840939998626709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025217829272150993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08804141481717427,
      "backward_entropy": 0.022435426712036133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2321102619171143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025284655392169952,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08800469835599263,
      "backward_entropy": 0.02389759909022938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0798072814941406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025351325049996376,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08796451489130656,
      "backward_entropy": 0.02355192466215654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.298969268798828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025417707860469818,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0879220962524414,
      "backward_entropy": 0.021423547105355698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8640503883361816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025482960045337677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08788494269053142,
      "backward_entropy": 0.021531351587989113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4996097087860107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025547854602336884,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08784626921017964,
      "backward_entropy": 0.02076954191381281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6930994987487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02561197616159916,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08780848979949951,
      "backward_entropy": 0.0222092176025564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.097484827041626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02567562460899353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08776849508285522,
      "backward_entropy": 0.02012942460450259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.609147548675537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025739338248968124,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08772167563438416,
      "backward_entropy": 0.019809124144640835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6607003211975098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025802558287978172,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08767329653104146,
      "backward_entropy": 0.0194919461553747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1518123149871826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02586541883647442,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08762240409851074,
      "backward_entropy": 0.01917709681120786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0602269172668457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025927336886525154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08757427334785461,
      "backward_entropy": 0.01886895028027621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1693191528320312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025988241657614708,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0875279704729716,
      "backward_entropy": 0.018983732570301403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3608596324920654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026048453524708748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08748300870259602,
      "backward_entropy": 0.018270546739751644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.42406964302063,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026108263060450554,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08743690450986226,
      "backward_entropy": 0.018390119075775146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2179160118103027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02616782672703266,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08738698561986287,
      "backward_entropy": 0.01809749820015647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3594279289245605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02622687816619873,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.087334543466568,
      "backward_entropy": 0.017809476364742626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0102076530456543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026285698637366295,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08727786938349406,
      "backward_entropy": 0.01879546723582528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.037341833114624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026343852281570435,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08722127477327983,
      "backward_entropy": 0.018508423458446156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8192189931869507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026401422917842865,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08716341853141785,
      "backward_entropy": 0.016544216058470985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.805782437324524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026458198204636574,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0871084729830424,
      "backward_entropy": 0.016270743174986405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.932708501815796,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02651423029601574,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0870535175005595,
      "backward_entropy": 0.016427022489634426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6438233852386475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026569819077849388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08699650565783183,
      "backward_entropy": 0.015737135301936756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9054673910140991,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026624565944075584,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08694073557853699,
      "backward_entropy": 0.015477696602994745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8744550943374634,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02667899988591671,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08688207467397054,
      "backward_entropy": 0.016878787766803394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7087334394454956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026733053848147392,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08681889375050862,
      "backward_entropy": 0.014966042204336687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6747926473617554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026786573231220245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08675443132718404,
      "backward_entropy": 0.014715267853303389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3048707246780396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026839543133974075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0866877834002177,
      "backward_entropy": 0.014468171379782936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5072509050369263,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026891404762864113,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08662416537602742,
      "backward_entropy": 0.014228253202004866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1990208625793457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026942629367113113,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08655924598375957,
      "backward_entropy": 0.014432278546420011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3963091373443604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699277549982071,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08649837970733643,
      "backward_entropy": 0.01420493017543446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1433289051055908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02704227715730667,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08643593390782674,
      "backward_entropy": 0.013982320373708551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2141616344451904,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027090804651379585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08637743194897969,
      "backward_entropy": 0.013764256780797785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.301948070526123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027138596400618553,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08632045984268188,
      "backward_entropy": 0.013107142665169456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8325042724609375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02718583680689335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08626051743825276,
      "backward_entropy": 0.013339898803017357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2382409572601318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723171003162861,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0862073004245758,
      "backward_entropy": 0.0126947435465726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.150612235069275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027277151122689247,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08615138133366902,
      "backward_entropy": 0.012937123125249689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.138429045677185,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732199802994728,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.086092342933019,
      "backward_entropy": 0.012298592112281105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1601427793502808,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02736637555062771,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08603174487749736,
      "backward_entropy": 0.012105110016736116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9517450928688049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027410361915826797,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08596767981847127,
      "backward_entropy": 0.011913944374431263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0880167484283447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027453621849417686,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08590567111968994,
      "backward_entropy": 0.011727457696741278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8851624131202698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027496494352817535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08584044377009074,
      "backward_entropy": 0.011543282053687355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8835191130638123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02753858081996441,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08577607075373332,
      "backward_entropy": 0.011363724415952509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8990176320075989,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027579959481954575,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08571147918701172,
      "backward_entropy": 0.012731896205381914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7943959832191467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027620762586593628,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08564581473668416,
      "backward_entropy": 0.011467252265323292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8053284883499146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02766081690788269,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08558115363121033,
      "backward_entropy": 0.010848181491548365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7977944612503052,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027700193226337433,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08551520109176636,
      "backward_entropy": 0.012210828336802397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8093909621238708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027738990262150764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08544837435086568,
      "backward_entropy": 0.010976528579538519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6312936544418335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027777327224612236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08537999788920085,
      "backward_entropy": 0.010364639488133516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.552468478679657,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814768254756927,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08531362811724345,
      "backward_entropy": 0.010666262697089802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.662333071231842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02785121276974678,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08525111277898152,
      "backward_entropy": 0.010517849163575605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.53021240234375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02788703888654709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08518725633621216,
      "backward_entropy": 0.009918239306319843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4708414673805237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02792196534574032,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08512598276138306,
      "backward_entropy": 0.009778022088787773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5948866605758667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02795589715242386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08506780862808228,
      "backward_entropy": 0.009642863815481012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5150920152664185,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02798926830291748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08500675360361735,
      "backward_entropy": 0.009510207582603802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4770987927913666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028021955862641335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08494618535041809,
      "backward_entropy": 0.009834914044900374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39298784732818604,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02805393747985363,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08488710721333821,
      "backward_entropy": 0.01072843305089257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4723348319530487,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028084982186555862,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08483072121938069,
      "backward_entropy": 0.009586157446557825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3978221118450165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028115518391132355,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08477493127187093,
      "backward_entropy": 0.009465801444920626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4610670208930969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028145330026745796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0847210983435313,
      "backward_entropy": 0.00890076228163459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42718619108200073,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028174694627523422,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08466550707817078,
      "backward_entropy": 0.009233565493063494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3779110908508301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0282035730779171,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08460937937100728,
      "backward_entropy": 0.009120942516760393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37294256687164307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028231807053089142,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08455320199330647,
      "backward_entropy": 0.008569533174688166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2441917508840561,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02825949527323246,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08449742197990417,
      "backward_entropy": 0.008904301984743639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26098915934562683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028286203742027283,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08444682757059734,
      "backward_entropy": 0.00836401026357304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28932932019233704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028312062844634056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0843992034594218,
      "backward_entropy": 0.008267370137301359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30120784044265747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833721786737442,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08435112237930298,
      "backward_entropy": 0.008173672313039953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2643035650253296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02836182899773121,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0843022068341573,
      "backward_entropy": 0.008082215081561695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2834562361240387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028385760262608528,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08425285418828328,
      "backward_entropy": 0.007993533530018547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2881607413291931,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028409253805875778,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08420320351918538,
      "backward_entropy": 0.007906757295131683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24152061343193054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02843230403959751,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08415105938911438,
      "backward_entropy": 0.007821640507741407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18571075797080994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02845471352338791,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08409775296847026,
      "backward_entropy": 0.008161422881213102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1748206913471222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028476359322667122,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08404684066772461,
      "backward_entropy": 0.008081046017733488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18707245588302612,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028497247025370598,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0839979350566864,
      "backward_entropy": 0.007583503696051511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.223214253783226,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02851746417582035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0839489996433258,
      "backward_entropy": 0.007929120551456104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1970638930797577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0285373292863369,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08389856417973836,
      "backward_entropy": 0.00785627690228549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26682475209236145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02855669893324375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08384703596433003,
      "backward_entropy": 0.0073673616756092415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18864090740680695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028576111420989037,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08379154404004414,
      "backward_entropy": 0.0077152902429754085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17454449832439423,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028595147654414177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08373662829399109,
      "backward_entropy": 0.007227679545229132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1886465698480606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861369587481022,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0836812953154246,
      "backward_entropy": 0.007160534912889654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15888012945652008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028631919994950294,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08362457156181335,
      "backward_entropy": 0.007094629786231301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15253815054893494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864965610206127,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08356730143229167,
      "backward_entropy": 0.007030608301812952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12700267136096954,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028666937723755836,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08350938558578491,
      "backward_entropy": 0.008361144499345259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12950018048286438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02868364378809929,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08345228433609009,
      "backward_entropy": 0.00690836256200617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18254423141479492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02869984321296215,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08339530229568481,
      "backward_entropy": 0.00727324052290483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15798217058181763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02871597371995449,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0833347737789154,
      "backward_entropy": 0.006792379373853857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1506049782037735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028731878846883774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08327205975850423,
      "backward_entropy": 0.006735309958457947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12055623531341553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028747541829943657,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08320777118206024,
      "backward_entropy": 0.00710708580233834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14312586188316345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028762729838490486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08314298590024312,
      "backward_entropy": 0.006624402647668665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12406902760267258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02877769246697426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08307591080665588,
      "backward_entropy": 0.006570609455758875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07799083739519119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02879239059984684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0830083688100179,
      "backward_entropy": 0.006517857313156128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08134154230356216,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028806323185563087,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0829421877861023,
      "backward_entropy": 0.006906144998290322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12993976473808289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028819695115089417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08287753661473592,
      "backward_entropy": 0.006860775026408109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09041096270084381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02883308380842209,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08281068007151286,
      "backward_entropy": 0.006372266872362657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09632817655801773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02884613163769245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08274482190608978,
      "backward_entropy": 0.006325681778517636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08153755217790604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028858907520771027,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08267850677172343,
      "backward_entropy": 0.00628012012351643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09653417021036148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028871318325400352,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08261275788148244,
      "backward_entropy": 0.0062359456311572685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046934548765420914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028883542865514755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08254573742548625,
      "backward_entropy": 0.006192428144541654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0780475065112114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028895024210214615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08248130480448405,
      "backward_entropy": 0.006151609800078652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07101088017225266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028906328603625298,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08241701126098633,
      "backward_entropy": 0.006111518225886605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06417464464902878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02891729027032852,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0823527177174886,
      "backward_entropy": 0.0060725665905258875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06812384724617004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02892783284187317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08228829503059387,
      "backward_entropy": 0.0060350725596601314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05805136263370514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028938094154000282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08222331603368123,
      "backward_entropy": 0.005998535589738326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07500329613685608,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028947973623871803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08215851088364919,
      "backward_entropy": 0.00643467903137207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06447328627109528,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02895776554942131,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08209194242954254,
      "backward_entropy": 0.007373361424966292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059996381402015686,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028967391699552536,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08202477792898814,
      "backward_entropy": 0.00637180967764421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04443012923002243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02897690236568451,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08195791641871135,
      "backward_entropy": 0.005859988656910983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051012083888053894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028985990211367607,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08189208805561066,
      "backward_entropy": 0.0058275352824818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033392228186130524,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028994925320148468,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08182669679323833,
      "backward_entropy": 0.00628345324234529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053155701607465744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02900329791009426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08176292975743611,
      "backward_entropy": 0.005765772678635337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039907872676849365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029011646285653114,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08169858654340108,
      "backward_entropy": 0.0062301544980569315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03323423117399216,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029019594192504883,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08163466056187947,
      "backward_entropy": 0.006204929541457783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03632160276174545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029027225449681282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08157217999299367,
      "backward_entropy": 0.005680174312808297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03680389001965523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029034599661827087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08151026566823323,
      "backward_entropy": 0.005653736604885621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035183195024728775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02904164418578148,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08144821226596832,
      "backward_entropy": 0.005628349767489867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028348147869110107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0290483720600605,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0813860942920049,
      "backward_entropy": 0.005604023283178156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02765938825905323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02905479073524475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08132518331209819,
      "backward_entropy": 0.005580714480443435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02447730302810669,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02906089462339878,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08126522103945415,
      "backward_entropy": 0.006074788218194788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02354414574801922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029066596180200577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08120619257291158,
      "backward_entropy": 0.005537535656582226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023474324494600296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029072079807519913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08114837606747945,
      "backward_entropy": 0.005517392334612933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028134144842624664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02907724678516388,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08109126488367717,
      "backward_entropy": 0.006023650142279538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026758674532175064,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02908230572938919,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08103400468826294,
      "backward_entropy": 0.006007898937572132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02083778753876686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029087116941809654,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08097643653551738,
      "backward_entropy": 0.005461551587690006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020089132711291313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02909170836210251,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08091977735360463,
      "backward_entropy": 0.005444312976165252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02225017175078392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029095958918333054,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.080863818526268,
      "backward_entropy": 0.006953304464166815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019748935475945473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029100235551595688,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08080851535002391,
      "backward_entropy": 0.005411968312480233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017459595575928688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029104212298989296,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08075355490048726,
      "backward_entropy": 0.005396732552485032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02046695537865162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029107900336384773,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08069928487141927,
      "backward_entropy": 0.005382425405762412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015075360424816608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029111593961715698,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08064522345860799,
      "backward_entropy": 0.005368143997409127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016436515375971794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029115045443177223,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08059219022591908,
      "backward_entropy": 0.005354659123854203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013992750085890293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02911846898496151,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08053988218307495,
      "backward_entropy": 0.0053413706746968355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016940109431743622,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02912166155874729,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08048860728740692,
      "backward_entropy": 0.0058862837878140535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014618122950196266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029124824330210686,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08043766021728516,
      "backward_entropy": 0.0058766617016358805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014869892969727516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029127858579158783,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08038736879825592,
      "backward_entropy": 0.005304300649599595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014606792479753494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029130833223462105,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0803374449412028,
      "backward_entropy": 0.0052925057031891565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015385907143354416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029133649542927742,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08028774956862132,
      "backward_entropy": 0.005849903957410293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013106555677950382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029136400669813156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08023801445960999,
      "backward_entropy": 0.00527011128989133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011472195386886597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029139095917344093,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08018878102302551,
      "backward_entropy": 0.005259240215474909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012043504975736141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029141724109649658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08014036218325298,
      "backward_entropy": 0.005248630588704889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010075222700834274,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029144292697310448,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0800924301147461,
      "backward_entropy": 0.00581781498410485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010780511423945427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02914665825664997,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08004534244537354,
      "backward_entropy": 0.005228508602489124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011139028705656528,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0291487704962492,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07999870677789052,
      "backward_entropy": 0.006823301992633126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012125088833272457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029150836169719696,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07995250821113586,
      "backward_entropy": 0.005798211829228835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00971915666013956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029152842238545418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0799063245455424,
      "backward_entropy": 0.005202241580594669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009190856479108334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02915485017001629,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0798608660697937,
      "backward_entropy": 0.005193639885295521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009855692274868488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029156729578971863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07981598377227783,
      "backward_entropy": 0.005185509269887751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008303055539727211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0291585810482502,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07977139453093211,
      "backward_entropy": 0.0051774914291771975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008456362411379814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029160378500819206,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07972750067710876,
      "backward_entropy": 0.005169683220711621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007654608227312565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02916198968887329,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07968408862749736,
      "backward_entropy": 0.005162465640089728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005286243744194508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029163559898734093,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07964137196540833,
      "backward_entropy": 0.006794792684641751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009770570322871208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029165048152208328,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07960009574890137,
      "backward_entropy": 0.005148717964237387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007401588372886181,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029166461899876595,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07955854137738545,
      "backward_entropy": 0.006790029731663791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0064587676897645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02916763909161091,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07951744397481282,
      "backward_entropy": 0.005136370320211758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006825246382504702,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02916867658495903,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07947704195976257,
      "backward_entropy": 0.005744880573316054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007112456019967794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02916966751217842,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07943708697954814,
      "backward_entropy": 0.005125855180350217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00678590964525938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029170570895075798,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07939739028612773,
      "backward_entropy": 0.005120972002094442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0070232306607067585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02917158603668213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07935811579227448,
      "backward_entropy": 0.005115758627653122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00571270938962698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029172653332352638,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07931906978289287,
      "backward_entropy": 0.0051104158840396185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00603379076346755,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02917369082570076,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.079280619819959,
      "backward_entropy": 0.006784546104344455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006412119138985872,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029174700379371643,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07924253741900127,
      "backward_entropy": 0.00572663816538724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005040141753852367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029175570234656334,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07920455932617188,
      "backward_entropy": 0.005723951215093786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0039055636152625084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02917638048529625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07916725178559621,
      "backward_entropy": 0.005090961740775542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004664617590606213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029177214950323105,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07913101216157277,
      "backward_entropy": 0.005086488344452598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004649491049349308,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029177991673350334,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07909536361694336,
      "backward_entropy": 0.00678280537778681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005203743930906057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029178764671087265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07906029125054677,
      "backward_entropy": 0.005078030242161317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038727542851120234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02917940728366375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07902541756629944,
      "backward_entropy": 0.0050742124969309025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004266636446118355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029179982841014862,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0789913535118103,
      "backward_entropy": 0.006783478639342568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041024633683264256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918054535984993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07895777622858684,
      "backward_entropy": 0.005067098547111858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043278345838189125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029181092977523804,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07892463107903798,
      "backward_entropy": 0.0050636468963189555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036563288886100054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029181627556681633,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07889173924922943,
      "backward_entropy": 0.005060256882147355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004033793695271015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918217144906521,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07885936896006267,
      "backward_entropy": 0.005056877366521142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031534479930996895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029182633385062218,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07882727682590485,
      "backward_entropy": 0.005053780972957611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002572163939476013,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918308787047863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07879591981569926,
      "backward_entropy": 0.005050718784332275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027108194772154093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029183559119701385,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07876554628213246,
      "backward_entropy": 0.005698822438716888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030345988925546408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029184000566601753,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07873595754305522,
      "backward_entropy": 0.005044729194857858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028946255333721638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029184525832533836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07870684067408244,
      "backward_entropy": 0.005041578276590867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031579998321831226,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02918502315878868,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07867817083994548,
      "backward_entropy": 0.006789381531151858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030645739752799273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029185501858592033,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07864969968795776,
      "backward_entropy": 0.0067898190834305506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026480108499526978,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029185933992266655,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0786214570204417,
      "backward_entropy": 0.005691132084889846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002284341026097536,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029186353087425232,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07859363655249278,
      "backward_entropy": 0.005030044777826829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020885944832116365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029186762869358063,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07856644193331401,
      "backward_entropy": 0.00568834895437414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002585765440016985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918718196451664,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07853991786638896,
      "backward_entropy": 0.005024700340899554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021203490905463696,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029187584295868874,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07851361234982808,
      "backward_entropy": 0.005685600367459384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002283890265971422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02918795682489872,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07848788301150005,
      "backward_entropy": 0.005684322931549766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026109961327165365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918839454650879,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07846246163050334,
      "backward_entropy": 0.005016946318474683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015424077864736319,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918873354792595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07843710978825887,
      "backward_entropy": 0.005014575340531089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020008005667477846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918909303843975,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07841261227925618,
      "backward_entropy": 0.005012181333520196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016937237232923508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029189422726631165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07838844259579976,
      "backward_entropy": 0.005009909583763642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016741983126848936,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02918975241482258,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07836481928825378,
      "backward_entropy": 0.005678042092106559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014394684694707394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919008769094944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07834165294965108,
      "backward_entropy": 0.005005433816801418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015939997974783182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029190460219979286,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07831907272338867,
      "backward_entropy": 0.005003129555420442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012742384569719434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919086627662182,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07829683025677998,
      "backward_entropy": 0.0056741765954277735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016086326213553548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029191292822360992,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07827524840831757,
      "backward_entropy": 0.0049983537332578135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016259067924693227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919165976345539,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825396458307902,
      "backward_entropy": 0.005671463906764984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013751351507380605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029192009940743446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07823286950588226,
      "backward_entropy": 0.004993969066576524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000815974548459053,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919234335422516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07821218172709148,
      "backward_entropy": 0.005669030953537334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011721232440322638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029192708432674408,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078192338347435,
      "backward_entropy": 0.004989750344644894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010210479376837611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029193012043833733,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07817299167315166,
      "backward_entropy": 0.004987825724211606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014325175434350967,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029193291440606117,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07815418144067128,
      "backward_entropy": 0.005665657533840699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001574640511535108,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919352613389492,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07813539107640584,
      "backward_entropy": 0.005664741112427278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010025816736742854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029193680733442307,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07811646660168965,
      "backward_entropy": 0.004982830448584123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011538935359567404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02919379621744156,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07809804379940033,
      "backward_entropy": 0.006803192875602029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012652730802074075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919388748705387,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07807988425095876,
      "backward_entropy": 0.0049802803180434485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000890574068762362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919396385550499,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07806175947189331,
      "backward_entropy": 0.00497908890247345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009226334514096379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919405698776245,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07804408669471741,
      "backward_entropy": 0.005661935291507028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008387736161239445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029194112867116928,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07802686591943105,
      "backward_entropy": 0.006808435375040228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007682896102778614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029194192960858345,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07801003257433574,
      "backward_entropy": 0.0049756030467423525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000620963575784117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029194265604019165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07799368600050609,
      "backward_entropy": 0.004974488168954849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006988359382376075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919435128569603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07797794540723164,
      "backward_entropy": 0.004973390224305066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000633030547760427,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919445000588894,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07796259721120198,
      "backward_entropy": 0.005659488114443692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006316772778518498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029194552451372147,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07794769605000813,
      "backward_entropy": 0.005658946254036643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007041235803626478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919464185833931,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07793322205543518,
      "backward_entropy": 0.004970118403434753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006464776233769953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029194705188274384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07791901628176372,
      "backward_entropy": 0.00496917421167547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007689408957958221,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029194774106144905,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07790505886077881,
      "backward_entropy": 0.0068171667781743136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000528818229213357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919480949640274,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07789116104443868,
      "backward_entropy": 0.005657171999866312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047301745507866144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919485792517662,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0778776506582896,
      "backward_entropy": 0.004966504194519736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004810858517885208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919492870569229,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07786457240581512,
      "backward_entropy": 0.00496559894897721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032032185117714107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919502556324005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07785184184710185,
      "backward_entropy": 0.004964642226696014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003751332114916295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029195144772529602,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07783974707126617,
      "backward_entropy": 0.0049636506221511145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005301954806782305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029195284470915794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0778281142314275,
      "backward_entropy": 0.004962611604820599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044197621173225343,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029195401817560196,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07781659066677094,
      "backward_entropy": 0.00565395402637395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00045104342279955745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029195547103881836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07780525088310242,
      "backward_entropy": 0.004960604689337991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005709781544283032,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919570729136467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07779402037461598,
      "backward_entropy": 0.004959534515034069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023376777244266123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029195822775363922,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07778273026148479,
      "backward_entropy": 0.00495859066193754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004467005201149732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029195968061685562,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07777202626069386,
      "backward_entropy": 0.004957595670765097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003275635826867074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196109622716904,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07776134709517162,
      "backward_entropy": 0.004956611855463548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005354342865757644,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196249321103096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07775100072224934,
      "backward_entropy": 0.004955647005276246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030290900031104684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029196348041296005,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07774046063423157,
      "backward_entropy": 0.005649515850977464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025457923766225576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196463525295258,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07773021360238393,
      "backward_entropy": 0.0049539167772639885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002769493730738759,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196610674262047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07772030433019002,
      "backward_entropy": 0.004952956668355248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000340232189046219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196754097938538,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07771073778470357,
      "backward_entropy": 0.004952021959153089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002611406962387264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196903109550476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07770121097564697,
      "backward_entropy": 0.004951075735417279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024355122877750546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029197050258517265,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0776919573545456,
      "backward_entropy": 0.004950153895399787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003367039898876101,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0291972067207098,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07768296202023824,
      "backward_entropy": 0.004949220202185891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027492482331581414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029197338968515396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0776739517847697,
      "backward_entropy": 0.004948355257511139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022029470710549504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919747121632099,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07766505082448323,
      "backward_entropy": 0.004947494715452194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022068883117754012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029197601601481438,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07765645285447438,
      "backward_entropy": 0.00494665652513504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023915628844406456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029197733849287033,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07764807343482971,
      "backward_entropy": 0.004945822060108185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016239572141785175,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029197853058576584,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07763986786206563,
      "backward_entropy": 0.005642621354623275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001442019856767729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919798344373703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07763199508190155,
      "backward_entropy": 0.004944233731790023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001933741004904732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919813059270382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0776244302590688,
      "backward_entropy": 0.004943400621414185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016735444660298526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919827774167061,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07761697967847188,
      "backward_entropy": 0.004942572252316909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001673829829087481,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02919841930270195,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07760978738466899,
      "backward_entropy": 0.005640119991519235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.980969480238855e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029198557138442993,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07760277390480042,
      "backward_entropy": 0.004941014064983888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013650489563588053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919870987534523,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07759614785512288,
      "backward_entropy": 0.004940207370302894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012962057371623814,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029198871925473213,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07758966088294983,
      "backward_entropy": 0.005638197741725228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013982734526507556,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029199030250310898,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07758339742819469,
      "backward_entropy": 0.004938603124835275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011443752737250179,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029199179261922836,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07757729291915894,
      "backward_entropy": 0.0049378363923593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014613218081649393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029199333861470222,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07757137219111125,
      "backward_entropy": 0.004937079819765958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001189343020087108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029199475422501564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07756551106770833,
      "backward_entropy": 0.004936357790773565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010637831292115152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029199616983532906,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07755978902180989,
      "backward_entropy": 0.006832258267836137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014179758727550507,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029199764132499695,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.077554186185201,
      "backward_entropy": 0.005634485997936942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001254931412404403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919989451766014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07754862308502197,
      "backward_entropy": 0.004934236068617214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.241501589305699e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029200013726949692,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07754313945770264,
      "backward_entropy": 0.004933598705313422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.755778253544122e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920013852417469,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07753791411717732,
      "backward_entropy": 0.004932956939393824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010170679161092266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029200255870819092,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07753292719523112,
      "backward_entropy": 0.006832619959657843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.904173591872677e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029200367629528046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07752800484498341,
      "backward_entropy": 0.004931765523823825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010534624743741006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920047752559185,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07752318183581035,
      "backward_entropy": 0.004931189119815826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.954371878644451e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920057624578476,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07751839359601338,
      "backward_entropy": 0.004930646243420514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011652587272692472,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920066937804222,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07751371463139851,
      "backward_entropy": 0.005630468103018674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69286120380275e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920074388384819,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07750902573267619,
      "backward_entropy": 0.004929659041491422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876304152887315e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029200812801718712,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07750434676806132,
      "backward_entropy": 0.00562970983711156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.378872346132994e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029200876131653786,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07749979694684346,
      "backward_entropy": 0.00562936778772961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.604167720070109e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029200928285717964,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0774953265984853,
      "backward_entropy": 0.005629047074101188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.193250010255724e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029200980439782143,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07749098042647044,
      "backward_entropy": 0.006834476508877494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3887437641387805e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920103259384632,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07748679320017497,
      "backward_entropy": 0.004927613518454812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.612480501644313e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201092198491096,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07748279968897502,
      "backward_entropy": 0.004927226088263772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.837634620955214e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201148077845573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07747888565063477,
      "backward_entropy": 0.004926844076676803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.528771387413144e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201192781329155,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07747499148050944,
      "backward_entropy": 0.005627482452175834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.040750668034889e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201241210103035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07747127612431844,
      "backward_entropy": 0.0049261653965169735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30991702969186e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201285913586617,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07746759057044983,
      "backward_entropy": 0.004925840957598252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2746807341463864e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201313853263855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07746388514836629,
      "backward_entropy": 0.004925558512861078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.354875247576274e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201338067650795,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07746030886967976,
      "backward_entropy": 0.004925297403877432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.353187614469789e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201362282037735,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07745679219563802,
      "backward_entropy": 0.004925030876289715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.009534263284877e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201388359069824,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07745339473088582,
      "backward_entropy": 0.006837379526008259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1830833399435505e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201405122876167,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07745002706845601,
      "backward_entropy": 0.006837731057947332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.952853487338871e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201418161392212,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07744672397772472,
      "backward_entropy": 0.0049243264577605505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3428968638181686e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201427474617958,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07744350532690684,
      "backward_entropy": 0.004924122582782398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.192598498775624e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201436787843704,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07744033634662628,
      "backward_entropy": 0.004923920062455264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.436132414615713e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920144610106945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07743720710277557,
      "backward_entropy": 0.004923719574104656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2719208573107608e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920144610106945,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07743408282597859,
      "backward_entropy": 0.006839605217630213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.196529723936692e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201453551650047,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07743117213249207,
      "backward_entropy": 0.005624847317283804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6202846129308455e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201464727520943,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07742834587891896,
      "backward_entropy": 0.004923180084336887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.937432327598799e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201479628682137,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07742564876874287,
      "backward_entropy": 0.005624507638541135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.648856727522798e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920149639248848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07742303609848022,
      "backward_entropy": 0.004922793331471356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.070926322834566e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201509431004524,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07742043336232503,
      "backward_entropy": 0.004922612824223258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.53252432635054e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920152060687542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07741795480251312,
      "backward_entropy": 0.0049224482341246175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7966374798561446e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920152060687542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07741541663805644,
      "backward_entropy": 0.004922311414371838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0832767404499464e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201528057456017,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07741300264994304,
      "backward_entropy": 0.006842098452828147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9941713617299683e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201539233326912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0774106780687968,
      "backward_entropy": 0.004921984266151081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8966309653478675e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201554134488106,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07740843296051025,
      "backward_entropy": 0.0049218183214014225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.143155325029511e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201572760939598,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07740630706151326,
      "backward_entropy": 0.0068428448655388574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1434405678301118e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920159138739109,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0774042656024297,
      "backward_entropy": 0.005623092705553228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.302263237652369e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920161746442318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07740237812201183,
      "backward_entropy": 0.00492130457000299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9384500774322078e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920163981616497,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07740050554275513,
      "backward_entropy": 0.004921128804033453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2967135262442753e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920166216790676,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07739868760108948,
      "backward_entropy": 0.004920972003178163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0758565369760618e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920168824493885,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07739696900049846,
      "backward_entropy": 0.006843745708465576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0035986381117254e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920171059668064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07739528020222981,
      "backward_entropy": 0.004920637065714056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.197124922531657e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201729223132133,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07739360630512238,
      "backward_entropy": 0.0049204880541021175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3774864530423656e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201744124293327,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07739194234212239,
      "backward_entropy": 0.004920349541035565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.047768430202268e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201753437519073,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07739022374153137,
      "backward_entropy": 0.006844502958384427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7418480638298206e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920175902545452,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07738850514094035,
      "backward_entropy": 0.0049201243303038855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9017212252947502e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920176275074482,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07738680144151051,
      "backward_entropy": 0.0049200118942694234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.641769793233834e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920176275074482,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07738510767618816,
      "backward_entropy": 0.00491992553526705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5563668057438917e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201768338680267,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07738351325194041,
      "backward_entropy": 0.004919813099232587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4995485798863228e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201772063970566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07738195856412251,
      "backward_entropy": 0.004919719628312371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2516906281234697e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201773926615715,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773804138104121,
      "backward_entropy": 0.005621121688322587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3818879425525665e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201777651906013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07737892866134644,
      "backward_entropy": 0.005621027201414108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1652732609945815e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920178696513176,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07737753788630168,
      "backward_entropy": 0.005620904266834259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1203392205061391e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201794415712357,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07737618684768677,
      "backward_entropy": 0.005620795556090095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4250761523726396e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201801866292953,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07737486561139424,
      "backward_entropy": 0.004919225180690939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.042758140101796e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201805591583252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07737353444099426,
      "backward_entropy": 0.005620579827915539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.905853751959512e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920180931687355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07737222810586293,
      "backward_entropy": 0.004919054494662719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.672390660853125e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201816767454147,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07737100124359131,
      "backward_entropy": 0.006847164170308547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3920404853706714e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201824218034744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736977934837341,
      "backward_entropy": 0.00491886856881055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3585428860096727e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201826080679893,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736854751904805,
      "backward_entropy": 0.004918798126957633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.773597983235959e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201824218034744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736732562383015,
      "backward_entropy": 0.0049187290397557345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2626705029106233e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201822355389595,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07736614346504211,
      "backward_entropy": 0.0056200460954145956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0694522643461823e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201816767454147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736497620741527,
      "backward_entropy": 0.004918618974360553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.023634922603378e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920180931687355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736380398273468,
      "backward_entropy": 0.004918573593551462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5977511793607846e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201800003647804,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736261188983917,
      "backward_entropy": 0.004918544807217338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.627174222259782e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201781377196312,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736136515935262,
      "backward_entropy": 0.004918520762161775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.116307410295121e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920176275074482,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07736014326413472,
      "backward_entropy": 0.004918510263616388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4828542488394305e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201744124293327,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07735895117123921,
      "backward_entropy": 0.004918499426408248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.537248853215715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201727360486984,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07735779881477356,
      "backward_entropy": 0.004918473688038913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.21389563093544e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920171432197094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07735673089822133,
      "backward_entropy": 0.004918454384261911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.879078682686668e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201703146100044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07735571265220642,
      "backward_entropy": 0.004918424920602279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.652436811942607e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201693832874298,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0773547391096751,
      "backward_entropy": 0.006850275803696026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.538113444141345e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201684519648552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07735378543535869,
      "backward_entropy": 0.004918370734561573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.719115274085198e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201678931713104,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07735287646452586,
      "backward_entropy": 0.005619534037329934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.010095603414811e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201669618487358,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07735195755958557,
      "backward_entropy": 0.005619490011171861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596065420832019e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920166216790676,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07735109329223633,
      "backward_entropy": 0.004918276924978603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.98633822746342e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201654717326164,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07735024392604828,
      "backward_entropy": 0.005619395862926136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.386104137665825e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201652854681015,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07734947899977367,
      "backward_entropy": 0.005619336258281361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.936383902531816e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201650992035866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734872897466023,
      "backward_entropy": 0.004918168552897193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.019172360538505e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201649129390717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734795411427815,
      "backward_entropy": 0.00491812757470391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.635536242858507e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734716931978862,
      "backward_entropy": 0.004918103529648347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.626089659926947e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920163795351982,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07734639445940654,
      "backward_entropy": 0.005619131367314945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3264397011880646e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201630502939224,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07734560469786327,
      "backward_entropy": 0.006852153350006451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.000112428708235e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201628640294075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734488447507222,
      "backward_entropy": 0.004918013106692921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.919410007962142e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201626777648926,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07734419405460358,
      "backward_entropy": 0.005618988112969832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.235286158087547e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201626777648926,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07734352350234985,
      "backward_entropy": 0.006852537393569946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2075901142670773e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201626777648926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734287281831105,
      "backward_entropy": 0.004917891188101335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.11609710479388e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201628640294075,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773422618707021,
      "backward_entropy": 0.0049178590151396665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5323954560008133e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201630502939224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734166582425435,
      "backward_entropy": 0.004917813972993331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.958594677693327e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201634228229523,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734109958012898,
      "backward_entropy": 0.004917770624160767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8363331239233958e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920163795351982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.077340563138326,
      "backward_entropy": 0.004917727952653711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1023444080346962e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920164167881012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773400366306305,
      "backward_entropy": 0.004917685958472165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3722567422955763e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733951508998871,
      "backward_entropy": 0.004917645318941636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0789968857570784e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07733898361523946,
      "backward_entropy": 0.0068533379923213615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4460268832626753e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733845710754395,
      "backward_entropy": 0.0049175850369713526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3391644390358124e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733795543511708,
      "backward_entropy": 0.0049175606532530355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3023005724098766e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733747363090515,
      "backward_entropy": 0.004917524755001068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.833915459632408e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920164354145527,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07733699679374695,
      "backward_entropy": 0.005618281662464142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.831669346254785e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920164167881012,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07733651002248128,
      "backward_entropy": 0.006853807378898968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6961465689746547e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201636090874672,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07733600835005443,
      "backward_entropy": 0.005618201738054102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.914618678711122e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201632365584373,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07733551661173503,
      "backward_entropy": 0.005618164146488363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.304848410654813e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201628640294075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07733503480752309,
      "backward_entropy": 0.005618137053468011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.853830212894536e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201626777648926,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733460267384847,
      "backward_entropy": 0.004917387257922779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3836016680434113e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201624915003777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733417054017384,
      "backward_entropy": 0.00491737574338913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.428441009920789e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201623052358627,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07733374834060669,
      "backward_entropy": 0.006854433227669109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5964043313942966e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201621189713478,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733334600925446,
      "backward_entropy": 0.0049173347651958466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0711778486438561e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920161932706833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733295361200969,
      "backward_entropy": 0.004917320880022916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5348142596849357e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920161932706833,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07733258605003357,
      "backward_entropy": 0.00561791489070112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4505350236504455e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920161932706833,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07733221848805745,
      "backward_entropy": 0.006854778663678603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6212720765906852e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920161932706833,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733187079429626,
      "backward_entropy": 0.004917250438169999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.86190617216198e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920161746442318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733150819937389,
      "backward_entropy": 0.004917236891659823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.087486225515022e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920161746442318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733118037382762,
      "backward_entropy": 0.004917219958522103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4360664408741286e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920161746442318,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07733085751533508,
      "backward_entropy": 0.005617732351476496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0027354164776625e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920161746442318,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07733052968978882,
      "backward_entropy": 0.0068551518700339575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.968569904420292e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920161746442318,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07733020186424255,
      "backward_entropy": 0.004917165433818644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5518508007517084e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920161373913288,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732986410458882,
      "backward_entropy": 0.004917152564633976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513251484349894e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201610013842583,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732951144377391,
      "backward_entropy": 0.004917145452716134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0736913509390433e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201606288552284,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732918361822765,
      "backward_entropy": 0.004917135970159011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.359162752123666e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201602563261986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732886572678883,
      "backward_entropy": 0.004917130212892185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.154283950199897e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201598837971687,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07732854286829631,
      "backward_entropy": 0.006855632771145214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5611692560923984e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920159511268139,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773282249768575,
      "backward_entropy": 0.005617537959055467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0698331607272848e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201587662100792,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732787728309631,
      "backward_entropy": 0.005617526105859063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.049663524099742e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201580211520195,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07732753952344258,
      "backward_entropy": 0.006855906410650773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.732534873459372e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201572760939598,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732722163200378,
      "backward_entropy": 0.004917117682370273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.068076244337135e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920156717300415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732691367467244,
      "backward_entropy": 0.004917106167836623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0866876891668653e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201561585068703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732660075028737,
      "backward_entropy": 0.004917106167836623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.892425853446184e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201555997133255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732630769411723,
      "backward_entropy": 0.005617469549179077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9092473141645314e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201550409197807,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07732599973678589,
      "backward_entropy": 0.00685634125362743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.159185315686045e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920154668390751,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773257464170456,
      "backward_entropy": 0.00561743906953118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.65575066452584e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920154295861721,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773254930973053,
      "backward_entropy": 0.004917098378593271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.876695230559562e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201539233326912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732524474461873,
      "backward_entropy": 0.00491709363731471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.972826784272911e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201533645391464,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732499639193217,
      "backward_entropy": 0.005617389286106283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718628012298723e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201528057456017,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732472817103068,
      "backward_entropy": 0.0049170922826636924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.003533030707331e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920152246952057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732446988423665,
      "backward_entropy": 0.0049170922826636924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6235010131567833e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920151688158512,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773242215315501,
      "backward_entropy": 0.005617350339889526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.146270940618706e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201513156294823,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732398311297099,
      "backward_entropy": 0.004917089234698902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.173327614713344e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201507568359375,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732374966144562,
      "backward_entropy": 0.005617333068089051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.784261816188518e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201501980423927,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732349634170532,
      "backward_entropy": 0.0056173269721594725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.221448186101043e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920149639248848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773232380549113,
      "backward_entropy": 0.00491709363731471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.758951715506555e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201490804553032,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773229996363322,
      "backward_entropy": 0.005617306313731454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.036981628516514e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201483353972435,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732275128364563,
      "backward_entropy": 0.0056173029271039095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2866586252566776e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201475903391838,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732249299685161,
      "backward_entropy": 0.004917119375684045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.457225545844267e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920147031545639,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732226451237996,
      "backward_entropy": 0.005617292428558523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5157989941581036e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201464727520943,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732206583023071,
      "backward_entropy": 0.004917121068997817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.853782797908934e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201461002230644,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732186714808147,
      "backward_entropy": 0.005617264996875416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8089328907299205e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201457276940346,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732167840003967,
      "backward_entropy": 0.005617256868969311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2886129613652884e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201453551650047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732148965199788,
      "backward_entropy": 0.004917119375684045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.796100938619929e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201451689004898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732133070627849,
      "backward_entropy": 0.005617236549204046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.139930697670934e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0292014479637146,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773211419582367,
      "backward_entropy": 0.005617215552113273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5661697716495837e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920144610106945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732098301251729,
      "backward_entropy": 0.004917103119871833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.136261679832387e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0292014442384243,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773208240667979,
      "backward_entropy": 0.004917097023942254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.107704623696918e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201442375779152,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07732066015402476,
      "backward_entropy": 0.0056171715259552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.70085643908169e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201438650488853,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732048134009044,
      "backward_entropy": 0.004917095330628482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6773228139754792e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201434925198555,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732029259204865,
      "backward_entropy": 0.004917095330628482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9900666592984635e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201431199908257,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732011874516805,
      "backward_entropy": 0.00491709363731471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0364258546123892e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201427474617958,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731994489828746,
      "backward_entropy": 0.004917097023942254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0430546499028424e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920142374932766,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731978098551433,
      "backward_entropy": 0.005617136982354251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.116115496164639e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920142188668251,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731963694095612,
      "backward_entropy": 0.00491709363731471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.84432195737827e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920142002403736,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773194928963979,
      "backward_entropy": 0.005617107857357372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3642552093861013e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201418161392212,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731935381889343,
      "backward_entropy": 0.005617096342823722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8286377212461957e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201416298747063,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731922964255016,
      "backward_entropy": 0.0049170848320830955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2438445651241636e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201414436101913,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0773191104332606,
      "backward_entropy": 0.005617064169862054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.147024756344763e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201414436101913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731899122397105,
      "backward_entropy": 0.004917075688188726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2814783190151502e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773188720146815,
      "backward_entropy": 0.004917071285572919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6515626555246854e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773187627394994,
      "backward_entropy": 0.004917054691097953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2550350447781966e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731865843137105,
      "backward_entropy": 0.005617005581205542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2978500762983458e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07731855909029643,
      "backward_entropy": 0.006858601488850333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5652368290375307e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731846968332927,
      "backward_entropy": 0.004917041144587777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.985413136817442e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731837034225464,
      "backward_entropy": 0.004917038435285742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.230281014841239e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731828093528748,
      "backward_entropy": 0.004917032339356162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.833637384152098e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07731820146242778,
      "backward_entropy": 0.006858701055700129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.178105009103092e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07731811702251434,
      "backward_entropy": 0.006858727471394973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5842057621284766e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07731802761554718,
      "backward_entropy": 0.0068587491458112545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0016798768219815e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07731794317563374,
      "backward_entropy": 0.006858777593482624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4023493122294894e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731786370277405,
      "backward_entropy": 0.004916994747790423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2270510296730208e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731777926286061,
      "backward_entropy": 0.005616861310872165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.118111255977055e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07731769979000092,
      "backward_entropy": 0.006858854808590629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.660016786483538e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731763521830241,
      "backward_entropy": 0.004916982555931265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1063635696473284e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0773175557454427,
      "backward_entropy": 0.0068589015440507365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.08194124349393e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731748620669048,
      "backward_entropy": 0.005616809834133495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0374664327628125e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731741666793823,
      "backward_entropy": 0.005616790869019248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.648642418369491e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731735706329346,
      "backward_entropy": 0.004916958172212948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.963151370584455e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731729249159495,
      "backward_entropy": 0.0049169554629109125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.634066807009731e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731721798578899,
      "backward_entropy": 0.004916952414946122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2144138850089803e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731715341409047,
      "backward_entropy": 0.004916950721632351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2095921420041122e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201412573456764,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731708884239197,
      "backward_entropy": 0.004916947673667561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.83151890004774e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201410710811615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731701930363973,
      "backward_entropy": 0.004916945980353789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.471099484566366e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201408848166466,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731693983078003,
      "backward_entropy": 0.004916945980353789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.007904739315563e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201406985521317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731687029202779,
      "backward_entropy": 0.004916944625702771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.159260206890394e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201405122876167,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731680075327556,
      "backward_entropy": 0.005616710944609208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907700450004995e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201403260231018,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731672624746959,
      "backward_entropy": 0.004916944625702771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.416848836148347e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920140139758587,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07731665174166362,
      "backward_entropy": 0.005616694011471488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.969398924638881e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920139953494072,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731657226880391,
      "backward_entropy": 0.004916945980353789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.423880011790061e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02920139767229557,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07731650769710541,
      "backward_entropy": 0.0068592571399428625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.275796866044402e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920139580965042,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773164431254069,
      "backward_entropy": 0.004916944625702771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.427947075669181e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201393947005272,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0773163636525472,
      "backward_entropy": 0.004916942932388999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4601340337967486e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029201392084360123,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07731629411379497,
      "backward_entropy": 0.004916944625702771,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 6.34815941005229e-07,
    "avg_log_Z": 0.029201491493731736,
    "success_rate": 1.0,
    "avg_reward": 45.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.32,
      "2": 0.53
    },
    "avg_forward_entropy": 0.07732325841983159,
    "avg_backward_entropy": 0.005432172305881977,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}