{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23103872934977213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23103872934977213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23103872934977213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23103872934977213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23103872934977213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23103872934977213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23091999689737955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23073395093282065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.938856601715088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459481358528137,
      "backward_entropy": 0.23103872934977213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.936556816101074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745989263057709,
      "backward_entropy": 0.23090620835622153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.579964637756348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019999960204586387,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460262179374695,
      "backward_entropy": 0.23069190979003906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.035419464111328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00029991540941409767,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460649609565735,
      "backward_entropy": 0.23087636629740396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8267340660095215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00039991422090679407,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2746097445487976,
      "backward_entropy": 0.2308604121208191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824934482574463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004998912918381393,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27461254596710205,
      "backward_entropy": 0.23062296708424887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.672503471374512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005998540436848998,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27461495995521545,
      "backward_entropy": 0.23059811194737753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.379633903503418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00069977663224563,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2746172249317169,
      "backward_entropy": 0.23099867502848306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.819486141204834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007998833898454905,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27461856603622437,
      "backward_entropy": 0.23099025090535483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.598592281341553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008999367128126323,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27461957931518555,
      "backward_entropy": 0.2307645877202352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.727339744567871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009995356667786837,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27462103962898254,
      "backward_entropy": 0.23097127676010132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.147705078125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010995094198733568,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27462145686149597,
      "backward_entropy": 0.23096080621083578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.869032382965088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001199261168949306,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2746218740940094,
      "backward_entropy": 0.23043425877888998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.909651279449463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001299029914662242,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27462202310562134,
      "backward_entropy": 0.23040364185969034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1959123611450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013988647842779756,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27462196350097656,
      "backward_entropy": 0.23037191232045492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.321470260620117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001498489174991846,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2746220529079437,
      "backward_entropy": 0.23091107606887817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.062666893005371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015983311459422112,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2746216654777527,
      "backward_entropy": 0.23030443986256918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.705056190490723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016982686938717961,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27462103962898254,
      "backward_entropy": 0.2305451234181722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51364517211914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017981503624469042,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2746204733848572,
      "backward_entropy": 0.23050940036773682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51179313659668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001898303278721869,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27461934089660645,
      "backward_entropy": 0.23047196865081787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.768678665161133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019986843690276146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2746177911758423,
      "backward_entropy": 0.23082653681437174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41064167022705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002099346136674285,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2746158242225647,
      "backward_entropy": 0.23011261224746704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.081923007965088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002200107090175152,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2746135890483856,
      "backward_entropy": 0.2300708293914795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.147533416748047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023004221729934216,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2746118903160095,
      "backward_entropy": 0.23030491669972739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471491813659668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00240079197101295,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2746100425720215,
      "backward_entropy": 0.23073695103327432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.498899459838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002501298440620303,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2746082544326782,
      "backward_entropy": 0.22993489106496176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.141094207763672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00260197464376688,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2746061384677887,
      "backward_entropy": 0.2306842803955078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426254272460938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002702648052945733,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460387349128723,
      "backward_entropy": 0.23010623455047607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.781375885009766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028034686110913754,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2746011018753052,
      "backward_entropy": 0.23062602678934732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.393528938293457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029041089583188295,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745984196662903,
      "backward_entropy": 0.22973386446634927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.162503242492676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0030048431362956762,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459558844566345,
      "backward_entropy": 0.22967976331710815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0652313232421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031051409896463156,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745930254459381,
      "backward_entropy": 0.22986706097920737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646053314208984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003205000190064311,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745911478996277,
      "backward_entropy": 0.23048810164133707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.800660610198975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033051578793674707,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745891213417053,
      "backward_entropy": 0.22973128159840903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.578134059906006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034047786612063646,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27458760142326355,
      "backward_entropy": 0.22944211959838867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.024221420288086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035042513627558947,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27458655834198,
      "backward_entropy": 0.23036736249923706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.751797676086426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003603810677304864,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27458545565605164,
      "backward_entropy": 0.2303234338760376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.44610595703125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037038226146250963,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27458325028419495,
      "backward_entropy": 0.2294116218884786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4636869430542,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003804012667387724,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745813727378845,
      "backward_entropy": 0.22917099793752035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366971015930176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0039044127333909273,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27457910776138306,
      "backward_entropy": 0.23017998536427817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.904012680053711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00400494085624814,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27457672357559204,
      "backward_entropy": 0.22914040088653564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.578993320465088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004105851519852877,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27457356452941895,
      "backward_entropy": 0.2300738493601481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.264081954956055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004206489305943251,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745702862739563,
      "backward_entropy": 0.23001790046691895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8324875831604,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00430716248229146,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27456721663475037,
      "backward_entropy": 0.2287875016530355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.887462615966797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004407696425914764,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745639979839325,
      "backward_entropy": 0.22870564460754395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9934587478637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004508607555180788,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27456003427505493,
      "backward_entropy": 0.2286223570505778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.123517990112305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004609399940818548,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27455630898475647,
      "backward_entropy": 0.22850656509399414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.246466636657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004710591398179531,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745526432991028,
      "backward_entropy": 0.22844823201497397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.909222602844238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0048117367550730705,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745491862297058,
      "backward_entropy": 0.22963372866312662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589476585388184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004913621582090855,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745451033115387,
      "backward_entropy": 0.228265643119812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.065835952758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005015536677092314,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745409607887268,
      "backward_entropy": 0.2280191977818807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671100616455078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0051172454841434956,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27453669905662537,
      "backward_entropy": 0.22807425260543823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.057395935058594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005219053011387587,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27453213930130005,
      "backward_entropy": 0.22776093085606894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.570054054260254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005320656578987837,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27452754974365234,
      "backward_entropy": 0.2276256481806437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.564955711364746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0054223062470555305,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745228707790375,
      "backward_entropy": 0.22777684529622397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.058206558227539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005523991771042347,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27451789379119873,
      "backward_entropy": 0.22766757011413574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.644797325134277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005625527817755938,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27451229095458984,
      "backward_entropy": 0.22719462712605795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519700527191162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005727161653339863,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745063304901123,
      "backward_entropy": 0.2288819948832194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890645980834961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0058283512480556965,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450060844421387,
      "backward_entropy": 0.22688361008961996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.398324012756348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005929787177592516,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27449455857276917,
      "backward_entropy": 0.22868388891220093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.224071502685547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006031668279320002,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27448803186416626,
      "backward_entropy": 0.22857971986134848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.538747787475586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006132829934358597,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27448350191116333,
      "backward_entropy": 0.22639524936676025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.573444366455078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006234107539057732,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27447807788848877,
      "backward_entropy": 0.22622754176457724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.59079360961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006334957201033831,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744734287261963,
      "backward_entropy": 0.22664831082026163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775918960571289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006435898598283529,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744690179824829,
      "backward_entropy": 0.22650365034739176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.756315231323242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006537087727338076,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27446356415748596,
      "backward_entropy": 0.22569815317789713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.449807167053223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006638437043875456,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27445781230926514,
      "backward_entropy": 0.22790269056955972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.115499973297119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006740328390151262,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27445048093795776,
      "backward_entropy": 0.22778064012527466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.151885986328125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006841457914561033,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744447886943817,
      "backward_entropy": 0.22512863079706827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.714196681976318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0069424984976649284,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274438738822937,
      "backward_entropy": 0.2275238831837972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.682186126708984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007043218705803156,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744332551956177,
      "backward_entropy": 0.2247244119644165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.271238803863525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007143107708543539,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744297981262207,
      "backward_entropy": 0.22451422611872354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.049030303955078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007242557127028704,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744273543357849,
      "backward_entropy": 0.22429869572321573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.788557052612305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007342514116317034,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442359924316406,
      "backward_entropy": 0.22696971893310547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.045206069946289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007442797999829054,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744189500808716,
      "backward_entropy": 0.22385404507319132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.684926986694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007543542888015509,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27441275119781494,
      "backward_entropy": 0.22459328174591064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919773101806641,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007644458673894405,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744061350822449,
      "backward_entropy": 0.22338736057281494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.767068862915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007745157461613417,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743997573852539,
      "backward_entropy": 0.2241860826810201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.324121952056885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007846136577427387,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27439218759536743,
      "backward_entropy": 0.2239773472150167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.826471328735352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00794663280248642,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743853032588959,
      "backward_entropy": 0.2237656315167745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3077392578125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008047426119446754,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743774652481079,
      "backward_entropy": 0.2223797639211019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.967188358306885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00814774539321661,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27437031269073486,
      "backward_entropy": 0.22569501399993896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6136603355407715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00824794638901949,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743632197380066,
      "backward_entropy": 0.22551997502644858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.36719799041748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008347801864147186,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27435731887817383,
      "backward_entropy": 0.2253411610921224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.199074745178223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008447769097983837,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743511497974396,
      "backward_entropy": 0.2251577377319336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.520155906677246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008548256941139698,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743437886238098,
      "backward_entropy": 0.22098445892333984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.742834568023682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008648891933262348,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27433568239212036,
      "backward_entropy": 0.22214214007059732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.581668853759766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008748679421842098,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743300199508667,
      "backward_entropy": 0.220388134320577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.734256744384766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008848688565194607,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27432379126548767,
      "backward_entropy": 0.22438251972198486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.809706687927246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008948459289968014,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743180990219116,
      "backward_entropy": 0.22418002287546793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.963181972503662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009048070758581161,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27431267499923706,
      "backward_entropy": 0.22397295633951822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.37548542022705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009147549979388714,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743082046508789,
      "backward_entropy": 0.21912757555643717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53066635131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00924719963222742,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27430298924446106,
      "backward_entropy": 0.220525860786438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.604870796203613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00934706162661314,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27429714798927307,
      "backward_entropy": 0.2184548775355021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.926042556762695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009446666575968266,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742912769317627,
      "backward_entropy": 0.21809901793797812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.749115943908691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009546719491481781,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27428382635116577,
      "backward_entropy": 0.22286240259806314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.817597389221191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009646547958254814,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27427664399147034,
      "backward_entropy": 0.219326913356781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.89422082901001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009746728464961052,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742682099342346,
      "backward_entropy": 0.219010591506958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.290782928466797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00984677579253912,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742595374584198,
      "backward_entropy": 0.2165813446044922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8718461990356445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009947436861693859,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742486596107483,
      "backward_entropy": 0.21617748339970908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.187174797058105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010047947987914085,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27423739433288574,
      "backward_entropy": 0.21576050917307535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42186164855957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010148400440812111,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27422600984573364,
      "backward_entropy": 0.2177091439565023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.831526279449463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01024891808629036,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742142975330353,
      "backward_entropy": 0.2173707683881124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.805564880371094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01034917775541544,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742031514644623,
      "backward_entropy": 0.22077536582946777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.37908935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010449749417603016,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27419042587280273,
      "backward_entropy": 0.21667170524597168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8900322914123535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01055039931088686,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741769254207611,
      "backward_entropy": 0.22017212708791098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.859031677246094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010650255717337132,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27416595816612244,
      "backward_entropy": 0.21594283978144327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.59603214263916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010749951004981995,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27415522933006287,
      "backward_entropy": 0.21255979935328165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23669719696045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010849416255950928,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741449475288391,
      "backward_entropy": 0.215186874071757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706925392150879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010948988609015942,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741338014602661,
      "backward_entropy": 0.21889473994572958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.879508018493652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011048946529626846,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741205096244812,
      "backward_entropy": 0.21440360943476358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.625049591064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011148756369948387,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27410799264907837,
      "backward_entropy": 0.2139965295791626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.609824180603027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011248252354562283,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27409619092941284,
      "backward_entropy": 0.2178573211034139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.123672485351562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011347459629178047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740844488143921,
      "backward_entropy": 0.21749866008758545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246738433837891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011447306722402573,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740689814090729,
      "backward_entropy": 0.21712962786356607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4742255210876465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011546667665243149,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740549147129059,
      "backward_entropy": 0.21675471464792886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.778589725494385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01164571288973093,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27404162287712097,
      "backward_entropy": 0.21182378133138022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.978482246398926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011744651943445206,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27402812242507935,
      "backward_entropy": 0.21598358949025473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.665453910827637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011844123713672161,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740119993686676,
      "backward_entropy": 0.21089359124501547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.966578483581543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011943366378545761,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739962339401245,
      "backward_entropy": 0.21517693996429443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.189754486083984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012042578309774399,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27397990226745605,
      "backward_entropy": 0.20515052477518717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.049482822418213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012141880579292774,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27396291494369507,
      "backward_entropy": 0.20943121115366617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.741371154785156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012240626849234104,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739492952823639,
      "backward_entropy": 0.21390628814697266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295391082763672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012339291162788868,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27393487095832825,
      "backward_entropy": 0.2084118127822876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.717141151428223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012438145466148853,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739188075065613,
      "backward_entropy": 0.20251313845316568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.012025833129883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012536845169961452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273902952671051,
      "backward_entropy": 0.21256210406621298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3613762855529785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012635580264031887,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27388614416122437,
      "backward_entropy": 0.20113754272460938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.596282005310059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01273396611213684,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738707661628723,
      "backward_entropy": 0.20626240968704224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.019896507263184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012832765467464924,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738523781299591,
      "backward_entropy": 0.19972455501556396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547689437866211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012931608594954014,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738327085971832,
      "backward_entropy": 0.21064865589141846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.669028282165527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013030791655182838,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738102674484253,
      "backward_entropy": 0.20456274350484213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.163651943206787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013130373321473598,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27378445863723755,
      "backward_entropy": 0.1975168983141581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.831981658935547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013229436241090298,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27376043796539307,
      "backward_entropy": 0.2033988038698832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.498235702514648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013327836990356445,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737395763397217,
      "backward_entropy": 0.20859551429748535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.25964879989624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013426661491394043,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737150490283966,
      "backward_entropy": 0.20219882329305014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.164404392242432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013525079935789108,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736920416355133,
      "backward_entropy": 0.20749938488006592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.130027770996094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013623068109154701,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27367091178894043,
      "backward_entropy": 0.1935632030169169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.492434501647949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013721263036131859,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27364712953567505,
      "backward_entropy": 0.20635883013407388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.308987617492676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013819261454045773,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27362337708473206,
      "backward_entropy": 0.20577216148376465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.813539028167725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013917564414441586,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27359652519226074,
      "backward_entropy": 0.20517297585805258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.552682399749756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014015867374837399,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27356892824172974,
      "backward_entropy": 0.19018956025441489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.178175926208496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014114025048911572,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2735408544540405,
      "backward_entropy": 0.19768198331197104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890307426452637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01421176828444004,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27351438999176025,
      "backward_entropy": 0.19699557622273764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827424049377441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014309599064290524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27348583936691284,
      "backward_entropy": 0.2026730179786682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4380364418029785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014408090151846409,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27345138788223267,
      "backward_entropy": 0.20201627413431802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69057559967041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014506352134048939,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734169065952301,
      "backward_entropy": 0.20134915908177695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9202446937561035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014605139382183552,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27337729930877686,
      "backward_entropy": 0.18476366996765137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.601380348205566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014703372493386269,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733401656150818,
      "backward_entropy": 0.19997642437616983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.196228981018066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01480144914239645,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27330246567726135,
      "backward_entropy": 0.1992765466372172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.86807918548584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014899811707437038,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732611894607544,
      "backward_entropy": 0.18187711636225382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.214007377624512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014998230151832104,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27321791648864746,
      "backward_entropy": 0.1978339950243632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.217225551605225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015096236951649189,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27317580580711365,
      "backward_entropy": 0.19037985801696777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.18818998336792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015193287283182144,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731398344039917,
      "backward_entropy": 0.19635212421417236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.09423828125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015289463102817535,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2731100916862488,
      "backward_entropy": 0.17783814668655396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.181100368499756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01538478396832943,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730906903743744,
      "backward_entropy": 0.18798659245173135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.037554740905762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015480074100196362,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273069828748703,
      "backward_entropy": 0.17575931549072266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.333071231842041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015575834549963474,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27304166555404663,
      "backward_entropy": 0.1932373841603597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.518019676208496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015671607106924057,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27301138639450073,
      "backward_entropy": 0.17361760139465332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.771413803100586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015767499804496765,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2729777693748474,
      "backward_entropy": 0.19159195820490518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220314979553223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01586427539587021,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729341387748718,
      "backward_entropy": 0.17141592502593994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.877251625061035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01596089079976082,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27288979291915894,
      "backward_entropy": 0.1898784637451172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.704059600830078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01605708710849285,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27284643054008484,
      "backward_entropy": 0.18204724788665771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2607421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0161528792232275,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2728053331375122,
      "backward_entropy": 0.1811596949895223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.290627479553223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01624862663447857,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2727620601654053,
      "backward_entropy": 0.1872328519821167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.020855903625488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01634373888373375,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27272331714630127,
      "backward_entropy": 0.1863314708073934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6289849281311035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016438748687505722,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27268335223197937,
      "backward_entropy": 0.18542373180389404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.073978424072266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01653403416275978,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726376950740814,
      "backward_entropy": 0.18450514475504556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0532708168029785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01662984862923622,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27258384227752686,
      "backward_entropy": 0.16210734844207764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.516103267669678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01672549359500408,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2725284695625305,
      "backward_entropy": 0.17558634281158447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.835549354553223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016820590943098068,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27247482538223267,
      "backward_entropy": 0.18164298931757608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.566562652587891,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01691477932035923,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27242910861968994,
      "backward_entropy": 0.15847894549369812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.877341270446777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017009343951940536,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27237722277641296,
      "backward_entropy": 0.17968990405400595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.826863765716553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017103765159845352,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723236680030823,
      "backward_entropy": 0.1560040314992269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.733992099761963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017197366803884506,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27227622270584106,
      "backward_entropy": 0.15475727121035257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.425693511962891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017291488125920296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27221980690956116,
      "backward_entropy": 0.1766656438509623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.015325546264648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01738520711660385,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27216413617134094,
      "backward_entropy": 0.1756350596745809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.386966228485107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017478320747613907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27211228013038635,
      "backward_entropy": 0.17459764083226523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.032393455505371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01757112704217434,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2720603942871094,
      "backward_entropy": 0.16641209522883096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.600846290588379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01766340434551239,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2720109224319458,
      "backward_entropy": 0.1484044094880422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.374269008636475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017755625769495964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27195870876312256,
      "backward_entropy": 0.1714304288228353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.80429744720459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017848294228315353,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2718973159790039,
      "backward_entropy": 0.14581147829691568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.451155662536621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017941026017069817,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2718316912651062,
      "backward_entropy": 0.16924595832824707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.507771968841553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01803356222808361,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2717646658420563,
      "backward_entropy": 0.16813530524571738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.094743251800537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01812593638896942,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2716953754425049,
      "backward_entropy": 0.14184580246607462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.140655040740967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018218614161014557,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27161893248558044,
      "backward_entropy": 0.15871313214302063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.28780460357666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018310915678739548,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27154356241226196,
      "backward_entropy": 0.13914748032887778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.054998874664307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018402976915240288,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2714672386646271,
      "backward_entropy": 0.15644504626592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.090893268585205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01849461905658245,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713911831378937,
      "backward_entropy": 0.16241397460301718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.363968849182129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018585937097668648,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713143825531006,
      "backward_entropy": 0.16124513745307922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.205999851226807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018677184358239174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2712339758872986,
      "backward_entropy": 0.16006401181221008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.146492004394531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018768180161714554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2711507976055145,
      "backward_entropy": 0.15887762109438577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.38554048538208,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018858276307582855,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27107566595077515,
      "backward_entropy": 0.13094645738601685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.939024925231934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018948452547192574,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2709946036338806,
      "backward_entropy": 0.14925670623779297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.14742374420166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019038395956158638,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2709120213985443,
      "backward_entropy": 0.15528184175491333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.669561386108398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019128240644931793,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27082502841949463,
      "backward_entropy": 0.1540635029474894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.963112831115723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01921771466732025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27073919773101807,
      "backward_entropy": 0.1528377135594686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.531893253326416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019306275993585587,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2706608772277832,
      "backward_entropy": 0.1443297564983368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.816834449768066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019393710419535637,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27059406042099,
      "backward_entropy": 0.15040228764216104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.305108070373535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019480379298329353,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2705339789390564,
      "backward_entropy": 0.12124581138292949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.825708866119385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019567443057894707,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2704619765281677,
      "backward_entropy": 0.11986064910888672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.247689247131348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01965375989675522,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2703954577445984,
      "backward_entropy": 0.139333446820577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.189388275146484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019739748910069466,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2703283131122589,
      "backward_entropy": 0.1454948385556539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.316008567810059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019825400784611702,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2702605128288269,
      "backward_entropy": 0.1368150512377421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.792197227478027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019910844042897224,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27018970251083374,
      "backward_entropy": 0.13555219769477844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.736396789550781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01999567821621895,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27012187242507935,
      "backward_entropy": 0.11290798584620158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.650530815124512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020079925656318665,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27005669474601746,
      "backward_entropy": 0.1115271548430125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.902348041534424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02016356773674488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2699943482875824,
      "backward_entropy": 0.13927114009857178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.658486843109131,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02024604193866253,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26994428038597107,
      "backward_entropy": 0.10880615313847859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.874698638916016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020328877493739128,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2698808014392853,
      "backward_entropy": 0.1291909416516622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.816763877868652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02041143737733364,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2698137164115906,
      "backward_entropy": 0.13555026054382324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.375275611877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020493704825639725,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2697440981864929,
      "backward_entropy": 0.12662005424499512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.522204399108887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02057618275284767,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.269663542509079,
      "backward_entropy": 0.1253324349721273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.097092628479004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02065814658999443,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26958367228507996,
      "backward_entropy": 0.10214975476264954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.779467821121216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020740149542689323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26949554681777954,
      "backward_entropy": 0.13050360480944315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.274779796600342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02082104980945587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2694184482097626,
      "backward_entropy": 0.1292471985022227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6859846115112305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02090137079358101,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2693430483341217,
      "backward_entropy": 0.12019617358843486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.085107326507568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0209815576672554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2692616581916809,
      "backward_entropy": 0.12673685948053995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.393138408660889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021061118692159653,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.269182950258255,
      "backward_entropy": 0.0956551730632782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.118102073669434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021140385419130325,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2691008150577545,
      "backward_entropy": 0.11637021104494731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.767273426055908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02121913991868496,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2690189480781555,
      "backward_entropy": 0.11510256926218669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1001391410827637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02129715494811535,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26894208788871765,
      "backward_entropy": 0.09183627367019653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.342669486999512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02137388102710247,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26888036727905273,
      "backward_entropy": 0.1205022931098938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.88930082321167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021450577303767204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26881030201911926,
      "backward_entropy": 0.11926910281181335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.258934497833252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021526824682950974,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2687382996082306,
      "backward_entropy": 0.11803875366846721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7363297939300537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021602075546979904,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2686745226383209,
      "backward_entropy": 0.10885968804359436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.251366138458252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021675968542695045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2686276137828827,
      "backward_entropy": 0.11561407645543416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.51043176651001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021749133244156837,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26858559250831604,
      "backward_entropy": 0.10641335447629292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.323435306549072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021822793409228325,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2685244381427765,
      "backward_entropy": 0.08329667647679646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.746917247772217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02189675159752369,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26844802498817444,
      "backward_entropy": 0.0821096400419871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.021950721740723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021970432251691818,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26836705207824707,
      "backward_entropy": 0.08092942833900452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9024665355682373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02204413153231144,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26827582716941833,
      "backward_entropy": 0.10953086614608765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.963683843612671,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022116733714938164,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2681947946548462,
      "backward_entropy": 0.10035902261734009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6936838626861572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022188464179635048,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26812049746513367,
      "backward_entropy": 0.09917444984118144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7644035816192627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02225911058485508,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2680566608905792,
      "backward_entropy": 0.07632700105508168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2619271278381348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022329846397042274,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2679803967475891,
      "backward_entropy": 0.07520533601442973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4890236854553223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022400179877877235,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26790112257003784,
      "backward_entropy": 0.09567325313886006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9734833240509033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02246931381523609,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.267833948135376,
      "backward_entropy": 0.1023957331975301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0957775115966797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022537900134921074,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26776641607284546,
      "backward_entropy": 0.07192328075567882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1636948585510254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02260613441467285,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26769477128982544,
      "backward_entropy": 0.07085161407788594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8033058643341064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02267410419881344,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26761680841445923,
      "backward_entropy": 0.09890935818354289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.908599376678467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02274145558476448,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26753929257392883,
      "backward_entropy": 0.09001998106638591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1549012660980225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022808365523815155,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2674586772918701,
      "backward_entropy": 0.09660486380259196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.670377016067505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022875148802995682,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26736870408058167,
      "backward_entropy": 0.09545448422431946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4463353157043457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02294130064547062,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26727917790412903,
      "backward_entropy": 0.09431389967600505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1085615158081055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023006612434983253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26719406247138977,
      "backward_entropy": 0.09318852424621582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2487409114837646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023071905598044395,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2670971155166626,
      "backward_entropy": 0.09206190705299377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.311051368713379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02313624508678913,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26700711250305176,
      "backward_entropy": 0.08353116114934285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.518598794937134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023199770599603653,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26692113280296326,
      "backward_entropy": 0.06175646185874939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7725257873535156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023262783885002136,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2668330669403076,
      "backward_entropy": 0.08877148230870564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.170287847518921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023325657472014427,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2667350769042969,
      "backward_entropy": 0.08768702546755473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5127482414245605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023387687280774117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2666410803794861,
      "backward_entropy": 0.086618572473526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.941199541091919,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023449352011084557,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26654136180877686,
      "backward_entropy": 0.05807049572467804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.142735004425049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023510001599788666,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2664491534233093,
      "backward_entropy": 0.0845150351524353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1183321475982666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02356996387243271,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2663578391075134,
      "backward_entropy": 0.056322952111562095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.319943904876709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023629292845726013,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2662660479545593,
      "backward_entropy": 0.05547170341014862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4225003719329834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023688295856118202,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26616761088371277,
      "backward_entropy": 0.05463354786237081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1263575553894043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023747161030769348,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26605844497680664,
      "backward_entropy": 0.08045099178949992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0860774517059326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02380552515387535,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2659456729888916,
      "backward_entropy": 0.07263066371281941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4016261100769043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02386339008808136,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2658292055130005,
      "backward_entropy": 0.07845951120058696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7368214130401611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023921223357319832,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2657000422477722,
      "backward_entropy": 0.07746825615564983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.05794095993042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02397811785340309,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26557624340057373,
      "backward_entropy": 0.07649605472882588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7945467233657837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024034610018134117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26544681191444397,
      "backward_entropy": 0.075531800587972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0826709270477295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024090394377708435,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26531800627708435,
      "backward_entropy": 0.06813841064771016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7996410131454468,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024145925417542458,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26518020033836365,
      "backward_entropy": 0.06727605561415355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5360546112060547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024200813844799995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2650411128997803,
      "backward_entropy": 0.07270339131355286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8487685918807983,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02425474300980568,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2649074196815491,
      "backward_entropy": 0.07179128626982371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6851310729980469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02430828846991062,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26476699113845825,
      "backward_entropy": 0.0461019774278005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2248706817626953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024361228570342064,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2646244168281555,
      "backward_entropy": 0.04540192584196726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6100479364395142,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024412935599684715,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.264492928981781,
      "backward_entropy": 0.06316267450650533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3521907329559326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024464108049869537,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26435795426368713,
      "backward_entropy": 0.06238318979740143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8351377248764038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024514373391866684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26422762870788574,
      "backward_entropy": 0.06742828090985616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3871433734893799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02456459030508995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2640843987464905,
      "backward_entropy": 0.06659191846847534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.458656907081604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024614041671156883,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2639434337615967,
      "backward_entropy": 0.042120128870010376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2317931652069092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02466292679309845,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2637996971607208,
      "backward_entropy": 0.05936662356058756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.588850736618042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02471093274652958,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26365938782691956,
      "backward_entropy": 0.04090265929698944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5469446182250977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024758746847510338,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26350823044776917,
      "backward_entropy": 0.057930116852124534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6076977252960205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0248063113540411,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2633477449417114,
      "backward_entropy": 0.06259167691071828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2012302875518799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024853769689798355,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26317453384399414,
      "backward_entropy": 0.056526973843574524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6175410747528076,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024900417774915695,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2630026340484619,
      "backward_entropy": 0.03857419888178507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1360666751861572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024947073310613632,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26281681656837463,
      "backward_entropy": 0.0380153035124143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9304670095443726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024992864578962326,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2626340687274933,
      "backward_entropy": 0.059529041250546776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5916122198104858,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025037487968802452,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2624609172344208,
      "backward_entropy": 0.036941997706890106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3882908821105957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025082306936383247,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2622697353363037,
      "backward_entropy": 0.05321189761161804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.104802131652832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025126932188868523,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2620672285556793,
      "backward_entropy": 0.05735186239083608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3988920450210571,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025170832872390747,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2618643045425415,
      "backward_entropy": 0.03539721171061198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.126361608505249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0252146665006876,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2616482973098755,
      "backward_entropy": 0.055934563279151917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1731891632080078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02525789849460125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2614295780658722,
      "backward_entropy": 0.05523788928985596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0651650428771973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025300687178969383,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26120495796203613,
      "backward_entropy": 0.03392562518517176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5887768268585205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025342853739857674,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2609784007072449,
      "backward_entropy": 0.03345518559217453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9360734224319458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025383437052369118,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2607695460319519,
      "backward_entropy": 0.053230891625086464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1264584064483643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025423340499401093,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2605603337287903,
      "backward_entropy": 0.04845583438873291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0972464084625244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025463055819272995,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26034075021743774,
      "backward_entropy": 0.032122209668159485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9995201230049133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02550254389643669,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26011088490486145,
      "backward_entropy": 0.047378545006116234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3090683221817017,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02554161101579666,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2598751187324524,
      "backward_entropy": 0.03126915544271469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9450675845146179,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025581033900380135,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2596181035041809,
      "backward_entropy": 0.05010979870955149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6611825227737427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025619925931096077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2593570351600647,
      "backward_entropy": 0.04949672023455302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6429253220558167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02565765008330345,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25910475850105286,
      "backward_entropy": 0.048904468615849815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.992609977722168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025694280862808228,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2588615119457245,
      "backward_entropy": 0.048332790533701576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8449681997299194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025730809196829796,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2586078941822052,
      "backward_entropy": 0.047762552897135414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8800680041313171,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025766871869564056,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2583497166633606,
      "backward_entropy": 0.04720127582550049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7969704866409302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025802617892622948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25808456540107727,
      "backward_entropy": 0.046646133065223694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9425966143608093,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025837857276201248,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25781455636024475,
      "backward_entropy": 0.0429679403702418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5347248315811157,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025873053818941116,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25753164291381836,
      "backward_entropy": 0.02782781918843587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8351234197616577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025907088071107864,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25725892186164856,
      "backward_entropy": 0.027487953503926594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5552681684494019,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02594091184437275,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2569761276245117,
      "backward_entropy": 0.04165185987949371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7404419183731079,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025973768904805183,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2566998302936554,
      "backward_entropy": 0.04400830467542013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4229089617729187,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0260063037276268,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2564171254634857,
      "backward_entropy": 0.026510680715243023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7445710897445679,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037584990262985,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25614601373672485,
      "backward_entropy": 0.04303617775440216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5372467637062073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026068713515996933,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2558637261390686,
      "backward_entropy": 0.04256361722946167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7058321237564087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02609907276928425,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.255583792924881,
      "backward_entropy": 0.04210387667020162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5949419140815735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026129307225346565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.255294531583786,
      "backward_entropy": 0.04164704432090124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4482250213623047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026159057393670082,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2550015449523926,
      "backward_entropy": 0.041198467214902244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43494072556495667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026187891140580177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25471386313438416,
      "backward_entropy": 0.040765377382437386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6683167219161987,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026215853169560432,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.254430890083313,
      "backward_entropy": 0.03822372108697891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3291221559047699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026243846863508224,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2541348338127136,
      "backward_entropy": 0.037883296608924866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5144304037094116,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026270659640431404,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25384950637817383,
      "backward_entropy": 0.02400932212670644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49952682852745056,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02629709430038929,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25355952978134155,
      "backward_entropy": 0.02376772214968999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44914907217025757,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632313407957554,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2532649040222168,
      "backward_entropy": 0.02353130280971527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6508573293685913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634865790605545,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25296923518180847,
      "backward_entropy": 0.03836547086636225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4922502040863037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026374496519565582,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2526567876338959,
      "backward_entropy": 0.03797951092322668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34200942516326904,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0264000091701746,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2523387372493744,
      "backward_entropy": 0.02284404883782069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2658020257949829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026424625888466835,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2520265281200409,
      "backward_entropy": 0.03723277896642685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3861071467399597,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02644811011850834,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.251724511384964,
      "backward_entropy": 0.035445248087247215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4687260687351227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026471083983778954,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2514207661151886,
      "backward_entropy": 0.03654338667790095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24328061938285828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026493990793824196,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25110799074172974,
      "backward_entropy": 0.03620234628518423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29482749104499817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02651583030819893,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25080445408821106,
      "backward_entropy": 0.035877746840318046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34412282705307007,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026536906138062477,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25050339102745056,
      "backward_entropy": 0.034411186973253884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3342634439468384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026557590812444687,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2502005994319916,
      "backward_entropy": 0.03525693714618683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4599772095680237,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026577821001410484,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24989482760429382,
      "backward_entropy": 0.021308936178684235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28943225741386414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026598263531923294,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24957416951656342,
      "backward_entropy": 0.03370808809995651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25568509101867676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026618095114827156,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2492547482252121,
      "backward_entropy": 0.034356117248535156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2976851761341095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026637224480509758,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24893924593925476,
      "backward_entropy": 0.034071813027064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24148204922676086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02665598876774311,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24862325191497803,
      "backward_entropy": 0.03379280865192413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21178452670574188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02667410299181938,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24831107258796692,
      "backward_entropy": 0.03352415810028712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22876735031604767,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02669144794344902,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2480044662952423,
      "backward_entropy": 0.03265915811061859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2887267768383026,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026708202436566353,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24770057201385498,
      "backward_entropy": 0.020235054194927216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3025709390640259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02672477997839451,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2473922073841095,
      "backward_entropy": 0.03277352203925451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19050045311450958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026741275563836098,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24707719683647156,
      "backward_entropy": 0.019969495634237926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26568764448165894,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02675704099237919,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24676671624183655,
      "backward_entropy": 0.03192903846502304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29722025990486145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026772646233439445,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2464524507522583,
      "backward_entropy": 0.032061402996381126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26944535970687866,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026788342744112015,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24613085389137268,
      "backward_entropy": 0.03158418834209442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2617061138153076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026803985238075256,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24580571055412292,
      "backward_entropy": 0.03159466634194056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3266253173351288,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02681954950094223,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24547713994979858,
      "backward_entropy": 0.019349842021862667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2292637825012207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026835447177290916,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24513697624206543,
      "backward_entropy": 0.019224272420008976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2235809564590454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026851056143641472,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24479639530181885,
      "backward_entropy": 0.019101457049449284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16759571433067322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026866331696510315,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24445463716983795,
      "backward_entropy": 0.030735082924365997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1473122239112854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026880955323576927,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24411791563034058,
      "backward_entropy": 0.018868952989578247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18825969099998474,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02689484693109989,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2437874674797058,
      "backward_entropy": 0.03042982518672943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19851401448249817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02690841443836689,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24345660209655762,
      "backward_entropy": 0.030045434832572937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17843401432037354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026921750977635384,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24312308430671692,
      "backward_entropy": 0.030145543317000072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2001534253358841,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026934746652841568,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24278901517391205,
      "backward_entropy": 0.029654997090498608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1290433406829834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026947658509016037,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24245139956474304,
      "backward_entropy": 0.02946360905965169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13706612586975098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026959877461194992,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24211853742599487,
      "backward_entropy": 0.01827331880728404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14651024341583252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02697160094976425,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.241789311170578,
      "backward_entropy": 0.029628098011016846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09491556882858276,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026982951909303665,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24146203696727753,
      "backward_entropy": 0.02951177954673767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14017923176288605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02699349634349346,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2411428689956665,
      "backward_entropy": 0.02878320465485255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.168867290019989,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027003711089491844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24082431197166443,
      "backward_entropy": 0.028630487620830536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16607193648815155,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027013981714844704,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24050238728523254,
      "backward_entropy": 0.028476834297180176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11717341840267181,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02702423557639122,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24017661809921265,
      "backward_entropy": 0.017810291300217312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11409544944763184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027034077793359756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23985403776168823,
      "backward_entropy": 0.028175418575604756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0909111425280571,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027043532580137253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2395348846912384,
      "backward_entropy": 0.028032769759496052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.158584326505661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027052422985434532,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23922142386436462,
      "backward_entropy": 0.027898068229357403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09573473036289215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0270614642649889,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23890197277069092,
      "backward_entropy": 0.027761558691660564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14027078449726105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0270700640976429,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23858699202537537,
      "backward_entropy": 0.027631059288978577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17284543812274933,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027078727260231972,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23826876282691956,
      "backward_entropy": 0.028549795349438984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13309094309806824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027087809517979622,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23794211447238922,
      "backward_entropy": 0.028458620111147564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12062990665435791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027096861973404884,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.237613707780838,
      "backward_entropy": 0.027225196361541748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11524547636508942,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027105780318379402,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2372848391532898,
      "backward_entropy": 0.01724355046947797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07420778274536133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027114609256386757,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23695670068264008,
      "backward_entropy": 0.0269566277662913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10178010165691376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02712283283472061,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23663505911827087,
      "backward_entropy": 0.026831698914368946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10849499702453613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027130894362926483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23631376028060913,
      "backward_entropy": 0.02670938769976298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11187122017145157,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027138832956552505,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23599085211753845,
      "backward_entropy": 0.02658866097529729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10099437087774277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027146754786372185,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23566535115242004,
      "backward_entropy": 0.02646838625272115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11192570626735687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027154576033353806,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23533962666988373,
      "backward_entropy": 0.0263496736685435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07551077753305435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0271624568849802,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2350112497806549,
      "backward_entropy": 0.026230856776237488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08035533875226974,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027169957756996155,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2346874624490738,
      "backward_entropy": 0.027659493188063305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08922988176345825,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027177173644304276,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23436671495437622,
      "backward_entropy": 0.027591442068417866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07730011641979218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027184316888451576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23404765129089355,
      "backward_entropy": 0.025898834069569904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09592009335756302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027191152796149254,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2337304651737213,
      "backward_entropy": 0.025794148445129395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09876295179128647,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027198083698749542,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23341161012649536,
      "backward_entropy": 0.016627291838328045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.091115802526474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02720516175031662,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23309102654457092,
      "backward_entropy": 0.025580130517482758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07270719856023788,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02721225842833519,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23276866972446442,
      "backward_entropy": 0.027257685859998066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07096679508686066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027219122275710106,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23244816064834595,
      "backward_entropy": 0.016490206122398376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08743922412395477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027225753292441368,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23212981224060059,
      "backward_entropy": 0.025266642371813457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07407410442829132,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027232488617300987,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2318103015422821,
      "backward_entropy": 0.027065744002660114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06281866878271103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027239184826612473,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23149241507053375,
      "backward_entropy": 0.016362033784389496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.070295050740242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02724567987024784,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23117808997631073,
      "backward_entropy": 0.026940425237019856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06414345651865005,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027252111583948135,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2308650016784668,
      "backward_entropy": 0.016278694073359173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054599545896053314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027258392423391342,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23055440187454224,
      "backward_entropy": 0.024769286314646404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048425719141960144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027264367789030075,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2302468866109848,
      "backward_entropy": 0.024677537381649017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05958488583564758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027270006015896797,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22994409501552582,
      "backward_entropy": 0.01616632690032323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041305866092443466,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027275504544377327,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22964182496070862,
      "backward_entropy": 0.016132953266302746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05516279861330986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027280649170279503,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2293449193239212,
      "backward_entropy": 0.024425305426120758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059334464371204376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027285709977149963,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2290486991405487,
      "backward_entropy": 0.024346279601256054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0659441277384758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02729084901511669,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2287527173757553,
      "backward_entropy": 0.026520659526189167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05557165667414665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027296124026179314,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2284546047449112,
      "backward_entropy": 0.024185193081696827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05052512139081955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02730143442749977,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22815801203250885,
      "backward_entropy": 0.015978070596853893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0546332523226738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027306705713272095,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22786366939544678,
      "backward_entropy": 0.026372705896695454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03900847211480141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027312062680721283,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22757020592689514,
      "backward_entropy": 0.023940836389859516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03485383093357086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027317160740494728,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22728079557418823,
      "backward_entropy": 0.015881553292274475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052773911505937576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027321960777044296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22699615359306335,
      "backward_entropy": 0.023788462082544964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03760284557938576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732689306139946,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22671180963516235,
      "backward_entropy": 0.02371266980965932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04408592730760574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027331655845046043,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22643139958381653,
      "backward_entropy": 0.023639097809791565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04435998573899269,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336422353982925,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22615259885787964,
      "backward_entropy": 0.023565637568632763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03151877596974373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02734125778079033,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22587493062019348,
      "backward_entropy": 0.023491596182187397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033102668821811676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02734585851430893,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22560164332389832,
      "backward_entropy": 0.023420865337053936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03522329777479172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027350284159183502,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22533190250396729,
      "backward_entropy": 0.02335268259048462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027770061045885086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027354562655091286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22506342828273773,
      "backward_entropy": 0.023286278049151104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03433569148182869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02735866792500019,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22480016946792603,
      "backward_entropy": 0.02322247624397278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027816981077194214,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02736271545290947,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2245384007692337,
      "backward_entropy": 0.015607364475727081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03915281966328621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02736653760075569,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22427937388420105,
      "backward_entropy": 0.015585764000813166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018846942111849785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027370529249310493,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22402000427246094,
      "backward_entropy": 0.02578349659840266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03290537744760513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02737409435212612,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22376608848571777,
      "backward_entropy": 0.02298128604888916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02628038451075554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027377743273973465,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22351372241973877,
      "backward_entropy": 0.022923901677131653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018701892346143723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02738133631646633,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22326502203941345,
      "backward_entropy": 0.022867321968078613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026399722322821617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02738458663225174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22302114963531494,
      "backward_entropy": 0.02281526227792104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0278610922396183,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027387842535972595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22277981042861938,
      "backward_entropy": 0.022763366500536602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01807287707924843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027391111478209496,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22253890335559845,
      "backward_entropy": 0.022711363931496937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01725553348660469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02739422582089901,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22230404615402222,
      "backward_entropy": 0.022661561767260235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02157340571284294,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02739710547029972,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22207355499267578,
      "backward_entropy": 0.025542994340260822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022919492796063423,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02739996835589409,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22184604406356812,
      "backward_entropy": 0.022568402191003162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017104899510741234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02740282006561756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22161969542503357,
      "backward_entropy": 0.022522283097108204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022002365440130234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027405492961406708,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22139662504196167,
      "backward_entropy": 0.022478699684143066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018355801701545715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027408234775066376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22117526829242706,
      "backward_entropy": 0.022434463103612263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01953829638659954,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027410980314016342,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22095805406570435,
      "backward_entropy": 0.015346802771091461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017305567860603333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027413731440901756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22074326872825623,
      "backward_entropy": 0.022345957656701405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0176842138171196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027416467666625977,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2205319106578827,
      "backward_entropy": 0.022302108506361645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01894599199295044,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027419136837124825,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22032217681407928,
      "backward_entropy": 0.015303142368793488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014131464064121246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027421917766332626,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22011449933052063,
      "backward_entropy": 0.022215232253074646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016973858699202538,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027424652129411697,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21991130709648132,
      "backward_entropy": 0.015272490680217743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016710368916392326,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027427425608038902,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21971023082733154,
      "backward_entropy": 0.015256721526384354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012573666870594025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027430210262537003,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21951109170913696,
      "backward_entropy": 0.022085271775722504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010007097385823727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743285894393921,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21931564807891846,
      "backward_entropy": 0.022043652832508087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015827946364879608,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027435336261987686,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2191253900527954,
      "backward_entropy": 0.0251931498448054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012614178471267223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743787132203579,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2189357578754425,
      "backward_entropy": 0.02196464439233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011323196813464165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744036726653576,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21874873340129852,
      "backward_entropy": 0.01518419881661733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01417290698736906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027442721650004387,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21856370568275452,
      "backward_entropy": 0.02188836286465327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011545637622475624,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027445130050182343,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2183798849582672,
      "backward_entropy": 0.015158683061599731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010728763416409492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744741179049015,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2181972712278366,
      "backward_entropy": 0.02181446800629298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006467086263000965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027449676766991615,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2180182933807373,
      "backward_entropy": 0.02177866796652476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013542505912482738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027451734989881516,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21784505248069763,
      "backward_entropy": 0.015124436467885971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009449027478694916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027453916147351265,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21767181158065796,
      "backward_entropy": 0.025018970171610515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008619213476777077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027456020936369896,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2175011932849884,
      "backward_entropy": 0.02167797088623047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010434585623443127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027458086609840393,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21733450889587402,
      "backward_entropy": 0.021645280222098034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009820724837481976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027460170909762383,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21716925501823425,
      "backward_entropy": 0.02161237100760142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010325035080313683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02746228314936161,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2170061469078064,
      "backward_entropy": 0.021579305330912273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008022901602089405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02746441960334778,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21684378385543823,
      "backward_entropy": 0.02154608319203059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006692654453217983,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02746652066707611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166845202445984,
      "backward_entropy": 0.02151344468196233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0055524976924061775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027468539774417877,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2165292352437973,
      "backward_entropy": 0.021481973429520924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005813103634864092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027470426633954048,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21637822687625885,
      "backward_entropy": 0.02485974133014679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006600198335945606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027472157031297684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21622982621192932,
      "backward_entropy": 0.02142464617888133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006621407810598612,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027473844587802887,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21608400344848633,
      "backward_entropy": 0.02482706308364868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0057782819494605064,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02747553028166294,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21594083309173584,
      "backward_entropy": 0.024810900290807087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006879269145429134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027477145195007324,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2158004343509674,
      "backward_entropy": 0.021344947318236034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005594176240265369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027478812262415886,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21566241979599,
      "backward_entropy": 0.02477899193763733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006302274763584137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027480443939566612,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21552713215351105,
      "backward_entropy": 0.014974954227606455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0054748570546507835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027482125908136368,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2153940498828888,
      "backward_entropy": 0.01496599738796552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007378486450761557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02748379483819008,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2152634859085083,
      "backward_entropy": 0.02124015986919403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004854345228523016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027485569939017296,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21513286232948303,
      "backward_entropy": 0.014947179704904556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006291644182056189,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027487285435199738,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21500463783740997,
      "backward_entropy": 0.014937758445739746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037308228202164173,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02748909406363964,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21487808227539062,
      "backward_entropy": 0.014927312731742859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003942458424717188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027490809559822083,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.214755117893219,
      "backward_entropy": 0.02113299568494161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0052224136888980865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027492452412843704,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2146349847316742,
      "backward_entropy": 0.021107887228329975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003806395921856165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027494117617607117,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21451568603515625,
      "backward_entropy": 0.024626371761163075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004177432041615248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027495693415403366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21439823508262634,
      "backward_entropy": 0.02105875809987386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004019339568912983,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027497269213199615,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21428297460079193,
      "backward_entropy": 0.02103496591250102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003707070602104068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027498794719576836,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21416881680488586,
      "backward_entropy": 0.02101174493630727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035093401093035936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027500290423631668,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21405677497386932,
      "backward_entropy": 0.020989003280798595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037695695646107197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02750176377594471,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2139473259449005,
      "backward_entropy": 0.020966599384943645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004214731976389885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027503252029418945,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21383994817733765,
      "backward_entropy": 0.014848757535219193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002611581003293395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027504803612828255,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2137339562177658,
      "backward_entropy": 0.020920770863691967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030545336194336414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027506256476044655,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2136303186416626,
      "backward_entropy": 0.020898935695489246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037091325502842665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027507668361067772,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2135281264781952,
      "backward_entropy": 0.014823640386263529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028280862607061863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027509137988090515,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21342700719833374,
      "backward_entropy": 0.014815207570791245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029184548184275627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027510598301887512,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21332812309265137,
      "backward_entropy": 0.020834033687909443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029953571502119303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02751205675303936,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21323098242282867,
      "backward_entropy": 0.014798243840535482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022831952665001154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027513517066836357,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21313507854938507,
      "backward_entropy": 0.02079107239842415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029351948760449886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027514951303601265,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21304212510585785,
      "backward_entropy": 0.020770000914732616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017247928772121668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027516424655914307,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21295025944709778,
      "backward_entropy": 0.020748596638441086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017500342801213264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027517816051840782,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21286135911941528,
      "backward_entropy": 0.02072824289401372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001842942670919001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02751908265054226,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2127739042043686,
      "backward_entropy": 0.020709510892629623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002953693736344576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027520274743437767,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21268802881240845,
      "backward_entropy": 0.020691769818464916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018689840799197555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027521563693881035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21260249614715576,
      "backward_entropy": 0.020672790706157684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020698257721960545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02752280794084072,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21251869201660156,
      "backward_entropy": 0.014735118796428045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016517203766852617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027524054050445557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21243618428707123,
      "backward_entropy": 0.020636143783728283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017576630925759673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027525264769792557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21235565841197968,
      "backward_entropy": 0.02061837042371432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017601450672373176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02752646803855896,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2122769057750702,
      "backward_entropy": 0.014713689684867859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018695465987548232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027527647092938423,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2121991068124771,
      "backward_entropy": 0.020583506673574448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001414529629983008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027528822422027588,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21212175488471985,
      "backward_entropy": 0.020566294590632122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011075652437284589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027529926970601082,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21204546093940735,
      "backward_entropy": 0.02054998278617859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019940794445574284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027530958876013756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21197140216827393,
      "backward_entropy": 0.020534637073675793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013201620895415545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027532074600458145,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2118978500366211,
      "backward_entropy": 0.014681304494539896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000937966164201498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02753315307199955,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21182551980018616,
      "backward_entropy": 0.020502385993798573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010628539603203535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027534140273928642,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21175503730773926,
      "backward_entropy": 0.020487817625204723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013694154331460595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027535080909729004,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21168607473373413,
      "backward_entropy": 0.02047379935781161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009896665578708053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027536017820239067,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21161754429340363,
      "backward_entropy": 0.020459866772095364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010462634963914752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02753690630197525,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21155047416687012,
      "backward_entropy": 0.020446597288052242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001172355841845274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027537770569324493,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21148470044136047,
      "backward_entropy": 0.020433584849039715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010800095042213798,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027538657188415527,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2114202082157135,
      "backward_entropy": 0.020420320332050323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001132378471083939,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027539527043700218,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2113564908504486,
      "backward_entropy": 0.02415909618139267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009813705692067742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027540437877178192,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21129395067691803,
      "backward_entropy": 0.024149368206659954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008976346580311656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027541307732462883,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21123173832893372,
      "backward_entropy": 0.014630439380804697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007697901455685496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754218503832817,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2111710160970688,
      "backward_entropy": 0.020367910464604694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008942387066781521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754301391541958,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21111127734184265,
      "backward_entropy": 0.020355621973673504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007625286234542727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027543863281607628,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2110525369644165,
      "backward_entropy": 0.020343127350012463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000512513390276581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754468098282814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21099454164505005,
      "backward_entropy": 0.020331087211767834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006264909170567989,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027545426040887833,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2109382152557373,
      "backward_entropy": 0.024096578359603882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006640200736001134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027546146884560585,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2108832746744156,
      "backward_entropy": 0.020309265702962875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006187226390466094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02754685841500759,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21082937717437744,
      "backward_entropy": 0.014600185056527456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005573314265348017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754756435751915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21077686548233032,
      "backward_entropy": 0.02028816690047582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000587575021199882,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027548257261514664,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21072569489479065,
      "backward_entropy": 0.02027784784634908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004528890422079712,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02754894644021988,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21067571640014648,
      "backward_entropy": 0.01458890363574028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005036948132328689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754962258040905,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2106275111436844,
      "backward_entropy": 0.020257533838351566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005203313194215298,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027550287544727325,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21058033406734467,
      "backward_entropy": 0.020247608423233032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005363689851947129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027550969272851944,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21053433418273926,
      "backward_entropy": 0.02023763706286748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047584660933353007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02755166031420231,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21048888564109802,
      "backward_entropy": 0.02022755394379298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036618829471990466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02755235694348812,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21044430136680603,
      "backward_entropy": 0.020217515528202057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000405969622079283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027553023770451546,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21040090918540955,
      "backward_entropy": 0.02020789434512456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035619421396404505,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027553686872124672,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21035844087600708,
      "backward_entropy": 0.02400839825471242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003647685516625643,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027554355561733246,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21031740307807922,
      "backward_entropy": 0.01455740878979365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003054557309951633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027554985135793686,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21027657389640808,
      "backward_entropy": 0.020179712524016697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002901928382925689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027555571869015694,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21023644506931305,
      "backward_entropy": 0.02017119526863098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034698646049946547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027556119486689568,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21019703149795532,
      "backward_entropy": 0.023982547223567963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003209618735127151,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027556689456105232,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2101585865020752,
      "backward_entropy": 0.023976484934488933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021567379008047283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027557242661714554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21012058854103088,
      "backward_entropy": 0.020146936178207397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026407602126710117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027557751163840294,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2100837230682373,
      "backward_entropy": 0.020139481872320175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022006321523804218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027558239176869392,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21004746854305267,
      "backward_entropy": 0.020132243633270264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001916167966555804,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027558686211705208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21001189947128296,
      "backward_entropy": 0.014533616602420807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021500943694263697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02755909599363804,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20997726917266846,
      "backward_entropy": 0.02011927341421445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018571210966911167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027559516951441765,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2099437713623047,
      "backward_entropy": 0.020112921794255573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019958079792559147,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027559896931052208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20991083979606628,
      "backward_entropy": 0.02394210050503413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019176173373125494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02756025828421116,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20987841486930847,
      "backward_entropy": 0.014526148637135824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015584551147185266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027560606598854065,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2098466157913208,
      "backward_entropy": 0.02009600152571996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014885507698636502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027560928836464882,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2098155915737152,
      "backward_entropy": 0.023930879930655163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015121465548872948,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756124548614025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2097855508327484,
      "backward_entropy": 0.020085886120796204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001420896005583927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027561550959944725,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2097562551498413,
      "backward_entropy": 0.02008104945222537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013125644181855023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027561860159039497,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20972785353660583,
      "backward_entropy": 0.020076200366020203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013032453716732562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027562160044908524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20970022678375244,
      "backward_entropy": 0.020071471730868023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001278525887755677,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756245620548725,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20967333018779755,
      "backward_entropy": 0.020066851129134495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012880342546850443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756272628903389,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2096468210220337,
      "backward_entropy": 0.02006252606709798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.921874203020707e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027563001960515976,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2096208930015564,
      "backward_entropy": 0.02005815878510475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012173257709946483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027563270181417465,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20959629118442535,
      "backward_entropy": 0.0200539268553257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011625447223195806,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027563534677028656,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2095719575881958,
      "backward_entropy": 0.023902138074239094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.157783642876893e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027563797309994698,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2095479667186737,
      "backward_entropy": 0.020045650502045948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67829512571916e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027564041316509247,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2095245122909546,
      "backward_entropy": 0.02004171907901764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.559031994082034e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027564268559217453,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20950159430503845,
      "backward_entropy": 0.020038048426310223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.152655937010422e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027564501389861107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20947939157485962,
      "backward_entropy": 0.014508010198672613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.088674465194345e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027564741671085358,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20945796370506287,
      "backward_entropy": 0.023888540764649708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.66810480854474e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027564987540245056,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20943740010261536,
      "backward_entropy": 0.02002680053313573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.675987970083952e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756522409617901,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2094171941280365,
      "backward_entropy": 0.020023149748643238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.529738336917944e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027565445750951767,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20939743518829346,
      "backward_entropy": 0.020019732415676117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.015637336531654e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756565436720848,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20937827229499817,
      "backward_entropy": 0.0200164628525575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0631638916675e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02756585367023945,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20935958623886108,
      "backward_entropy": 0.02387581765651703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.196489655645564e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027566028758883476,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20934100449085236,
      "backward_entropy": 0.020010468860467274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3193703934084624e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027566203847527504,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.209322988986969,
      "backward_entropy": 0.020007686068614323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0067224947270006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027566373348236084,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20930546522140503,
      "backward_entropy": 0.020004988958438236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9908663640962914e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027566533535718918,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20928826928138733,
      "backward_entropy": 0.02000240112344424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2947496694978327e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02756670117378235,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2092716097831726,
      "backward_entropy": 0.014499203612407049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.243762668920681e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027566853910684586,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20925529301166534,
      "backward_entropy": 0.019997282574574154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0287508454639465e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027566997334361076,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20923934876918793,
      "backward_entropy": 0.02386254072189331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.201752042514272e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02756713703274727,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20922380685806274,
      "backward_entropy": 0.023860861857732136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6027853639097884e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027567269280552864,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20920884609222412,
      "backward_entropy": 0.019990441699822743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2975440262816846e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756739966571331,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20919430255889893,
      "backward_entropy": 0.019988320767879486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.373995059519075e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027567537501454353,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20918028056621552,
      "backward_entropy": 0.023856048782666523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6888708816841245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027567686513066292,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2091667354106903,
      "backward_entropy": 0.014496161291996637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.328491220599972e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027567828074097633,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2091536521911621,
      "backward_entropy": 0.01998154694835345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5090153940254822e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027567971497774124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20914074778556824,
      "backward_entropy": 0.019979315499464672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2765965695725754e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027568116784095764,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20912840962409973,
      "backward_entropy": 0.019977092742919922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8745909983408637e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027568254619836807,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20911651849746704,
      "backward_entropy": 0.019974929591019947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4875454982975498e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027568385004997253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20910510420799255,
      "backward_entropy": 0.019972934077183407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3475247871829197e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027568506076931953,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2090938240289688,
      "backward_entropy": 0.01997103914618492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1150544853298925e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027568621560931206,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20908266305923462,
      "backward_entropy": 0.02384289602438609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7661215679254383e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027568737044930458,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2090717852115631,
      "backward_entropy": 0.019967392086982727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.673425686021801e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756885625422001,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20906135439872742,
      "backward_entropy": 0.019965560485919315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7934631614480168e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756897546350956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20905137062072754,
      "backward_entropy": 0.019963766137758892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.762343708833214e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027569090947508812,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20904158055782318,
      "backward_entropy": 0.019961959371964138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3832001059199683e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027569200843572617,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20903190970420837,
      "backward_entropy": 0.02383566399415334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5485380572499707e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027569305151700974,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20902258157730103,
      "backward_entropy": 0.01995869105060895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5092075045686215e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756940759718418,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.209013432264328,
      "backward_entropy": 0.01995709290107091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2689635696006007e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027569502592086792,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20900441706180573,
      "backward_entropy": 0.023831836879253387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.149268246081192e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027569591999053955,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20899561047554016,
      "backward_entropy": 0.01995418593287468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.108264950744342e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027569683268666267,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20898713171482086,
      "backward_entropy": 0.01995278274019559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0809026207425632e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02756977081298828,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20897895097732544,
      "backward_entropy": 0.014488226423660914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.086330485122744e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027569856494665146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20897093415260315,
      "backward_entropy": 0.0199500968058904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.114328349824063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756994217634201,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20896312594413757,
      "backward_entropy": 0.01994876315196355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.060968295671046e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570031583309174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20895567536354065,
      "backward_entropy": 0.019947461783885956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.342736353166401e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027570117264986038,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20894837379455566,
      "backward_entropy": 0.01448700949549675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.815069122647401e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570197358727455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2089414745569229,
      "backward_entropy": 0.01994490126768748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5301404649508186e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570273727178574,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20893463492393494,
      "backward_entropy": 0.01994376505414645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.043545338092372e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570342645049095,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2089279592037201,
      "backward_entropy": 0.019942658642927807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.156903393479297e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570411562919617,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20892156660556793,
      "backward_entropy": 0.019941574583450954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3933554227114655e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570480480790138,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20891526341438293,
      "backward_entropy": 0.019940529018640518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.087582849228056e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757054753601551,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2089093029499054,
      "backward_entropy": 0.019939493387937546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7612037380749825e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570614591240883,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20890361070632935,
      "backward_entropy": 0.019938516120115917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7719140638946556e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570676058530807,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20889812707901,
      "backward_entropy": 0.01993754878640175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.064476681582164e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027570735663175583,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2088928073644638,
      "backward_entropy": 0.014484974245230356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.023867288400652e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757079340517521,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20888766646385193,
      "backward_entropy": 0.019935781757036846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9364649637718685e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027570847421884537,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20888260006904602,
      "backward_entropy": 0.023814255992571514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8091637836478185e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027570901438593864,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2088777720928192,
      "backward_entropy": 0.0238134761651357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4060690268233884e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570951730012894,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2088729739189148,
      "backward_entropy": 0.019933321823676426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.944763537016115e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571002021431923,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2088683843612671,
      "backward_entropy": 0.01993255193034808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.596681608541985e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571050450205803,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20886410772800446,
      "backward_entropy": 0.01993186150987943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.973829734604806e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571097016334534,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20885998010635376,
      "backward_entropy": 0.019931164880593617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.271055447839899e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027571137994527817,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2088557779788971,
      "backward_entropy": 0.01448394109805425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8035924515279476e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0275711752474308,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20885170996189117,
      "backward_entropy": 0.019929921875397365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2809907679620665e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571212500333786,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20884782075881958,
      "backward_entropy": 0.019929314653078716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9130710572644603e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027571246027946472,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20884394645690918,
      "backward_entropy": 0.014483833064635595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.658052153492463e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757127769291401,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20884013175964355,
      "backward_entropy": 0.019928262879451115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.710009994189022e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571307495236397,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2088364064693451,
      "backward_entropy": 0.019927818328142166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.349547685298603e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571333572268486,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2088327258825302,
      "backward_entropy": 0.01992734024922053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2601921045861673e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027571359649300575,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2088291496038437,
      "backward_entropy": 0.023806636532147724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9422543573455187e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571385726332664,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20882564783096313,
      "backward_entropy": 0.019926461080710094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5516576468144194e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571411803364754,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2088223099708557,
      "backward_entropy": 0.019926056265830994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6795805777292117e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571439743041992,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2088191658258438,
      "backward_entropy": 0.019925581912199657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6353400269508711e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757146768271923,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20881617069244385,
      "backward_entropy": 0.014483908812204996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8381686004431685e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757149748504162,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20881325006484985,
      "backward_entropy": 0.02380446841319402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7253174746656441e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027571523562073708,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20881035923957825,
      "backward_entropy": 0.02380407104889552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.476342504247441e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0275715459138155,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20880752801895142,
      "backward_entropy": 0.02380365878343582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3991937066748505e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757156826555729,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20880475640296936,
      "backward_entropy": 0.019923494507869084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2277509995328728e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757159061729908,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2088020294904709,
      "backward_entropy": 0.02380293607711792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0465076911714277e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757161296904087,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20879945158958435,
      "backward_entropy": 0.023802568515141804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1703117479555658e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757163718342781,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20879702270030975,
      "backward_entropy": 0.02380216121673584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3238570772955427e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757166139781475,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20879462361335754,
      "backward_entropy": 0.019922027985254925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.681327360842261e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571681886911392,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20879217982292175,
      "backward_entropy": 0.019921685258547466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0103863132826518e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571704238653183,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20878994464874268,
      "backward_entropy": 0.019921318938334782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.519513130522682e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571724727749825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20878778398036957,
      "backward_entropy": 0.019920976211627323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.847702588354878e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027571747079491615,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20878568291664124,
      "backward_entropy": 0.014483715097109476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.417683036692324e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571767568588257,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20878362655639648,
      "backward_entropy": 0.0199203093846639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.605084419992636e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0275717880576849,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087816745042801,
      "backward_entropy": 0.019919985284407932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.164487101363193e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757180854678154,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20877975225448608,
      "backward_entropy": 0.019919673601786297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.27301505523792e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757182903587818,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20877788960933685,
      "backward_entropy": 0.014483576019605001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.99328700445767e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027571845799684525,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2087760716676712,
      "backward_entropy": 0.014483576019605001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.171939048726927e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571862563490868,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20877426862716675,
      "backward_entropy": 0.019918867697318394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.657607064473268e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757187932729721,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20877254009246826,
      "backward_entropy": 0.023798249661922455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3879762756660057e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571897953748703,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20877091586589813,
      "backward_entropy": 0.019918331255515415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.199814836487349e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027571916580200195,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20876938104629517,
      "backward_entropy": 0.023797633747259777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5352635424933396e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757193334400654,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20876790583133698,
      "backward_entropy": 0.014483438183863958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.786056138073036e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757195010781288,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20876649022102356,
      "backward_entropy": 0.014483409623305002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.316839863349742e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027571966871619225,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20876508951187134,
      "backward_entropy": 0.019917309284210205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3242395147681236e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757198177278042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087637186050415,
      "backward_entropy": 0.01991708328326543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2079395257133e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757199853658676,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20876243710517883,
      "backward_entropy": 0.01991681382060051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.321688097912556e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572013437747955,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20876112580299377,
      "backward_entropy": 0.0144833376010259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5898901273867523e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757202833890915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875990390777588,
      "backward_entropy": 0.019916397829850514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.101907566360751e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572041377425194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875871181488037,
      "backward_entropy": 0.019916202872991562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.811316903716943e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757205441594124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875756442546844,
      "backward_entropy": 0.019916019092003506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.163447388487839e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572067454457283,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2087564468383789,
      "backward_entropy": 0.023795137802759807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6021979238066706e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757207863032818,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20875535905361176,
      "backward_entropy": 0.014483244468768438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0999338801175327e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572089806199074,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875433087348938,
      "backward_entropy": 0.019915512452522915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9942453377552738e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757210098206997,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875340700149536,
      "backward_entropy": 0.01991533984740575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4199388803936017e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572112157940865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875252783298492,
      "backward_entropy": 0.01991516351699829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.497512809895852e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757212333381176,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875170826911926,
      "backward_entropy": 0.019915003329515457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0574248082994018e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572132647037506,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875084400177002,
      "backward_entropy": 0.019914870460828144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8547439140093047e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572141960263252,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20875000953674316,
      "backward_entropy": 0.01991472269097964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5798833885583008e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572151273489,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087491750717163,
      "backward_entropy": 0.019914576162894566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3997251357977802e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572160586714745,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874840021133423,
      "backward_entropy": 0.019914478063583374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7986526756885723e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757216989994049,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20874769985675812,
      "backward_entropy": 0.014483215908209482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.392315596149274e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572177350521088,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874693989753723,
      "backward_entropy": 0.019914202392101288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.236846145502568e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572184801101685,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20874625444412231,
      "backward_entropy": 0.023792922496795654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.241677125563001e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757219225168228,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087455540895462,
      "backward_entropy": 0.01991397763291995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0124538363243119e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757219970226288,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874492824077606,
      "backward_entropy": 0.019913847247759502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1750573492008698e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572207152843475,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874430239200592,
      "backward_entropy": 0.0199137640496095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.240565552507178e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572214603424072,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874370634555817,
      "backward_entropy": 0.019913628697395325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.097177317888054e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757222205400467,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874309539794922,
      "backward_entropy": 0.019913518180449803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.221482599741648e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572229504585266,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20874249935150146,
      "backward_entropy": 0.023792038361231487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955937147447912e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572235092520714,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874188840389252,
      "backward_entropy": 0.019913329432408016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.694300308003221e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757224068045616,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874136686325073,
      "backward_entropy": 0.019913254926602047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.880238683810603e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757224813103676,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874086022377014,
      "backward_entropy": 0.01991313820083936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.119959460373138e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572253718972206,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20874041318893433,
      "backward_entropy": 0.019913078596194584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.083747194907119e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572259306907654,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2087399661540985,
      "backward_entropy": 0.023791444798310597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.909237460992699e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0275722648948431,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087395340204239,
      "backward_entropy": 0.01991290847460429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.259342910652776e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757227048277855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873916149139404,
      "backward_entropy": 0.019912804166475933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.699664822917839e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572276070713997,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087387889623642,
      "backward_entropy": 0.01991273711125056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.821282738656009e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572281658649445,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873838663101196,
      "backward_entropy": 0.019912636528412502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.201751290291213e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572287246584892,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873796939849854,
      "backward_entropy": 0.019912589341402054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8566371308188536e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757229097187519,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087375968694687,
      "backward_entropy": 0.01991252725323041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7681867221836e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757229469716549,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873722434043884,
      "backward_entropy": 0.019912441571553547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.23713686359406e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572298422455788,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20873680710792542,
      "backward_entropy": 0.0237905556956927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5551111327313265e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572302147746086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873641967773438,
      "backward_entropy": 0.019912369549274445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.597585601118226e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572305873036385,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873606204986572,
      "backward_entropy": 0.01991228386759758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.201367159202164e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572309598326683,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873570442199707,
      "backward_entropy": 0.019912260274092358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9066805729580665e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572311460971832,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20873534679412842,
      "backward_entropy": 0.023790304859479267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9341245755840646e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757231332361698,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873495936393738,
      "backward_entropy": 0.019912199427684147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4526909331589195e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757231518626213,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873460173606873,
      "backward_entropy": 0.019912174592415493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.650981478780068e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757231704890728,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20873422920703888,
      "backward_entropy": 0.014483369886875153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8804601370779892e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757231891155243,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087339162826538,
      "backward_entropy": 0.019912101328372955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.318996277812403e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757232077419758,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873361825942993,
      "backward_entropy": 0.019912075251340866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1887913703722006e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572322636842728,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20873329043388367,
      "backward_entropy": 0.014483429491519928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.069725451609884e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572324499487877,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2087329924106598,
      "backward_entropy": 0.023789947231610615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6934542657054408e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572326362133026,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873266458511353,
      "backward_entropy": 0.019912021855513256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1328197874481702e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572328224778175,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20873242616653442,
      "backward_entropy": 0.014483521382013956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1468601119067898e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027572330087423325,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20873209834098816,
      "backward_entropy": 0.023789815604686737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5719599844032928e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572331950068474,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20873183012008667,
      "backward_entropy": 0.014483548700809479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7535739971208386e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572333812713623,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873160660266876,
      "backward_entropy": 0.019911903887987137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4513140911276423e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572335675358772,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873139798641205,
      "backward_entropy": 0.01991187905271848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.889094392026891e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757233753800392,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20873117446899414,
      "backward_entropy": 0.02378963182369868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.604714583436362e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757233940064907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873096585273743,
      "backward_entropy": 0.019911841799815495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.738562360742435e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757234126329422,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087307721376419,
      "backward_entropy": 0.019911819448073704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3135348808646086e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757234312593937,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.208730548620224,
      "backward_entropy": 0.019911813239256542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5356050653281272e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757234498858452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873036980628967,
      "backward_entropy": 0.019911757359902065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2873613286501495e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572346851229668,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20873016119003296,
      "backward_entropy": 0.019911739975214005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2235645385771932e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572348713874817,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872999727725983,
      "backward_entropy": 0.019911727557579677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.003628065329394e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572350576519966,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087298333644867,
      "backward_entropy": 0.019911715139945347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1370296704171778e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572352439165115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872966945171356,
      "backward_entropy": 0.019911696513493855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.831712250412238e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572354301810265,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20872953534126282,
      "backward_entropy": 0.014483697712421417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37022548441746e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572356164455414,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2087293565273285,
      "backward_entropy": 0.014483701437711716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.494392662010796e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572358027100563,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20872917771339417,
      "backward_entropy": 0.014483715097109476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.070951824061922e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572359889745712,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872905850410461,
      "backward_entropy": 0.019911635667085648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.623089632284973e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02757236175239086,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20872892439365387,
      "backward_entropy": 0.02378915747006734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.498442755604628e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757236361503601,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20872880518436432,
      "backward_entropy": 0.014483733723560968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.800355834002403e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757236547768116,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20872868597507477,
      "backward_entropy": 0.014483737448851267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5699055085133296e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757236734032631,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2087285816669464,
      "backward_entropy": 0.019911563644806545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.950816728272912e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02757236920297146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872846245765686,
      "backward_entropy": 0.019911551227172215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4689621720172e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572371065616608,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2087283730506897,
      "backward_entropy": 0.014483742415904999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4872408011542575e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572372928261757,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872826874256134,
      "backward_entropy": 0.019911532600720722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.54211965209106e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572374790906906,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872816443443298,
      "backward_entropy": 0.019911520183086395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.68493874197884e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572376653552055,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872808992862701,
      "backward_entropy": 0.019911501556634903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4372896468303225e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572378516197205,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872798562049866,
      "backward_entropy": 0.019911495347817738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.319169022437563e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572380378842354,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2087278962135315,
      "backward_entropy": 0.01448377842704455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.252033474789641e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027572382241487503,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20872783660888672,
      "backward_entropy": 0.01991147796312968,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.2266505521173484e-07,
    "avg_log_Z": 0.027572168260812758,
    "success_rate": 1.0,
    "avg_reward": 51.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.19,
      "2": 0.66
    },
    "avg_forward_entropy": 0.20874738797545433,
    "avg_backward_entropy": 0.01946436704446872,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}