{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09892041342599052,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09892041342599052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09892041342599052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09892041342599052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09892041342599052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09892041342599052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09894282477242607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09898793697357178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.861249923706055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371401995420456,
      "backward_entropy": 0.09892041342599052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.936613082885742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371394693851471,
      "backward_entropy": 0.09891530445643834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.012073516845703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0002000138338189572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371384561061859,
      "backward_entropy": 0.0989100592476981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.845419883728027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00030005062581039965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371370404958725,
      "backward_entropy": 0.09897543702806745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.653932571411133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00040005246410146356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371355950832367,
      "backward_entropy": 0.0989707623209272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.610003471374512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000499998452141881,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713385164737701,
      "backward_entropy": 0.0988933869770595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.99139404296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006001343717798591,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713188469409943,
      "backward_entropy": 0.09888752017702375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.90549087524414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007002527127042413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712972402572632,
      "backward_entropy": 0.09895506926945277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.981334686279297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000800329027697444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712747395038605,
      "backward_entropy": 0.09887518201555524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.976325035095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009004017920233309,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13712497055530548,
      "backward_entropy": 0.09888267517089844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.890384674072266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010004707146435976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712218403816223,
      "backward_entropy": 0.0989366088594709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.966296195983887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011005051201209426,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711929321289062,
      "backward_entropy": 0.09886711835861206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.61844539642334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012005422031506896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13711614906787872,
      "backward_entropy": 0.09892288276127406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.974637031555176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013004736974835396,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711251318454742,
      "backward_entropy": 0.09885033539363317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.285651206970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014004057738929987,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13710927963256836,
      "backward_entropy": 0.0988416246005467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26430606842041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015001132851466537,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13710647821426392,
      "backward_entropy": 0.09883270944867815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.179449081420898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001599657814949751,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13710354268550873,
      "backward_entropy": 0.09882346221378871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.855609893798828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016990310978144407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13710063695907593,
      "backward_entropy": 0.09881086008889335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.655694007873535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017984958831220865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709747791290283,
      "backward_entropy": 0.09887569291251046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.910737991333008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018976314458996058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13709430396556854,
      "backward_entropy": 0.09879446029663086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.179773330688477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001996574690565467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709117472171783,
      "backward_entropy": 0.09885726656232562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.498824119567871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0020958047825843096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13708758354187012,
      "backward_entropy": 0.09877392223903111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.657687187194824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021950385998934507,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13708388805389404,
      "backward_entropy": 0.09876328706741333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.735251426696777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0022943520452827215,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707970082759857,
      "backward_entropy": 0.09875224317823138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.986642837524414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002393366303294897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370759904384613,
      "backward_entropy": 0.09874088423592704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.474709510803223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002492212690412998,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707265257835388,
      "backward_entropy": 0.09874073096684047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.731451034545898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025907333474606276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370697021484375,
      "backward_entropy": 0.0987172041620527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.88607406616211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026894565671682358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706648349761963,
      "backward_entropy": 0.09878039360046387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630670547485352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027880454435944557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706320524215698,
      "backward_entropy": 0.0987677914755685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.38357162475586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00288642686791718,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705989718437195,
      "backward_entropy": 0.09875491687229701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37501335144043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002984908176586032,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13705646991729736,
      "backward_entropy": 0.098665109702519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.95829963684082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003083511022850871,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705246150493622,
      "backward_entropy": 0.09872770309448242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.368013381958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031828091014176607,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13704761862754822,
      "backward_entropy": 0.09863669531685966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.448993682861328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032821239437907934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370423436164856,
      "backward_entropy": 0.09865518978663854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.030603408813477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003381463000550866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703685998916626,
      "backward_entropy": 0.09864291974476405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.109262466430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003480643266811967,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370316445827484,
      "backward_entropy": 0.09859100409916469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.196464538574219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035797280725091696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702645897865295,
      "backward_entropy": 0.098650404385158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.184374809265137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036783514078706503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702186942100525,
      "backward_entropy": 0.09863354478563581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261884689331055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037769945338368416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701710104942322,
      "backward_entropy": 0.09861603804997035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.164417266845703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003875664435327053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701243698596954,
      "backward_entropy": 0.09859798635755267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.681558609008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003974772058427334,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700687885284424,
      "backward_entropy": 0.09850530964987618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.591835975646973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004073647316545248,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700130581855774,
      "backward_entropy": 0.09848650864192418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.343507766723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004172235261648893,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13699637353420258,
      "backward_entropy": 0.09846690722874232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.405624389648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004270470235496759,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13699214160442352,
      "backward_entropy": 0.09844669273921422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.644775390625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004368877504020929,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698750734329224,
      "backward_entropy": 0.0984257800238473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.903156280517578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004467536695301533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698244094848633,
      "backward_entropy": 0.09848670448575701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.739917755126953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0045660813339054585,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13697762787342072,
      "backward_entropy": 0.0984535643032619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.675393104553223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004664473235607147,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697290420532227,
      "backward_entropy": 0.0983586141041347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.19100570678711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004762235563248396,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13696914911270142,
      "backward_entropy": 0.09833435501371111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.450891494750977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004860579967498779,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13696441054344177,
      "backward_entropy": 0.09842057738985334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8621416091918945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004959098994731903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695938885211945,
      "backward_entropy": 0.09840316431862968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.200263977050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0050566112622618675,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13695599138736725,
      "backward_entropy": 0.09825751611164638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547697067260742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005154297687113285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695234060287476,
      "backward_entropy": 0.09836700132914952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.997425556182861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00525183929130435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13694894313812256,
      "backward_entropy": 0.09834832804543632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.002298355102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005349045619368553,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13694584369659424,
      "backward_entropy": 0.09817385673522949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.467877388000488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005446868482977152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694152235984802,
      "backward_entropy": 0.09823331662586757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.549906730651855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005544532090425491,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693752884864807,
      "backward_entropy": 0.09811420100075859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.967589378356934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005642106290906668,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693366944789886,
      "backward_entropy": 0.09808312143598284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.509330749511719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0057392967864871025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693061470985413,
      "backward_entropy": 0.09814817564828056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.56894588470459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005836916156113148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692645728588104,
      "backward_entropy": 0.09822257075990949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.251209735870361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00593491829931736,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13692152500152588,
      "backward_entropy": 0.09798521654946464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.089020729064941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006032175850123167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691803812980652,
      "backward_entropy": 0.0981753042766026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.405588150024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006129656918346882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691401481628418,
      "backward_entropy": 0.09802610533578056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.032687187194824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006227492354810238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13690915703773499,
      "backward_entropy": 0.09811984641211373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.882022380828857,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006324969232082367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369050145149231,
      "backward_entropy": 0.09808998448508126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75185489654541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006422076374292374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690155744552612,
      "backward_entropy": 0.09792862619672503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.747702598571777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006519275717437267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689787685871124,
      "backward_entropy": 0.09776516471590314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.802226066589355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006616558413952589,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13689395785331726,
      "backward_entropy": 0.09785902500152588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.290298461914062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00671391561627388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368900090456009,
      "backward_entropy": 0.09795597621372767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.995881080627441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006811602506786585,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13688531517982483,
      "backward_entropy": 0.09792001758302961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.411487579345703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006909481715410948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687992095947266,
      "backward_entropy": 0.09774623598371233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.330700874328613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007007214706391096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136874720454216,
      "backward_entropy": 0.09754749706813268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.40256404876709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007105235941708088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686898350715637,
      "backward_entropy": 0.09766411781311035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.905735492706299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007203095126897097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13686354458332062,
      "backward_entropy": 0.09776455163955688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.535343170166016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007300542667508125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685905933380127,
      "backward_entropy": 0.09757792949676514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.21761417388916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007397943641990423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685472309589386,
      "backward_entropy": 0.09753336225237165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.104337692260742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007495617959648371,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13684988021850586,
      "backward_entropy": 0.09763870920453753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09871768951416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0075935437344014645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684430718421936,
      "backward_entropy": 0.0974405322756086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33678150177002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007691693026572466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368381530046463,
      "backward_entropy": 0.0975487572806222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.177799224853516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007789606228470802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683277368545532,
      "backward_entropy": 0.097502487046378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.677889823913574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007887325249612331,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368274688720703,
      "backward_entropy": 0.0972914525440761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.534055709838867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007985075935721397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13682202994823456,
      "backward_entropy": 0.09740464176450457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.037330627441406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008082805201411247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13681650161743164,
      "backward_entropy": 0.09735346691949028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.209073066711426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008180242031812668,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13681170344352722,
      "backward_entropy": 0.09730106592178345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.283035278320312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008277530781924725,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13680720329284668,
      "backward_entropy": 0.09680025918143136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.648929595947266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00837522093206644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368016004562378,
      "backward_entropy": 0.0971895796912057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.458572387695312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008472945541143417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13679584860801697,
      "backward_entropy": 0.09695720672607422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.664229393005371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008570658043026924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678987324237823,
      "backward_entropy": 0.0968962482043675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671154975891113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008668940514326096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367824375629425,
      "backward_entropy": 0.0968333397592817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.359050750732422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00876725371927023,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13677485287189484,
      "backward_entropy": 0.09695462669645037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.946319580078125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008865360170602798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367679238319397,
      "backward_entropy": 0.09689271450042725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.368937492370605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00896313227713108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676173985004425,
      "backward_entropy": 0.09663633789334979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.515811920166016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009061296470463276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367546021938324,
      "backward_entropy": 0.09656770740236555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.191883087158203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00915937963873148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13674767315387726,
      "backward_entropy": 0.09669829266411918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23293399810791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009258314035832882,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367388367652893,
      "backward_entropy": 0.09605908393859863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.740841388702393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009356980212032795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367306411266327,
      "backward_entropy": 0.09635119778769356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.415968894958496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009455128572881222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13672366738319397,
      "backward_entropy": 0.09648808411189488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.609034538269043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00955367460846901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13671563565731049,
      "backward_entropy": 0.09619860989706856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.60642147064209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009652206674218178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670745491981506,
      "backward_entropy": 0.09611902918134417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.784904479980469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009750653058290482,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13669957220554352,
      "backward_entropy": 0.09562210525785174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.113593101501465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009849674999713898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366901993751526,
      "backward_entropy": 0.09618662084851946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.291842460632324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009948890656232834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668020069599152,
      "backward_entropy": 0.09586852788925171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.568798065185547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010048856027424335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13666826486587524,
      "backward_entropy": 0.09578043222427368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.094484329223633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010148636996746063,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665662705898285,
      "backward_entropy": 0.09523705073765346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.291248321533203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010248984210193157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13664346933364868,
      "backward_entropy": 0.09559834003448486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.892362594604492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010348928160965443,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663113117218018,
      "backward_entropy": 0.09577373095921107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.229089736938477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01044883206486702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13661864399909973,
      "backward_entropy": 0.09568569489887782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7001371383667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010548379272222519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13660691678524017,
      "backward_entropy": 0.09531177793230329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.25168228149414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010647808201611042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659527897834778,
      "backward_entropy": 0.09521262986319405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.68028736114502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0107474559918046,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365828514099121,
      "backward_entropy": 0.09460522447313581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.706165313720703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010846965946257114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13657057285308838,
      "backward_entropy": 0.09530394417898995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.70073413848877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010946879163384438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13655734062194824,
      "backward_entropy": 0.09520256519317627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.949172019958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011046678759157658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365443766117096,
      "backward_entropy": 0.09478680576596941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.893366813659668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011146469973027706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13653120398521423,
      "backward_entropy": 0.09413714068276542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.394881248474121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011246255598962307,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13651782274246216,
      "backward_entropy": 0.09401359728404454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.912436485290527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011346295475959778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13650348782539368,
      "backward_entropy": 0.09441744429724556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.239142417907715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011446284130215645,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13648897409439087,
      "backward_entropy": 0.09375803811209542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35301399230957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011546444147825241,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13647392392158508,
      "backward_entropy": 0.0936227696282523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.872620582580566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011646798811852932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13645802438259125,
      "backward_entropy": 0.09401176656995501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.224445343017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011747049167752266,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13644202053546906,
      "backward_entropy": 0.09334228719983782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.465425491333008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01184688601642847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364271342754364,
      "backward_entropy": 0.09415511574063982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.115485191345215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01194644533097744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13641279935836792,
      "backward_entropy": 0.09402521167482648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.76720666885376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012045596726238728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13639946281909943,
      "backward_entropy": 0.09343070643288749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.17379379272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012144225649535656,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13638770580291748,
      "backward_entropy": 0.09273961612156459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.160481452941895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012242591008543968,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363765448331833,
      "backward_entropy": 0.09258076122828893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.855831146240234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012340715155005455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13636596500873566,
      "backward_entropy": 0.0929626396724156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.172993659973145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012438985519111156,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363544911146164,
      "backward_entropy": 0.0922525439943586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.492632865905762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012537531554698944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13634184002876282,
      "backward_entropy": 0.09316555091312953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.06155014038086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012636014260351658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13632944226264954,
      "backward_entropy": 0.0924584184374128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.832086563110352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012734152376651764,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363179236650467,
      "backward_entropy": 0.0917325530733381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.641251564025879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012832400389015675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13630560040473938,
      "backward_entropy": 0.09210268088749476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66443157196045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012931223958730698,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362908035516739,
      "backward_entropy": 0.09251419135502406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.301932334899902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01303061656653881,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362735629081726,
      "backward_entropy": 0.09233971152986799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.580596923828125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013129170052707195,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362590491771698,
      "backward_entropy": 0.09099066257476807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.070148468017578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013228239491581917,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13624240458011627,
      "backward_entropy": 0.09198015076773507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.904976844787598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013327499851584435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13622471690177917,
      "backward_entropy": 0.09179380961826869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.460667610168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013427394442260265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13620460033416748,
      "backward_entropy": 0.0903989587511335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.209259986877441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013527055270969868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136184960603714,
      "backward_entropy": 0.09140724795205253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.148481369018555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013626915402710438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13616451621055603,
      "backward_entropy": 0.0904965911592756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.036775588989258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01372695155441761,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13614317774772644,
      "backward_entropy": 0.089761563709804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.781116962432861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013825981877744198,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361253410577774,
      "backward_entropy": 0.08954078810555595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.40168571472168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013924522325396538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13610902428627014,
      "backward_entropy": 0.08982397828783308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5401482582092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014022400602698326,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13609488308429718,
      "backward_entropy": 0.08908627714429583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.997793197631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014119716361165047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13608244061470032,
      "backward_entropy": 0.08936042445046562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.622849464416504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014216780662536621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360703408718109,
      "backward_entropy": 0.08912256785801478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.223116874694824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014313467778265476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13605919480323792,
      "backward_entropy": 0.08888122013636998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6200408935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014410690404474735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13604480028152466,
      "backward_entropy": 0.08811836583273751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.874312400817871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014507491141557693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360314041376114,
      "backward_entropy": 0.08838003022330147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.126697540283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014604062773287296,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1360187530517578,
      "backward_entropy": 0.08760535717010498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.90781307220459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014700575731694698,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13600584864616394,
      "backward_entropy": 0.08870465414864677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.805830955505371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014796923846006393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13599316775798798,
      "backward_entropy": 0.08759474754333496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.066362380981445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014893057756125927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359810084104538,
      "backward_entropy": 0.08731799466269356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.534975051879883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014989718794822693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13596589863300323,
      "backward_entropy": 0.0879192692892892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.88774299621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015086589381098747,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359492391347885,
      "backward_entropy": 0.08623653650283813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.706387996673584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015183264389634132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359337866306305,
      "backward_entropy": 0.08643507957458496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.717180252075195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015279642306268215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13591954112052917,
      "backward_entropy": 0.08613041469029017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.348838806152344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015375732444226742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13590624928474426,
      "backward_entropy": 0.08582166263035365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.542728424072266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015471411868929863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13589432835578918,
      "backward_entropy": 0.08650938102177211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.322347640991211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015567376278340816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13588044047355652,
      "backward_entropy": 0.086213333266122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.625552654266357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015663480386137962,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358652263879776,
      "backward_entropy": 0.08591227872031075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.695609092712402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01575876958668232,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13585320115089417,
      "backward_entropy": 0.08409273624420166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.930409908294678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015853935852646828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358409821987152,
      "backward_entropy": 0.08420561892645699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.034029483795166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015949133783578873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13582804799079895,
      "backward_entropy": 0.08387127092906407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.131423950195312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01604381948709488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13581722974777222,
      "backward_entropy": 0.0835338830947876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.65098762512207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01613871566951275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358044594526291,
      "backward_entropy": 0.08318878071648735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.022622585296631,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016233526170253754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13579130172729492,
      "backward_entropy": 0.08397996425628662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.65855598449707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01632787473499775,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13577988743782043,
      "backward_entropy": 0.08363832746233259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47751235961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016422145068645477,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13576820492744446,
      "backward_entropy": 0.08167051417487008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.188567161560059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016516853123903275,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13575349748134613,
      "backward_entropy": 0.08129984991891044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.888729572296143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016611218452453613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13573971390724182,
      "backward_entropy": 0.08136721168245588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.974912643432617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01670566387474537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13572466373443604,
      "backward_entropy": 0.08098135675702776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2705864906311035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016799647361040115,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13571128249168396,
      "backward_entropy": 0.08015529598508563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.455981731414795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0168934129178524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135698139667511,
      "backward_entropy": 0.08150730814252581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.692902565002441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016987130045890808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13568423688411713,
      "backward_entropy": 0.07979507105691093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.838130474090576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01708030514419079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356724500656128,
      "backward_entropy": 0.07939055136271886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.663645267486572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017173077911138535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1356620192527771,
      "backward_entropy": 0.08036023378372192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7294487953186035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017265984788537025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1356498897075653,
      "backward_entropy": 0.07996753283909389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.946552276611328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017359038814902306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13563594222068787,
      "backward_entropy": 0.07957121304103307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.293268203735352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017451809719204903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13562248647212982,
      "backward_entropy": 0.077707724911826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.157971382141113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017544496804475784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13560840487480164,
      "backward_entropy": 0.07875963619777135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.933666229248047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017636416479945183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13559773564338684,
      "backward_entropy": 0.07682919502258301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.384809494018555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017728153616189957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13558700680732727,
      "backward_entropy": 0.07638214315686907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.370982646942139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017820017412304878,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13557425141334534,
      "backward_entropy": 0.07546877861022949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.39361572265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017911959439516068,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13555973768234253,
      "backward_entropy": 0.07499602011271886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538261413574219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018003391101956367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355469971895218,
      "backward_entropy": 0.07499550070081439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.794530391693115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018095137551426888,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13553112745285034,
      "backward_entropy": 0.0740351676940918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.329553604125977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01818665862083435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355152726173401,
      "backward_entropy": 0.07403774772371564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.421750545501709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01827831007540226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13549722731113434,
      "backward_entropy": 0.073546188218253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.252460479736328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018369469791650772,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135480597615242,
      "backward_entropy": 0.07479302372251238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.733936309814453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01846013218164444,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354655921459198,
      "backward_entropy": 0.0720369815826416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.67498779296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018550008535385132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13545414805412292,
      "backward_entropy": 0.07383715254919869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.178013324737549,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01864044927060604,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13543786108493805,
      "backward_entropy": 0.07100668123790196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.468520641326904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018731040880084038,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13541898131370544,
      "backward_entropy": 0.0704816962991442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.092650890350342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018821341916918755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13540028035640717,
      "backward_entropy": 0.0704988922391619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.368953227996826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018911154940724373,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13538303971290588,
      "backward_entropy": 0.07183378083365304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9521074295043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019000699743628502,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353657841682434,
      "backward_entropy": 0.06888288259506226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.063586235046387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019089704379439354,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353500485420227,
      "backward_entropy": 0.06834439294678825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.14923620223999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019178291782736778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353350281715393,
      "backward_entropy": 0.06837208781923566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.961420059204102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019267255440354347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353156864643097,
      "backward_entropy": 0.06725062642778669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.649787902832031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019355744123458862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352972686290741,
      "backward_entropy": 0.06728034360068184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.302977561950684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0194443017244339,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13527637720108032,
      "backward_entropy": 0.06613647086279732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.756182670593262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019532673060894012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13525453209877014,
      "backward_entropy": 0.0661654600075313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.499133586883545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019621213898062706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13522951304912567,
      "backward_entropy": 0.06745279686791557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.321150779724121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019709698855876923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13520251214504242,
      "backward_entropy": 0.06502293263162885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.333293437957764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01979733444750309,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.135178804397583,
      "backward_entropy": 0.06631355626242501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.885897636413574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019884230569005013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13515780866146088,
      "backward_entropy": 0.06573997225080218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.320733547210693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01997082121670246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13513632118701935,
      "backward_entropy": 0.06516508119446891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.597838401794434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020057471469044685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13511201739311218,
      "backward_entropy": 0.06271928548812866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.85776948928833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02014368586242199,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1350882351398468,
      "backward_entropy": 0.06151395184653146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.342144966125488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0202297642827034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13506360352039337,
      "backward_entropy": 0.06340993302209037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.42243766784668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020315995439887047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13503526151180267,
      "backward_entropy": 0.06281380142484393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.272276401519775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020401719957590103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350077986717224,
      "backward_entropy": 0.0603580858026232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.999396324157715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02048761211335659,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13497653603553772,
      "backward_entropy": 0.06161154167992728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.222588539123535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020573457702994347,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13494166731834412,
      "backward_entropy": 0.06100528580801828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.564907550811768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020658737048506737,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1349077969789505,
      "backward_entropy": 0.0579170286655426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.239717960357666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020743776112794876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13487310707569122,
      "backward_entropy": 0.05977786438805716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6036601066589355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02082834392786026,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13483919203281403,
      "backward_entropy": 0.05670738220214844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.467191696166992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020912079140543938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348097026348114,
      "backward_entropy": 0.05672959770475115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596047401428223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020995622500777245,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347782164812088,
      "backward_entropy": 0.05550201450075422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.579647064208984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021079102531075478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347438246011734,
      "backward_entropy": 0.05728397199085781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.921499729156494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02116180583834648,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347125619649887,
      "backward_entropy": 0.054290992873055596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.758449554443359,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021244056522846222,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1346815824508667,
      "backward_entropy": 0.053686439990997314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.813770771026611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021325834095478058,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.134651780128479,
      "backward_entropy": 0.05308431386947632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.005353927612305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021407144144177437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13462182879447937,
      "backward_entropy": 0.053072495119912286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.654046058654785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021487371996045113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13459664583206177,
      "backward_entropy": 0.05246699282101223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.125622272491455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021567124873399734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13457101583480835,
      "backward_entropy": 0.053519325596945624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.68426513671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02164606936275959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13454817235469818,
      "backward_entropy": 0.051257116453988213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1089653968811035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021724743768572807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13452360033988953,
      "backward_entropy": 0.05065195049558367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.019735336303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021802738308906555,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13450103998184204,
      "backward_entropy": 0.049465217760631015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8607282638549805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021880000829696655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13448035717010498,
      "backward_entropy": 0.04945246662412371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.720338821411133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021956531330943108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13446222245693207,
      "backward_entropy": 0.04885937486376081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.601937294006348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0220330897718668,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13443970680236816,
      "backward_entropy": 0.04984151891299656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.851015567779541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022109568119049072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13441355526447296,
      "backward_entropy": 0.04765931623322623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.221447467803955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022186243906617165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1343819499015808,
      "backward_entropy": 0.04705206411225455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.676124095916748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022262530401349068,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13434916734695435,
      "backward_entropy": 0.04587513208389282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.488372802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0223380234092474,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13431891798973083,
      "backward_entropy": 0.045282334089279175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.808202028274536,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022413484752178192,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1342843919992447,
      "backward_entropy": 0.04679389936583383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7658300399780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0224883072078228,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13425037264823914,
      "backward_entropy": 0.044099628925323486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.426521062850952,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022562572732567787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13421666622161865,
      "backward_entropy": 0.044033437967300415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.108940601348877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022635942324995995,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13418526947498322,
      "backward_entropy": 0.04293114798409598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.413731813430786,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022709248587489128,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13415026664733887,
      "backward_entropy": 0.044390861477170675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.394557237625122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02278183214366436,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13411685824394226,
      "backward_entropy": 0.04177686997822353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.505542278289795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02285376377403736,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13408465683460236,
      "backward_entropy": 0.04320173604147775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5052361488342285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022925186902284622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1340518742799759,
      "backward_entropy": 0.041096891675676615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6300954818725586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02299613505601883,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13401789963245392,
      "backward_entropy": 0.04202697958265032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.037018299102783,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0230668056756258,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13398119807243347,
      "backward_entropy": 0.041445221219744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.928030252456665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023136690258979797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13394683599472046,
      "backward_entropy": 0.04086612803595407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.528359889984131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023206740617752075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13390611112117767,
      "backward_entropy": 0.03881004878452846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5161914825439453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023276519030332565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1338624805212021,
      "backward_entropy": 0.039713693516595025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.128962516784668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023346122354269028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13381579518318176,
      "backward_entropy": 0.03913964969771249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5173864364624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02341514639556408,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1337689459323883,
      "backward_entropy": 0.03677680662700108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.326155662536621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02348298206925392,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13372702896595,
      "backward_entropy": 0.03624320455959865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8020358085632324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023549534380435944,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1336909830570221,
      "backward_entropy": 0.03571792159761701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.835057497024536,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023615475744009018,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13365504145622253,
      "backward_entropy": 0.035473327551569254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3092246055603027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023680897429585457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13361814618110657,
      "backward_entropy": 0.03636015313012259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6407876014709473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023746371269226074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1335749477148056,
      "backward_entropy": 0.0358191898890904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.52459454536438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023811133578419685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1335318386554718,
      "backward_entropy": 0.033888193113463264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1223397254943848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023875152692198753,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13348951935768127,
      "backward_entropy": 0.03316586783954075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.801873207092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02393915131688118,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13344082236289978,
      "backward_entropy": 0.032668496881212504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3481760025024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024002857506275177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333894282579422,
      "backward_entropy": 0.03233470448425838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5553319454193115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02406572923064232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333412528038025,
      "backward_entropy": 0.03182669835431235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2643048763275146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02412813901901245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13329243659973145,
      "backward_entropy": 0.03132385866982596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2377302646636963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024189768359065056,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1332446187734604,
      "backward_entropy": 0.030741746936525618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3720102310180664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024250684306025505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13319748640060425,
      "backward_entropy": 0.030343104686055864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.095154047012329,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024311130866408348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13314878940582275,
      "backward_entropy": 0.02986179292201996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9264006614685059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024370793253183365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13310115039348602,
      "backward_entropy": 0.029388725757598877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2170345783233643,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024429459124803543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133055180311203,
      "backward_entropy": 0.030252763203212192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9875636100769043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024487659335136414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13300660252571106,
      "backward_entropy": 0.02846672066620418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9498533010482788,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024545205757021904,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13295859098434448,
      "backward_entropy": 0.02805755819593157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6313823461532593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024602005258202553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13290971517562866,
      "backward_entropy": 0.027570798993110657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4075255393981934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024657752364873886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13286402821540833,
      "backward_entropy": 0.02713739446231297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6577305793762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024713687598705292,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13281038403511047,
      "backward_entropy": 0.026798084378242493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.657454013824463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02476871944963932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13275879621505737,
      "backward_entropy": 0.02627697799886976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5855076313018799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024822980165481567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13270872831344604,
      "backward_entropy": 0.025860264897346497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4920977354049683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024876421317458153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326601505279541,
      "backward_entropy": 0.02545229664870671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9087949991226196,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024928878992795944,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1326126754283905,
      "backward_entropy": 0.025202299867357527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.512079119682312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024981088936328888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13255923986434937,
      "backward_entropy": 0.02586021593638829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4038282632827759,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025032497942447662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13250721991062164,
      "backward_entropy": 0.024266711303165982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3814575672149658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025083027780056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13245819509029388,
      "backward_entropy": 0.02507185084479196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7228381633758545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02513275109231472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13240937888622284,
      "backward_entropy": 0.023512857300894602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4528974294662476,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025182340294122696,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13235481083393097,
      "backward_entropy": 0.023348738040242876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.370531678199768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025231434032320976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13229921460151672,
      "backward_entropy": 0.022776375923837935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4421753883361816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025279905647039413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13224294781684875,
      "backward_entropy": 0.02241785611425127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4361975193023682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025327924638986588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13218411803245544,
      "backward_entropy": 0.022063695958682468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3195282220840454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025375505909323692,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1321217119693756,
      "backward_entropy": 0.022843829223087857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0343117713928223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025422479957342148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13205717504024506,
      "backward_entropy": 0.02137028319495065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9517578482627869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025468310341238976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13199439644813538,
      "backward_entropy": 0.021036673869405473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2063826322555542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025513140484690666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13193580508232117,
      "backward_entropy": 0.02071340594972883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9987910389900208,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025557545945048332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1318754106760025,
      "backward_entropy": 0.021492583411080495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9020117521286011,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02560100145637989,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318148970603943,
      "backward_entropy": 0.02008438536099025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0710455179214478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02564357779920101,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1317571997642517,
      "backward_entropy": 0.01978261981691633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1569316387176514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02568558230996132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1316966414451599,
      "backward_entropy": 0.0205550023487636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7320942282676697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025727281346917152,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13163122534751892,
      "backward_entropy": 0.020254439541271756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9924929141998291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025767771527171135,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13156911730766296,
      "backward_entropy": 0.019276689205850874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1267106533050537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02580779790878296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1315048485994339,
      "backward_entropy": 0.018628301365034922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7420575618743896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025847749784588814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13143496215343475,
      "backward_entropy": 0.01834986252444131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6931931972503662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025886761024594307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13136716187000275,
      "backward_entropy": 0.018079991851534163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7295210957527161,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025924760848283768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13130119442939758,
      "backward_entropy": 0.018853387662342617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6933643817901611,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025961859151721,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13123470544815063,
      "backward_entropy": 0.01859477162361145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.707633912563324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02599814534187317,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13116872310638428,
      "backward_entropy": 0.017757279532296315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7771538496017456,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603372186422348,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.131102055311203,
      "backward_entropy": 0.017526919288294657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8677413463592529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02606886811554432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1310327649116516,
      "backward_entropy": 0.01785589967455183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6784500479698181,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026103973388671875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13095927238464355,
      "backward_entropy": 0.016601858394486562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6416539549827576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026138436049222946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13088464736938477,
      "backward_entropy": 0.016369399215493883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5259969234466553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026172315701842308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13081032037734985,
      "backward_entropy": 0.016141716923032488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5055761337280273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02620529569685459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13073785603046417,
      "backward_entropy": 0.015921294689178467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6437303423881531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026237405836582184,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13066700100898743,
      "backward_entropy": 0.016241849533149173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5688903331756592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626919560134411,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1305941343307495,
      "backward_entropy": 0.015497016055243356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3804725408554077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02630041353404522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1305200159549713,
      "backward_entropy": 0.015290413584027971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4443601369857788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026330547407269478,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1304492950439453,
      "backward_entropy": 0.01608967993940626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.518449068069458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026359805837273598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1303786039352417,
      "backward_entropy": 0.015895749841417586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34089192748069763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026388658210635185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1303063929080963,
      "backward_entropy": 0.014712435858590263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35491999983787537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026416542008519173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13023725152015686,
      "backward_entropy": 0.015521225120340074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.512635350227356,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02644358016550541,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1301698088645935,
      "backward_entropy": 0.015343016811779566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34578120708465576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026470383629202843,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13009850680828094,
      "backward_entropy": 0.01483137799160821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5648903846740723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026496335864067078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1300276815891266,
      "backward_entropy": 0.014016887971333094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45175933837890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026522425934672356,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12995100021362305,
      "backward_entropy": 0.014521944735731398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2556738555431366,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026548124849796295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1298709213733673,
      "backward_entropy": 0.014666696744305747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3457985520362854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02657272294163704,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1297936737537384,
      "backward_entropy": 0.01422643129314695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3183879256248474,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026596687734127045,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12971580028533936,
      "backward_entropy": 0.014086912785257612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41959965229034424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026620082557201385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.129638671875,
      "backward_entropy": 0.01322386520249503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2678169906139374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026643352583050728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12955772876739502,
      "backward_entropy": 0.013075437928949083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27621930837631226,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026665858924388885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.129477858543396,
      "backward_entropy": 0.013916223176888056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22903670370578766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026687664911150932,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12939788401126862,
      "backward_entropy": 0.013777294329234533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36277341842651367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670872211456299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12931978702545166,
      "backward_entropy": 0.01266083334173475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22449098527431488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026729725301265717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.129238098859787,
      "backward_entropy": 0.012527939464364733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25718018412590027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026749882847070694,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12915663421154022,
      "backward_entropy": 0.013214678636619024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16027149558067322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02676951140165329,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12907427549362183,
      "backward_entropy": 0.01325943214552743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2535030245780945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026788314804434776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1289955973625183,
      "backward_entropy": 0.012158684432506561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21351182460784912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02680659480392933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12891435623168945,
      "backward_entropy": 0.012043660240513938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2562066912651062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026824329048395157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12883299589157104,
      "backward_entropy": 0.011932142078876495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24746054410934448,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02684183605015278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12874948978424072,
      "backward_entropy": 0.011821994824068887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17523926496505737,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026859136298298836,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12866422533988953,
      "backward_entropy": 0.012617067566939763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24433830380439758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02687571942806244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12857922911643982,
      "backward_entropy": 0.011609073196138655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17784211039543152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02689214237034321,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1284918636083603,
      "backward_entropy": 0.01244094009910311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24106526374816895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026908010244369507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12840485572814941,
      "backward_entropy": 0.012399753289563316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1918463110923767,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026923710480332375,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12831467390060425,
      "backward_entropy": 0.01227455266884395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19790315628051758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026939110830426216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12822407484054565,
      "backward_entropy": 0.011209625218595778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16555100679397583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02695424109697342,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.128132164478302,
      "backward_entropy": 0.01111428758927754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17112714052200317,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026968946680426598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804041802883148,
      "backward_entropy": 0.01102168538740703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1546144187450409,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026983341202139854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12794837355613708,
      "backward_entropy": 0.011945741517203195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1610507369041443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026997242122888565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1278560310602188,
      "backward_entropy": 0.01186281442642212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1677304208278656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027010701596736908,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12776243686676025,
      "backward_entropy": 0.01182543592793601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14797143638134003,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027023734524846077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1276663988828659,
      "backward_entropy": 0.011760276343141283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11713334918022156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027036450803279877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12757015228271484,
      "backward_entropy": 0.010595814457961492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15628762543201447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027048440650105476,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1274741142988205,
      "backward_entropy": 0.010519757866859436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13095058500766754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02706032618880272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1273772418498993,
      "backward_entropy": 0.010444214301449912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12187710404396057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027071982622146606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12728102505207062,
      "backward_entropy": 0.01037019384758813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10813728719949722,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027083173394203186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12718451023101807,
      "backward_entropy": 0.01029901419367109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15503281354904175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027093883603811264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1270885169506073,
      "backward_entropy": 0.0102307562317167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11133667826652527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027104534208774567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12698949873447418,
      "backward_entropy": 0.010162651538848877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10886184871196747,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027114709839224815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1268901526927948,
      "backward_entropy": 0.01117668833051409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10208000242710114,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027124404907226562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12679025530815125,
      "backward_entropy": 0.011121195341859545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10483796149492264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02713373489677906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12669071555137634,
      "backward_entropy": 0.011067924754960197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09438256919384003,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027142807841300964,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1265912801027298,
      "backward_entropy": 0.011193515998976571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09365002065896988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0271515641361475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12649232149124146,
      "backward_entropy": 0.010966580893312181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11418289691209793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027159953489899635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12639334797859192,
      "backward_entropy": 0.010919082377638136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07299670577049255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02716830000281334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12629307806491852,
      "backward_entropy": 0.010872033025537218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07072999328374863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02717621624469757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1261945217847824,
      "backward_entropy": 0.010827506227152688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09164153784513474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027183525264263153,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12609654664993286,
      "backward_entropy": 0.009648874402046204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08989640325307846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027190713211894035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12599804997444153,
      "backward_entropy": 0.010746182075568609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0715198963880539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02719774655997753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12589901685714722,
      "backward_entropy": 0.010706916451454163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08188290148973465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027204612269997597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1258014738559723,
      "backward_entropy": 0.010668746062687464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08158863335847855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027211373671889305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12570405006408691,
      "backward_entropy": 0.00946326766695295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09214022755622864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02721797116100788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12560603022575378,
      "backward_entropy": 0.009418992059571403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08428749442100525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027224602177739143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12550649046897888,
      "backward_entropy": 0.009374451424394335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05591645464301109,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723134495317936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12540680170059204,
      "backward_entropy": 0.009329360510621752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07071473449468613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723780646920204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12530921399593353,
      "backward_entropy": 0.009286089667252131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05632501095533371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02724393643438816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12521067261695862,
      "backward_entropy": 0.009244659117289953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06735584884881973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027249587699770927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1251125931739807,
      "backward_entropy": 0.009205975702830724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056076422333717346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027255212888121605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12501482665538788,
      "backward_entropy": 0.010391602558749062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05430610477924347,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027260590344667435,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12491799890995026,
      "backward_entropy": 0.010362599577222551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053860023617744446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027265731245279312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12482206523418427,
      "backward_entropy": 0.009094711925302233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05206291377544403,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027270745486021042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12472707033157349,
      "backward_entropy": 0.010308167764118739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05902143195271492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027275513857603073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12463241070508957,
      "backward_entropy": 0.010282763413020543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04060310870409012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027280224487185478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12453727424144745,
      "backward_entropy": 0.008993316973958696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05405737832188606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027284638956189156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12444386631250381,
      "backward_entropy": 0.008961985153811318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054275061935186386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027289144694805145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12435087561607361,
      "backward_entropy": 0.008930242487362452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04828893393278122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027293674647808075,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12425786256790161,
      "backward_entropy": 0.010579157088484083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04051873832941055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027297981083393097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12416469305753708,
      "backward_entropy": 0.008867761386292321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04027297720313072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027302000671625137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12407236546278,
      "backward_entropy": 0.010143334312098367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051710519939661026,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027305733412504196,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12398059666156769,
      "backward_entropy": 0.010537319949695043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04436658322811127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027309522032737732,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1238880529999733,
      "backward_entropy": 0.010524676314422063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039332315325737,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02731327712535858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12379569560289383,
      "backward_entropy": 0.008756219276360102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04823819920420647,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027316881343722343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1237039864063263,
      "backward_entropy": 0.00872962230018207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03741339594125748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732066996395588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12361185252666473,
      "backward_entropy": 0.008702085486480169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038201965391635895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732418291270733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1235198825597763,
      "backward_entropy": 0.00867606805903571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03544381260871887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027327485382556915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12342678010463715,
      "backward_entropy": 0.008651195360081536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04201866313815117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027330709621310234,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1233341246843338,
      "backward_entropy": 0.010455792503697532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03572121635079384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027333850041031837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12324020266532898,
      "backward_entropy": 0.009978424225534712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02924937754869461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733701281249523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12314684689044952,
      "backward_entropy": 0.008579008813415254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02848423272371292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339907363057137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12305442988872528,
      "backward_entropy": 0.008556579904896873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025946669280529022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02734278328716755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12296368181705475,
      "backward_entropy": 0.008534386221851622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022808663547039032,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02734559215605259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12287482619285583,
      "backward_entropy": 0.00851266405412129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029845045879483223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027348089963197708,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12278750538825989,
      "backward_entropy": 0.010405971535614558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026830460876226425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02735055796802044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1227002739906311,
      "backward_entropy": 0.008473046123981476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026539238169789314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02735282853245735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12261326611042023,
      "backward_entropy": 0.008454419672489166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026233511045575142,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027355041354894638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12252677232027054,
      "backward_entropy": 0.009871956493173326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028859542682766914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027357250452041626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12244077026844025,
      "backward_entropy": 0.009861086096082414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02273254282772541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027359629049897194,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12235493957996368,
      "backward_entropy": 0.009849288633891515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020248951390385628,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027361886575818062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12227001786231995,
      "backward_entropy": 0.00838075312120574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020510556176304817,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027364009991288185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12218651920557022,
      "backward_entropy": 0.009827802223818643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017655743286013603,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02736610546708107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12210437655448914,
      "backward_entropy": 0.009817689657211304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01588088646531105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02736816555261612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12202411890029907,
      "backward_entropy": 0.008329192442553384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019894909113645554,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02736997976899147,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1219453513622284,
      "backward_entropy": 0.009799487888813019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02023271471261978,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027371801435947418,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12186720222234726,
      "backward_entropy": 0.010347147073064531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017242543399333954,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027373598888516426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12178923189640045,
      "backward_entropy": 0.009782657027244568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0188522357493639,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027375150471925735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12171168625354767,
      "backward_entropy": 0.01034023186990193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01710762269794941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027376696467399597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12163449078798294,
      "backward_entropy": 0.00825527310371399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01754843257367611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027378316968679428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12155836075544357,
      "backward_entropy": 0.0082410957132067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014870488084852695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027379916980862617,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12148265540599823,
      "backward_entropy": 0.010330859039511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013794057071208954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027381500229239464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12140825390815735,
      "backward_entropy": 0.008213268326861518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015643969178199768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027382979169487953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12133492529392242,
      "backward_entropy": 0.008200091975075858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014778547920286655,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02738434262573719,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12126167863607407,
      "backward_entropy": 0.00973308618579592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013856733217835426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027385707944631577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12118900567293167,
      "backward_entropy": 0.008175045251846313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012067180126905441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02738708257675171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12111710011959076,
      "backward_entropy": 0.00972054898738861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010631846264004707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027388548478484154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12104684859514236,
      "backward_entropy": 0.008149848452636175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013652092777192593,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02738998271524906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12097832560539246,
      "backward_entropy": 0.009707470025335039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013505984097719193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02739141322672367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12091001868247986,
      "backward_entropy": 0.008124909230640956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01399521715939045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027392912656068802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12084206938743591,
      "backward_entropy": 0.008112140532050813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01295366883277893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027394436299800873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12077390402555466,
      "backward_entropy": 0.00968690003667559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010352419689297676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027396032586693764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12070602923631668,
      "backward_entropy": 0.009679271706512995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01008641067892313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027397513389587402,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12063895165920258,
      "backward_entropy": 0.008073472550937108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01141683105379343,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02739892341196537,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12057274580001831,
      "backward_entropy": 0.010286810142653329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010018721222877502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02740028314292431,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12050659954547882,
      "backward_entropy": 0.00804959556886128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008689027279615402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027401704341173172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12044137716293335,
      "backward_entropy": 0.008037534143243517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008611570112407207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02740294858813286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12037695944309235,
      "backward_entropy": 0.00964647957256862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008014378137886524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02740412950515747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12031339854001999,
      "backward_entropy": 0.008015855082443782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008074949495494366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027405261993408203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12025099992752075,
      "backward_entropy": 0.008005571684667043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007215579506009817,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02740626409649849,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12018921971321106,
      "backward_entropy": 0.010271210755620683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007937910035252571,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02740713581442833,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12012842297554016,
      "backward_entropy": 0.009627342224121094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007302987854927778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027408016845583916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12006834149360657,
      "backward_entropy": 0.007978338748216629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006952330470085144,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027408720925450325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1200086697936058,
      "backward_entropy": 0.009620361030101776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005591347347944975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02740936540067196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11994978785514832,
      "backward_entropy": 0.007962900613035475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007163723465055227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02740984410047531,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11989203840494156,
      "backward_entropy": 0.010272646588938577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005826891865581274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027410224080085754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11983440816402435,
      "backward_entropy": 0.007950209613357271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006347996648401022,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02741062268614769,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11977794021368027,
      "backward_entropy": 0.009612883840288435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005925942212343216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027411123737692833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11972236633300781,
      "backward_entropy": 0.00793753085391862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005161074455827475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027411723509430885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11966775357723236,
      "backward_entropy": 0.007930523582867213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004288116004317999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02741231769323349,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11961421370506287,
      "backward_entropy": 0.007923617426838194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0051087746396660805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02741282433271408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11956194788217545,
      "backward_entropy": 0.007917250373533793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004445144906640053,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027413344010710716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11951044946908951,
      "backward_entropy": 0.009601677102702004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004437936004251242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027413705363869667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11945955455303192,
      "backward_entropy": 0.007905459829739161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004703755024820566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027414025738835335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11940941214561462,
      "backward_entropy": 0.007900248680795943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004047398921102285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027414394542574883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11935992538928986,
      "backward_entropy": 0.007894850202969142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004202750977128744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027414778247475624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11931140720844269,
      "backward_entropy": 0.007889451725142342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038000394124537706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02741513028740883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192634254693985,
      "backward_entropy": 0.007884272507258825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004061826504766941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02741546928882599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11921624094247818,
      "backward_entropy": 0.007879193872213364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038512079045176506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027415823191404343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11916958540678024,
      "backward_entropy": 0.007874130138329096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038220335263758898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0274161659181118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11912345886230469,
      "backward_entropy": 0.00786916006888662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032446477562189102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027416566386818886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11907796561717987,
      "backward_entropy": 0.007863941469362803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003518162528052926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027417017146945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11903351545333862,
      "backward_entropy": 0.009587704070976802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031120770145207644,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027417464181780815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.118989497423172,
      "backward_entropy": 0.00958572221653802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026163049042224884,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027417924255132675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11894629895687103,
      "backward_entropy": 0.00784781202673912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002350409049540758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02741835080087185,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11890414357185364,
      "backward_entropy": 0.007842671658311571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024765438865870237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02741875872015953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11886316537857056,
      "backward_entropy": 0.007837720215320587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025867801159620285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027419177815318108,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11882316321134567,
      "backward_entropy": 0.01029620532478605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025109881535172462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027419589459896088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11878382414579391,
      "backward_entropy": 0.00782791046159608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002176205161958933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02741997130215168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11874501407146454,
      "backward_entropy": 0.00782323522227151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024037454277276993,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027420323342084885,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11870694905519485,
      "backward_entropy": 0.01029724201985768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019370290683582425,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027420705184340477,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11866942048072815,
      "backward_entropy": 0.009572057851723261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016551073640584946,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02742106281220913,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11863270401954651,
      "backward_entropy": 0.010297804006508418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015241150977090001,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027421394363045692,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11859706044197083,
      "backward_entropy": 0.009569303265639715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001713730744086206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02742167003452778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11856237053871155,
      "backward_entropy": 0.0078019483813217706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016341630835086107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027421968057751656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11852855980396271,
      "backward_entropy": 0.009567296930721827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016715985257178545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02742225117981434,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11849546432495117,
      "backward_entropy": 0.010299465485981532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001867095474153757,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027422547340393066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11846302449703217,
      "backward_entropy": 0.009565246956689017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001526002655737102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027422882616519928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.118430957198143,
      "backward_entropy": 0.007786687995706286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014472382608801126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0274231918156147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11839940398931503,
      "backward_entropy": 0.007782946207693645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015188280958682299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027423495426774025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1183684766292572,
      "backward_entropy": 0.0077792565737451825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012537779984995723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027423763647675514,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11833779513835907,
      "backward_entropy": 0.010300261633736747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015133279375731945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02742403745651245,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11830787360668182,
      "backward_entropy": 0.010300521339688982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013003433123230934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027424348518252373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11827829480171204,
      "backward_entropy": 0.007768754980393818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011346139945089817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027424676343798637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11824931204319,
      "backward_entropy": 0.007765112178666251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011247512884438038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027424998581409454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1182209923863411,
      "backward_entropy": 0.007761526852846146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012827692553400993,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0274252500385046,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11819301545619965,
      "backward_entropy": 0.01030042554650988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001116836559958756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027425521984696388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11816530674695969,
      "backward_entropy": 0.007755063474178314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010735797695815563,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02742576412856579,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11813794076442719,
      "backward_entropy": 0.010300953473363603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007359127048403025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02742602303624153,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11811110377311707,
      "backward_entropy": 0.010301159960883004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008719860343262553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027426233515143394,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11808502674102783,
      "backward_entropy": 0.010301604866981506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008808442507870495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027426449581980705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11805960536003113,
      "backward_entropy": 0.007743165429149356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008058535750024021,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027426663786172867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11803467571735382,
      "backward_entropy": 0.007740376783268792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000840138818603009,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027426855638623238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11801022291183472,
      "backward_entropy": 0.007737720119101661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008245523204095662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027427084743976593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11798632144927979,
      "backward_entropy": 0.007734958614621844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008096031378954649,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027427343651652336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11796287447214127,
      "backward_entropy": 0.0077320534203733715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006559600005857646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027427611872553825,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1179397851228714,
      "backward_entropy": 0.00954426292862211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006094329874031246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02742784284055233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11791715025901794,
      "backward_entropy": 0.007726449519395828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007081257062964141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027428044006228447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11789502203464508,
      "backward_entropy": 0.007723933351891381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006928581860847771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027428271248936653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11787330359220505,
      "backward_entropy": 0.0077213166015488765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005891789915040135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027428507804870605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11785190552473068,
      "backward_entropy": 0.00771866153393473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005496109952218831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02742874063551426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783093959093094,
      "backward_entropy": 0.007716075650283268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006464643520303071,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02742898464202881,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781051754951477,
      "backward_entropy": 0.007713454110281808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006041364395059645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02742927148938179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11779040098190308,
      "backward_entropy": 0.0077106644000325885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005517073441296816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02742958813905716,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11777063459157944,
      "backward_entropy": 0.010301230209214347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004330411902628839,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02742992341518402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11775124073028564,
      "backward_entropy": 0.009533504290240151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004018113831989467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027430249378085136,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11773239076137543,
      "backward_entropy": 0.010299410138811384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047805573558434844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027430517598986626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11771386861801147,
      "backward_entropy": 0.007699243192161832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039595493581146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743079513311386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11769565939903259,
      "backward_entropy": 0.0076966142015797755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034906022483482957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027431054040789604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11767783761024475,
      "backward_entropy": 0.007694124111107418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003696819767355919,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027431311085820198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11766057461500168,
      "backward_entropy": 0.007691658501114164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004132283211220056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027431538328528404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1176435798406601,
      "backward_entropy": 0.007689385541847774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036096578696742654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027431782335042953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11762680858373642,
      "backward_entropy": 0.0076870231756142205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003518529993016273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027432028204202652,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1176103800535202,
      "backward_entropy": 0.009523322539670127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029070861637592316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027432292699813843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11759431660175323,
      "backward_entropy": 0.007682276623589652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003121558402199298,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027432531118392944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11757861077785492,
      "backward_entropy": 0.007680036127567291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003313509514555335,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027432778850197792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11756326258182526,
      "backward_entropy": 0.00951964727469853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023139863333199173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027433034032583237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11754812300205231,
      "backward_entropy": 0.007675450827394213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002934547665063292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027433285489678383,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11753344535827637,
      "backward_entropy": 0.009517153458935874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000215598163777031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027433551847934723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11751905083656311,
      "backward_entropy": 0.007670920874391284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002385015250183642,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027433808892965317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11750508099794388,
      "backward_entropy": 0.009514602167265756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022785684268455952,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743406407535076,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11749140173196793,
      "backward_entropy": 0.007666502680097308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021482733427546918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743430808186531,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11747795343399048,
      "backward_entropy": 0.007664387779576438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001870582636911422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743455581367016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1174648255109787,
      "backward_entropy": 0.007662262235369001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020535876683425158,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743479050695896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11745204031467438,
      "backward_entropy": 0.007660234613077981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019351094670128077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027435019612312317,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11743947863578796,
      "backward_entropy": 0.0076582639345100945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019987438281532377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743522822856903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11742708086967468,
      "backward_entropy": 0.007656385856015342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001242551952600479,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743544615805149,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11741490662097931,
      "backward_entropy": 0.007654473717723574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017087702872231603,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02743563801050186,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11740314215421677,
      "backward_entropy": 0.010285539286477225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013970139843877405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027435829862952232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11739157140254974,
      "backward_entropy": 0.007650987378188542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016290979692712426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027436021715402603,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11738033592700958,
      "backward_entropy": 0.009503903133528573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013497690088115633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02743622101843357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11736926436424255,
      "backward_entropy": 0.00950294520173754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013232653145678341,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027436399832367897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11735837161540985,
      "backward_entropy": 0.010283323270933968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012585733202286065,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027436580508947372,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11734773218631744,
      "backward_entropy": 0.010282793215342931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012598891044035554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027436740696430206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11733727157115936,
      "backward_entropy": 0.007642817284379687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001104618058889173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743690088391304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11732698976993561,
      "backward_entropy": 0.007641333554472242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010369395022280514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027437053620815277,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11731694638729095,
      "backward_entropy": 0.007639921137264797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011552233627298847,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743719518184662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11730712652206421,
      "backward_entropy": 0.007638552359172276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.971775580197573e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027437329292297363,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11729742586612701,
      "backward_entropy": 0.010281096611704146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730305853532627e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027437463402748108,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11728794872760773,
      "backward_entropy": 0.010280818811484746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.595564238727093e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027437591925263405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11727871000766754,
      "backward_entropy": 0.007634671671049935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.369536226382479e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027437711134552956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11726974695920944,
      "backward_entropy": 0.007633475320679801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.320666190935299e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027437835931777954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11726099252700806,
      "backward_entropy": 0.007632261940411159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.177380757639185e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027437960729002953,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11725249886512756,
      "backward_entropy": 0.010279792760099684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.567116699647158e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027438072487711906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1172441840171814,
      "backward_entropy": 0.009494115199361528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.063742668833584e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02743818610906601,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11723603308200836,
      "backward_entropy": 0.010279323373522078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.267361459322274e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027438296005129814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11722800880670547,
      "backward_entropy": 0.0076277899955000195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8565947256283835e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02743840031325817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11722017824649811,
      "backward_entropy": 0.00949260698897498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.739958942285739e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027438506484031677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11721254885196686,
      "backward_entropy": 0.007625705429485866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7394176363013685e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02743859961628914,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11720505356788635,
      "backward_entropy": 0.009491684181349618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.054172263247892e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027438681572675705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11719776690006256,
      "backward_entropy": 0.007623863539525441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.196766505832784e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027438754215836525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11719056963920593,
      "backward_entropy": 0.007623032799788884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.72306419396773e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027438828721642494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11718349903821945,
      "backward_entropy": 0.009490654936858587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6437737182714045e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027438899502158165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1171766072511673,
      "backward_entropy": 0.007621381431818008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.401870319270529e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027438968420028687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11716984212398529,
      "backward_entropy": 0.007620590605906078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.468829865800217e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743903547525406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11716325581073761,
      "backward_entropy": 0.007619822131735938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.948943049181253e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743910439312458,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11715677380561829,
      "backward_entropy": 0.007619044610432216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.474379991530441e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027439171448349953,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1171504408121109,
      "backward_entropy": 0.010278305837086268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.370411286596209e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027439245954155922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11714431643486023,
      "backward_entropy": 0.0076175257563591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.078653026022948e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02743932418525219,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11713837832212448,
      "backward_entropy": 0.010278078062193734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.523172563291155e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027439391240477562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11713254451751709,
      "backward_entropy": 0.007616004241364343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.212189403711818e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027439462020993233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11712683737277985,
      "backward_entropy": 0.007615276745387486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5555315005476587e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027439532801508904,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11712121963500977,
      "backward_entropy": 0.010277813034398215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6027593776234426e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027439597994089127,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11711576581001282,
      "backward_entropy": 0.009487039276531764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.440900425426662e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0274396613240242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11711042374372482,
      "backward_entropy": 0.007613195372479302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2445901777246036e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027439717203378677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11710521578788757,
      "backward_entropy": 0.009486466646194458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2780395738664083e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027439771220088005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11710014939308167,
      "backward_entropy": 0.007611967623233795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0371568098198622e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027439825236797333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11709518730640411,
      "backward_entropy": 0.007611383284841265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1525334886973724e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02743988297879696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1170903891324997,
      "backward_entropy": 0.007610766483204705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7981445125769824e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027439936995506287,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11708568036556244,
      "backward_entropy": 0.007610194385051727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.937010711117182e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027439989149570465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11708108335733414,
      "backward_entropy": 0.007609626544373376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7626569388085045e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027440043166279793,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11707660555839539,
      "backward_entropy": 0.009484933955328805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.611055267858319e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440093457698822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1170722246170044,
      "backward_entropy": 0.00760851481131145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.52595584950177e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440140023827553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11706794798374176,
      "backward_entropy": 0.0076079874166420525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3008806490688585e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027440186589956284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11706378310918808,
      "backward_entropy": 0.009484249566282545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2296362911001779e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440229430794716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11705972999334335,
      "backward_entropy": 0.007607015648058483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4041552276466973e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440272271633148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11705581098794937,
      "backward_entropy": 0.007606542004006249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0529241990298033e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744031511247158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11705197393894196,
      "backward_entropy": 0.009483653519834791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0685181223379914e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027440350502729416,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1170482337474823,
      "backward_entropy": 0.010277128645351954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1125869605166372e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744038589298725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11704462021589279,
      "backward_entropy": 0.009483317179339272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.834468983171973e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027440425008535385,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11704107373952866,
      "backward_entropy": 0.010277110551084791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.58103464654414e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744046226143837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11703763902187347,
      "backward_entropy": 0.009482957422733307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.473103662254289e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440499514341354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11703427135944366,
      "backward_entropy": 0.007603983261755535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26385075924918e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744053117930889,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11703099310398102,
      "backward_entropy": 0.009482658335140772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.775798621878494e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744055911898613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11702780425548553,
      "backward_entropy": 0.007603272795677185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.858022516098572e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027440587058663368,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11702470481395721,
      "backward_entropy": 0.009482416723455702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.156587344070431e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027440613135695457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11702170222997665,
      "backward_entropy": 0.009482290063585554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.302665951807285e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027440637350082397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11701876670122147,
      "backward_entropy": 0.009482195334775107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.764252819062676e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027440661564469337,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11701592803001404,
      "backward_entropy": 0.009482083576066154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.957009761914378e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744068205356598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11701315641403198,
      "backward_entropy": 0.007601665599005563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9964081629004795e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027440708130598068,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11701047420501709,
      "backward_entropy": 0.01027715312583106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6214627218432724e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440736070275307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11700787395238876,
      "backward_entropy": 0.007601052522659302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.811905793962069e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440765872597694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11700534075498581,
      "backward_entropy": 0.007600734276430947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.210113729641307e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440793812274933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11700284481048584,
      "backward_entropy": 0.007600425077336175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.148679181525949e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744082547724247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11700046062469482,
      "backward_entropy": 0.007600115346057075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3479230953380466e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440855279564857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11699812859296799,
      "backward_entropy": 0.007599806146962302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6737822028953815e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440883219242096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11699584126472473,
      "backward_entropy": 0.007599532072033201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9651708902965765e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027440911158919334,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11699363589286804,
      "backward_entropy": 0.010276841265814645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9126293813751545e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027440940961241722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11699149012565613,
      "backward_entropy": 0.007598950394562313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8047734303981997e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744097076356411,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1169893741607666,
      "backward_entropy": 0.009480688188757216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3416672522434965e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0274409968405962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11698734015226364,
      "backward_entropy": 0.00759839585849217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.609872808534419e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744102105498314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11698535084724426,
      "backward_entropy": 0.007598149457148143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6034099391836207e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744104526937008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11698341369628906,
      "backward_entropy": 0.009480336947100503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4774517441983335e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744106948375702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11698155105113983,
      "backward_entropy": 0.007597641221114567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3933234842843376e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744109183549881,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11697971820831299,
      "backward_entropy": 0.007597410253116063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3408256311086006e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441110461950302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11697794497013092,
      "backward_entropy": 0.0075972165380205426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1874554931855528e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441127225756645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11697620153427124,
      "backward_entropy": 0.009479965482439314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9358233203092823e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744114398956299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11697453260421753,
      "backward_entropy": 0.007596824850354876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9094443359790603e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744116075336933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11697287857532501,
      "backward_entropy": 0.007596621555941445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6986692799036973e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441173791885376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11697129160165787,
      "backward_entropy": 0.00759645232132503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8680707398743834e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744118496775627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11696973443031311,
      "backward_entropy": 0.009479723870754242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5923194496281212e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441198006272316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11696820706129074,
      "backward_entropy": 0.007596127156700406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.434680257261789e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744120918214321,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11696672439575195,
      "backward_entropy": 0.007595970162323543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1796122407758958e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441218495368958,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11696527898311615,
      "backward_entropy": 0.0102765325989042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3253235238153138e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441225945949554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11696390807628632,
      "backward_entropy": 0.007595689701182502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2448325605873833e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744123339653015,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11696253716945648,
      "backward_entropy": 0.009479523769446782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1963245469814865e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0274412389844656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11696122586727142,
      "backward_entropy": 0.009479506739548274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0779903050206485e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441244572401047,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11695994436740875,
      "backward_entropy": 0.010276699704783303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0956811138385092e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441250160336494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11695869266986847,
      "backward_entropy": 0.007595235747950417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.349901688437967e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441255748271942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11695747077465057,
      "backward_entropy": 0.007595132504190717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722649340597854e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744126133620739,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11695630103349686,
      "backward_entropy": 0.01027682636465345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.335597160817997e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441266924142838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11695515364408493,
      "backward_entropy": 0.00759491537298475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.64112655815552e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441274374723434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11695405840873718,
      "backward_entropy": 0.007594814790146691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.081738774810219e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441279962658882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11695297807455063,
      "backward_entropy": 0.007594717932598931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.310856406344101e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744128555059433,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11695194989442825,
      "backward_entropy": 0.010276947702680315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.457059384956665e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441291138529778,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11695094406604767,
      "backward_entropy": 0.009479315153190069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.391973445512122e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441296726465225,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11694998294115067,
      "backward_entropy": 0.010276983891214644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.698473160009598e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441300451755524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694904416799545,
      "backward_entropy": 0.007594346467937742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756838052344392e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744130603969097,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11694813519716263,
      "backward_entropy": 0.00947928215776171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.444020416689455e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744130976498127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694726347923279,
      "backward_entropy": 0.007594186280454908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.909945801045978e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744131349027157,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11694639921188354,
      "backward_entropy": 0.01027709458555494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.284960368750035e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441319078207016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694556474685669,
      "backward_entropy": 0.007594027689525059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.760023841754446e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441322803497314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11694474518299103,
      "backward_entropy": 0.009479231068066188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.950560483190202e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441324666142464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694395542144775,
      "backward_entropy": 0.007593889853784016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6437666040001204e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441326528787613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11694318056106567,
      "backward_entropy": 0.009479215102536338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6150348137198307e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744133025407791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694243550300598,
      "backward_entropy": 0.007593751485858645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.38614603631504e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744133397936821,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694170534610748,
      "backward_entropy": 0.0075936998639787945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.632330620144785e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744133770465851,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11694101989269257,
      "backward_entropy": 0.009479169334684099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9708331794608966e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441339567303658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11694034188985825,
      "backward_entropy": 0.007593571075371334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.379796910645382e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441341429948807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11693967878818512,
      "backward_entropy": 0.009479158690997533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2133934862722526e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441345155239105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11693904548883438,
      "backward_entropy": 0.009479150176048279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0228300456892612e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441347017884254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693844199180603,
      "backward_entropy": 0.007593405033860888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2395667542696174e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441348880529404,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11693784594535828,
      "backward_entropy": 0.010277390480041504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9603650969202135e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441350743174553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693726480007172,
      "backward_entropy": 0.007593313498156411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8813501867498417e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441352605819702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693671345710754,
      "backward_entropy": 0.007593268262488502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4283938298831345e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744135446846485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693617701530457,
      "backward_entropy": 0.007593209722212383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6533400071239157e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744135633111,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11693564057350159,
      "backward_entropy": 0.010277461792741503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5781040474394104e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0274413600564003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693514883518219,
      "backward_entropy": 0.007593122976166862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.203518422698835e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441363781690598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693467199802399,
      "backward_entropy": 0.00759308146578925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1284402745559419e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441365644335747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693419516086578,
      "backward_entropy": 0.007593031972646713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1157063539712908e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441367506980896,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11693373322486877,
      "backward_entropy": 0.010277515011174338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.42112440926212e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441369369626045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693330109119415,
      "backward_entropy": 0.007592951612813132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0300659170070503e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441371232271194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693286895751953,
      "backward_entropy": 0.007592921810490745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.012754964335727e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441373094916344,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1169324517250061,
      "backward_entropy": 0.010277554392814636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.975811821050229e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441374957561493,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11693204194307327,
      "backward_entropy": 0.010277577808925084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870743783973012e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441376820206642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693164706230164,
      "backward_entropy": 0.007592810051781791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.89112561960792e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744137868285179,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11693126708269119,
      "backward_entropy": 0.009479062897818429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788071343384217e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744138054549694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11693089455366135,
      "backward_entropy": 0.0075927674770355225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.685107933890322e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744138240814209,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11693054437637329,
      "backward_entropy": 0.00947905651160649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3932083687868726e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744138427078724,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11693020164966583,
      "backward_entropy": 0.00947905651160649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4163706408871803e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744138613343239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692987382411957,
      "backward_entropy": 0.007592663701091494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.457087664557548e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441387996077538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169295608997345,
      "backward_entropy": 0.00759264241371836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4476913646794856e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441389858722687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692926287651062,
      "backward_entropy": 0.007592618997607913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9354039905201716e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441391721367836,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692894995212555,
      "backward_entropy": 0.01027768531015941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.059894192527281e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441393584012985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692865937948227,
      "backward_entropy": 0.007592568440096719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4591331516130595e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441395446658134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692838370800018,
      "backward_entropy": 0.007592542895248958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3538753996253945e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441397309303284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169281154870987,
      "backward_entropy": 0.007592525865350451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.21784278614723e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441399171948433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169278472661972,
      "backward_entropy": 0.0075924912733691076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.130450565436149e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441399171948433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692758649587631,
      "backward_entropy": 0.009479011808122908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.024648975724631e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441401034593582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692733317613602,
      "backward_entropy": 0.00759245827794075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9210386998101967e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744140289723873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692710220813751,
      "backward_entropy": 0.007592425282512393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8050067157892045e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744140475988388,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1169268786907196,
      "backward_entropy": 0.010277761944702693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.371724233147688e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744140662252903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169266551733017,
      "backward_entropy": 0.007592390158346721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.842715041140309e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744140848517418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692646145820618,
      "backward_entropy": 0.009478992649487086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6807795094896392e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744141034781933,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692623794078827,
      "backward_entropy": 0.010277793875762395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5788949642446823e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441412210464478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692602932453156,
      "backward_entropy": 0.007592326828411647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5328503738819563e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441414073109627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692583560943604,
      "backward_entropy": 0.00759230979851314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0116061705266475e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441415935754776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692564189434052,
      "backward_entropy": 0.007592295961720603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0569672187775723e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441417798399925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692546308040619,
      "backward_entropy": 0.009478962847164698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8967796222568722e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441417798399925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692528426647186,
      "backward_entropy": 0.00947895965405873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7257418605254315e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441417798399925,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692509055137634,
      "backward_entropy": 0.010277824742453439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9491229963364276e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441419661045074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169249415397644,
      "backward_entropy": 0.007592235292707171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4174190710036783e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441419661045074,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692476272583008,
      "backward_entropy": 0.010277836450508662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3242342333796842e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027441421523690224,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692461371421814,
      "backward_entropy": 0.010277858802250453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.072105959565306e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441421523690224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692444980144501,
      "backward_entropy": 0.007592181542090007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2772943591699004e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027441421523690224,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692430078983307,
      "backward_entropy": 0.00947893304484231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.749179076199653e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441423386335373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692415177822113,
      "backward_entropy": 0.00759216131908553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.53392742530923e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441425248980522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692402511835098,
      "backward_entropy": 0.0075921496110303065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.011351499386365e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692388355731964,
      "backward_entropy": 0.009478922401155745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.923628058710165e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692376434803009,
      "backward_entropy": 0.010277874767780304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.297291742564994e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692363768815994,
      "backward_entropy": 0.007592105439731053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.747303243377246e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692352592945099,
      "backward_entropy": 0.007592094796044486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.938638191262726e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692341417074203,
      "backward_entropy": 0.009478911757469177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3562631541790324e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692330241203308,
      "backward_entropy": 0.007592076701777322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.228994209322991e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692319810390472,
      "backward_entropy": 0.007592067122459412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9358100656936585e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692309379577637,
      "backward_entropy": 0.007592059671878815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.565510718952282e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692298948764801,
      "backward_entropy": 0.009478884083884103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.562966975958261e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692290008068085,
      "backward_entropy": 0.007592029869556427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6858730229359935e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692279577255249,
      "backward_entropy": 0.00759202241897583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.466414793569129e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692271381616592,
      "backward_entropy": 0.009478878762040819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.901142520135181e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692261695861816,
      "backward_entropy": 0.00759201283965792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.766217560041696e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169225350022316,
      "backward_entropy": 0.007592003260340009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.228795091876236e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692245304584503,
      "backward_entropy": 0.007591999002865383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5990908031635627e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692237854003906,
      "backward_entropy": 0.009478874504566193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.986258434451884e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1169223040342331,
      "backward_entropy": 0.010277938629899706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.795559339574538e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692221462726593,
      "backward_entropy": 0.0075919851660728455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0006680756523565e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692214757204056,
      "backward_entropy": 0.007591979844229562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.960106826321862e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692208051681519,
      "backward_entropy": 0.007591959621225085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7977264949186065e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692200601100922,
      "backward_entropy": 0.010277954595429557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7584974304772913e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692194640636444,
      "backward_entropy": 0.007591959621225085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0013430912513286e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692188680171967,
      "backward_entropy": 0.007591949509722846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4162537809170317e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169218197464943,
      "backward_entropy": 0.007591947380985532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7972325849768822e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692176014184952,
      "backward_entropy": 0.007591945252248219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6622010434730328e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692169308662415,
      "backward_entropy": 0.009478860667773656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.830947837788699e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692164838314056,
      "backward_entropy": 0.009478863860879625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6798296087472409e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692159622907639,
      "backward_entropy": 0.007591933544192996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2612346722562506e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692154407501221,
      "backward_entropy": 0.00759193194764001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1223448836972238e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692150682210922,
      "backward_entropy": 0.010278000363281794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2071055266460462e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11692143976688385,
      "backward_entropy": 0.010278000363281794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0701342034735717e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692140251398087,
      "backward_entropy": 0.007591921836137772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142890806084324e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692135781049728,
      "backward_entropy": 0.0075919197074004584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.982983328882256e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169213205575943,
      "backward_entropy": 0.0075919170464788166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.024390124068304e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692127585411072,
      "backward_entropy": 0.007591912789004189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.173390935757197e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692124605178833,
      "backward_entropy": 0.007591912789004189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.49606590741314e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692120879888535,
      "backward_entropy": 0.0075919101280825475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.861018502808292e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692117154598236,
      "backward_entropy": 0.007591907999345234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.104485805735749e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692114174365997,
      "backward_entropy": 0.007591902677501951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.939018248885986e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11692111194133759,
      "backward_entropy": 0.007591900548764637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.811671144329011e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169210821390152,
      "backward_entropy": 0.007591882986681802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.98355143210938e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744142711162567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11692103743553162,
      "backward_entropy": 0.009478846830981118,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.170340520445961e-08,
    "avg_log_Z": 0.02744139954447746,
    "success_rate": 1.0,
    "avg_reward": 49.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.17,
      "1": 0.21,
      "2": 0.62
    },
    "avg_forward_entropy": 0.11692786775529385,
    "avg_backward_entropy": 0.00844511090112584,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}