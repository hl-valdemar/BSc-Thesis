{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06300981478257613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.0630116191777316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.113402366638184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09148941437403361,
      "backward_entropy": 0.06301225857301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.111762046813965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914863149325053,
      "backward_entropy": 0.06301106106151234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21778678894043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00019999980577267706,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09148312608400981,
      "backward_entropy": 0.06300805915485728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.692583084106445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00030002748826518655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147975842158,
      "backward_entropy": 0.06300703503868797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.906549453735352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00040016372804529965,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09147630135218303,
      "backward_entropy": 0.06300594589926979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55917739868164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005004252307116985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914724866549174,
      "backward_entropy": 0.06300806999206543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.010735511779785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006006773910485208,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146855274836223,
      "backward_entropy": 0.06300907785242255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.975739002227783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007010518456809223,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09146448969841003,
      "backward_entropy": 0.06300837343389337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.897895812988281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008012044709175825,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09146083394686381,
      "backward_entropy": 0.06300079280679877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.443541526794434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000901469902601093,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145691990852356,
      "backward_entropy": 0.0630066611550071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.550647735595703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010016710730269551,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145283699035645,
      "backward_entropy": 0.06300275434147228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.657957077026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011018650839105248,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144871433575948,
      "backward_entropy": 0.06300461292266846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547234535217285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012020966969430447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914444625377655,
      "backward_entropy": 0.06300006129524925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.630094528198242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001302312477491796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143998225529988,
      "backward_entropy": 0.06299196048216386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.335456848144531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014021964743733406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143638610839844,
      "backward_entropy": 0.0629897876219316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.310892105102539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015024099266156554,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143233299255371,
      "backward_entropy": 0.06299533627249977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.662290573120117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016025360673666,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142841895421346,
      "backward_entropy": 0.06298509511080655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.328071594238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017026900313794613,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09142409761746724,
      "backward_entropy": 0.06299638206308539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.226987838745117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018031341023743153,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.091419517993927,
      "backward_entropy": 0.06299472938884389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.857797622680664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019037489546462893,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141446153322856,
      "backward_entropy": 0.06298755515705455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.100974082946777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002004016889259219,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140978256861369,
      "backward_entropy": 0.06297407367012718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.532008171081543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002104457700625062,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0914047360420227,
      "backward_entropy": 0.06298918615687978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.639983177185059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002204836579039693,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913996696472168,
      "backward_entropy": 0.06298045136711815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.865458488464355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002305214060470462,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913946529229482,
      "backward_entropy": 0.06297780166972768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.073431015014648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024056690745055676,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913894275824229,
      "backward_entropy": 0.0629827922040766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.970878601074219,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0025058912578970194,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138471881548564,
      "backward_entropy": 0.06297199834476817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.413381576538086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026062666438519955,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137983123461406,
      "backward_entropy": 0.06296883929859508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.961184501647949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027065263129770756,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137485424677531,
      "backward_entropy": 0.06296550685709174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.739583969116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002806515898555517,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09137036403020223,
      "backward_entropy": 0.0629721771587025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.174622535705566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002906609559431672,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136594335238139,
      "backward_entropy": 0.06295817006718028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.287897109985352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003006596816703677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136269489924113,
      "backward_entropy": 0.06295412236993964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.843322277069092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003106518881395459,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09136007229487102,
      "backward_entropy": 0.06296238032254306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399316787719727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003206179942935705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135826428731282,
      "backward_entropy": 0.06292356144298207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.735856056213379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0033058468252420425,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09135655562082927,
      "backward_entropy": 0.0629548267884688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.177961349487305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0034056352451443672,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09135412176450093,
      "backward_entropy": 0.06291172721169212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.06762409210205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035052946768701077,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09135168790817261,
      "backward_entropy": 0.06294665011492642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.175393104553223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003604781348258257,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134918451309204,
      "backward_entropy": 0.06289867379448631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72878360748291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003704177215695381,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913467009862264,
      "backward_entropy": 0.06292059204795143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.835714340209961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038037344347685575,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134360154469807,
      "backward_entropy": 0.06291507049040361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.942462921142578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0039034944493323565,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09133998552958171,
      "backward_entropy": 0.06287669051777232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.718210220336914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004003493115305901,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133599201838176,
      "backward_entropy": 0.06290338256142357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.937849998474121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004103610757738352,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133212765057881,
      "backward_entropy": 0.06289712949232622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.374126434326172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004203923046588898,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132790565490723,
      "backward_entropy": 0.06289061633023349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.494686126708984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004304617643356323,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09132322669029236,
      "backward_entropy": 0.0628838214007291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.584809303283691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0044052195735275745,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131842851638794,
      "backward_entropy": 0.0628997954455289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.613051414489746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004506289027631283,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09131341179211934,
      "backward_entropy": 0.06289360198107632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.048563003540039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00460681039839983,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130932887395223,
      "backward_entropy": 0.06281550364060835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.810799598693848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0047070663422346115,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09130585193634033,
      "backward_entropy": 0.06288023428483443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700349807739258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0048074619844555855,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09130239486694336,
      "backward_entropy": 0.06279463117772882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.586416244506836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004907917231321335,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.091298907995224,
      "backward_entropy": 0.06283597512678667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.480327606201172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005008392967283726,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129581848780315,
      "backward_entropy": 0.0627719597382979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259263038635254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005108789540827274,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129251043001811,
      "backward_entropy": 0.06275998462330211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.123677253723145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005209020338952541,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09128940105438232,
      "backward_entropy": 0.06280683929269965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.008955955505371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0053095463663339615,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912859837214152,
      "backward_entropy": 0.06273469057950107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.573540687561035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005410300102084875,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09128270546595256,
      "backward_entropy": 0.0628244009884921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.245796203613281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005511031951755285,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127992391586304,
      "backward_entropy": 0.06281522187319669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.812387943267822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005611582193523645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912778377532959,
      "backward_entropy": 0.06269352002577348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.458595275878906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0057117450051009655,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127668539683025,
      "backward_entropy": 0.06274973262440074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.857234954833984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0058118849992752075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0912756621837616,
      "backward_entropy": 0.06273692304437811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.205353736877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005912703927606344,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127356608708699,
      "backward_entropy": 0.06277482076124712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.563085556030273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00601380318403244,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127114216486613,
      "backward_entropy": 0.06270995465191928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.778535842895508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006114797201007605,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126847982406616,
      "backward_entropy": 0.06269585002552379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.088601112365723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006215793080627918,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126520156860352,
      "backward_entropy": 0.06268140944567593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.326615333557129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006316978484392166,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0912615954875946,
      "backward_entropy": 0.06258208101445978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.001460075378418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0064179725013673306,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125882387161255,
      "backward_entropy": 0.06256415085359053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.616071701049805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006518631242215633,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125714500745137,
      "backward_entropy": 0.06254572759975087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.187540054321289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006619769148528576,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125423431396484,
      "backward_entropy": 0.06261826103383844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86300277709961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0067211054265499115,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125048915545146,
      "backward_entropy": 0.06250688162716952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.07699966430664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0068224528804421425,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09124630689620972,
      "backward_entropy": 0.06248652935028076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.985652446746826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006923906039446592,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09124132990837097,
      "backward_entropy": 0.06246572191065008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.620699882507324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007024953607469797,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09123769402503967,
      "backward_entropy": 0.062444535168734466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.833718299865723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007125964388251305,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123453497886658,
      "backward_entropy": 0.06261972947554155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.874161243438721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007227038964629173,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09123138586680095,
      "backward_entropy": 0.06250918453389948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.360116004943848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007327676750719547,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122919042905171,
      "backward_entropy": 0.06237678636204113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.984176158905029,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007428676821291447,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09122614065806071,
      "backward_entropy": 0.062468225305730644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.715609550476074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007529279682785273,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122371673583984,
      "backward_entropy": 0.062327813018452034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.562434196472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007629918400198221,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09122109413146973,
      "backward_entropy": 0.06253793022849342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.489665031433105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0077310120686888695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121721982955933,
      "backward_entropy": 0.06227559393102473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.655057907104492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007831979542970657,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09121377269426982,
      "backward_entropy": 0.0625020211393183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.796406745910645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007932376116514206,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121143817901611,
      "backward_entropy": 0.062220551750876686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24637222290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00803288258612156,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09120896458625793,
      "backward_entropy": 0.062463912096890534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.220475196838379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008133663795888424,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120500087738037,
      "backward_entropy": 0.06216228008270264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.117304801940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008234708569943905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09119998415311177,
      "backward_entropy": 0.06213159994645552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20919132232666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008335922844707966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09119405349095662,
      "backward_entropy": 0.06210002032193271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.38185977935791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00843734573572874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118741750717163,
      "backward_entropy": 0.0620674653486772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.474678993225098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008539514616131783,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117849667867024,
      "backward_entropy": 0.062198097055608574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.276626586914062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008641389198601246,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09117005268732707,
      "backward_entropy": 0.062169784849340264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776487350463867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00874287448823452,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09116192658742268,
      "backward_entropy": 0.06231120499697598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94187068939209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00884429644793272,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09115362167358398,
      "backward_entropy": 0.06228683211586692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45511245727539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008945804089307785,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09114567438761394,
      "backward_entropy": 0.062079819765957917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.545915603637695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009047075174748898,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113798538843791,
      "backward_entropy": 0.06185360930182717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.680665969848633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009148194454610348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09113051493962605,
      "backward_entropy": 0.061814709143205124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.534921646118164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009249763563275337,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0911216139793396,
      "backward_entropy": 0.062183130871165886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.144563674926758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009351140819489956,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09111308058102925,
      "backward_entropy": 0.061946635896509346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.387162208557129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009452668018639088,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09110400080680847,
      "backward_entropy": 0.06191171299327503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.961809158325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009554948657751083,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09109252691268921,
      "backward_entropy": 0.06187615611336448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30081558227539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009657126851379871,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09108036756515503,
      "backward_entropy": 0.06160364367745139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.484454154968262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009758926928043365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09106938044230144,
      "backward_entropy": 0.061558528379960495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.532354354858398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0098605090752244,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105946620305379,
      "backward_entropy": 0.06151245940815319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.816593170166016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00996293593198061,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09104726711908977,
      "backward_entropy": 0.061464873227206146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.299301147460938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010065184906125069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910348892211914,
      "backward_entropy": 0.0614168643951416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.781227111816406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010167552158236504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09102193514506023,
      "backward_entropy": 0.06136759844693271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.65594482421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010269759222865105,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09100942810376485,
      "backward_entropy": 0.06160276586359197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.459131240844727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010372319258749485,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09099648396174113,
      "backward_entropy": 0.06126538189974698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.449259757995605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010475066490471363,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098305304845174,
      "backward_entropy": 0.061212008649652656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14106559753418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010577973909676075,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09096930424372356,
      "backward_entropy": 0.0614691051569852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.039237022399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010680858977138996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09095606207847595,
      "backward_entropy": 0.06110104105689309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.734874725341797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010783656500279903,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09094279011090596,
      "backward_entropy": 0.06137401407415217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.725325584411621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010886725969612598,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09092818697293599,
      "backward_entropy": 0.061644640835848724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.595977783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010989516973495483,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09091418981552124,
      "backward_entropy": 0.061604001305320046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09312629699707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011093036271631718,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0908977488676707,
      "backward_entropy": 0.060868631709705696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.102601051330566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011196431703865528,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09088152647018433,
      "backward_entropy": 0.061170745979655876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.384016990661621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011299689300358295,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09086500604947408,
      "backward_entropy": 0.061477298086339775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.971990585327148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011402973905205727,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0908477505048116,
      "backward_entropy": 0.06106242266568271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983016490936279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011506079696118832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09083093206087749,
      "backward_entropy": 0.06061546910892834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.373659133911133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011608509346842766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09081655740737915,
      "backward_entropy": 0.06054832718589089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.139820098876953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011710526421666145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0908033053080241,
      "backward_entropy": 0.060480052774602715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.099287033081055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011812579818069935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09078941742579143,
      "backward_entropy": 0.06041006608442827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.976388931274414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01191516313701868,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09077301621437073,
      "backward_entropy": 0.06033794988285412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587132453918457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012018171139061451,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09075478712717693,
      "backward_entropy": 0.06026368791406805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.710201263427734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012121337465941906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073532621065776,
      "backward_entropy": 0.060187561945481735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.620138168334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012225247919559479,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09071309367815654,
      "backward_entropy": 0.061039155179804024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890829086303711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012328681536018848,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09069157640139262,
      "backward_entropy": 0.06098486618562178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.422502517700195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012431835755705833,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09067012866338094,
      "backward_entropy": 0.0604064247824929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.68763542175293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01253505703061819,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09064810474713643,
      "backward_entropy": 0.06032849441875111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.967023849487305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012638481333851814,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09062517682711284,
      "backward_entropy": 0.06081366539001465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.36047649383545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012742209248244762,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09060036142667134,
      "backward_entropy": 0.05969277295199307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.393840789794922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012845932506024837,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0905759831269582,
      "backward_entropy": 0.060079233212904495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142269134521484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012949585914611816,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09055033326148987,
      "backward_entropy": 0.06063135645606301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.253103256225586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013052565045654774,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09052753448486328,
      "backward_entropy": 0.05942046642303467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.226978302001953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013156057335436344,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09050220251083374,
      "backward_entropy": 0.05981007489291104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.768141746520996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013259456492960453,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09047665198644002,
      "backward_entropy": 0.05923018672249534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.568211555480957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013362502679228783,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09045148889223735,
      "backward_entropy": 0.059618911959908226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823607444763184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01346513070166111,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09042732914288838,
      "backward_entropy": 0.06029791723598133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.735414505004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013567526824772358,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.090403417746226,
      "backward_entropy": 0.060226077383214775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.594942092895508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013669111765921116,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09038252631823222,
      "backward_entropy": 0.05931258201599121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.679606437683105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013771001249551773,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0903597076733907,
      "backward_entropy": 0.059205559166994964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12450885772705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013872675597667694,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09033769369125366,
      "backward_entropy": 0.05862719904292713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.397991180419922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013974367640912533,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09031445781389873,
      "backward_entropy": 0.0585199161009355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.062734603881836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014075682498514652,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09029211600621541,
      "backward_entropy": 0.0598406737500971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.223963737487793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01417707372456789,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09026988347371419,
      "backward_entropy": 0.05875208161093972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256529808044434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014278613962233067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09024701515833537,
      "backward_entropy": 0.05818565325303511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.721129417419434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014379731379449368,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09022578597068787,
      "backward_entropy": 0.05850718238136985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.648506164550781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014480170793831348,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09020763635635376,
      "backward_entropy": 0.0595002987168052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.500181198120117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014580542221665382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09018993377685547,
      "backward_entropy": 0.05783070217479359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.516347408294678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014681313186883926,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09016969799995422,
      "backward_entropy": 0.05811988765543157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.1206636428833,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014781310223042965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09015259146690369,
      "backward_entropy": 0.05798611315813931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.334366798400879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014881527982652187,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09013356765111287,
      "backward_entropy": 0.05912934650074352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9543938636779785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01498150173574686,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09011512994766235,
      "backward_entropy": 0.05903158404610374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.63183307647705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01508108526468277,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09009961287180583,
      "backward_entropy": 0.057567379691384056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10289192199707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015180670656263828,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09008351961771648,
      "backward_entropy": 0.05705694718794389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.261268615722656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01528055127710104,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0900661051273346,
      "backward_entropy": 0.057273030281066895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.994272232055664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015380186028778553,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09004909793535869,
      "backward_entropy": 0.05677770484577526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12757396697998,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015480018220841885,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09002949794133504,
      "backward_entropy": 0.056966190988367256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.683403015136719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01558012142777443,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09000789125760396,
      "backward_entropy": 0.05648564750497991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.017806053161621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0156802237033844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08998610575993855,
      "backward_entropy": 0.056334072893316094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.160382270812988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015780476853251457,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08996176719665527,
      "backward_entropy": 0.056477167389609596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.197637557983398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015880392864346504,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08993837237358093,
      "backward_entropy": 0.05630872466347434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890624523162842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015980061143636703,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08991660674413045,
      "backward_entropy": 0.05613655935634266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.152037620544434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01607927680015564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08989575505256653,
      "backward_entropy": 0.0556969859383323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9977240562438965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016178296878933907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08987716833750407,
      "backward_entropy": 0.05552784421227195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.531253814697266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01627701334655285,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0898591677347819,
      "backward_entropy": 0.05560562285509976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.398552417755127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016375776380300522,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08983972668647766,
      "backward_entropy": 0.057409600778059525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.046061992645264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016473909839987755,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08982300758361816,
      "backward_entropy": 0.05727672576904297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.692580223083496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016571292653679848,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08981068929036458,
      "backward_entropy": 0.057141347364945846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.604569435119629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01666896417737007,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08979534109433492,
      "backward_entropy": 0.05485937270251187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.60037899017334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016766300424933434,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08978299299875896,
      "backward_entropy": 0.05466373400254683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.483700752258301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01686331257224083,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08977250258127849,
      "backward_entropy": 0.05427941950884732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.326193809509277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016959983855485916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08976458509763081,
      "backward_entropy": 0.054091589017347855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.970944404602051,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017056839540600777,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08975499868392944,
      "backward_entropy": 0.05405327406796542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.569455146789551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017153669148683548,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08974578976631165,
      "backward_entropy": 0.053839889439669525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.216525077819824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017250224947929382,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08973805109659831,
      "backward_entropy": 0.053503973917527634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.347429275512695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017346344888210297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08973348140716553,
      "backward_entropy": 0.05330157279968262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6218767166137695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01744326949119568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08972023924191792,
      "backward_entropy": 0.05309184031053023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9828948974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017539963126182556,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08970857659975688,
      "backward_entropy": 0.055650413036346436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.913100242614746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017636658623814583,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0896964172522227,
      "backward_entropy": 0.05266180363568393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33610725402832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017733288928866386,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08968307574590047,
      "backward_entropy": 0.05247680707411333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8838324546813965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01783011481165886,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08966665466626485,
      "backward_entropy": 0.052234346216375176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.716413497924805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017926879227161407,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08965012431144714,
      "backward_entropy": 0.05198445103385232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.940990924835205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018024060875177383,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0896288553873698,
      "backward_entropy": 0.05478381568735296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.986355781555176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01812119595706463,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08960773547490437,
      "backward_entropy": 0.051478884436867454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.273684978485107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01821768842637539,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08959018190701802,
      "backward_entropy": 0.05441450530832464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.059403419494629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01831376738846302,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08957397937774658,
      "backward_entropy": 0.050961738282983955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.073455333709717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01840994693338871,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08955492575963338,
      "backward_entropy": 0.05069875717163086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8273701667785645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01850566454231739,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08953896164894104,
      "backward_entropy": 0.05043159831653942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.984234809875488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018601393327116966,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08952103058497111,
      "backward_entropy": 0.050275748426263984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.984220027923584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018696628510951996,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08950559298197429,
      "backward_entropy": 0.050021144476803864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.514882564544678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018792057409882545,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08948846658070882,
      "backward_entropy": 0.049760948527943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.134930610656738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01888737641274929,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08947116136550903,
      "backward_entropy": 0.0493257533420216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.887763023376465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01898232288658619,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08945441246032715,
      "backward_entropy": 0.04922954060814597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.409614562988281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019077399745583534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08943391839663188,
      "backward_entropy": 0.048957141962918366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.924617290496826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019171757623553276,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08941957354545593,
      "backward_entropy": 0.05230601267381148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.617124557495117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019265735521912575,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08940641085306804,
      "backward_entropy": 0.04841007427735762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.779716491699219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01935982145369053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08939068516095479,
      "backward_entropy": 0.04813011667945168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.733470439910889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0194541122764349,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08937154213587443,
      "backward_entropy": 0.04756388880989768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.58074951171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019548561424016953,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08934928973515828,
      "backward_entropy": 0.05135289647362449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.627890586853027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019643021747469902,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08932393789291382,
      "backward_entropy": 0.04725734754042192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7404093742370605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01973695680499077,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08930215239524841,
      "backward_entropy": 0.046960646455938164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.892895221710205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01983110047876835,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08927650252978007,
      "backward_entropy": 0.04630655592138117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.949086666107178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019924893975257874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08925171693166097,
      "backward_entropy": 0.046353600241921165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.160591125488281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020018402487039566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08922695120175679,
      "backward_entropy": 0.046046657995744186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.75728178024292,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02011118084192276,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08920734127362569,
      "backward_entropy": 0.04981433803384954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.688169002532959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02020367607474327,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08918808897336324,
      "backward_entropy": 0.044997686689550224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.093986988067627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020296500995755196,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08916271726290385,
      "backward_entropy": 0.049269340255043724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.863034725189209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020389271900057793,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08913561701774597,
      "backward_entropy": 0.04899154468016191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.668638229370117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02048182301223278,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08910773197809856,
      "backward_entropy": 0.04447358033873818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.431914329528809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020574061200022697,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08908011515935262,
      "backward_entropy": 0.04414911703629927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.942303657531738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020665867254137993,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08905402819315593,
      "backward_entropy": 0.043292259628122505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.19290828704834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020757626742124557,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08902548750241597,
      "backward_entropy": 0.04349386692047119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.861945152282715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02084885723888874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08899959921836853,
      "backward_entropy": 0.04316386309537021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.682482719421387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020939406007528305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08897840976715088,
      "backward_entropy": 0.042832155119289055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.227622985839844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021029895171523094,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08895431955655415,
      "backward_entropy": 0.041890569708564064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.889877796173096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02112068608403206,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08892291784286499,
      "backward_entropy": 0.042153301564129914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.240536689758301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021211538463830948,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08888769149780273,
      "backward_entropy": 0.04116775772788308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.574658393859863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021302025765180588,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08885361750920613,
      "backward_entropy": 0.046029220927845345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.574085712432861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021392425522208214,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08881778518358867,
      "backward_entropy": 0.045715559612620964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.863604545593262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021482735872268677,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0887799859046936,
      "backward_entropy": 0.0400511080568487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.541707515716553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02157248556613922,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08874564369519551,
      "backward_entropy": 0.039673079143870964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.780028820037842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02166152000427246,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08871682484944661,
      "backward_entropy": 0.04475716027346524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.199423789978027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021750055253505707,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08868976434071858,
      "backward_entropy": 0.04443204673853787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.007867813110352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021838461980223656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08866055806477864,
      "backward_entropy": 0.03932053392583674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.553642272949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021926630288362503,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08863061666488647,
      "backward_entropy": 0.043774138797413216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.919789791107178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022014254704117775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08860339721043904,
      "backward_entropy": 0.038603988560763275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.986482620239258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02210167422890663,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08857510487238567,
      "backward_entropy": 0.04310668598521839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9083123207092285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022188957780599594,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08854448795318604,
      "backward_entropy": 0.03787961331280795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.418120861053467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022275332361459732,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08852147062619527,
      "backward_entropy": 0.03752014853737571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.114602088928223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022361280396580696,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08850004275639851,
      "backward_entropy": 0.03620256619019942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.773505210876465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022446613758802414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08848213156064351,
      "backward_entropy": 0.03680155764926563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.405120372772217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02253187820315361,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08845996856689453,
      "backward_entropy": 0.041394710540771484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.102509498596191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022616812959313393,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08843711018562317,
      "backward_entropy": 0.04104405641555786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2396745681762695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02270198054611683,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08840591708819072,
      "backward_entropy": 0.03570892052216963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.544962406158447,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022786732763051987,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08837559819221497,
      "backward_entropy": 0.04033631086349487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.06428337097168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022871335968375206,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08834211031595866,
      "backward_entropy": 0.03385051001201977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.881731033325195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022955449298024178,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08831001321474712,
      "backward_entropy": 0.03459971330382607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7476582527160645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023038992658257484,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08828095595041911,
      "backward_entropy": 0.03306265039877458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.640133380889893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02312193624675274,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08825560410817464,
      "backward_entropy": 0.033862173557281494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.579289436340332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023204253986477852,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0882339874903361,
      "backward_entropy": 0.03349526903846047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.523283004760742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023285964503884315,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08821575840314229,
      "backward_entropy": 0.03313008492643183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.772172927856445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02336786314845085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08818840980529785,
      "backward_entropy": 0.031486164439808235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.51078987121582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02344936691224575,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08816127975781758,
      "backward_entropy": 0.031090595505454323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6974711418151855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023530298843979836,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08813659350077312,
      "backward_entropy": 0.037070762027393685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.96891188621521,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02361087128520012,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08811106284459432,
      "backward_entropy": 0.03670084476470947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.173586845397949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02369052916765213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08809308211008708,
      "backward_entropy": 0.03128878636793657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.096063137054443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02376953698694706,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08807847897211711,
      "backward_entropy": 0.029530051079663364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.068624973297119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023847894743084908,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08806713422139485,
      "backward_entropy": 0.0355873162096197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.358171463012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023925654590129852,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08805829286575317,
      "backward_entropy": 0.03521580045873469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4506354331970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02400312013924122,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08804723620414734,
      "backward_entropy": 0.034843536940487946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7593343257904053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024080414324998856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.088032066822052,
      "backward_entropy": 0.02949911897832697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.274431228637695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0241569634526968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08802127838134766,
      "backward_entropy": 0.02914448759772561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.24945592880249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02423328347504139,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08800697326660156,
      "backward_entropy": 0.028789043426513672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3353848457336426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024309393018484116,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08798879384994507,
      "backward_entropy": 0.026871025562286377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5735843181610107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0243845097720623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08797833323478699,
      "backward_entropy": 0.028081953525543213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.167291641235352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024458931758999825,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0879709521929423,
      "backward_entropy": 0.02612960609522733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.864563465118408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024533282965421677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08795743187268575,
      "backward_entropy": 0.027386833320964466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.146623134613037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024607302621006966,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08794152736663818,
      "backward_entropy": 0.03182119672948664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.535346031188965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02468128874897957,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08791870872179668,
      "backward_entropy": 0.026686638593673706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4802229404449463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02475469559431076,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08789690335591634,
      "backward_entropy": 0.026335653933611782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.244947671890259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024827536195516586,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08787580331166585,
      "backward_entropy": 0.0259860483082858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0089151859283447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02489963173866272,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08785802125930786,
      "backward_entropy": 0.02392133257605813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5854222774505615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024970846250653267,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0878454049428304,
      "backward_entropy": 0.025300475684079258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3944079875946045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025041822344064713,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08782842755317688,
      "backward_entropy": 0.02320154688575051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6408398151397705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025112397968769073,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08780940373738606,
      "backward_entropy": 0.022845224900679154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8592591285705566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02518286183476448,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0877840518951416,
      "backward_entropy": 0.022491064938631924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.090423822402954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025252459570765495,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08776328961054485,
      "backward_entropy": 0.023944654247977516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.232187032699585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025321505963802338,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08774249752362569,
      "backward_entropy": 0.028112817894328724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.077690362930298,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025390205904841423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08771852652231853,
      "backward_entropy": 0.023280284621498802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0085268020629883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02545844577252865,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08769278724988301,
      "backward_entropy": 0.02739053964614868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.024355411529541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025526201352477074,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08766566713651021,
      "backward_entropy": 0.027032651684500954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7902090549468994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02559353969991207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08763654033342998,
      "backward_entropy": 0.022297065366398205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6379497051239014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025660265237092972,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08760760227839152,
      "backward_entropy": 0.021974984895099293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4056613445281982,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025726279243826866,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08758013447125752,
      "backward_entropy": 0.019800741564143787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6902525424957275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025791404768824577,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08755630254745483,
      "backward_entropy": 0.02562425353310325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7207140922546387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02585603855550289,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.087531179189682,
      "backward_entropy": 0.019165594469417225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7510533332824707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025920270010828972,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08750328421592712,
      "backward_entropy": 0.024936589327725498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.513160467147827,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025984181091189384,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08747111757596333,
      "backward_entropy": 0.018547192215919495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2888503074645996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026047537103295326,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08743809660275777,
      "backward_entropy": 0.02425877885384993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.649489402770996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02611013874411583,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0874065359433492,
      "backward_entropy": 0.019817181608893654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5877203941345215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026172488927841187,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08736944198608398,
      "backward_entropy": 0.019517520611936397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1996254920959473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026234548538923264,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08732716242472331,
      "backward_entropy": 0.01735460487279025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.220968246459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02629588358104229,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08728579680124919,
      "backward_entropy": 0.022943187843669544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1647183895111084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026356594637036324,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0872443715731303,
      "backward_entropy": 0.01678024638782848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7997251749038696,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026416679844260216,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08720237016677856,
      "backward_entropy": 0.018343613906340164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.128262996673584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02647573873400688,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0871657927831014,
      "backward_entropy": 0.016224415464834732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0725338459014893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026534300297498703,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.087126890818278,
      "backward_entropy": 0.017784839326685124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7262274026870728,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026592345908284187,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08708603183428447,
      "backward_entropy": 0.021377446976574985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9614332914352417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02664947137236595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08704951405525208,
      "backward_entropy": 0.0172413709488782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6975903511047363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706088334321976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08701038360595703,
      "backward_entropy": 0.016975550488992172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8558531999588013,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026761887595057487,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08697338898976643,
      "backward_entropy": 0.014915618029507723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5293467044830322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02681717462837696,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08693398038546245,
      "backward_entropy": 0.016457267782904884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.486126184463501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026871537789702415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08689759174982707,
      "backward_entropy": 0.01620524444363334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.704857349395752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02692500688135624,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08686432242393494,
      "backward_entropy": 0.019627147100188515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.661421537399292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02697799541056156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08682845036188762,
      "backward_entropy": 0.015715269879861313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.731751799583435,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027030495926737785,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08679083983103435,
      "backward_entropy": 0.013718092983419245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.365107774734497,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027082663029432297,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08674760659535725,
      "backward_entropy": 0.015236062082377348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3390990495681763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027133965864777565,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08670444289843242,
      "backward_entropy": 0.015002237124876543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3533110618591309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027184460312128067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08666445811589558,
      "backward_entropy": 0.014773924242366444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.358617901802063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723425067961216,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08662547667821248,
      "backward_entropy": 0.014550100673328747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1993900537490845,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027283407747745514,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08658491571744283,
      "backward_entropy": 0.01262940060008656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.395672082901001,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027331728488206863,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08654538790384929,
      "backward_entropy": 0.012424462220885536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3445645570755005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02737964317202568,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08650254209836324,
      "backward_entropy": 0.017273333939639004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.197550654411316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027427103370428085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08645594120025635,
      "backward_entropy": 0.013689818707379427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1607708930969238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027473902329802513,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08640879392623901,
      "backward_entropy": 0.011832024563442577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1221966743469238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02752004750072956,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08636133869489034,
      "backward_entropy": 0.01656180891123685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2783881425857544,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02756553702056408,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08631356557210286,
      "backward_entropy": 0.011457444591955706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9886788725852966,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02761072665452957,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0862598717212677,
      "backward_entropy": 0.011274912817911669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.238543152809143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027655096724629402,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08620684345563252,
      "backward_entropy": 0.011096298017285088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.238334059715271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027699220925569534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08614684144655864,
      "backward_entropy": 0.012495168230750343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1228463649749756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027743129059672356,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08607908089955647,
      "backward_entropy": 0.012302078984000465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7238223552703857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02778664603829384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08600805203119914,
      "backward_entropy": 0.012111372568390587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6890496015548706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02782898023724556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08594325184822083,
      "backward_entropy": 0.011927612803199074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7043991088867188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027870161458849907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08588370680809021,
      "backward_entropy": 0.011750329624522816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8411628007888794,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02791033312678337,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08582768837610881,
      "backward_entropy": 0.014643448320302095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6936104893684387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027949903160333633,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08577019969622295,
      "backward_entropy": 0.009934812106869438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8469046950340271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027988601475954056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08571508526802063,
      "backward_entropy": 0.01124600117856806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7532998323440552,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028026852756738663,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08565537134806316,
      "backward_entropy": 0.011084013364531776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.73079913854599,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028064507991075516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08559467395146687,
      "backward_entropy": 0.00949112664569508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6294381022453308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028101587668061256,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0855334997177124,
      "backward_entropy": 0.010769233784892342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49121761322021484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028137896209955215,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08547396461168925,
      "backward_entropy": 0.010617231780832464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.747751772403717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028173135593533516,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08541863163312276,
      "backward_entropy": 0.010470719500021501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7163846492767334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028208104893565178,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08535870909690857,
      "backward_entropy": 0.008949432183395733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3794606328010559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028242750093340874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08529434601465861,
      "backward_entropy": 0.01018172096122395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6046284437179565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028276195749640465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08523760239283244,
      "backward_entropy": 0.010044479911977594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4265764653682709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028309188783168793,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08517865339914958,
      "backward_entropy": 0.008578415621410717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4139065444469452,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028341244906187057,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0851226548353831,
      "backward_entropy": 0.009779158640991558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3962932229042053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02837243303656578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08506972591082256,
      "backward_entropy": 0.009653270244598389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5044568181037903,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0284027811139822,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08501950899759929,
      "backward_entropy": 0.008241390640085394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4622285068035126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028432676568627357,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08496564626693726,
      "backward_entropy": 0.009411660785024816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5495944023132324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02846204675734043,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08490978678067525,
      "backward_entropy": 0.008031123063781044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39929860830307007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028491254895925522,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08484851320584615,
      "backward_entropy": 0.009177137504924427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38714566826820374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028519801795482635,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08478679259618123,
      "backward_entropy": 0.007829406722025438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41420143842697144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028547730296850204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08472507198651631,
      "backward_entropy": 0.008952257985418493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3923969566822052,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028575193136930466,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08466115593910217,
      "backward_entropy": 0.0076385844837535515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5061326622962952,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02860214374959469,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08459484577178955,
      "backward_entropy": 0.007546598261052912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3180936574935913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028629077598452568,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08452109495798747,
      "backward_entropy": 0.008629737252538855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36840346455574036,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02865528129041195,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08444769183794658,
      "backward_entropy": 0.011168161576444452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2757490873336792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028681056573987007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08437236150105794,
      "backward_entropy": 0.008423910899595781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2594263255596161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028706077486276627,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0842989186445872,
      "backward_entropy": 0.008324851366606626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28830602765083313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028730329126119614,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08422672748565674,
      "backward_entropy": 0.008229001001878218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31112974882125854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02875404991209507,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08415455619494121,
      "backward_entropy": 0.008135448125275698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25802406668663025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028777414932847023,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08408085505167644,
      "backward_entropy": 0.010632358491420746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28965702652931213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028800176456570625,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08400668700536092,
      "backward_entropy": 0.010533357208425348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27513912320137024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02882251888513565,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08392914136250813,
      "backward_entropy": 0.006819634952328422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1936289519071579,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028844410553574562,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08384839693705241,
      "backward_entropy": 0.0077796476808461275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14357146620750427,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028865529224276543,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08376922210057576,
      "backward_entropy": 0.01025313138961792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16707728803157806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028885697945952415,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08369393150011699,
      "backward_entropy": 0.007617951116778634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2047901749610901,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028905175626277924,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08362120389938354,
      "backward_entropy": 0.00655731355602091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16594980657100677,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028924167156219482,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08354671796162923,
      "backward_entropy": 0.00746843083338304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1471365988254547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02894260548055172,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08347417910893758,
      "backward_entropy": 0.006440661170265891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18988536298274994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028960445895791054,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08340421319007874,
      "backward_entropy": 0.006385696882551367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1348613202571869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02897789143025875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08333152532577515,
      "backward_entropy": 0.007261099463159388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13553671538829803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028994783759117126,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08326156437397003,
      "backward_entropy": 0.007196286185221238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11331102252006531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029011107981204987,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08319244782129924,
      "backward_entropy": 0.009634972973303362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08391033858060837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029026860371232033,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08312645554542542,
      "backward_entropy": 0.007073839279738339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12950937449932098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029041752219200134,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08306294679641724,
      "backward_entropy": 0.009505167603492737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12405821681022644,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029056290164589882,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08299950261910756,
      "backward_entropy": 0.006962240419604562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1352626383304596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029070476070046425,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08293611804644267,
      "backward_entropy": 0.006055495955727317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13788054883480072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029084419831633568,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08287134766578674,
      "backward_entropy": 0.009325093843720177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10752250254154205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029098186641931534,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08280485371748607,
      "backward_entropy": 0.009267346425489946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09754739701747894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02911148965358734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08273787299791972,
      "backward_entropy": 0.006753118878061121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12056004256010056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0291244275867939,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08267233272393544,
      "backward_entropy": 0.006704199720512737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06778193265199661,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0291371438652277,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08260482549667358,
      "backward_entropy": 0.00910470566966317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10388743132352829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029149185866117477,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08253931999206543,
      "backward_entropy": 0.006610369817777114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05016438290476799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029160916805267334,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0824719766775767,
      "backward_entropy": 0.009006076238372109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06630884110927582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02917191945016384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08240778247515361,
      "backward_entropy": 0.006524114446206527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06942102313041687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02918248064815998,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08234533667564392,
      "backward_entropy": 0.008916725489226255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07234610617160797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029192667454481125,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0822838544845581,
      "backward_entropy": 0.008874500339681452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06954287737607956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029202453792095184,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0822218507528305,
      "backward_entropy": 0.008834087713198229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.082210473716259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029211923480033875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08215996623039246,
      "backward_entropy": 0.006372696296735244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06931059062480927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029221225529909134,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08209649721781413,
      "backward_entropy": 0.006337282332507047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10309605300426483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029230261221528053,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08203273018201192,
      "backward_entropy": 0.006302832202477889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06856992095708847,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02923956885933876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08196593324343364,
      "backward_entropy": 0.006267283450473438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06975957006216049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029248612001538277,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08189865946769714,
      "backward_entropy": 0.005561992187391628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06369443982839584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029257480055093765,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08183083931605022,
      "backward_entropy": 0.006198723885146054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07554478198289871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02926603890955448,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0817623237768809,
      "backward_entropy": 0.0061658363450657235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06259104609489441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029274597764015198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08169236779212952,
      "backward_entropy": 0.006132906133478338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07338989526033401,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02928287908434868,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08162149290243785,
      "backward_entropy": 0.006100947883996097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05919293314218521,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029291139915585518,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0815487156311671,
      "backward_entropy": 0.005452560768886046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06085493415594101,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02929927594959736,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08147606750329335,
      "backward_entropy": 0.006037531251257116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0491255521774292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029307257384061813,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08140258987744649,
      "backward_entropy": 0.006006626920266585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04742748290300369,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029314937070012093,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08132958908875783,
      "backward_entropy": 0.005976838144389066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0492817759513855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02932230569422245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08125683168570201,
      "backward_entropy": 0.005948180502111261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04202471300959587,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029329555109143257,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08118444681167603,
      "backward_entropy": 0.008318754759701815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0414053276181221,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029336581006646156,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08111309011777242,
      "backward_entropy": 0.008290476419708946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04174554720520973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02934332750737667,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08104218045870464,
      "backward_entropy": 0.005322995849631049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03889983519911766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029349861666560173,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08097148935000102,
      "backward_entropy": 0.005307336761192842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03925034776329994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02935609221458435,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08090090751647949,
      "backward_entropy": 0.005292692645029588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04090041667222977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02936222217977047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0808308372894923,
      "backward_entropy": 0.005792499943213029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03220745548605919,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029368354007601738,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076094587643941,
      "backward_entropy": 0.005768535489385778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034523919224739075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029374275356531143,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0806921770175298,
      "backward_entropy": 0.005745381116867065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02623121254146099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937994711101055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.080623393257459,
      "backward_entropy": 0.005723093720999631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03171081095933914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02938523143529892,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08055582642555237,
      "backward_entropy": 0.005702188746495681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02838178537786007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029390409588813782,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0804886519908905,
      "backward_entropy": 0.005681702359156175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0272375475615263,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02939535863697529,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08042202393213908,
      "backward_entropy": 0.005202158946882595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024493422359228134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029400091618299484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08035593728224437,
      "backward_entropy": 0.005643155087124218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023306332528591156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029404500499367714,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0802904615799586,
      "backward_entropy": 0.005182727832685818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021353336051106453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02940879762172699,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08022627234458923,
      "backward_entropy": 0.005173748189752752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021406084299087524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0294127706438303,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.080162912607193,
      "backward_entropy": 0.007996840910478071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016054246574640274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029416654258966446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08010076483090718,
      "backward_entropy": 0.00557616115971045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015382351353764534,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029420239850878716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08004045486450195,
      "backward_entropy": 0.0051511600613594055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0190728809684515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029423629865050316,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07998210688432057,
      "backward_entropy": 0.0055475573648105965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018377942964434624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029426883906126022,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.079924409588178,
      "backward_entropy": 0.005534537813880227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024196399375796318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029430009424686432,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.079867422580719,
      "backward_entropy": 0.005522034384987571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017858080565929413,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029433224350214005,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07980972528457642,
      "backward_entropy": 0.00792124325578863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016251137480139732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294362660497427,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07975247502326965,
      "backward_entropy": 0.005496692928400907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014750530011951923,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943912148475647,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07969595988591512,
      "backward_entropy": 0.005116627297618173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019707797095179558,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944178134202957,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07964039345582326,
      "backward_entropy": 0.00788942047140815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018636392429471016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029444515705108643,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07958455383777618,
      "backward_entropy": 0.0054623599756847725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01603626273572445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02944738231599331,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07952885329723358,
      "backward_entropy": 0.007868333973667839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014285625889897346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029450146481394768,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07947343587875366,
      "backward_entropy": 0.005438762970946052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01189393363893032,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02945280447602272,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07941875358422597,
      "backward_entropy": 0.005092285573482513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013184829615056515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029455281794071198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0793652484814326,
      "backward_entropy": 0.005416911772706292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01368662342429161,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029457617551088333,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07931227485338847,
      "backward_entropy": 0.005084198984232816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012180580757558346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02945982664823532,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07925947507222493,
      "backward_entropy": 0.005397110838781704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009949665516614914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029461964964866638,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07920743028322856,
      "backward_entropy": 0.005077498541636901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010171781294047832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294638741761446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07915644844373067,
      "backward_entropy": 0.005379361862486059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010055686347186565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02946559526026249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07910628616809845,
      "backward_entropy": 0.005371564491228623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010421890765428543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029467180371284485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07905690868695577,
      "backward_entropy": 0.0050714625553651286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011335719376802444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02946874313056469,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07900822162628174,
      "backward_entropy": 0.005357001654126428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009504901245236397,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029470305889844894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0789596935113271,
      "backward_entropy": 0.0053497332740913735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00926883239299059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02947171777486801,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07891164720058441,
      "backward_entropy": 0.0053429989652200175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00795583426952362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029473116621375084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07886435588200887,
      "backward_entropy": 0.005336318503726612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009839081205427647,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029474513605237007,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078818346063296,
      "backward_entropy": 0.005329679697751999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008608282543718815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029475990682840347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07877262433369954,
      "backward_entropy": 0.00532274760983207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006880749948322773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029477503150701523,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07872761289278667,
      "backward_entropy": 0.007755351337519559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007549887057393789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02947896532714367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07868385314941406,
      "backward_entropy": 0.005308883772654967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008616826497018337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02948044054210186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07864088813463847,
      "backward_entropy": 0.005302051251584833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006602639332413673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02948191575706005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07859792808691661,
      "backward_entropy": 0.005295201458714225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006950082257390022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029483381658792496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855600118637085,
      "backward_entropy": 0.00528841499577869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006653128191828728,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029484905302524567,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07851485908031464,
      "backward_entropy": 0.005050872198560021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006213920656591654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029486369341611862,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07847422858079274,
      "backward_entropy": 0.005274728279222141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0066054207272827625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02948768436908722,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0784339706103007,
      "backward_entropy": 0.005047016523101113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005672819912433624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029488956555724144,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07839394112428029,
      "backward_entropy": 0.005262510004368695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004944336600601673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029490135610103607,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07835448284943898,
      "backward_entropy": 0.005256867205554789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005612336564809084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02949126623570919,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07831602295239766,
      "backward_entropy": 0.005043131383982572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003936248831450939,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029492415487766266,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07827803492546082,
      "backward_entropy": 0.005041938275098801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005101497750729322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02949356473982334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07824158171812694,
      "backward_entropy": 0.005240807140415365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004297077190130949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029494760558009148,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07820566495259602,
      "backward_entropy": 0.005235359072685242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004118693061172962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029495982453227043,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07817075649897258,
      "backward_entropy": 0.005229883234609257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043563926592469215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02949722483754158,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0781367818514506,
      "backward_entropy": 0.007679839703169736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004841270390897989,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029498450458049774,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07810328404108684,
      "backward_entropy": 0.007675141096115112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00439057033509016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02949959971010685,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0780695378780365,
      "backward_entropy": 0.00521379675377499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003308993298560381,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029500700533390045,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07803598046302795,
      "backward_entropy": 0.007666657594117251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004477487877011299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02950175851583481,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07800345619519551,
      "backward_entropy": 0.0052041042257439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003688512137159705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029502835124731064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07797087728977203,
      "backward_entropy": 0.005199249495159496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002960158744826913,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02950390800833702,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07793879508972168,
      "backward_entropy": 0.007654324173927307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033873918000608683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029504956677556038,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07790777087211609,
      "backward_entropy": 0.005189688368277116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002544636372476816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02950606867671013,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07787737250328064,
      "backward_entropy": 0.005184761502526023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003304352518171072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029507119208574295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07784805198510487,
      "backward_entropy": 0.005180078812620856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030938307754695415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029508136212825775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07781886061032613,
      "backward_entropy": 0.005175505172122608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022721150889992714,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029509149491786957,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07779000202814738,
      "backward_entropy": 0.005019855770197782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028549598064273596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951004169881344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07776198784510295,
      "backward_entropy": 0.005166849290782755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002657575299963355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951095625758171,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07773431142171223,
      "backward_entropy": 0.005162675272334705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025150610599666834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029511816799640656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07770685354868571,
      "backward_entropy": 0.005158740688454021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020940026734024286,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029512591660022736,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07767963409423828,
      "backward_entropy": 0.007619432427666404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002616619924083352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029513346031308174,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07765317956606548,
      "backward_entropy": 0.005015338347716765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020977696403861046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951407991349697,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07762670516967773,
      "backward_entropy": 0.00514812632040544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001692592864856124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951480820775032,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0776008168856303,
      "backward_entropy": 0.005144698376005346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002026174683123827,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02951553650200367,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07757599155108134,
      "backward_entropy": 0.0050134608014063406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002034600358456373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029516175389289856,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07755138476689656,
      "backward_entropy": 0.005138258365067569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017690528184175491,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951677329838276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07752694686253865,
      "backward_entropy": 0.005135332996195013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016997138736769557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029517387971282005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07750310997168224,
      "backward_entropy": 0.005132358182560314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016124570975080132,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02951803244650364,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07747986912727356,
      "backward_entropy": 0.00501197949051857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015479541616514325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029518673196434975,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0774571696917216,
      "backward_entropy": 0.005126277492804961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014757479075342417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029519323259592056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0774350215991338,
      "backward_entropy": 0.005123261700976978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016786375781521201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951996587216854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07741334040959676,
      "backward_entropy": 0.005120299417864193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014114001533016562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02952057309448719,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07739159961541493,
      "backward_entropy": 0.005117465149272572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001493378309533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029521219432353973,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07737032572428386,
      "backward_entropy": 0.00511452013796026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012784480350092053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029521888121962547,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07734920084476471,
      "backward_entropy": 0.005111529745838859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001131176482886076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02952253259718418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07732853293418884,
      "backward_entropy": 0.0051086409525437785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011229788651689887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029523134231567383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07730846603711446,
      "backward_entropy": 0.005105913024057041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012021453585475683,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02952374890446663,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0772889753182729,
      "backward_entropy": 0.007572908970442685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009530789684504271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029524292796850204,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07726960877577464,
      "backward_entropy": 0.005100639706308191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001058362890034914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029524797573685646,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07725090781847636,
      "backward_entropy": 0.0050056976350871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009730352903716266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02952527068555355,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0772324800491333,
      "backward_entropy": 0.00500548393888907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008950378396548331,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02952573448419571,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07721444467703502,
      "backward_entropy": 0.005093844776803797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009774655336514115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02952619642019272,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07719691594441731,
      "backward_entropy": 0.005091661079363389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008592223166488111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029526669532060623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07717954119046529,
      "backward_entropy": 0.005089435387741436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008099884144030511,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0295270886272192,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07716249922911327,
      "backward_entropy": 0.005004555664279244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007935342146083713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02952750027179718,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.077145849665006,
      "backward_entropy": 0.005085420202125202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000732431304641068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029527928680181503,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07712955276171367,
      "backward_entropy": 0.005083385516296734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006953339325264096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029528366401791573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07711368302504222,
      "backward_entropy": 0.0050813257694244385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006556235603056848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029528820887207985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0770982454220454,
      "backward_entropy": 0.005079224028370597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007032788125798106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029529308900237083,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07708326975504558,
      "backward_entropy": 0.0050028945234688845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004592448240146041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029529787600040436,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07706839839617412,
      "backward_entropy": 0.0050023624842817135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005990881472826004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029530273750424385,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07705446084340413,
      "backward_entropy": 0.0050017664378339596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005692312261089683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029530750587582588,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07704074184099834,
      "backward_entropy": 0.005070771006020633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004982958198525012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029531190171837807,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07702727615833282,
      "backward_entropy": 0.005068840966983275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046488011139445007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02953164279460907,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07701422274112701,
      "backward_entropy": 0.005066886205564846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004905406967736781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029532095417380333,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07700162132581075,
      "backward_entropy": 0.004999710077589209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044708806672133505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029532499611377716,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07698927819728851,
      "backward_entropy": 0.004999334839257327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035580157418735325,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029532892629504204,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07697725296020508,
      "backward_entropy": 0.007531149820847945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004948208807036281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02953331544995308,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07696586847305298,
      "backward_entropy": 0.004998501728881489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038078168290667236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029533693566918373,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0769543747107188,
      "backward_entropy": 0.007527305998585441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042614361154846847,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02953404188156128,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07694326837857564,
      "backward_entropy": 0.005056543445045298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036818505031988025,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02953439950942993,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07693212727705638,
      "backward_entropy": 0.004997598853978244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037674896884709597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029534755274653435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07692122459411621,
      "backward_entropy": 0.005053441971540451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004075300239492208,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02953505702316761,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07691051562627156,
      "backward_entropy": 0.004997120662169023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002943066356237978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029535312205553055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07689969738324483,
      "backward_entropy": 0.005050861022689126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003024952602572739,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029535561800003052,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07688933114210765,
      "backward_entropy": 0.005049689249558883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028651722823269665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0295358095318079,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07687925795714061,
      "backward_entropy": 0.0050485262816602535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025685783475637436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029536038637161255,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07686949769655864,
      "backward_entropy": 0.0075155144388025456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028436287539079785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029536264017224312,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07686014970143636,
      "backward_entropy": 0.005046369338577444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002355442993575707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029536470770835876,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07685092091560364,
      "backward_entropy": 0.004997360096736388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024854886578395963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029536690562963486,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07684203485647838,
      "backward_entropy": 0.005044341087341309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023335215519182384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02953687682747841,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07683340708414714,
      "backward_entropy": 0.005043435164473273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000249560980591923,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029537059366703033,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07682498792807262,
      "backward_entropy": 0.005042548884044994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018311405437998474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029537251219153404,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07681642969449361,
      "backward_entropy": 0.005041615190831098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021499254216905683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02953745611011982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07680831849575043,
      "backward_entropy": 0.005040647970004516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021233029838185757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02953764609992504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07680031657218933,
      "backward_entropy": 0.0050397515296936035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018801244732458144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029537823051214218,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0767923394838969,
      "backward_entropy": 0.005038886246356097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016268811305053532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029537996277213097,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07678454120953877,
      "backward_entropy": 0.005038038234819065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016170513117685914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029538175091147423,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07677707076072693,
      "backward_entropy": 0.00503719225525856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016481884813401848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0295383520424366,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07676986356576283,
      "backward_entropy": 0.004998062821951779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001882181386463344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029538530856370926,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07676273584365845,
      "backward_entropy": 0.0075013129548593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001417096791556105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029538676142692566,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07675546407699585,
      "backward_entropy": 0.005034769461913543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012991111725568771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029538828879594803,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07674841086069743,
      "backward_entropy": 0.005034012550657446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012851400242652744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029538990929722786,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07674161593119304,
      "backward_entropy": 0.007498619231310758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001381871843477711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029539158567786217,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07673501968383789,
      "backward_entropy": 0.005032446574081074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012021228758385405,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029539309442043304,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07672849297523499,
      "backward_entropy": 0.004998389970172535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000118810981803108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029539451003074646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07672223448753357,
      "backward_entropy": 0.005031022497198798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.836007666308433e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02953958697617054,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07671611507733662,
      "backward_entropy": 0.005030358718200164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010524609388085082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02953973039984703,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07671034336090088,
      "backward_entropy": 0.004998591135848652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010249783372273669,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02953987568616867,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07670463124910991,
      "backward_entropy": 0.004998626695437865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.514255750924349e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029540017247200012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07669896880785625,
      "backward_entropy": 0.005028379234400662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010519589704927057,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954016998410225,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07669358452161153,
      "backward_entropy": 0.007491619749502702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.218648872571066e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029540296643972397,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07668819030125935,
      "backward_entropy": 0.00502710992639715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.090068877208978e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029540427029132843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0766830046971639,
      "backward_entropy": 0.007490070706064051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.076963083818555e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954055927693844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07667797307173412,
      "backward_entropy": 0.0050259273160587654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.967753142816946e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954070083796978,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0766731599966685,
      "backward_entropy": 0.0074884566393765535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.214869401650503e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954084239900112,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07666865984598796,
      "backward_entropy": 0.005024703388864344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.695985939586535e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029540980234742165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07666422426700592,
      "backward_entropy": 0.005024099214510484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.14719683653675e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954111620783806,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07665986816088359,
      "backward_entropy": 0.007485932924530723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.770323670934886e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029541252180933952,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07665570576985677,
      "backward_entropy": 0.004998635500669479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.430929352063686e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0295413751155138,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07665153344472249,
      "backward_entropy": 0.00499863245270469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3423205827130005e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029541485011577606,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07664745052655537,
      "backward_entropy": 0.004998673769560727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9463102186564356e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954159677028656,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07664350668589275,
      "backward_entropy": 0.005021421069448645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.859192995354533e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029541712254285812,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0766398956378301,
      "backward_entropy": 0.005020916800607334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.329566945671104e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029541829600930214,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07663645346959432,
      "backward_entropy": 0.005020437592809851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.404645733302459e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029541952535510063,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0766330858071645,
      "backward_entropy": 0.007480579343709079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6429067879216745e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029542075470089912,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0766298274199168,
      "backward_entropy": 0.005019432441754775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.318332867114805e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029542189091444016,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0766266534725825,
      "backward_entropy": 0.007479086518287659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.94568924093619e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954229898750782,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07662361860275269,
      "backward_entropy": 0.004998496987602927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.225724478601478e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029542405158281326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07662064333756764,
      "backward_entropy": 0.0050180967558513985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3198666642419994e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029542500153183937,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07661760846773784,
      "backward_entropy": 0.004998506131497296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2249405194306746e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029542597010731697,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07661463816960652,
      "backward_entropy": 0.005017309364947406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.878178176819347e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029542695730924606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07661182681719463,
      "backward_entropy": 0.0050168945030732584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.162552457069978e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954278141260147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07660903533299764,
      "backward_entropy": 0.005016536197879098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.25072614941746e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029542865231633186,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07660637299219768,
      "backward_entropy": 0.005016192116520621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0956827686168253e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029542941600084305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07660369575023651,
      "backward_entropy": 0.005015860227021304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7755770133808255e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543012380599976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07660111784934998,
      "backward_entropy": 0.005015554075891321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7417623641667888e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543081298470497,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07659856975078583,
      "backward_entropy": 0.0050152580846439705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2307825929601677e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954314462840557,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07659604648749034,
      "backward_entropy": 0.005014979026534341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1320280211512e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029543213546276093,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07659366726875305,
      "backward_entropy": 0.004998830909078772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2330135834636167e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543286189436913,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07659135262171428,
      "backward_entropy": 0.005014376545494253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.129610402334947e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543356969952583,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07658910751342773,
      "backward_entropy": 0.005014077506282113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.98046000150498e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029543425887823105,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07658691207567851,
      "backward_entropy": 0.00499889152971181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.185473931604065e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029543494805693626,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07658480604489644,
      "backward_entropy": 0.0049989104948260565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2884369172970764e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954355999827385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07658280928929646,
      "backward_entropy": 0.005013237283988433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.852614150266163e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543615877628326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07658084233601888,
      "backward_entropy": 0.005012996156107296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3448191566567402e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543671756982803,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07657899459203084,
      "backward_entropy": 0.005012761124155738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.663323382672388e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954373136162758,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07657717665036519,
      "backward_entropy": 0.004999067973006855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4872051906422712e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543790966272354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765754481156667,
      "backward_entropy": 0.005012268031185324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2381444321363233e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954385243356228,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07657383879025777,
      "backward_entropy": 0.004999105903235349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2943575711688027e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029543917626142502,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07657229900360107,
      "backward_entropy": 0.0050117668103088035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4812555491516832e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029543984681367874,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.076570858558019,
      "backward_entropy": 0.007466227493502877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2688467904808931e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0295440461486578,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656945288181305,
      "backward_entropy": 0.005011283199895512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3198475244280417e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544107615947723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656808694203694,
      "backward_entropy": 0.005011046813292937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.274598344025435e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0295441672205925,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656681040922801,
      "backward_entropy": 0.005010832778432153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1353676200087648e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544221237301826,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656553387641907,
      "backward_entropy": 0.005010616034269333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0386915164417587e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544273391366005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656429211298625,
      "backward_entropy": 0.005010420964522796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.808521099330392e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544321820139885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765630304813385,
      "backward_entropy": 0.005010240118611942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0118685167981312e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544372111558914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656185328960419,
      "backward_entropy": 0.005010053176771511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.416773314616876e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544420540332794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07656072080135345,
      "backward_entropy": 0.005009866573593833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0426812877994962e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544468969106674,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07655959328015645,
      "backward_entropy": 0.005009682341055436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.734773811942432e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544511809945107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07655847072601318,
      "backward_entropy": 0.005009521814909848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.646109224879183e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954455092549324,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765573779741923,
      "backward_entropy": 0.005009369416670365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.352050826943014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544590041041374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07655630509058635,
      "backward_entropy": 0.005009223791685971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.721052614011569e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954462356865406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07655522227287292,
      "backward_entropy": 0.005009084939956665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.005784027569462e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544660821557045,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07655421892801921,
      "backward_entropy": 0.005008943040262569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.156973995530279e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954469621181488,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07655326028664906,
      "backward_entropy": 0.0074604864824901924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.730512268404709e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544731602072716,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07655234138170879,
      "backward_entropy": 0.005008679221976887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.680321348540019e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954476699233055,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.076551487048467,
      "backward_entropy": 0.004999407990412278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.026869297988014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544798657298088,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07655060291290283,
      "backward_entropy": 0.0050084113397381525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.314038844517199e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544826596975327,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07654972871144612,
      "backward_entropy": 0.005008305338296023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.049564606451895e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544852674007416,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07654884457588196,
      "backward_entropy": 0.005008203400806947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.824476491194218e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029544878751039505,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07654797037442525,
      "backward_entropy": 0.007458795200694691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3241674322634935e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544902965426445,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07654713094234467,
      "backward_entropy": 0.0050079998644915495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.40700068793376e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029544925317168236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07654628157615662,
      "backward_entropy": 0.004999700595032085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.851038283959497e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029544945806264877,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07654541730880737,
      "backward_entropy": 0.007458133453672583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.136274921824224e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954496443271637,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07654458284378052,
      "backward_entropy": 0.0049998140470548106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8365883483493235e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544981196522713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07654378811518352,
      "backward_entropy": 0.005007664249701934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4565317693923134e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029544999822974205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07654303312301636,
      "backward_entropy": 0.005007602274417877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2759187433839543e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545016586780548,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07654229799906413,
      "backward_entropy": 0.005007526075298136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7781335322506493e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954503335058689,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07654158771038055,
      "backward_entropy": 0.005000057884237983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5954444683738984e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545051977038383,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765409270922343,
      "backward_entropy": 0.005007381127639251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0033819459495135e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029545068740844727,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07654031117757161,
      "backward_entropy": 0.007456755096262152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3548841454612557e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954508364200592,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653968036174774,
      "backward_entropy": 0.0050072581930594015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.188448090440943e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545100405812263,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07653909424940745,
      "backward_entropy": 0.005000261759216135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.474226903359522e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545115306973457,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653850813706715,
      "backward_entropy": 0.0050071274692362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3626062102266587e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954513020813465,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07653792202472687,
      "backward_entropy": 0.005000362003391439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5605202154110884e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545145109295845,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07653736074765523,
      "backward_entropy": 0.005000406706875021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.84700558950135e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954516001045704,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0765368143717448,
      "backward_entropy": 0.007455694404515353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.639367039591889e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545174911618233,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07653629779815674,
      "backward_entropy": 0.005000497807155956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1755863599537406e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545187950134277,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653579115867615,
      "backward_entropy": 0.005006832832639868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2826534404885024e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545200988650322,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653530438741048,
      "backward_entropy": 0.00500678304921497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3748650644629379e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545214027166367,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653483748435974,
      "backward_entropy": 0.005006730556488037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9440985852270387e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954522706568241,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.076534370581309,
      "backward_entropy": 0.005006681789051403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9952431102865376e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545240104198456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765338937441508,
      "backward_entropy": 0.005006631666963751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5594688420605962e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954525128006935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653345664342244,
      "backward_entropy": 0.0050065812062133445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5441499954249593e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545264318585396,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653302450974782,
      "backward_entropy": 0.005006530406800183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9175256511516636e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954527549445629,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.076532577474912,
      "backward_entropy": 0.005006486719304865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2420125585776987e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545284807682037,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07653212547302246,
      "backward_entropy": 0.005000879141417417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4768846767765353e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545294120907784,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653167843818665,
      "backward_entropy": 0.005006416277451949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2452759392544976e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954530343413353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653127113978068,
      "backward_entropy": 0.0050063786858862095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5728110156487674e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545312747359276,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653084894021352,
      "backward_entropy": 0.0050063390623439445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4788026874157367e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545320197939873,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653043667475383,
      "backward_entropy": 0.005006302486766468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3175808817322832e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954532764852047,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07653004924456279,
      "backward_entropy": 0.005006278103048151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2411006764523336e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545335099101067,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652968168258667,
      "backward_entropy": 0.0050062415274706755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3112360193190398e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545340687036514,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0765293041865031,
      "backward_entropy": 0.005001174794002013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.470362556385226e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545346274971962,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652894655863444,
      "backward_entropy": 0.005006192760034041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.480567998958577e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954535186290741,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652858893076579,
      "backward_entropy": 0.007453281093727459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0383369044575375e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545361176133156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652829090754192,
      "backward_entropy": 0.005001293664628809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.95086748439644e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545368626713753,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652799288431804,
      "backward_entropy": 0.005006100982427597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0204419140791288e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954537607729435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765276849269867,
      "backward_entropy": 0.005006076260046525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.033288168007857e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545383527874947,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765274167060852,
      "backward_entropy": 0.005006044425747611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.006428515727748e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545392841100693,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652718822161357,
      "backward_entropy": 0.005006006834181872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.81888672918285e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954540029168129,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652692993481953,
      "backward_entropy": 0.0050059821118008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.399408221113845e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545407742261887,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765266865491867,
      "backward_entropy": 0.005005949938839132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.291467222283245e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545415192842484,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652643322944641,
      "backward_entropy": 0.00500593131238764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.533925104828086e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954542264342308,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652619977792104,
      "backward_entropy": 0.005005902187390761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.160718382692721e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545430094003677,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765259861946106,
      "backward_entropy": 0.005005881190299988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.372262646436866e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545437544584274,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652578751246135,
      "backward_entropy": 0.005005848678675565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.382559831763501e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545443132519722,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0765255739291509,
      "backward_entropy": 0.0050015883012251424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.787013949680841e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954544872045517,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652536034584045,
      "backward_entropy": 0.0050016197968613015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.251051445360645e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545454308390617,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652513186136882,
      "backward_entropy": 0.005001644180579619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.712667589501507e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545459896326065,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652493317921956,
      "backward_entropy": 0.00500576062635942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.86758779061347e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029545463621616364,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652472456296285,
      "backward_entropy": 0.007451795718886636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.183775328987394e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954546920955181,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652453581492107,
      "backward_entropy": 0.005005735903978348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.215481226310658e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954547479748726,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652435700098674,
      "backward_entropy": 0.007451650093902241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5480402971188596e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545480385422707,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652419805526733,
      "backward_entropy": 0.005005694925785065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6193906655389583e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545485973358154,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652402917544048,
      "backward_entropy": 0.00500566613945094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2911614766817365e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545491561293602,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652388016382854,
      "backward_entropy": 0.005005655302242799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6520955859487003e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954549714922905,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652372121810913,
      "backward_entropy": 0.005005641078407114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.056624902659678e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545500874519348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765235424041748,
      "backward_entropy": 0.005005619065328078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8314795486039657e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545502737164497,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652336359024048,
      "backward_entropy": 0.005005610937421972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0481785390511504e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545506462454796,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652318477630615,
      "backward_entropy": 0.005005600438876586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.801072582769848e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545508325099945,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652303576469421,
      "backward_entropy": 0.005005592988295989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.996117984821467e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545510187745094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652285695075989,
      "backward_entropy": 0.005005584860389883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7053624762629624e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029545512050390244,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652269800504048,
      "backward_entropy": 0.00745102966373617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3756310813259915e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029545513913035393,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652254402637482,
      "backward_entropy": 0.007450984960252588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2260700777442253e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545515775680542,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652239004770915,
      "backward_entropy": 0.005005553364753723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2339405347793218e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954551763832569,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652225593725841,
      "backward_entropy": 0.005005549978126179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.825056810706883e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954552136361599,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652213176091512,
      "backward_entropy": 0.0050055408342318105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.810070043324231e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545525088906288,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652202745278676,
      "backward_entropy": 0.005005531690337441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.194818478074012e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545528814196587,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652193307876587,
      "backward_entropy": 0.005005511709234931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.205462976689887e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545532539486885,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652185360590617,
      "backward_entropy": 0.005005500872026791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6152168313965376e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545536264777184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765217791001002,
      "backward_entropy": 0.005005490034818649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4418129978821526e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029545539990067482,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652170459429423,
      "backward_entropy": 0.007450541312044317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3806284471229446e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954554371535778,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652163505554199,
      "backward_entropy": 0.005005458200519735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7055066336979507e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545549303293228,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765215555826823,
      "backward_entropy": 0.005005446008660577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7451094436182757e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545553028583527,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652148604393005,
      "backward_entropy": 0.005005436864766208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.377022442738962e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545558616518974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652142147223155,
      "backward_entropy": 0.005005415867675434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.489282652755719e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545562341809273,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765213668346405,
      "backward_entropy": 0.005005402321165258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8475111573934555e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954556606709957,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0765213171641032,
      "backward_entropy": 0.005002227357842706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2829040940687264e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954556979238987,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652125755945842,
      "backward_entropy": 0.00500537319616838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.297347438367069e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029545573517680168,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652118802070618,
      "backward_entropy": 0.00745010105046359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2335941335095413e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545577242970467,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765211284160614,
      "backward_entropy": 0.0050053549083796415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.533118307861514e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545580968260765,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652106881141663,
      "backward_entropy": 0.005005348473787308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.862131212732493e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545584693551064,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652101914087932,
      "backward_entropy": 0.005005342377857728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1350635276130561e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545588418841362,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652095953623454,
      "backward_entropy": 0.005002296783707358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1257706944434176e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954559214413166,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652091483275096,
      "backward_entropy": 0.0050053146075118675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.092197217341891e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954559586942196,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652088006337483,
      "backward_entropy": 0.005005307156931271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.785144072793628e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545599594712257,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652085026105244,
      "backward_entropy": 0.005002318119460886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.632149052165914e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545603320002556,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765208254257838,
      "backward_entropy": 0.005005288530479778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3838700608821455e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029545607045292854,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652079065640767,
      "backward_entropy": 0.007449679753997109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.831961568172119e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545610770583153,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652077078819275,
      "backward_entropy": 0.005005260082808408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.97302908747588e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954561449587345,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652074098587036,
      "backward_entropy": 0.005002330988645554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0103592273935647e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954561822116375,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652070621649425,
      "backward_entropy": 0.005005244504321705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.005248730569292e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0295456200838089,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652066648006439,
      "backward_entropy": 0.005002350292422555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.008780673028014e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545621946454048,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652063171068828,
      "backward_entropy": 0.00500522181391716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6140930126957755e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545623809099197,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0765205870072047,
      "backward_entropy": 0.00500236451625824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.621991595537111e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545625671744347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652056217193604,
      "backward_entropy": 0.005005213008685546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.996769575882354e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545627534389496,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652052740255992,
      "backward_entropy": 0.005005209960720756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.421020787821362e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545629397034645,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652050256729126,
      "backward_entropy": 0.005005203864791177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.697701072586824e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545631259679794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765204628308614,
      "backward_entropy": 0.005005197768861597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9813901508978233e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545633122324944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652043302853902,
      "backward_entropy": 0.005005191334269263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.542842191312957e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029545634984970093,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652040322621663,
      "backward_entropy": 0.005002407187765295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4951048156226534e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545636847615242,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652035355567932,
      "backward_entropy": 0.005005176094445315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.709727008389564e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954563871026039,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652032375335693,
      "backward_entropy": 0.005005171691829508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.428950989814439e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954564057290554,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652028401692708,
      "backward_entropy": 0.005002428523518823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.933235686621629e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652025421460469,
      "backward_entropy": 0.0074491724371910095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.416714378090546e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652020454406738,
      "backward_entropy": 0.005005166950550946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5569414080782735e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.076520174741745,
      "backward_entropy": 0.005002462051131509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6033969646732658e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652012507120769,
      "backward_entropy": 0.007449120283126831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.870884495744576e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07652010520299275,
      "backward_entropy": 0.007449105381965637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1851161708118525e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07652006546656291,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.963145900343079e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07652003069718678,
      "backward_entropy": 0.005002503367987546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.192586461864266e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651999592781067,
      "backward_entropy": 0.005005159161307595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.250730884474251e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07651996612548828,
      "backward_entropy": 0.007449032230810685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1535876132693375e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765199214220047,
      "backward_entropy": 0.005005159161307595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7595252305445683e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651989658673604,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3659744385895465e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07651987671852112,
      "backward_entropy": 0.007448985495350577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2451207115636862e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651984691619873,
      "backward_entropy": 0.005005159161307595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.640896212824373e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651981214682262,
      "backward_entropy": 0.005005159161307595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.727612009005952e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651978731155396,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.816401784537902e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651975254217784,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1947915485043268e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651971777280171,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4333977560454514e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651967803637187,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3399585441220552e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07651964326699574,
      "backward_entropy": 0.00744889879768545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5417139564988247e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651960849761963,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1339943206678527e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651958862940471,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1811067679445841e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07651955882708232,
      "backward_entropy": 0.005002641203728589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4756772692692266e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651952902475993,
      "backward_entropy": 0.005005160854621367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5516816276317513e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765194942553838,
      "backward_entropy": 0.005005159161307595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3177670510344797e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651946445306142,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5033817746257228e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07651943465073903,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.489033696344677e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07651939988136292,
      "backward_entropy": 0.007448819550600919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4622020927390622e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.076519380013148,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3400291543064213e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954564243555069,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0765193502108256,
      "backward_entropy": 0.005005162209272385,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.344200013482123e-07,
    "avg_log_Z": 0.029545558784157037,
    "success_rate": 1.0,
    "avg_reward": 53.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.15,
      "2": 0.7
    },
    "avg_forward_entropy": 0.0765220316251119,
    "avg_backward_entropy": 0.005371660803529349,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}