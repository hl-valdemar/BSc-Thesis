{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09879030500139509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09871695722852435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.533615112304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719263672828674,
      "backward_entropy": 0.09880738598959786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25733470916748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371985673904419,
      "backward_entropy": 0.09870765890393939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.882416725158691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00019995809998363256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720421493053436,
      "backward_entropy": 0.09877018417630877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.522725105285645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00030002230778336525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720841705799103,
      "backward_entropy": 0.09875971930367607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4342622756958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004000575572717935,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721266388893127,
      "backward_entropy": 0.09876923901694161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890989303588867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005000465898774564,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721723854541779,
      "backward_entropy": 0.09875930207116264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.597566604614258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005998605629429221,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722194731235504,
      "backward_entropy": 0.09872710704803467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776742935180664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006997664459049702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372258961200714,
      "backward_entropy": 0.0986464364188058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.591206550598145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007997770444490016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722968101501465,
      "backward_entropy": 0.09863557134355817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.941425323486328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008998243720270693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723285496234894,
      "backward_entropy": 0.0986243827002389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67158031463623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010000064503401518,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723522424697876,
      "backward_entropy": 0.09861295563834054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.933929443359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011002165265381336,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723687827587128,
      "backward_entropy": 0.09869314091546195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.578093528747559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012005246244370937,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137238010764122,
      "backward_entropy": 0.0986811603818621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.66232967376709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013007939560338855,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723890483379364,
      "backward_entropy": 0.09857673304421562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.746936798095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014010678278282285,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372392773628235,
      "backward_entropy": 0.09865612643105644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.269064903259277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015013820957392454,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723908364772797,
      "backward_entropy": 0.09864307301385063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.129197120666504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016018914757296443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723838329315186,
      "backward_entropy": 0.09859742437090192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.561735153198242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017021840903908014,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723723590373993,
      "backward_entropy": 0.09852478333881923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.688663005828857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018024267628788948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372361034154892,
      "backward_entropy": 0.09856711966650826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295530319213867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019023152999579906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723531365394592,
      "backward_entropy": 0.0985513584954398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76728343963623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020021277014166117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723453879356384,
      "backward_entropy": 0.0985351630619594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.814984321594238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002102397382259369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723324239253998,
      "backward_entropy": 0.09847065380641393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.893303871154785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002202746458351612,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372312307357788,
      "backward_entropy": 0.0984565189906529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.374160766601562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023031660821288824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372290402650833,
      "backward_entropy": 0.09848461832318987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.23197078704834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024034613743424416,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372266709804535,
      "backward_entropy": 0.09842735528945923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.750364303588867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025039678439497948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372239738702774,
      "backward_entropy": 0.09844892365591866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.455195426940918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002604874549433589,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722068071365356,
      "backward_entropy": 0.09839729751859393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.708110809326172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027056224644184113,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721716403961182,
      "backward_entropy": 0.09838174070630755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.194904327392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028063245117664337,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721342384815216,
      "backward_entropy": 0.09844212021146502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46550178527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029067930299788713,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720954954624176,
      "backward_entropy": 0.09842414515359062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.356093406677246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003007533960044384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720546662807465,
      "backward_entropy": 0.09833280529294695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.202547073364258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031080793123692274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720141351222992,
      "backward_entropy": 0.09833138329642159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.945199012756348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032087897416204214,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719716668128967,
      "backward_entropy": 0.09836791242871966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.777175903320312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003309544874355197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371927410364151,
      "backward_entropy": 0.09828851904187884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33255386352539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003410286270081997,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718798756599426,
      "backward_entropy": 0.09826295716421944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25429630279541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003510773181915283,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718390464782715,
      "backward_entropy": 0.09824467556817192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.000557899475098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003611031686887145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718004524707794,
      "backward_entropy": 0.09828685011182513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.764152526855469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037109865806996822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371764838695526,
      "backward_entropy": 0.09819723878587995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.672674179077148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003811024595052004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717252016067505,
      "backward_entropy": 0.09818714005606514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.845806121826172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0039110854268074036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716836273670197,
      "backward_entropy": 0.09814834594726562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.517085075378418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0040112645365297794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716372847557068,
      "backward_entropy": 0.0981230480330331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.911550521850586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0041118464432656765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371583342552185,
      "backward_entropy": 0.0980971200125558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731912612915039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004212481435388327,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715282082557678,
      "backward_entropy": 0.0981019139289856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.896230220794678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0043130605481565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714754581451416,
      "backward_entropy": 0.09807923861912318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.733919143676758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0044132256880402565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714291155338287,
      "backward_entropy": 0.0980559161731175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.824173927307129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004512969870120287,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713879883289337,
      "backward_entropy": 0.09803181035178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.063949584960938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004612861201167107,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713420927524567,
      "backward_entropy": 0.09804817608424596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729411125183105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004712517838925123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371299922466278,
      "backward_entropy": 0.0979821767125811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.551029205322266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004812280647456646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371256411075592,
      "backward_entropy": 0.09795649562563215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7222261428833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004912033211439848,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712134957313538,
      "backward_entropy": 0.09786738668169294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.631325721740723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005011879839003086,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711678981781006,
      "backward_entropy": 0.0979360852922712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.96019458770752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005111756268888712,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711214065551758,
      "backward_entropy": 0.09790652990341187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.691276550292969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005211816634982824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13710713386535645,
      "backward_entropy": 0.09776954139981951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.109488487243652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0053123547695577145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13710156083106995,
      "backward_entropy": 0.09784584386008126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.924209594726562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005413049831986427,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709579408168793,
      "backward_entropy": 0.09781476429530553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.769084930419922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005514249205589294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708938658237457,
      "backward_entropy": 0.09766874143055507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.084293365478516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00561536243185401,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708308339118958,
      "backward_entropy": 0.09763382162366595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.274649620056152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005717028398066759,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707588613033295,
      "backward_entropy": 0.09771011556897845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.63202428817749,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0058183311484754086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706907629966736,
      "backward_entropy": 0.09768033027648926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.923921585083008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0059190369211137295,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706287741661072,
      "backward_entropy": 0.09764793940952846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.832488059997559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006019804626703262,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705642521381378,
      "backward_entropy": 0.09748693874904088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.346460342407227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0061205714009702206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704992830753326,
      "backward_entropy": 0.09758360045296806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.909565925598145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0062211183831095695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704364001750946,
      "backward_entropy": 0.097549421446664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.818171501159668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0063217380084097385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703706860542297,
      "backward_entropy": 0.09736875125340053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.810559272766113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006422366015613079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370304524898529,
      "backward_entropy": 0.09732721533094134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.980761528015137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006523532327264547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370226889848709,
      "backward_entropy": 0.09744208199637276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.691155433654785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006624744739383459,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701465725898743,
      "backward_entropy": 0.09740468433925084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4350714683532715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006726316642016172,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700592517852783,
      "backward_entropy": 0.09731439181736537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251080513000488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006827120203524828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699853420257568,
      "backward_entropy": 0.0971520287649972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569679260253906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006927673704922199,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13699132204055786,
      "backward_entropy": 0.09722046341214861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630732536315918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007028165273368359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698408007621765,
      "backward_entropy": 0.09706005028315953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.118332862854004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007128600496798754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13697677850723267,
      "backward_entropy": 0.09720332281930107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.909736633300781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007229252718389034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13696886599063873,
      "backward_entropy": 0.09715941122600011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.226191520690918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007329494692385197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13696157932281494,
      "backward_entropy": 0.09691526208605085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.319717407226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007429533172398806,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13695448637008667,
      "backward_entropy": 0.09696752684456962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.894612789154053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007529884576797485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694696128368378,
      "backward_entropy": 0.0968140619141715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.475566864013672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0076298494823277,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13694004714488983,
      "backward_entropy": 0.09697266987391881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.302096366882324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007730237208306789,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693228363990784,
      "backward_entropy": 0.09680186850684029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753631591796875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007830891758203506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692408800125122,
      "backward_entropy": 0.09687318972178868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.455013275146484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007931554690003395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369156837463379,
      "backward_entropy": 0.09682190418243408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.282549858093262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008032552897930145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13690653443336487,
      "backward_entropy": 0.09653946331569127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722391128540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008133739233016968,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13689707219600677,
      "backward_entropy": 0.09656681333269392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.91421127319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008234814740717411,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13688784837722778,
      "backward_entropy": 0.09650589738573347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698488235473633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008336433209478855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368774026632309,
      "backward_entropy": 0.0963576350893293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.550580024719238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008437836542725563,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13686782121658325,
      "backward_entropy": 0.0965517589024135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.941274642944336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008539033122360706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685844838619232,
      "backward_entropy": 0.09649443626403809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.304177284240723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008640258572995663,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684868812561035,
      "backward_entropy": 0.09616137402398246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902243614196777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008741176687180996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683941960334778,
      "backward_entropy": 0.09609344175883702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.838211059570312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008841600269079208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683119416236877,
      "backward_entropy": 0.09631398745945521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.123230934143066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008942073211073875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13682271540164948,
      "backward_entropy": 0.09625095980507987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.500578880310059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009042204357683659,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13681501150131226,
      "backward_entropy": 0.0959673183304923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.88677978515625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009142199531197548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13680781424045563,
      "backward_entropy": 0.09580848046711513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.167989253997803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009242286905646324,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13680046796798706,
      "backward_entropy": 0.09605406863348824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.806440353393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009341566823422909,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367952823638916,
      "backward_entropy": 0.09573001520974296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.321338653564453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009441502392292023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136788472533226,
      "backward_entropy": 0.0955783384186881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.62288761138916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009541249834001064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678239285945892,
      "backward_entropy": 0.09549803393227714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.386940956115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00964048970490694,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367778331041336,
      "backward_entropy": 0.09547273601804461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.309840202331543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009739663451910019,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677331805229187,
      "backward_entropy": 0.09533330372401647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991061210632324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009839270263910294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367674469947815,
      "backward_entropy": 0.09524783066340856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.432037353515625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009939094074070454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367608606815338,
      "backward_entropy": 0.09516010114124843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19474983215332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010038782842457294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13675469160079956,
      "backward_entropy": 0.0954420736857823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.970635414123535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010138235054910183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674908876419067,
      "backward_entropy": 0.09499914305550712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.190799713134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010237407870590687,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674399256706238,
      "backward_entropy": 0.09489876883370536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.865405082702637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010336440987884998,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13673897087574005,
      "backward_entropy": 0.09479621478489467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.788808822631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010435681790113449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673318922519684,
      "backward_entropy": 0.09469425678253174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.312175750732422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010535098612308502,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672658801078796,
      "backward_entropy": 0.09458531652178083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9961576461792,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010634396225214005,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136720210313797,
      "backward_entropy": 0.09447646141052246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.583098411560059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010733967646956444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13671275973320007,
      "backward_entropy": 0.09480546201978411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28403377532959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010834602639079094,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670223951339722,
      "backward_entropy": 0.09470754010336739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.260648727416992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010934971272945404,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366923600435257,
      "backward_entropy": 0.09414081914084298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.119097709655762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011035047471523285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668346405029297,
      "backward_entropy": 0.09450553144727435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.796793937683105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011134848929941654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13667519390583038,
      "backward_entropy": 0.09440103599003383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.377998352050781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011234783567488194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13666625320911407,
      "backward_entropy": 0.09384012222290039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.154027938842773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011335112154483795,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366559863090515,
      "backward_entropy": 0.09365934133529663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366307258605957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011435126885771751,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13664653897285461,
      "backward_entropy": 0.09407486234392438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988792419433594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01153496652841568,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663749396800995,
      "backward_entropy": 0.0939615113394601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.103771209716797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011635073460638523,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13662737607955933,
      "backward_entropy": 0.09384500980377197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94784927368164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011735420674085617,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13661634922027588,
      "backward_entropy": 0.09372619220188685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.319594383239746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011835917830467224,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366046667098999,
      "backward_entropy": 0.09299778086798531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.503509521484375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011936163529753685,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13659362494945526,
      "backward_entropy": 0.09285659449441093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.452138900756836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012035785242915154,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658446073532104,
      "backward_entropy": 0.09271182332720075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.999613285064697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012135343626141548,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13657575845718384,
      "backward_entropy": 0.09256382499422346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.007222175598145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01223461702466011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365683376789093,
      "backward_entropy": 0.09254223108291626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.194246292114258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012334131635725498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13655999302864075,
      "backward_entropy": 0.09239826883588519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.962433815002441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012433463707566261,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365521401166916,
      "backward_entropy": 0.09282047407967704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.80872106552124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01253251451998949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13654515147209167,
      "backward_entropy": 0.09210274049213954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.232222557067871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012631249614059925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13653919100761414,
      "backward_entropy": 0.0925364579473223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654552459716797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012729919515550137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365332454442978,
      "backward_entropy": 0.09179418427603585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.24163293838501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012828747741878033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13652634620666504,
      "backward_entropy": 0.09162775959287371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.18895435333252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012926936149597168,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13652178645133972,
      "backward_entropy": 0.09208566801888603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.903214454650879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013025096617639065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13651707768440247,
      "backward_entropy": 0.0912858077457973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.082082748413086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013123612850904465,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365106850862503,
      "backward_entropy": 0.09093814236777169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79394817352295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013221997767686844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13650451600551605,
      "backward_entropy": 0.0916036708014352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.191551208496094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013320647180080414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364973485469818,
      "backward_entropy": 0.0907408424786159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.110478401184082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013419194146990776,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13649040460586548,
      "backward_entropy": 0.09126733882086617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.255731582641602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013517635874450207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364835798740387,
      "backward_entropy": 0.0901944637298584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.583820343017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013616128824651241,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364762932062149,
      "backward_entropy": 0.09000071457454137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.350017547607422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013714782893657684,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364680528640747,
      "backward_entropy": 0.09073632104056222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.116328239440918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013813459314405918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13645941019058228,
      "backward_entropy": 0.08976243223462786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231157302856445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013912034220993519,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645078241825104,
      "backward_entropy": 0.09036763225282941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42788314819336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014010523445904255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13644221425056458,
      "backward_entropy": 0.09017884731292725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.913075923919678,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014109039679169655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13643434643745422,
      "backward_entropy": 0.08998783997126988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.24934196472168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014207337982952595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364269256591797,
      "backward_entropy": 0.08890897035598755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.016350746154785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014304534532129765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364237368106842,
      "backward_entropy": 0.0886927672794887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.070624351501465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01440169382840395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13642039895057678,
      "backward_entropy": 0.08847200870513916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19129467010498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014498863369226456,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13641658425331116,
      "backward_entropy": 0.08824670314788818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.176948547363281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014596093446016312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13641276955604553,
      "backward_entropy": 0.08801651000976562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.154484272003174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014693411998450756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13640841841697693,
      "backward_entropy": 0.0877819401877267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.565330505371094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014790196903049946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13640612363815308,
      "backward_entropy": 0.08854299783706665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39278793334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01488676480948925,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13640426099300385,
      "backward_entropy": 0.08710081236703056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654441833496094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014983581379055977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13640102744102478,
      "backward_entropy": 0.087055504322052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.208393096923828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015080776065587997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363958865404129,
      "backward_entropy": 0.08680230379104614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902230262756348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015178070403635502,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363898515701294,
      "backward_entropy": 0.08762834753308978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.596883773803711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015275277197360992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13638374209403992,
      "backward_entropy": 0.08628584657396589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220179080963135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015372226946055889,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13637825846672058,
      "backward_entropy": 0.08714718478066581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.178093910217285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015468715690076351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13637447357177734,
      "backward_entropy": 0.08690132413591657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.743738174438477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015565338544547558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363697648048401,
      "backward_entropy": 0.08665205751146589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.343282699584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01566188968718052,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363646388053894,
      "backward_entropy": 0.08489797796521868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.685963153839111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015758702531456947,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363578885793686,
      "backward_entropy": 0.08491698333195277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.761528015136719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015855349600315094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635136187076569,
      "backward_entropy": 0.08462181261607579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.912075519561768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015951329842209816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13634726405143738,
      "backward_entropy": 0.0856073158127921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.028559684753418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016047373414039612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136342391371727,
      "backward_entropy": 0.08401920114244733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.482076644897461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016143565997481346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13633623719215393,
      "backward_entropy": 0.0837085587637765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.072227954864502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016240155324339867,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363278180360794,
      "backward_entropy": 0.08303984573909215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.566680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01633625477552414,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363210380077362,
      "backward_entropy": 0.08271116869790214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.868254661560059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016431618481874466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13631704449653625,
      "backward_entropy": 0.08419617584773473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.133335590362549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016527701169252396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136309415102005,
      "backward_entropy": 0.08389989818845477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.546318531036377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01662340760231018,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13630279898643494,
      "backward_entropy": 0.0820744548525129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.496024131774902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01671837829053402,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362990140914917,
      "backward_entropy": 0.08329235655920846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0479736328125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016813894733786583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362922638654709,
      "backward_entropy": 0.08138493129185267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2617573738098145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016909608617424965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13628408312797546,
      "backward_entropy": 0.08266740185873848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.511393070220947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01700442098081112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13627934455871582,
      "backward_entropy": 0.08234829562050956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.692250728607178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01709919050335884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13627411425113678,
      "backward_entropy": 0.08030555077961513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.247583389282227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017194069921970367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13626766204833984,
      "backward_entropy": 0.07993495464324951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.750547409057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017288751900196075,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13626134395599365,
      "backward_entropy": 0.07912881033761161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.927489280700684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01738296076655388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13625642657279968,
      "backward_entropy": 0.08101261513573783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3480424880981445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017477506771683693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13624924421310425,
      "backward_entropy": 0.07879212924412318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.987757205963135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017571330070495605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13624462485313416,
      "backward_entropy": 0.07840219565800258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.93855094909668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017664935439825058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13624019920825958,
      "backward_entropy": 0.07800727231161934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4437994956970215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017758939415216446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13623318076133728,
      "backward_entropy": 0.07760399580001831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.668002605438232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01785300299525261,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13622504472732544,
      "backward_entropy": 0.07719474179404122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08005142211914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01794726587831974,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362151801586151,
      "backward_entropy": 0.07878811870302473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.565291404724121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018041962757706642,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13620255887508392,
      "backward_entropy": 0.07588733094079154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6015472412109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01813668943941593,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361888200044632,
      "backward_entropy": 0.07546005078724452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.869370937347412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018230928108096123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13617652654647827,
      "backward_entropy": 0.07502949237823486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.737369537353516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018324870616197586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13616468012332916,
      "backward_entropy": 0.0750497579574585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.00026798248291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018418408930301666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13615356385707855,
      "backward_entropy": 0.07460721049989973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.336390018463135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01851172372698784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13614137470722198,
      "backward_entropy": 0.07415808950151716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.684517860412598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018603814765810966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13613423705101013,
      "backward_entropy": 0.07371116536004203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.387721061706543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018695678561925888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361270695924759,
      "backward_entropy": 0.075498138155256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2853569984436035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018788421526551247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13611476123332977,
      "backward_entropy": 0.07506610666002546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.400493621826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018881265074014664,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13610076904296875,
      "backward_entropy": 0.07187154463359288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.731413841247559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018973680213093758,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360878348350525,
      "backward_entropy": 0.07418466465813774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.00462532043457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019066503271460533,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13607171177864075,
      "backward_entropy": 0.07092513356889997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.790676593780518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01915922202169895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1360546499490738,
      "backward_entropy": 0.07044077345303126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.620241165161133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019252441823482513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13603423535823822,
      "backward_entropy": 0.07282644510269165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.423086166381836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019345298409461975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13601408898830414,
      "backward_entropy": 0.07236272948128837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.554157733917236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019437026232481003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13599814474582672,
      "backward_entropy": 0.07189529282706124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.301375389099121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01952855847775936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13598209619522095,
      "backward_entropy": 0.07142101441110883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.638898849487305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019620362669229507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13596321642398834,
      "backward_entropy": 0.07094224010195051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.796247482299805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01971127651631832,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13594716787338257,
      "backward_entropy": 0.07046069417681013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.797652244567871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019801538437604904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13593308627605438,
      "backward_entropy": 0.06731596163340978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.441187858581543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019891899079084396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13591669499874115,
      "backward_entropy": 0.06679373979568481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2541069984436035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01998209021985531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358993947505951,
      "backward_entropy": 0.06898712260382515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.965974807739258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02007133886218071,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13588586449623108,
      "backward_entropy": 0.06848738874707903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.454559803009033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02016090787947178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358688473701477,
      "backward_entropy": 0.06520687256540571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.805166244506836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02024967223405838,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585397601127625,
      "backward_entropy": 0.06747828211103167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.23958158493042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020338045433163643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13583989441394806,
      "backward_entropy": 0.06696775555610657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.533341884613037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020426351577043533,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13582436740398407,
      "backward_entropy": 0.06317859888076782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.64514684677124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020514756441116333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13580593466758728,
      "backward_entropy": 0.06304316009793963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.913005352020264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020603416487574577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357845813035965,
      "backward_entropy": 0.065413555928639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.618069171905518,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020691771060228348,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13576306402683258,
      "backward_entropy": 0.061525234154292514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5091400146484375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020779548212885857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13574181497097015,
      "backward_entropy": 0.06136184079306466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.895975112915039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020867494866251945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13571713864803314,
      "backward_entropy": 0.060789670263017924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.315854072570801,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020955203101038933,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13569176197052002,
      "backward_entropy": 0.05983990005084446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.109918117523193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021043075248599052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13566435873508453,
      "backward_entropy": 0.059635238988058906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.009141445159912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021130168810486794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356397271156311,
      "backward_entropy": 0.05905888761792864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.097586631774902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021216435357928276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13561733067035675,
      "backward_entropy": 0.05848437973431179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.529836177825928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021302785724401474,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355918049812317,
      "backward_entropy": 0.057560162884848456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.368050575256348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02138880267739296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13556572794914246,
      "backward_entropy": 0.06057993429047721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.455255031585693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02147519960999489,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355355679988861,
      "backward_entropy": 0.056408473423549106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.111992359161377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021561969071626663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13550060987472534,
      "backward_entropy": 0.05947070462363107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.798059940338135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02164812944829464,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354680359363556,
      "backward_entropy": 0.055252173117228916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.14239501953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021733442321419716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13543811440467834,
      "backward_entropy": 0.058349396501268656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.681453704833984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021818282082676888,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13540871441364288,
      "backward_entropy": 0.057786098548344204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.601150035858154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02190232276916504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13538174331188202,
      "backward_entropy": 0.05375613910811288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.234621047973633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021986454725265503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13535284996032715,
      "backward_entropy": 0.056652767317635674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3639655113220215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02206951193511486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13532817363739014,
      "backward_entropy": 0.05257256967680795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6298298835754395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022151755169034004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13530707359313965,
      "backward_entropy": 0.055514088698795865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.768362522125244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02223348617553711,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13528728485107422,
      "backward_entropy": 0.05121139969144549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.448192596435547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02231483906507492,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1352669894695282,
      "backward_entropy": 0.05082706468445914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.71120023727417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02239561267197132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13524800539016724,
      "backward_entropy": 0.05024781397410801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.077677249908447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022476045414805412,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13522760570049286,
      "backward_entropy": 0.05322502340589251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.758760929107666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022556515410542488,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13520380854606628,
      "backward_entropy": 0.05265189068658011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3285932540893555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02263677679002285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13517867028713226,
      "backward_entropy": 0.04849513939448765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3805365562438965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022716477513313293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13515424728393555,
      "backward_entropy": 0.047911414078303745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.194894313812256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02279575541615486,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13513025641441345,
      "backward_entropy": 0.050929439919335504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.027965068817139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022874508053064346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13510762155056,
      "backward_entropy": 0.046752099479947774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.252212047576904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022952569648623466,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1350855678319931,
      "backward_entropy": 0.04602281962122236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.132802963256836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023030254989862442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350628286600113,
      "backward_entropy": 0.049211978912353516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.294239521026611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023107485845685005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350395381450653,
      "backward_entropy": 0.045031138828822544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.182675361633301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023184482008218765,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13501456379890442,
      "backward_entropy": 0.044312315327780585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.437976598739624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023261114954948425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13498738408088684,
      "backward_entropy": 0.04388600162097386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.528066396713257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023336753249168396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349630355834961,
      "backward_entropy": 0.04332075800214495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.86464524269104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02341168001294136,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13494175672531128,
      "backward_entropy": 0.04261825340134757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.235653400421143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02348623052239418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13491961359977722,
      "backward_entropy": 0.045815472091947286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.005895614624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02356080897152424,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13489361107349396,
      "backward_entropy": 0.04150612439428057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.422122001647949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023635195568203926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13486507534980774,
      "backward_entropy": 0.04468877400670733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6148834228515625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023709800094366074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13483069837093353,
      "backward_entropy": 0.04052389519555228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.840043067932129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02378380112349987,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347956508398056,
      "backward_entropy": 0.04357033542224339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.123311758041382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0238575991243124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347595602273941,
      "backward_entropy": 0.03940551621573312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.514254570007324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02393040619790554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13472580909729004,
      "backward_entropy": 0.038765324013573785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1986711025238037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02400274947285652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346910446882248,
      "backward_entropy": 0.038310004132134576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.621443033218384,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024074360728263855,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1346573382616043,
      "backward_entropy": 0.03769687243870327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.940138816833496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02414580248296261,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13462147116661072,
      "backward_entropy": 0.037169145686285834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.236176013946533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024216284975409508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13458698987960815,
      "backward_entropy": 0.03670152170317514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.190316915512085,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02428637444972992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13455316424369812,
      "backward_entropy": 0.03975432685443333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0740935802459717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024355974048376083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13451820611953735,
      "backward_entropy": 0.039223168577466695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.823078155517578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024425042793154716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13448306918144226,
      "backward_entropy": 0.035130977630615234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.227369546890259,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0244933869689703,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1344497948884964,
      "backward_entropy": 0.03460724438939776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7643609046936035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024561483412981033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1344132423400879,
      "backward_entropy": 0.03410823004586356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.005509376525879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024628816172480583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13437671959400177,
      "backward_entropy": 0.03713861107826233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7139368057250977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024695783853530884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13433808088302612,
      "backward_entropy": 0.03309719903128488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5762922763824463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024762146174907684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13430048525333405,
      "backward_entropy": 0.032598993607929776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7013893127441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02482776902616024,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1342637836933136,
      "backward_entropy": 0.032168997185570855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.826875925064087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024892808869481087,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.134224995970726,
      "backward_entropy": 0.03169692839894976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8941619396209717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02495758794248104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1341840922832489,
      "backward_entropy": 0.034628493445260186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3090951442718506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02502218261361122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13413932919502258,
      "backward_entropy": 0.030651797141347612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.415295362472534,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025085890665650368,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13409607112407684,
      "backward_entropy": 0.03365093895367214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2089171409606934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025148918852210045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1340521275997162,
      "backward_entropy": 0.03317202201911381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3339221477508545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025211047381162643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1340084969997406,
      "backward_entropy": 0.03270132839679718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.309800148010254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025272585451602936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13396403193473816,
      "backward_entropy": 0.028789997100830078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.252582311630249,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025333590805530548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13391873240470886,
      "backward_entropy": 0.03177526593208313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9838379621505737,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025394050404429436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13387265801429749,
      "backward_entropy": 0.03131626972130367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4007192850112915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025453640148043633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13382790982723236,
      "backward_entropy": 0.027458107897213528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0143423080444336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025511644780635834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1337907314300537,
      "backward_entropy": 0.027037746139935086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8619208335876465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025569111108779907,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13375309109687805,
      "backward_entropy": 0.02998337149620056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.841266393661499,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02562587335705757,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13371600210666656,
      "backward_entropy": 0.026477415646825517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8040133714675903,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02568199671804905,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13367938995361328,
      "backward_entropy": 0.02608305641583034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5808076858520508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025737440213561058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13364210724830627,
      "backward_entropy": 0.025416331631796702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6814920902252197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025791998952627182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13360726833343506,
      "backward_entropy": 0.025028995105198452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5701221227645874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025845834985375404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13357138633728027,
      "backward_entropy": 0.024644366332462857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.973594069480896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02589886449277401,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13353554904460907,
      "backward_entropy": 0.027483224868774414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7067734003067017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025951866060495377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13349470496177673,
      "backward_entropy": 0.0238881345306124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5106221437454224,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02600444108247757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133452370762825,
      "backward_entropy": 0.026693893330437795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4426685571670532,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02605632320046425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13341066241264343,
      "backward_entropy": 0.026307106018066406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3542251586914062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02610744908452034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13336952030658722,
      "backward_entropy": 0.025924825242587497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5185950994491577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026157699525356293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1333286166191101,
      "backward_entropy": 0.02555032287325178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2733091115951538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02620752342045307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13328604400157928,
      "backward_entropy": 0.022085538932255337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2962604761123657,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026256466284394264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13324373960494995,
      "backward_entropy": 0.021744647196360996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3264893293380737,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026304734870791435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13320177793502808,
      "backward_entropy": 0.021410216178212847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1429191827774048,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026352379471063614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13315795361995697,
      "backward_entropy": 0.024111070803233554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3752354383468628,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026399193331599236,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13311544060707092,
      "backward_entropy": 0.02119294660431998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0359466075897217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026445727795362473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13307030498981476,
      "backward_entropy": 0.023427841918809072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2039783000946045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026491381227970123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13302753865718842,
      "backward_entropy": 0.023094534873962402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5015984773635864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026536425575613976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13298176229000092,
      "backward_entropy": 0.019824717726026262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8190507888793945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026581596583127975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1329289972782135,
      "backward_entropy": 0.01951758563518524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9647229313850403,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026625487953424454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328798532485962,
      "backward_entropy": 0.022131677184786116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8847219944000244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026668639853596687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13283228874206543,
      "backward_entropy": 0.021823463695389882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0391873121261597,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02671097032725811,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13278713822364807,
      "backward_entropy": 0.02152105314391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.050434947013855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026752745732665062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1327390968799591,
      "backward_entropy": 0.018375747970172336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8981198072433472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02679404243826866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13268743455410004,
      "backward_entropy": 0.018102507506098067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7945725321769714,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02683464251458645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13263536989688873,
      "backward_entropy": 0.02065166618142809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9214617609977722,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026874437928199768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13258489966392517,
      "backward_entropy": 0.020374023488589695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8563217520713806,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026913724839687347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13253198564052582,
      "backward_entropy": 0.017925156014306203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5744081735610962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026952557265758514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13247908651828766,
      "backward_entropy": 0.017067224851676395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8358737230300903,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026990100741386414,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13242898881435394,
      "backward_entropy": 0.019574537873268127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6224842071533203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027027316391468048,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13237768411636353,
      "backward_entropy": 0.01931890206677573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7382952570915222,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027063658460974693,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13232849538326263,
      "backward_entropy": 0.017019512397902354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.685656726360321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027099428698420525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13227742910385132,
      "backward_entropy": 0.01613000673907144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6876217126846313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027134597301483154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1322256177663803,
      "backward_entropy": 0.018587082624435425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6196657419204712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027169186621904373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.132172092795372,
      "backward_entropy": 0.016395932861736844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5802362561225891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02720319665968418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13211911916732788,
      "backward_entropy": 0.01547780420098986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5917353630065918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027236510068178177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13206632435321808,
      "backward_entropy": 0.01790194426264082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4911783039569855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02726921997964382,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13201290369033813,
      "backward_entropy": 0.01581625214644841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5288007855415344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027301045134663582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13196028769016266,
      "backward_entropy": 0.01747226289340428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4858388304710388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273321233689785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13190637528896332,
      "backward_entropy": 0.014680636780602592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.468151718378067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02736244723200798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318521946668625,
      "backward_entropy": 0.014494888484477997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6199834942817688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027392033487558365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13179773092269897,
      "backward_entropy": 0.014314332178660802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6203795671463013,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027421336621046066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1317378580570221,
      "backward_entropy": 0.014134959450789861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43558448553085327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027450548484921455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13167375326156616,
      "backward_entropy": 0.013956100812980108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38036680221557617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027478938922286034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13160890340805054,
      "backward_entropy": 0.01631718873977661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.508728563785553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02750653773546219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13154558837413788,
      "backward_entropy": 0.013615337865693229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43534398078918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027533935382962227,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13148021697998047,
      "backward_entropy": 0.014336234756878443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3416355848312378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0275608841329813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1314142644405365,
      "backward_entropy": 0.015798685806138173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39950793981552124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027587080374360085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13134989142417908,
      "backward_entropy": 0.013129879321370806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42746514081954956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027612783014774323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1312846541404724,
      "backward_entropy": 0.012976255800042833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32227665185928345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027638092637062073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1312173306941986,
      "backward_entropy": 0.015311282660279955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3611079156398773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02766268141567707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13115063309669495,
      "backward_entropy": 0.012678846716880798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2933688163757324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027686886489391327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13108360767364502,
      "backward_entropy": 0.012535448585237776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2846263349056244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771027758717537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13101664185523987,
      "backward_entropy": 0.012397306306021554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21108116209506989,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027732938528060913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.130949929356575,
      "backward_entropy": 0.01471990772656032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2722196578979492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027754561975598335,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13088510930538177,
      "backward_entropy": 0.012137234210968018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38931897282600403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027775797992944717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13082148134708405,
      "backward_entropy": 0.01201344174998147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2680467665195465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027797061949968338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13075357675552368,
      "backward_entropy": 0.01432363476072039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21604472398757935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781790681183338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13068608939647675,
      "backward_entropy": 0.011767847197396415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31640034914016724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02783782035112381,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13061870634555817,
      "backward_entropy": 0.01165210029908589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28469204902648926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02785770408809185,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13054931163787842,
      "backward_entropy": 0.012654121432985579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27470824122428894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027877138927578926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13047724962234497,
      "backward_entropy": 0.011423438787460327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26502493023872375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027896126732230186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13040268421173096,
      "backward_entropy": 0.011312782764434814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2854281961917877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02791466936469078,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1303258240222931,
      "backward_entropy": 0.013612971774169378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1315978616476059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027933157980442047,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13024687767028809,
      "backward_entropy": 0.012287526258400508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2234068661928177,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027950743213295937,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13017185032367706,
      "backward_entropy": 0.012203614626611983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14989562332630157,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027967922389507294,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1300957202911377,
      "backward_entropy": 0.012122288346290588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14324352145195007,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027984200045466423,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13002091646194458,
      "backward_entropy": 0.012046457401343755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23645371198654175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027999775484204292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12994807958602905,
      "backward_entropy": 0.010708624763148171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15569892525672913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02801533415913582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12987279891967773,
      "backward_entropy": 0.01061792139496122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14297185838222504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028030427172780037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12979881465435028,
      "backward_entropy": 0.010530109916414534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16698943078517914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02804476022720337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12972518801689148,
      "backward_entropy": 0.010446642126355852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15989497303962708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028058815747499466,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12965147197246552,
      "backward_entropy": 0.010364819850240434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16818127036094666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02807263284921646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12957793474197388,
      "backward_entropy": 0.010284494076456343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12820999324321747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02808612957596779,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12950316071510315,
      "backward_entropy": 0.010205885129315513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1555531620979309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028099246323108673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12942978739738464,
      "backward_entropy": 0.010129668882914953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14226430654525757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02811209112405777,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12935546040534973,
      "backward_entropy": 0.010054923593997955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1359395980834961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028124552220106125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12928049266338348,
      "backward_entropy": 0.012384944728442602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13292568922042847,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028136679902672768,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12920533120632172,
      "backward_entropy": 0.011363605303423745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11671238392591476,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028148433193564415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12912967801094055,
      "backward_entropy": 0.012248243604387556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09716102480888367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028159847483038902,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12905468046665192,
      "backward_entropy": 0.012183120208127158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10110172629356384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028170520439743996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12898030877113342,
      "backward_entropy": 0.00971368487392153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09965399652719498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028180845081806183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1289069801568985,
      "backward_entropy": 0.011179058679512568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12761716544628143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028190787881612778,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1288343071937561,
      "backward_entropy": 0.01113889366388321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11146741360425949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028200561180710793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1287599802017212,
      "backward_entropy": 0.009537119950566973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12253767997026443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028209993615746498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12868483364582062,
      "backward_entropy": 0.009481260819094521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09427183121442795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028219401836395264,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12860837578773499,
      "backward_entropy": 0.011025638452598028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1016671359539032,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028228485956788063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1285323053598404,
      "backward_entropy": 0.009371527603694372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06622958183288574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028237229213118553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284555196762085,
      "backward_entropy": 0.009319356509617396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09199392795562744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02824539691209793,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1283806711435318,
      "backward_entropy": 0.010926605335303716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07544812560081482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02825317345559597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12830525636672974,
      "backward_entropy": 0.00922353139945439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09162816405296326,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028260689228773117,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12823092937469482,
      "backward_entropy": 0.011614698384489332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07833456248044968,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028268076479434967,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12815606594085693,
      "backward_entropy": 0.0108457122530256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07814782112836838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028275219723582268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280815452337265,
      "backward_entropy": 0.009089953133038111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09828037023544312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028282085433602333,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12800702452659607,
      "backward_entropy": 0.00904800636427743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0711435079574585,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828899398446083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12793084979057312,
      "backward_entropy": 0.011458115918295724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06557789444923401,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028295522555708885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12785495817661285,
      "backward_entropy": 0.008965427322047097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07172509282827377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028302032500505447,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12778040766716003,
      "backward_entropy": 0.011386603116989136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06975384056568146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02830822393298149,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12770560383796692,
      "backward_entropy": 0.008887130234922682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061681196093559265,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028314242139458656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1276308000087738,
      "backward_entropy": 0.008849726191588811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06421177834272385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02831994742155075,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1275564730167389,
      "backward_entropy": 0.010671813573156084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06766141206026077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028325282037258148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12748196721076965,
      "backward_entropy": 0.008780156395265035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06934535503387451,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833053469657898,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12740720808506012,
      "backward_entropy": 0.008746734687260218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0637570321559906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028335750102996826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12733186781406403,
      "backward_entropy": 0.008713510419641222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05508454516530037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340866789221764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12725642323493958,
      "backward_entropy": 0.00868077895471028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05351661145687103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028345784172415733,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12718158960342407,
      "backward_entropy": 0.011149396853787559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06260322034358978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02835051156580448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12710732221603394,
      "backward_entropy": 0.008618605456181936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049554988741874695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028355279937386513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1270325779914856,
      "backward_entropy": 0.008587830833026342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05388427898287773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028359966352581978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12695875763893127,
      "backward_entropy": 0.011073665959494454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05472471937537193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02836466021835804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12688511610031128,
      "backward_entropy": 0.008527430040495736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04860405996441841,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028368918225169182,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12681084871292114,
      "backward_entropy": 0.011026200439248766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.043752312660217285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0283732321113348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12673722207546234,
      "backward_entropy": 0.00847113664661135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0450659804046154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028377462178468704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12666453421115875,
      "backward_entropy": 0.010981152100222451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04355773329734802,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028381379321217537,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12659209966659546,
      "backward_entropy": 0.010960581047194344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04320786893367767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02838527224957943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12652026116847992,
      "backward_entropy": 0.008391550609043666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04318933188915253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028388945385813713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12644866108894348,
      "backward_entropy": 0.008366816278014864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04121624305844307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028392639011144638,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1263773888349533,
      "backward_entropy": 0.010471635631152562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03589850291609764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028396189212799072,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12630639970302582,
      "backward_entropy": 0.0104632026382855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0353395901620388,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028399519622325897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12623625993728638,
      "backward_entropy": 0.010455902133669173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04331127554178238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028402792289853096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12616696953773499,
      "backward_entropy": 0.01044858353478568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04604647308588028,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028405914083123207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12609703838825226,
      "backward_entropy": 0.010833019656794412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039227720350027084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028409114107489586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12602610886096954,
      "backward_entropy": 0.008229034287588937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03808927536010742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028412185609340668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12595506012439728,
      "backward_entropy": 0.008207548941884722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03860018774867058,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02841506339609623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12588393688201904,
      "backward_entropy": 0.008187000240598406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0342731773853302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028418004512786865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12581267952919006,
      "backward_entropy": 0.008166188640253884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03965325281023979,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02842085063457489,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574177980422974,
      "backward_entropy": 0.010414638689586095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038371216505765915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028423547744750977,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12567013502120972,
      "backward_entropy": 0.01074205871139254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028603725135326385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028426170349121094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12559795379638672,
      "backward_entropy": 0.008106982601540429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03568797931075096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028428571298718452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1255268007516861,
      "backward_entropy": 0.008088885673454829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03309369459748268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028430549427866936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1254551112651825,
      "backward_entropy": 0.01070587124143328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03290266543626785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028432663530111313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12538348138332367,
      "backward_entropy": 0.008056027016469411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030472762882709503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028434637933969498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1253117322921753,
      "backward_entropy": 0.00803997420838901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02653573267161846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028436509892344475,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1252402365207672,
      "backward_entropy": 0.010407251971108573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03201444447040558,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028438063338398933,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1251695156097412,
      "backward_entropy": 0.010410192821707045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026161037385463715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02843964844942093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12509840726852417,
      "backward_entropy": 0.007996424500431334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021146468818187714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02844124846160412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12502804398536682,
      "backward_entropy": 0.01041530498436519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02378549426794052,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028442731127142906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12495922297239304,
      "backward_entropy": 0.007969021264995848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026945753023028374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028444141149520874,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12489114701747894,
      "backward_entropy": 0.010635216321263994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02206549048423767,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02844560518860817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12482303380966187,
      "backward_entropy": 0.010627612471580505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024982698261737823,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028447050601243973,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12475579231977463,
      "backward_entropy": 0.010425952928406852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018661104142665863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028448592871427536,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12468863278627396,
      "backward_entropy": 0.010427641017096383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020026294514536858,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028450097888708115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12462286651134491,
      "backward_entropy": 0.007903606231723512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021000169217586517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028451375663280487,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12455788254737854,
      "backward_entropy": 0.010597709034170424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020891349762678146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028452696278691292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12449335306882858,
      "backward_entropy": 0.007879687207085746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020232923328876495,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028453944250941277,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12442915141582489,
      "backward_entropy": 0.010584409747804915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01930617354810238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02845512330532074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12436529994010925,
      "backward_entropy": 0.007856790508542742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019661039113998413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028456291183829308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12430191785097122,
      "backward_entropy": 0.007845645504338401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01796218939125538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02845741994678974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1242387443780899,
      "backward_entropy": 0.007834715502602714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013962987810373306,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028458410874009132,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12417614459991455,
      "backward_entropy": 0.010560964899403709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016640210524201393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028459321707487106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12411501258611679,
      "backward_entropy": 0.007814794778823853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017839886248111725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028460286557674408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1240544468164444,
      "backward_entropy": 0.007804916373320988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019216308370232582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02846124954521656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12399393320083618,
      "backward_entropy": 0.00779506830232484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01588904857635498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028462115675210953,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12393298745155334,
      "backward_entropy": 0.010466990726334708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015309734269976616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028463125228881836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1238725334405899,
      "backward_entropy": 0.007775608450174332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014001390896737576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028464144095778465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12381257861852646,
      "backward_entropy": 0.007765609238828931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011771874502301216,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02846507728099823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1237533837556839,
      "backward_entropy": 0.0105252063700131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01330667082220316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02846601977944374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12369552254676819,
      "backward_entropy": 0.007746652300868716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01309901662170887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028466949239373207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12363827228546143,
      "backward_entropy": 0.010483507599149431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012494116090238094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028467819094657898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12358155846595764,
      "backward_entropy": 0.01051049998828343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013317251577973366,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02846846543252468,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1235254555940628,
      "backward_entropy": 0.010506901357855116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010512293316423893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028469080105423927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12346955388784409,
      "backward_entropy": 0.007712791008608682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009702070616185665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02846970595419407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12341469526290894,
      "backward_entropy": 0.007705147777284894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009527463465929031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028470421209931374,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12336105108261108,
      "backward_entropy": 0.010505265423229762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007485976442694664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02847127430140972,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12330847978591919,
      "backward_entropy": 0.010507915701184953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009633743204176426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028472209349274635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12325756251811981,
      "backward_entropy": 0.010486326047352381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00907792430371046,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02847319468855858,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12320727109909058,
      "backward_entropy": 0.010481059551239014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011451664380729198,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02847425825893879,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12315769493579865,
      "backward_entropy": 0.010475415204252516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009067324921488762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028475144878029823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12310776859521866,
      "backward_entropy": 0.007653765380382538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008451472967863083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02847599983215332,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12305837869644165,
      "backward_entropy": 0.007645626153264727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007738467771559954,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028476808220148087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12300968170166016,
      "backward_entropy": 0.010461500712803431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006907990202307701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028477642685174942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12296181917190552,
      "backward_entropy": 0.007629902235099247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009228620678186417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028478465974330902,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12291502207517624,
      "backward_entropy": 0.010521191571440016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008968471549451351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02847915142774582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1228681355714798,
      "backward_entropy": 0.007615070790052414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00535261956974864,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028479762375354767,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12282116711139679,
      "backward_entropy": 0.010445126465388707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00589583208784461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02848046086728573,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12277573347091675,
      "backward_entropy": 0.01052933612040111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006756345741450787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028481056913733482,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12273138761520386,
      "backward_entropy": 0.007594842463731766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00612113531678915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028481539338827133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12268751114606857,
      "backward_entropy": 0.007588970341852733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006299533881247044,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02848193794488907,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12264398485422134,
      "backward_entropy": 0.010539438043321882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007639499381184578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02848224528133869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12260081619024277,
      "backward_entropy": 0.007578551237072263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007361787836998701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028482496738433838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12255722284317017,
      "backward_entropy": 0.007573805217232023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004423648584634066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028482699766755104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12251336872577667,
      "backward_entropy": 0.010427662304469518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004679655656218529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028482912108302116,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12247081845998764,
      "backward_entropy": 0.010558864900044032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00410512974485755,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028483249247074127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12242923676967621,
      "backward_entropy": 0.007559897644179208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004607991315424442,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02848358266055584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12238883972167969,
      "backward_entropy": 0.007555097341537476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004302612040191889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028483925387263298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12234915792942047,
      "backward_entropy": 0.010419879640851702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004823950584977865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028484301641583443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12231028079986572,
      "backward_entropy": 0.007545466401747295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0040185945108532906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02848457172513008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12227175384759903,
      "backward_entropy": 0.010415839297430856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004980052355676889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028484921902418137,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12223399430513382,
      "backward_entropy": 0.010580130985804967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003132147016003728,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02848532423377037,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1221962422132492,
      "backward_entropy": 0.010582939854690008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003932168707251549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02848566509783268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12215971201658249,
      "backward_entropy": 0.010409097586359297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005115202162414789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028485959395766258,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12212367355823517,
      "backward_entropy": 0.010407221104417528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037727190647274256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028486080467700958,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12208724766969681,
      "backward_entropy": 0.010593714458601815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025017661973834038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028486190363764763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12205132097005844,
      "backward_entropy": 0.007516069071633475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036137497518211603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028486356139183044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12201676517724991,
      "backward_entropy": 0.0075125545263290405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028725210577249527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028486518189311028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12198252975940704,
      "backward_entropy": 0.010402565555913108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002858889289200306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028486749157309532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12194912135601044,
      "backward_entropy": 0.00750537748847689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002912714146077633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02848701924085617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12191644310951233,
      "backward_entropy": 0.007501551083156041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023139133118093014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028487244620919228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12188433110713959,
      "backward_entropy": 0.007497997688395637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002737918868660927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028487414121627808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12185319513082504,
      "backward_entropy": 0.007494747106518064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019309775670990348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028487613424658775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1218225434422493,
      "backward_entropy": 0.0074914321303367615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020873439498245716,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028487857431173325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1217929795384407,
      "backward_entropy": 0.010393251265798296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002134355716407299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028488077223300934,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12176425755023956,
      "backward_entropy": 0.010627101574625288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002028897637501359,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028488345444202423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12173619866371155,
      "backward_entropy": 0.007481305726936885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023410855792462826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02848859690129757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12170881032943726,
      "backward_entropy": 0.0074780115059443885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013757640263065696,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028488818556070328,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12168169021606445,
      "backward_entropy": 0.010634008262838637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021957652643322945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02848905324935913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12165573984384537,
      "backward_entropy": 0.00747179559298924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002010111231356859,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028489289805293083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12162996828556061,
      "backward_entropy": 0.01038359637771334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017618180718272924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028489593416452408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12160450965166092,
      "backward_entropy": 0.007465334343058723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011944554280489683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0284898579120636,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12157957255840302,
      "backward_entropy": 0.0074621981808117455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017111313063651323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028490129858255386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12155568599700928,
      "backward_entropy": 0.007459093417440142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019093552837148309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028490373864769936,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12153217941522598,
      "backward_entropy": 0.0074561600174222675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001897296984679997,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028490625321865082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12150871753692627,
      "backward_entropy": 0.007453200008187976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018831694032996893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028490863740444183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12148527055978775,
      "backward_entropy": 0.010373150663716453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016020848415791988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028491072356700897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12146183848381042,
      "backward_entropy": 0.00744753224509103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013934130547568202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028491275385022163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12143869698047638,
      "backward_entropy": 0.007444818105016436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013365615159273148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849149890244007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12141571938991547,
      "backward_entropy": 0.007442049149956022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017245194176211953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02849171869456768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12139301747083664,
      "backward_entropy": 0.010366925171443395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013207559240981936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028491903096437454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12137002497911453,
      "backward_entropy": 0.007436768284865788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001330744824372232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028492029756307602,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1213473528623581,
      "backward_entropy": 0.010660528072289057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001195290475152433,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028492160141468048,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12132492661476135,
      "backward_entropy": 0.01066280688558306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011877537472173572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849230170249939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12130287289619446,
      "backward_entropy": 0.007429989320891244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001335245673544705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028492437675595284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12128116190433502,
      "backward_entropy": 0.007427760000739779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007978536887094378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028492536395788193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12125948071479797,
      "backward_entropy": 0.010359756648540497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009767875308170915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028492668643593788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12123866379261017,
      "backward_entropy": 0.00742358501468386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010328850476071239,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02849278599023819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12121830880641937,
      "backward_entropy": 0.010357421423707689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001039565191604197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028492942452430725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12119822204113007,
      "backward_entropy": 0.007419382355042866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008847357239574194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028493158519268036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12117835879325867,
      "backward_entropy": 0.007416953465768269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009122830233536661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849338948726654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1211588978767395,
      "backward_entropy": 0.007414504885673523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010023056529462337,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028493627905845642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.121139757335186,
      "backward_entropy": 0.010351034147398812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008366544498130679,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02849387377500534,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12112066894769669,
      "backward_entropy": 0.010680029434817178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009802646236494184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028494104743003845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12110191583633423,
      "backward_entropy": 0.007407132536172867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010647765593603253,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02849433571100235,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12108315527439117,
      "backward_entropy": 0.010345799582345145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008520017727278173,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028494521975517273,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12106417119503021,
      "backward_entropy": 0.010683612099715642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008982007275335491,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028494717553257942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12104538083076477,
      "backward_entropy": 0.00740027693765504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006745052523910999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028494859114289284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12102662026882172,
      "backward_entropy": 0.007398276988949094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006853414233773947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028495056554675102,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12100832164287567,
      "backward_entropy": 0.010687865316867828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00056664296425879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849528007209301,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12099038064479828,
      "backward_entropy": 0.007393767258950642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005607851780951023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849552407860756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12097300589084625,
      "backward_entropy": 0.007391415536403656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006333235069178045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028495775535702705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12095610797405243,
      "backward_entropy": 0.010334576879228865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005756210302934051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02849600836634636,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12093943357467651,
      "backward_entropy": 0.010691146765436445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004755556583404541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028496259823441505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12092308700084686,
      "backward_entropy": 0.007384513105664935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005575961549766362,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028496526181697845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12090723216533661,
      "backward_entropy": 0.010329145405973707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048479990800842643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028496770188212395,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12089158594608307,
      "backward_entropy": 0.010692739060946874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000481096823932603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028497012332081795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1208762675523758,
      "backward_entropy": 0.007377763944012778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005379635840654373,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028497254475951195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1208612471818924,
      "backward_entropy": 0.010323854429381234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004253368533682078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028497474268078804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12084631621837616,
      "backward_entropy": 0.010322211044175284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003643376112449914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028497692197561264,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12083171308040619,
      "backward_entropy": 0.010694976363863264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003756715450435877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028497934341430664,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12081755697727203,
      "backward_entropy": 0.010695344635418482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003193969023413956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028498178347945213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12080375850200653,
      "backward_entropy": 0.0073673246162278315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046053415280766785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849842607975006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12079042196273804,
      "backward_entropy": 0.007365235792739051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004639184626284987,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849864400923252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12077702581882477,
      "backward_entropy": 0.007363307688917432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030270812567323446,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028498854488134384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12076355516910553,
      "backward_entropy": 0.010312217686857496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035674855462275445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028499063104391098,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12075048685073853,
      "backward_entropy": 0.007359532373292106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029011524748057127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028499267995357513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12073756754398346,
      "backward_entropy": 0.010309167206287384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003898130962625146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028499452397227287,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12072500586509705,
      "backward_entropy": 0.007355963545186179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003153334546368569,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02849961817264557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12071238458156586,
      "backward_entropy": 0.007354307919740677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002796292246785015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02849975973367691,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12069995701313019,
      "backward_entropy": 0.0103052875825337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022956922475714236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028499895706772804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12068778276443481,
      "backward_entropy": 0.010304148708071028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018711452139541507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028500035405158997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12067599594593048,
      "backward_entropy": 0.007349843957594463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002759723283816129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028500208631157875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12066467851400375,
      "backward_entropy": 0.007348254323005676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023994136427063495,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028500372543931007,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.120653435587883,
      "backward_entropy": 0.010300448962620326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001521250669611618,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028500529006123543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12064237892627716,
      "backward_entropy": 0.007345242159707206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001668145996518433,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028500691056251526,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12063182890415192,
      "backward_entropy": 0.010702839919498988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002501407579984516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028500854969024658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12062165141105652,
      "backward_entropy": 0.007342292794159481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002618138096295297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028500987216830254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12061145901679993,
      "backward_entropy": 0.010295713586466653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018501326849218458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028501080349087715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12060118466615677,
      "backward_entropy": 0.010294837611062186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016408946248702705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028501151129603386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1205911636352539,
      "backward_entropy": 0.010294086166790553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001733546087052673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028501223772764206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12058138847351074,
      "backward_entropy": 0.007337772420474461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012604660878423601,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028501277789473534,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1205718144774437,
      "backward_entropy": 0.007336842162268502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014659792941529304,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028501342982053757,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12056262046098709,
      "backward_entropy": 0.01070817347083773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018038561393041164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028501395136117935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1205536425113678,
      "backward_entropy": 0.010291323065757751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015757037908770144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850142866373062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1205446720123291,
      "backward_entropy": 0.007334243506193161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013738602865487337,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028501447290182114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12053582072257996,
      "backward_entropy": 0.01029031617300851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010902903886744753,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028501471504569054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12052714079618454,
      "backward_entropy": 0.010289826563426427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.915336704580113e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850150503218174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1205187514424324,
      "backward_entropy": 0.007332048778023038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.466828487347811e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850155346095562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12051066756248474,
      "backward_entropy": 0.0073312584842954364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011161578731844202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028501613065600395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12050285935401917,
      "backward_entropy": 0.007330419229609626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012748222798109055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028501687571406364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12049518525600433,
      "backward_entropy": 0.007329543786389487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.692405440844595e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850175090134144,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1204875111579895,
      "backward_entropy": 0.010716052992003304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010046636452898383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850181609392166,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1204802393913269,
      "backward_entropy": 0.010716654360294342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.493781933793798e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850186824798584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12047308683395386,
      "backward_entropy": 0.010285436042717524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.326831786893308e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028501924127340317,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12046611309051514,
      "backward_entropy": 0.007326434233358928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71123920660466e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028501976281404495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12045922875404358,
      "backward_entropy": 0.0073256998189858025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.062429358484223e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028502019122242928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12045247107744217,
      "backward_entropy": 0.010283702186175756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.669376984471455e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028502069413661957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12044592201709747,
      "backward_entropy": 0.007324346474238804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.368633330566809e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850210852921009,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12043941020965576,
      "backward_entropy": 0.010720519082886832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.387750909198076e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850216068327427,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12043310701847076,
      "backward_entropy": 0.010721080005168915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.136929732747376e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028502216562628746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1204269677400589,
      "backward_entropy": 0.010281457432678767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.420188244897872e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028502268716692924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12042099237442017,
      "backward_entropy": 0.007321675973279136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4947842727415264e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028502320870757103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12041521072387695,
      "backward_entropy": 0.007321045867034367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.496861194842495e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850237861275673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12040956318378448,
      "backward_entropy": 0.007320393409047808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.829861791222356e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028502434492111206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12040407210588455,
      "backward_entropy": 0.0073197515947478154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7642894060118124e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850249595940113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12039870768785477,
      "backward_entropy": 0.00731909168618066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4674641685560346e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028502561151981354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12039348483085632,
      "backward_entropy": 0.007318436567272458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3076681069796905e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850262075662613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12038840353488922,
      "backward_entropy": 0.010277396866253443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3383988668210804e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028502680361270905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1203833594918251,
      "backward_entropy": 0.010276829557759421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.265971074346453e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850273624062538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12037843465805054,
      "backward_entropy": 0.007316578711782183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9340802939259447e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850279025733471,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12037358433008194,
      "backward_entropy": 0.007315995969942638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4412412787787616e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028502851724624634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12036895751953125,
      "backward_entropy": 0.010275185108184814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5194127121940255e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028502902016043663,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1203644797205925,
      "backward_entropy": 0.010274678468704224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0236482163891196e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850295789539814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12036008387804031,
      "backward_entropy": 0.007314293512276241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.530662434059195e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850300818681717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12035570293664932,
      "backward_entropy": 0.010273632194314684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2662755984347314e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0285030510276556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1203514039516449,
      "backward_entropy": 0.007313264799969537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.202786319889128e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503084555268288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12034717202186584,
      "backward_entropy": 0.00731282468352999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.360466169193387e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028503112494945526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12034302949905396,
      "backward_entropy": 0.010272399655410222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.153717625536956e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850314974784851,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12033902108669281,
      "backward_entropy": 0.010271984551634108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6117701054317877e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028503183275461197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12033504247665405,
      "backward_entropy": 0.01027157689843859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6058614821522497e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850322052836418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12033115327358246,
      "backward_entropy": 0.00731106528214046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7900074201170355e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503254055976868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12032732367515564,
      "backward_entropy": 0.00731064858181136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2299125703284517e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503285720944405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12032352387905121,
      "backward_entropy": 0.007310245718274798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.137706360372249e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850332297384739,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12031979858875275,
      "backward_entropy": 0.007309803473097938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9510078345774673e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503362089395523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12031617015600204,
      "backward_entropy": 0.007309375064713615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4816942893958185e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028503406792879105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1203126311302185,
      "backward_entropy": 0.010269211871283395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6323472664225847e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503453359007835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1203092411160469,
      "backward_entropy": 0.0073084719479084015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8497919882065617e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503503650426865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12030595541000366,
      "backward_entropy": 0.0073080360889434814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9489600163069554e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028503555804491043,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.120302714407444,
      "backward_entropy": 0.010267892054149083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3383318218984641e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503596782684326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12029951065778732,
      "backward_entropy": 0.007307160113539014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4696646758238785e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850363589823246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202964186668396,
      "backward_entropy": 0.007306768425873348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4464940250036307e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028503673151135445,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12029340118169785,
      "backward_entropy": 0.010731205344200134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.546570820210036e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503714129328728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12029044330120087,
      "backward_entropy": 0.00730599622641291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2444797903299332e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850375324487686,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12028751522302628,
      "backward_entropy": 0.010266041117055076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3422875781543553e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503792360424995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12028466165065765,
      "backward_entropy": 0.007305241056850978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2062035239068791e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850383147597313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12028184533119202,
      "backward_entropy": 0.007304880768060684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.656424481363501e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503868728876114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12027908861637115,
      "backward_entropy": 0.007304517818348748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.921443052007817e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503907844424248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12027643620967865,
      "backward_entropy": 0.0073041415640286034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.662537766213063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850394882261753,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12027384340763092,
      "backward_entropy": 0.010732196271419525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0426424523757305e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503991663455963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12027133256196976,
      "backward_entropy": 0.007303417793342045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.131566573865712e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504028916358948,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12026886641979218,
      "backward_entropy": 0.010732359119824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.78386890690308e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504064306616783,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12026646733283997,
      "backward_entropy": 0.010732480457850866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.213675755541772e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850409597158432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12026412785053253,
      "backward_entropy": 0.007302448153495789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.168386673583882e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504127636551857,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12026183307170868,
      "backward_entropy": 0.010262755411011832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.758653737255372e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504157438874245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202596053481102,
      "backward_entropy": 0.007301846253020423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.547718723799335e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504187241196632,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1202574223279953,
      "backward_entropy": 0.010262199810573034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.415883267938625e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850421518087387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12025526165962219,
      "backward_entropy": 0.007301297038793564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4603482314851135e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504246845841408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12025320529937744,
      "backward_entropy": 0.007301002208675657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.505730769073125e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504278510808945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12025119364261627,
      "backward_entropy": 0.007300733987774167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.139008291938808e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850431017577648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12024923413991928,
      "backward_entropy": 0.0102611386350223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.832946044392884e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850433811545372,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12024731189012527,
      "backward_entropy": 0.010733417102268763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.787930604128633e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850436232984066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12024540454149246,
      "backward_entropy": 0.010260675634656633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.076480308867758e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850438468158245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12024353444576263,
      "backward_entropy": 0.007299706339836121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.195559085928835e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850440703332424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12024172395467758,
      "backward_entropy": 0.007299479097127914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.973244020016864e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504429385066032,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1202399730682373,
      "backward_entropy": 0.010260039142199926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.958296929340577e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504451736807823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12023826688528061,
      "backward_entropy": 0.010259826268468584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5439831006224267e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504475951194763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202366054058075,
      "backward_entropy": 0.0072988154632704595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5799527065828443e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504500165581703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12023501098155975,
      "backward_entropy": 0.007298594074589866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5698330975719728e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504524379968643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12023350596427917,
      "backward_entropy": 0.007298372685909271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.038152726730914e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504546731710434,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12023201584815979,
      "backward_entropy": 0.010734185576438904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.094027761108009e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504569083452225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12023057043552399,
      "backward_entropy": 0.007297969822372709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7439932637207676e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504587709903717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12022915482521057,
      "backward_entropy": 0.00729779207280704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.087780103465775e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850460447371006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12022779136896133,
      "backward_entropy": 0.010258471327168601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0145598682574928e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504623100161552,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12022648751735687,
      "backward_entropy": 0.007297430719648089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5428738556220196e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504639863967896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12022523581981659,
      "backward_entropy": 0.007297264145953315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.127885636582505e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850465103983879,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12022396177053452,
      "backward_entropy": 0.01073464219059263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.068923549813917e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504662215709686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12022273987531662,
      "backward_entropy": 0.007296983152627945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8613555969059234e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850467339158058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12022154033184052,
      "backward_entropy": 0.0072968580893107825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3294392121897545e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850468084216118,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12022034823894501,
      "backward_entropy": 0.010257650698934282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4375755199580453e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504686430096626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202191710472107,
      "backward_entropy": 0.0072966281856809345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.888226620394562e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504693880677223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12021803855895996,
      "backward_entropy": 0.0072965047189167565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7304290622632834e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850469946861267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12021694332361221,
      "backward_entropy": 0.010257360126291002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0640578693710268e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850470505654812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12021587789058685,
      "backward_entropy": 0.010257270719323839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0241284346411703e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504712507128716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12021483480930328,
      "backward_entropy": 0.010257158960614885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8656234033187502e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504718095064163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202138289809227,
      "backward_entropy": 0.007296089615140643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7433929997423547e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12021280825138092,
      "backward_entropy": 0.010257007820265633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8391339153822628e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850472368299961,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12021180987358093,
      "backward_entropy": 0.010735864085810525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0391491969130584e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12021081894636154,
      "backward_entropy": 0.007295861840248108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.078985746971739e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12020987272262573,
      "backward_entropy": 0.010256846036229814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.566823564455262e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12020894885063171,
      "backward_entropy": 0.010736273867743356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1594365787459537e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12020806968212128,
      "backward_entropy": 0.007295666528599603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.204955517816416e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12020720541477203,
      "backward_entropy": 0.007295605327401843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1380049045328633e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12020637840032578,
      "backward_entropy": 0.00729554146528244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2195455383334775e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504719957709312,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12020555883646011,
      "backward_entropy": 0.007295503148010799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1352665296726627e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504716232419014,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12020476162433624,
      "backward_entropy": 0.010256561849798475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.439010000278358e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504712507128716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12020395696163177,
      "backward_entropy": 0.010256522468158178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329758429681533e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504706919193268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202031672000885,
      "backward_entropy": 0.00729538021343095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.934843549468496e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850470319390297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12020240724086761,
      "backward_entropy": 0.010256485215255193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.269146410886606e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850469760596752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12020164728164673,
      "backward_entropy": 0.007295313690389905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.135742521313659e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504693880677223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12020093202590942,
      "backward_entropy": 0.010737652225153787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.358972998692479e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504690155386925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12020023167133331,
      "backward_entropy": 0.0072952402489525935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.466006314236438e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504688292741776,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12019955366849899,
      "backward_entropy": 0.010737892772470201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.267534166046971e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504686430096626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12019890546798706,
      "backward_entropy": 0.010256341525486537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.929360895606806e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504686430096626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019827216863632,
      "backward_entropy": 0.007295131151165281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.152261787268799e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504686430096626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019766867160797,
      "backward_entropy": 0.007295085915497371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.772384727402823e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504684567451477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019707262516022,
      "backward_entropy": 0.00729505398443767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.40800960177512e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504682704806328,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12019646912813187,
      "backward_entropy": 0.01073841324874333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.171267503101262e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850468084216118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201959028840065,
      "backward_entropy": 0.007294990122318268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9343822777482274e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850467897951603,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12019534409046173,
      "backward_entropy": 0.01073859738452094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2641429470459116e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850467897951603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019479274749756,
      "backward_entropy": 0.007294915616512299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.052932638387574e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850467897951603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019426375627518,
      "backward_entropy": 0.007294882621083941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6606713277033123e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850468084216118,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12019374221563339,
      "backward_entropy": 0.010255998798779078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.741687351066503e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504682704806328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019325792789459,
      "backward_entropy": 0.007294812372752598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5418395921406045e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504682704806328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019278109073639,
      "backward_entropy": 0.007294763943978718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.838056047949067e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504684567451477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019230425357819,
      "backward_entropy": 0.0072947415922369275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.295393753433018e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504686430096626,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019187211990356,
      "backward_entropy": 0.007294688905988421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0963868507806183e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504688292741776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019141018390656,
      "backward_entropy": 0.007294656974928719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.441495610128186e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504690155386925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019099295139313,
      "backward_entropy": 0.007294604820864541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9273986140433408e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504692018032074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201905757188797,
      "backward_entropy": 0.00729457288980484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6261986957033514e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504695743322372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019017338752747,
      "backward_entropy": 0.007294520735740662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.782705680852814e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850469946861267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018978595733643,
      "backward_entropy": 0.007294463792017528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2351726158831298e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850470505654812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018942832946777,
      "backward_entropy": 0.010255507060459681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.841203527419566e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504708781838417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018907070159912,
      "backward_entropy": 0.00729437917470932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.587572313610508e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504714369773865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018871307373047,
      "backward_entropy": 0.010255388915538788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3498049611371243e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504718095064163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018837034702301,
      "backward_entropy": 0.0072942908321108136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0054788646129964e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850472182035446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018804252147675,
      "backward_entropy": 0.0072942567723137995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6253397916443646e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850472740828991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018772959709167,
      "backward_entropy": 0.0072942062148026055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4048423224721773e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504731133580208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1201874315738678,
      "backward_entropy": 0.010255186685494013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.002117002713021e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504734858870506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018713355064392,
      "backward_entropy": 0.007294122129678726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.307534915895303e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504740446805954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018683552742004,
      "backward_entropy": 0.010255088763577598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3346550531423418e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504744172096252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018655240535736,
      "backward_entropy": 0.007294047091688428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2874764365733427e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850474789738655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018628418445587,
      "backward_entropy": 0.007294015160628727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1536985766724683e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850475162267685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018601596355438,
      "backward_entropy": 0.0072939763111727575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.564381914766273e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504753485322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201857477426529,
      "backward_entropy": 0.0072939518306936535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.903469085273173e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504755347967148,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1201854795217514,
      "backward_entropy": 0.010254875889846258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.627417630828859e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504759073257446,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018522620201111,
      "backward_entropy": 0.010254830121994019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.551669511940418e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504762798547745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201850026845932,
      "backward_entropy": 0.007293860827173505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.470965274729679e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504766523838043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201847642660141,
      "backward_entropy": 0.007293821445533207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3353762297092544e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850477024912834,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018454074859619,
      "backward_entropy": 0.010254721556391035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.857304413188103e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850477397441864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018433958292007,
      "backward_entropy": 0.007293771420206342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6971753537027325e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850477769970894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018412351608276,
      "backward_entropy": 0.010254651308059692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.462701662712789e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504781424999237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018391489982605,
      "backward_entropy": 0.007293710219008582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.303036942905237e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504783287644386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018372118473053,
      "backward_entropy": 0.007293670837368284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.981338008747116e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504787012934685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018352746963501,
      "backward_entropy": 0.007293648485626493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.826033617177927e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504790738224983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018333375453949,
      "backward_entropy": 0.01025451613324029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8113778799697684e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850479446351528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018315494060516,
      "backward_entropy": 0.010254491652761186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.164103645758587e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850479818880558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018299102783203,
      "backward_entropy": 0.010254451206752233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.08719892877707e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850480191409588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201828122138977,
      "backward_entropy": 0.007293550563710076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2873231248231605e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504803776741028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018263339996338,
      "backward_entropy": 0.010254386280264174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.267992347375184e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504807502031326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018249183893204,
      "backward_entropy": 0.0072934989418302265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0204440665547736e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028504809364676476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018232047557831,
      "backward_entropy": 0.010254327739988054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8017340386886644e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504811227321625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018215656280518,
      "backward_entropy": 0.007293467010770526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.602030590992399e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504813089966774,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12018199265003204,
      "backward_entropy": 0.010739857597010476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9518430366692883e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504814952611923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201818436384201,
      "backward_entropy": 0.007293421775102615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.549319060880407e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028504816815257072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018169462680817,
      "backward_entropy": 0.007293409534863063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3648220210125146e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850481867790222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018154561519623,
      "backward_entropy": 0.007293391972780228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.233763479215668e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018141150474548,
      "backward_entropy": 0.010254220238753728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7855760365014248e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018126249313354,
      "backward_entropy": 0.010254213852541787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2659028431348816e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1201811134815216,
      "backward_entropy": 0.007293345672743661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.44999078802266e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018098682165146,
      "backward_entropy": 0.007293334496872765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.579260005575179e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12018085271120071,
      "backward_entropy": 0.010739990643092565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4941955228664483e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018072605133057,
      "backward_entropy": 0.007293321192264557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8184717731628552e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12018059939146042,
      "backward_entropy": 0.010740034282207489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.328449172888213e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018048018217087,
      "backward_entropy": 0.007293306823287692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0408712114440277e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850482054054737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12018036097288132,
      "backward_entropy": 0.007293298308338437,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.577329569663504e-07,
    "avg_log_Z": 0.028504718206822873,
    "success_rate": 1.0,
    "avg_reward": 49.4,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.11,
      "1": 0.28,
      "2": 0.61
    },
    "avg_forward_entropy": 0.12019784405827522,
    "avg_backward_entropy": 0.008502701387873717,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}