{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.0770111083984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07694069544474284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704863548278809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977673530578613,
      "backward_entropy": 0.07696764998965794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.342336654663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977389812469482,
      "backward_entropy": 0.0769635902510749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.70009708404541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0001999391824938357,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097707986831665,
      "backward_entropy": 0.07695941130320232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.612785339355469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0002999362477567047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976769924163818,
      "backward_entropy": 0.07700783676571316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.695329666137695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00039993590326048434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976471900939941,
      "backward_entropy": 0.07691922452714708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.524307250976562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000499964167829603,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976163148880005,
      "backward_entropy": 0.07700520753860474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.880637168884277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005999515997245908,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975884199142456,
      "backward_entropy": 0.0770037571589152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.045943260192871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007000110344961286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975627899169922,
      "backward_entropy": 0.07693600654602051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.423558235168457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008001812966540456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097535252571106,
      "backward_entropy": 0.07700064447191027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587350845336914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009005129104480147,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975139141082764,
      "backward_entropy": 0.07699906826019287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.061497688293457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001001026132144034,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974934101104736,
      "backward_entropy": 0.07692111863030328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.853527069091797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011015088530257344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974764823913574,
      "backward_entropy": 0.07687841521369086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.222016334533691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012022124137729406,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974605083465576,
      "backward_entropy": 0.07691126399570042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426868438720703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013029042165726423,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097443699836731,
      "backward_entropy": 0.07686687840355767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.236030578613281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001403312897309661,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974282026290894,
      "backward_entropy": 0.07686077223883735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.942183494567871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015034365933388472,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974104404449463,
      "backward_entropy": 0.07685426208708021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.56418228149414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016035698354244232,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973904132843018,
      "backward_entropy": 0.07698613405227661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.91376781463623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001703915186226368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973694324493408,
      "backward_entropy": 0.07698384920756023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.934683799743652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018045553006231785,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973474979400635,
      "backward_entropy": 0.07683368523915608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.038463592529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001905109966173768,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973231792449951,
      "backward_entropy": 0.07687060700522529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.766153335571289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020056036300957203,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973013639450073,
      "backward_entropy": 0.07697641849517822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.143680572509766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002105952939018607,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972802639007569,
      "backward_entropy": 0.07697370317247179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.544095993041992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002205950440838933,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972591638565063,
      "backward_entropy": 0.07680516772800022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840819358825684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023061754181981087,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972363948822021,
      "backward_entropy": 0.07684332794613308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.375019073486328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002406330546364188,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972130298614502,
      "backward_entropy": 0.07678956455654568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7889299392700195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025066128000617027,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971907377243043,
      "backward_entropy": 0.07696127229266697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.182358741760254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002606397494673729,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971693992614746,
      "backward_entropy": 0.07677306069268121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.483224868774414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027063072193413973,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971463918685913,
      "backward_entropy": 0.07695404688517253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.375983238220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002806047210469842,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971231460571289,
      "backward_entropy": 0.07680337958865696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.521501541137695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029056237544864416,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970951318740844,
      "backward_entropy": 0.07679417398240831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.904887199401855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030054962262511253,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970654487609863,
      "backward_entropy": 0.07673569520314534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.08816909790039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003105386160314083,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970338582992553,
      "backward_entropy": 0.07672550943162706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24581241607666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003205349436029792,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970028638839721,
      "backward_entropy": 0.07676511340671116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.791420936584473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033054605592042208,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10969692468643188,
      "backward_entropy": 0.07670440938737658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.389484405517578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003405539318919182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969297885894776,
      "backward_entropy": 0.07692246966891819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.156899452209473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035053729079663754,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968930721282959,
      "backward_entropy": 0.07673319180806477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.074586868286133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036053285002708435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968571901321411,
      "backward_entropy": 0.07691152890523274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700766563415527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037053474225103855,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968221426010132,
      "backward_entropy": 0.07670989301469591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.618963241577148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0038052985910326242,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967832803726196,
      "backward_entropy": 0.07669735617107815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.537520408630371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0039051456842571497,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967422723770141,
      "backward_entropy": 0.07668422328101264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.777759552001953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004004856571555138,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109670090675354,
      "backward_entropy": 0.0766705142127143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.403173446655273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004104934632778168,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966643095016479,
      "backward_entropy": 0.07688013050291273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.031643867492676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004205210134387016,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966269969940186,
      "backward_entropy": 0.07664326826731364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.186283111572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00430504884570837,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965932607650757,
      "backward_entropy": 0.07662880420684814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.764937877655029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004404591396450996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965596437454224,
      "backward_entropy": 0.07685865958531697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.601025581359863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004503670614212751,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965290069580078,
      "backward_entropy": 0.07685082488589817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.70578670501709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004602743778377771,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964956283569335,
      "backward_entropy": 0.07653280761506823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.733153343200684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00470183277502656,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964632034301758,
      "backward_entropy": 0.07656374242570665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.905685424804688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0048009115271270275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964369773864746,
      "backward_entropy": 0.07682567172580296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.716931343078613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004900538362562656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964111089706421,
      "backward_entropy": 0.07681700918409559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.433367729187012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005000582896173,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963807106018067,
      "backward_entropy": 0.0768081612057156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.598572254180908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005100415088236332,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963503122329712,
      "backward_entropy": 0.07649376657274035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.612408638000488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0051996465772390366,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963273048400879,
      "backward_entropy": 0.07647487852308485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42593002319336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00529882637783885,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963056087493897,
      "backward_entropy": 0.07645544740888807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.684103965759277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005397893022745848,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962834358215331,
      "backward_entropy": 0.07676937845018175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.462573051452637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005496974103152752,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962607860565185,
      "backward_entropy": 0.07675882180531819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.938422203063965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005596407689154148,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096238374710083,
      "backward_entropy": 0.07635668913523357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.34907341003418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005695926491171122,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962156057357789,
      "backward_entropy": 0.0763368739022149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854525566101074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005795726552605629,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096189022064209,
      "backward_entropy": 0.07631664805942112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.936461448669434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005895521491765976,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961641073226928,
      "backward_entropy": 0.07632791333728367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.588723182678223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00599583750590682,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961338281631469,
      "backward_entropy": 0.07630530993143718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.200119972229004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006095971446484327,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961053371429444,
      "backward_entropy": 0.07628195815616184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.736377716064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006195705384016037,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960865020751953,
      "backward_entropy": 0.07625812954372829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.964590072631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006295415572822094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096064567565918,
      "backward_entropy": 0.0766645007663303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.063907623291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006395245902240276,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960346460342407,
      "backward_entropy": 0.07620794243282741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.315415382385254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006495202425867319,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960010290145875,
      "backward_entropy": 0.0766375462214152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.671204566955566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006594894919544458,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959694385528565,
      "backward_entropy": 0.07662345303429498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642204284667969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006694976706057787,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959371328353881,
      "backward_entropy": 0.07660906182395087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.330511093139648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006794941611588001,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959045886993408,
      "backward_entropy": 0.0765941407945421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.655913352966309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006894608493894339,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958787202835082,
      "backward_entropy": 0.07606180508931477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.295047760009766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006994664669036865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958513021469116,
      "backward_entropy": 0.07656238476435344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.473196983337402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007094929460436106,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958213806152343,
      "backward_entropy": 0.07600960466596815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.054300308227539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007194953039288521,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957943201065064,
      "backward_entropy": 0.07598239845699734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.641454696655273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007295041345059872,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10957672595977783,
      "backward_entropy": 0.07593990034527248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.130711555480957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007394971325993538,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957437753677368,
      "backward_entropy": 0.07592679394616021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.436964988708496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007494525518268347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095723032951355,
      "backward_entropy": 0.07647142807642619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879158020019531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007594896014779806,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10956920385360717,
      "backward_entropy": 0.07583604918585883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.525732040405273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007695185951888561,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10956635475158691,
      "backward_entropy": 0.07643152607811822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11483097076416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00779526773840189,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956352949142456,
      "backward_entropy": 0.07580910788642035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.001099586486816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00789494626224041,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956113338470459,
      "backward_entropy": 0.07577764325671726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.434940338134766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007994744926691055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955820083618165,
      "backward_entropy": 0.07636577553219265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.820074081420898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00809479970484972,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10955517292022705,
      "backward_entropy": 0.07571241590711805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.908560752868652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00819486379623413,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955157279968261,
      "backward_entropy": 0.07560395532184178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981629371643066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008294950239360332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10954769849777221,
      "backward_entropy": 0.07564299636416966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.57182788848877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008395104669034481,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954341888427735,
      "backward_entropy": 0.07626676559448242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.21047306060791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008495100773870945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10953915119171143,
      "backward_entropy": 0.07623979780409071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.809316635131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008595747873187065,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095341682434082,
      "backward_entropy": 0.07542675071292454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21938419342041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008696292527019978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10952922105789184,
      "backward_entropy": 0.07618370321061876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.291302680969238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008796494454145432,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095242977142334,
      "backward_entropy": 0.07545184426837498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.999866485595703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008896870538592339,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10951918363571167,
      "backward_entropy": 0.07612425751156277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.87612533569336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008997812867164612,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951300859451293,
      "backward_entropy": 0.07522945271597968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.702533721923828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00909862294793129,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10950711965560914,
      "backward_entropy": 0.07532434993320042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.175461769104004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009199246764183044,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950143337249756,
      "backward_entropy": 0.0751226478152805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.090782165527344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009299968369305134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10949593782424927,
      "backward_entropy": 0.07523345947265625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.084043502807617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009400722570717335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094902753829956,
      "backward_entropy": 0.0759606228934394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.268620491027832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009501502849161625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948444604873657,
      "backward_entropy": 0.07592533694373237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.06124210357666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009601902216672897,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10947890281677246,
      "backward_entropy": 0.07489135530259874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528872489929199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009702395647764206,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1094728946685791,
      "backward_entropy": 0.07503644625345866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.649458408355713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009802183136343956,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109467613697052,
      "backward_entropy": 0.07476662264929877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.88547134399414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009900842793285847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946401357650756,
      "backward_entropy": 0.07492735650804308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9283599853515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00999967660754919,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10946003198623658,
      "backward_entropy": 0.07463702890608045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.43370246887207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010098121128976345,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10945680141448974,
      "backward_entropy": 0.0756933954026964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38168716430664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010197043418884277,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945278406143188,
      "backward_entropy": 0.07475460900200738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.858099937438965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010295870713889599,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944867134094238,
      "backward_entropy": 0.07469507058461507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54123592376709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010394844226539135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944422483444213,
      "backward_entropy": 0.0746342142422994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.206537246704102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010493741370737553,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109440016746521,
      "backward_entropy": 0.0755141708585951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.645210266113281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010592435486614704,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094360113143921,
      "backward_entropy": 0.07420880264706081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.587738037109375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010691648349165916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943140983581542,
      "backward_entropy": 0.07541840606265598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.953895092010498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010790837928652763,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10942662954330444,
      "backward_entropy": 0.07438080840640598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495431900024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0108896279707551,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10942252874374389,
      "backward_entropy": 0.07531849543253581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.926878929138184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010988382622599602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10941834449768066,
      "backward_entropy": 0.07424630059136285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.198355674743652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011087805964052677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1094132661819458,
      "backward_entropy": 0.07417809963226318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.001311302185059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011187470518052578,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940775871276856,
      "backward_entropy": 0.07372075981563991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.610247611999512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01128672156482935,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940284729003906,
      "backward_entropy": 0.07363318072424994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.532156944274902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011386013589799404,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939737558364868,
      "backward_entropy": 0.07354439629448785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.630370140075684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011485249735414982,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939179658889771,
      "backward_entropy": 0.0738884343041314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.675704002380371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011585002765059471,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938527584075927,
      "backward_entropy": 0.07493023077646892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42868423461914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01168470736593008,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937870740890503,
      "backward_entropy": 0.07373298539055718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7990217208862305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011784246191382408,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10937225818634033,
      "backward_entropy": 0.07316554254955715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.469151496887207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011883256025612354,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936682224273682,
      "backward_entropy": 0.07306353251139323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.943706512451172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011981655843555927,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936233997344971,
      "backward_entropy": 0.0734865599208408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.780686378479004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012080342508852482,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935707092285156,
      "backward_entropy": 0.07461624675326878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.389053344726562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0121791772544384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935134887695312,
      "backward_entropy": 0.07331153419282702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.545059204101562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012277880683541298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934591293334961,
      "backward_entropy": 0.07448180516560872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.541085243225098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012377125211060047,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10933903455734253,
      "backward_entropy": 0.07251740826500787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502384185791016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01247681025415659,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933111906051636,
      "backward_entropy": 0.07433913151423137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.574843406677246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012576398439705372,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932302474975586,
      "backward_entropy": 0.07426471180386013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.109139442443848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012675909325480461,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10931487083435058,
      "backward_entropy": 0.07216140958997938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9388203620910645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012775631621479988,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930614471435547,
      "backward_entropy": 0.0741106006834242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.15954875946045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012874873355031013,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10929864645004272,
      "backward_entropy": 0.07403116756015354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29391860961914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012974395416676998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10929034948348999,
      "backward_entropy": 0.07254681984583537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.449295043945312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013073706068098545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10928220748901367,
      "backward_entropy": 0.07386675145890978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502792358398438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01317340787500143,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10927319526672363,
      "backward_entropy": 0.07151437467998928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.723388671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013272983953356743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10926415920257568,
      "backward_entropy": 0.07369466622670491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.937278747558594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013371997512876987,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925627946853637,
      "backward_entropy": 0.07211547427707249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.620275497436523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013470658101141453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10924890041351318,
      "backward_entropy": 0.07351631588406032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.455951690673828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013569350354373455,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092413067817688,
      "backward_entropy": 0.07094501786761814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824141979217529,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013667959719896317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10923384428024292,
      "backward_entropy": 0.0733303427696228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034416198730469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013766187243163586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10922702550888061,
      "backward_entropy": 0.07323477003309461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.408367156982422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013864747248589993,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10921918153762818,
      "backward_entropy": 0.07313692569732666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698737144470215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01396325696259737,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10921119451522827,
      "backward_entropy": 0.071391052669949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.066929817199707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014061885885894299,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10920264720916747,
      "backward_entropy": 0.0712587833404541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.755326747894287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014160795137286186,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1091933012008667,
      "backward_entropy": 0.07112471262613933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10850715637207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014259254559874535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10918519496917725,
      "backward_entropy": 0.07271960046556261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33212661743164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014358049258589745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10917624235153198,
      "backward_entropy": 0.07260839806662665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.073822975158691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014456731267273426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10916720628738404,
      "backward_entropy": 0.07249500354131062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.241266250610352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01455570850521326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10915710926055908,
      "backward_entropy": 0.06931241353352864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6046953201293945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014653961174190044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10914857387542724,
      "backward_entropy": 0.07226147916581896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.266225814819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014751739799976349,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914103984832764,
      "backward_entropy": 0.06894874572753906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.15249252319336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014849480241537094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10913326740264892,
      "backward_entropy": 0.07012282477484809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23122787475586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014947647228837013,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10912413597106933,
      "backward_entropy": 0.06996611754099528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.562789916992188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015045717358589172,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10911486148834229,
      "backward_entropy": 0.06837770011689928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167362213134766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015144435688853264,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10910358428955078,
      "backward_entropy": 0.06818162070380317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.326006889343262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015243499539792538,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909105539321899,
      "backward_entropy": 0.07150014241536458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7844929695129395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015342493541538715,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10907814502716065,
      "backward_entropy": 0.06931186384624904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.541107654571533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015441084280610085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10906589031219482,
      "backward_entropy": 0.06913879844877455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.706638813018799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015539099462330341,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10905503034591675,
      "backward_entropy": 0.06735392411549886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.206106662750244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015636172145605087,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10904661417007447,
      "backward_entropy": 0.06713407569461399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.596095085144043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01573263667523861,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090397834777832,
      "backward_entropy": 0.06860287984212239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42416763305664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015829436480998993,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1090315818786621,
      "backward_entropy": 0.06841729084650676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.666752815246582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01592637225985527,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10902270078659057,
      "backward_entropy": 0.07048577732510036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.895252227783203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0160230603069067,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10901412963867188,
      "backward_entropy": 0.06803854306538899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.916460990905762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01612016372382641,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10900405645370484,
      "backward_entropy": 0.0659763150744968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.525947093963623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016217105090618134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10899405479431153,
      "backward_entropy": 0.07000001271565755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.383756637573242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016313662752509117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10898482799530029,
      "backward_entropy": 0.06983119249343872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.414129734039307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016410380601882935,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1089748501777649,
      "backward_entropy": 0.06523415115144518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.095088481903076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016506753861904144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10896544456481934,
      "backward_entropy": 0.06948296229044597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.018115043640137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016602586954832077,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10895729064941406,
      "backward_entropy": 0.0693052609761556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.923724174499512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016698447987437248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10894864797592163,
      "backward_entropy": 0.06912512911690606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.751062393188477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016794314607977867,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10893950462341309,
      "backward_entropy": 0.06639720996220906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.582928657531738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016890062019228935,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10893025398254394,
      "backward_entropy": 0.06875763999091254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.077249526977539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016985628753900528,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10892107486724853,
      "backward_entropy": 0.06856910387674968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.542807579040527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017081888392567635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.108909273147583,
      "backward_entropy": 0.06571914752324422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9363203048706055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01717846468091011,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10889595746994019,
      "backward_entropy": 0.06548656357659234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.552974700927734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017274966463446617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1088823676109314,
      "backward_entropy": 0.06797643502553304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.949884414672852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017371736466884613,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10886744260787964,
      "backward_entropy": 0.06501244836383396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.286236763000488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017467856407165527,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10885411500930786,
      "backward_entropy": 0.06476902961730957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.969978332519531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017564764246344566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10883784294128418,
      "backward_entropy": 0.06734993722703722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5799560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01766103319823742,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1088231086730957,
      "backward_entropy": 0.06161727507909139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.127181053161621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01775706373155117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10880849361419678,
      "backward_entropy": 0.06401561366187201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.243101596832275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017853261902928352,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10879273414611816,
      "backward_entropy": 0.06669559081395467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7733049392700195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017949074506759644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10877764225006104,
      "backward_entropy": 0.06349196698930529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.175898551940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018044820055365562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1087620735168457,
      "backward_entropy": 0.06624347633785671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919395446777344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018140142783522606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10874733924865723,
      "backward_entropy": 0.0629536443286472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0549726486206055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01823553256690502,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10873266458511352,
      "backward_entropy": 0.06577144066492717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.637362957000732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018330546095967293,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1087188720703125,
      "backward_entropy": 0.06553088956409031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65950870513916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018425455316901207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1087045431137085,
      "backward_entropy": 0.06528567605548435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.088106155395508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018520941957831383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10868738889694214,
      "backward_entropy": 0.061835143301222056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.196994304656982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018615996465086937,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10867102146148681,
      "backward_entropy": 0.0647808247142368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.647518634796143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018710756674408913,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10865499973297119,
      "backward_entropy": 0.06452237235175239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8884735107421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018805526196956635,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10863817930221557,
      "backward_entropy": 0.05761396884918213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.091538906097412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01890045776963234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1086199164390564,
      "backward_entropy": 0.06399499045477973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.396159648895264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018995048478245735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10860209465026856,
      "backward_entropy": 0.06372625960244073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2538371086120605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01908949203789234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10858385562896729,
      "backward_entropy": 0.060032268365224205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.316223621368408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019183030351996422,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10856819152832031,
      "backward_entropy": 0.06317804919348823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.103508949279785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019276438280940056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1085519790649414,
      "backward_entropy": 0.05940790971120199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.243863105773926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01937028206884861,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10853296518325806,
      "backward_entropy": 0.06261237462361653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.222516059875488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01946396939456463,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10851356983184815,
      "backward_entropy": 0.05876886182361179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.82399320602417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01955813728272915,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10849130153656006,
      "backward_entropy": 0.05462158388561673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.255298137664795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019651837646961212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10846971273422241,
      "backward_entropy": 0.061727702617645264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.474827766418457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019745388999581337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10844749212265015,
      "backward_entropy": 0.0614239772160848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.514246940612793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01983831450343132,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842664241790771,
      "backward_entropy": 0.0611214107937283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.731187343597412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019931409507989883,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10840412378311157,
      "backward_entropy": 0.06081463893254598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.753781318664551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020024752244353294,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10837936401367188,
      "backward_entropy": 0.052639858590232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.245171070098877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02011835016310215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10835248231887817,
      "backward_entropy": 0.056407656934526235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.327882289886475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02021115832030773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10832760334014893,
      "backward_entropy": 0.05605414178636339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.101492404937744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020303992554545403,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1083013653755188,
      "backward_entropy": 0.05569782521989611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.972688674926758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02039606124162674,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10827716588973998,
      "backward_entropy": 0.055338104565938316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.00898551940918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02048800326883793,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10825209617614746,
      "backward_entropy": 0.05497535400920444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.014143466949463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020579161122441292,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1082289457321167,
      "backward_entropy": 0.05017326275507609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.024882793426514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020670348778367043,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10820438861846923,
      "backward_entropy": 0.05820631980895996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.851778984069824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020761538296937943,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10817830562591553,
      "backward_entropy": 0.05786351362864176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.023284435272217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02085264027118683,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10815114974975586,
      "backward_entropy": 0.05349749657842848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.375455856323242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02094304747879505,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10812540054321289,
      "backward_entropy": 0.048466662565867104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.760526657104492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02103315480053425,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10809979438781739,
      "backward_entropy": 0.048033936156166926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0812835693359375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02112319879233837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10807347297668457,
      "backward_entropy": 0.05645678440729777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.473440647125244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0212127435952425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10804816484451293,
      "backward_entropy": 0.05609753396775988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.613407611846924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021301453933119774,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10802562236785888,
      "backward_entropy": 0.04672191540400187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.306341171264648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02138950303196907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.108004891872406,
      "backward_entropy": 0.05116311046812269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.938767910003662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02147739939391613,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10798301696777343,
      "backward_entropy": 0.04583891232808431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.052080154418945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021565601229667664,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10795770883560181,
      "backward_entropy": 0.04539426830079821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.154838562011719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021652864292263985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10793625116348267,
      "backward_entropy": 0.05427308546172248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.996337413787842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021740738302469254,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10791035890579223,
      "backward_entropy": 0.04955514603190952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4865217208862305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02182835526764393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10788434743881226,
      "backward_entropy": 0.049143205086390175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9035468101501465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021916061639785767,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10785608291625977,
      "backward_entropy": 0.053137746122148305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.878374099731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022002674639225006,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10783143043518066,
      "backward_entropy": 0.043170011705822416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.480742931365967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02208898589015007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10780594348907471,
      "backward_entropy": 0.05237191253238254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.087365627288818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02217482030391693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10778141021728516,
      "backward_entropy": 0.05198615789413452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1964616775512695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022260671481490135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10775511264801026,
      "backward_entropy": 0.041826996538374156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.850558280944824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022346552461385727,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10772628784179687,
      "backward_entropy": 0.04137716690699259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.507435321807861,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022432249039411545,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10769636631011963,
      "backward_entropy": 0.05080545610851712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.502645492553711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022517569363117218,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10766671895980835,
      "backward_entropy": 0.040476487742529974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.199928283691406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02260250598192215,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10763683319091796,
      "backward_entropy": 0.04535652531517877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.274094104766846,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022687599062919617,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10760340690612794,
      "backward_entropy": 0.03957678543196784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.042782783508301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02277299016714096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1075666069984436,
      "backward_entropy": 0.044503907362620033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.617669582366943,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022857628762722015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10753110647201539,
      "backward_entropy": 0.044076856639650136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.390241622924805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022942034527659416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1074949860572815,
      "backward_entropy": 0.043649004565344915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.679057598114014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02302607335150242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10745863914489746,
      "backward_entropy": 0.0479601522286733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.724804401397705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023110052570700645,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10742034912109374,
      "backward_entropy": 0.042791909641689725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.825494766235352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02319399081170559,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10737974643707275,
      "backward_entropy": 0.03689110279083252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6055169105529785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02327718399465084,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10734063386917114,
      "backward_entropy": 0.036445912387635976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.434718608856201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023359546437859535,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10730371475219727,
      "backward_entropy": 0.036002145873175725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.754034519195557,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023441854864358902,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10726464986801147,
      "backward_entropy": 0.03556015756395128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.599156856536865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023524371907114983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10722190141677856,
      "backward_entropy": 0.04544652501742045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1581339836120605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023606115952134132,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1071805477142334,
      "backward_entropy": 0.04021237293879191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9410247802734375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023688457906246185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10713348388671876,
      "backward_entropy": 0.04459429449505276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.753395080566406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023769455030560493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10709060430526733,
      "backward_entropy": 0.04416961802376641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.144625663757324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023850014433264732,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10704772472381592,
      "backward_entropy": 0.03892719414499071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.508418560028076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023929554969072342,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10700715780258178,
      "backward_entropy": 0.043321159150865346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.073956489562988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024008501321077347,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10696622133255004,
      "backward_entropy": 0.032494419150882296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.817572116851807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024087419733405113,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10692164897918702,
      "backward_entropy": 0.04247126314375135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.289984703063965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024166164919734,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10687510967254639,
      "backward_entropy": 0.03724790281719632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.59816837310791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024244269356131554,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10682904720306396,
      "backward_entropy": 0.0416124959786733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.079111099243164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024322139099240303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10678181648254395,
      "backward_entropy": 0.03641303711467319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.74973726272583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02439931221306324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10673601627349853,
      "backward_entropy": 0.040755636162228055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8022572994232178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024476395919919014,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10668665170669556,
      "backward_entropy": 0.040325820446014404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.048154830932617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02455255761742592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10663909912109375,
      "backward_entropy": 0.03989919357829624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.900477409362793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024628164246678352,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10659170150756836,
      "backward_entropy": 0.03947411643134223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4402055740356445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024703174829483032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10654544830322266,
      "backward_entropy": 0.03905147976345486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.531851291656494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024777133017778397,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10650217533111572,
      "backward_entropy": 0.03863302535480923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4868826866149902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02485121600329876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10645437240600586,
      "backward_entropy": 0.0382118026415507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.199065208435059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024924449622631073,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10640882253646851,
      "backward_entropy": 0.027497417396969266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.257924795150757,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024997714906930923,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1063614845275879,
      "backward_entropy": 0.027102967103322346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.174134254455566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025069868192076683,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10631585121154785,
      "backward_entropy": 0.026712318261464436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.367233991622925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02514197863638401,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1062659502029419,
      "backward_entropy": 0.03654865423838297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.393601894378662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025213375687599182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10621829032897949,
      "backward_entropy": 0.036137637164857656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.597217321395874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025284120813012123,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10617153644561768,
      "backward_entropy": 0.025561342636744182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.812662363052368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025354459881782532,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10612334012985229,
      "backward_entropy": 0.03532322578959995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.162499189376831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025424713268876076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10607244968414306,
      "backward_entropy": 0.03491638435257806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6838552951812744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02549409307539463,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10602182149887085,
      "backward_entropy": 0.024445835087034438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4605886936187744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025562210008502007,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1059751033782959,
      "backward_entropy": 0.02963753541310628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.263834238052368,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02563011646270752,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10592656135559082,
      "backward_entropy": 0.02926409575674269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5432746410369873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025697557255625725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10587648153305054,
      "backward_entropy": 0.0333274867799547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4540932178497314,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02576490491628647,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10582250356674194,
      "backward_entropy": 0.02301787171098921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0672013759613037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025832146406173706,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.105765962600708,
      "backward_entropy": 0.028160128328535292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0411667823791504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025898858904838562,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10570954084396363,
      "backward_entropy": 0.02779616912206014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.364959478378296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025965001434087753,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10565242767333985,
      "backward_entropy": 0.031760970751444496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.362243890762329,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026031145825982094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10559306144714356,
      "backward_entropy": 0.03137351406945123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.202946424484253,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026097159832715988,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10552928447723389,
      "backward_entropy": 0.02672013309266832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.017981767654419,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026162998750805855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10546374320983887,
      "backward_entropy": 0.03060008419884576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8228137493133545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026228392496705055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1053961992263794,
      "backward_entropy": 0.03021667732132806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.054701805114746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026293255388736725,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10532939434051514,
      "backward_entropy": 0.0256641772058275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4455690383911133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026357846334576607,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10525956153869628,
      "backward_entropy": 0.02945955263243781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.919229507446289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026421446353197098,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10519170761108398,
      "backward_entropy": 0.024980348017480638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.557605743408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0264834463596344,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1051295280456543,
      "backward_entropy": 0.019420554240544636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2346506118774414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026544826105237007,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10506591796875,
      "backward_entropy": 0.02836894326739841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2636337280273438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026605328544974327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10500483512878418,
      "backward_entropy": 0.024000876479678683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6645790338516235,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026665138080716133,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10494616031646728,
      "backward_entropy": 0.023681312799453735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1345016956329346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026723502203822136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10489494800567627,
      "backward_entropy": 0.027334150340822008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2519874572753906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026781193912029266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10484516620635986,
      "backward_entropy": 0.027002321349249944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2343294620513916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02683837153017521,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10479388236999512,
      "backward_entropy": 0.017716207438045077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.962052822113037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026894982904195786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10473982095718384,
      "backward_entropy": 0.026346964968575373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8235971927642822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026950722560286522,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10468575954437256,
      "backward_entropy": 0.017186726133028667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.674607276916504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0270069632679224,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10462285280227661,
      "backward_entropy": 0.02186033460828993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9022704362869263,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027063483372330666,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10455316305160522,
      "backward_entropy": 0.025373493631680805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.412717342376709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027119124308228493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10448466539382935,
      "backward_entropy": 0.025052375263637967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8492655754089355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02717471495270729,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10441091060638427,
      "backward_entropy": 0.020989921357896592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8378382921218872,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02722947858273983,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1043386459350586,
      "backward_entropy": 0.015916185246573553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9430854320526123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027283519506454468,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10426807403564453,
      "backward_entropy": 0.020429760217666626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5913381576538086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027337122708559036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10419799089431762,
      "backward_entropy": 0.02380003035068512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7422455549240112,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027391420677304268,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10412122011184692,
      "backward_entropy": 0.015201288792822096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0359129905700684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027444815263152122,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10404453277587891,
      "backward_entropy": 0.023186278012063768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8267579078674316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0274979118257761,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10396420955657959,
      "backward_entropy": 0.019337268339263067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2667925357818604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02755032666027546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10388132333755493,
      "backward_entropy": 0.022586633761723835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5061317682266235,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027602992951869965,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10379180908203126,
      "backward_entropy": 0.01881449752383762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.441056489944458,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027654437348246574,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10370255708694458,
      "backward_entropy": 0.014082262913386026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3772282600402832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027704769745469093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10361509323120117,
      "backward_entropy": 0.01831476390361786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9680522680282593,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02775409072637558,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10353132486343383,
      "backward_entropy": 0.01366776062382592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3547158241271973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027803534641861916,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10344244241714477,
      "backward_entropy": 0.013464853167533875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6128135919570923,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027852099388837814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10335768461227417,
      "backward_entropy": 0.02087390919526418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5518202781677246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027900250628590584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10327118635177612,
      "backward_entropy": 0.02060332563188341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.584479570388794,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027947891503572464,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10318241119384766,
      "backward_entropy": 0.012881572047869364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3864022493362427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027995118871331215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10309011936187744,
      "backward_entropy": 0.02007164226637946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3515620231628418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028041617944836617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1029970407485962,
      "backward_entropy": 0.019811951451831393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2610961198806763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028087401762604713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10290312767028809,
      "backward_entropy": 0.016465428802702162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4154664278030396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028132587671279907,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10281319618225097,
      "backward_entropy": 0.019306815332836576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4164437055587769,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028177285566926003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10271942615509033,
      "backward_entropy": 0.01604082187016805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3173209428787231,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028221646323800087,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10262211561203002,
      "backward_entropy": 0.015833669238620333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5535190105438232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028265535831451416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10252330303192139,
      "backward_entropy": 0.015629635916815862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.463748574256897,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028309661895036697,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10242044925689697,
      "backward_entropy": 0.015425602595011393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.886756181716919,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028353700414299965,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10231277942657471,
      "backward_entropy": 0.018090710043907166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2865182161331177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02839643508195877,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10221091508865357,
      "backward_entropy": 0.017858796649509005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1945611238479614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02843896672129631,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10210697650909424,
      "backward_entropy": 0.01762893133693271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3428705930709839,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028481151908636093,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10200257301330566,
      "backward_entropy": 0.017402059502071805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6518639326095581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028523357585072517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1018939733505249,
      "backward_entropy": 0.017175787025027804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9514567852020264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02856384590268135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10179288387298584,
      "backward_entropy": 0.010559760861926608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8724462985992432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286035668104887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10169280767440796,
      "backward_entropy": 0.014089345932006836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2546206712722778,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028642436489462852,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10159502029418946,
      "backward_entropy": 0.013914755649036832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9966234564781189,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028681520372629166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10149116516113281,
      "backward_entropy": 0.013741003142462837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9470160007476807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02872016839683056,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10138652324676514,
      "backward_entropy": 0.013569934500588311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1259465217590332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028758211061358452,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10128164291381836,
      "backward_entropy": 0.013402627574072944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0257093906402588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028796426951885223,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10117350816726685,
      "backward_entropy": 0.00975748317109214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7113118767738342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028834190219640732,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1010594367980957,
      "backward_entropy": 0.015543551908599006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9867327213287354,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028871096670627594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10095174312591552,
      "backward_entropy": 0.01535308195485009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8542999625205994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028907719999551773,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10083882808685303,
      "backward_entropy": 0.015164448155297173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6779757738113403,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028943676501512527,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10072298049926758,
      "backward_entropy": 0.009270383252037896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6877542734146118,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028978444635868073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10060706138610839,
      "backward_entropy": 0.014801644616656832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5653303861618042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029012398794293404,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1004929780960083,
      "backward_entropy": 0.009049486782815721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.52195143699646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029045140370726585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10038169622421264,
      "backward_entropy": 0.01446255710389879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6299535036087036,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029076796025037766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10027527809143066,
      "backward_entropy": 0.012044758432441287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43144798278808594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029107794165611267,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10016957521438599,
      "backward_entropy": 0.011914166311422983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7179169058799744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02913738042116165,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10006742477416992,
      "backward_entropy": 0.008658373521433936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4593334197998047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02916686050593853,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09996247291564941,
      "backward_entropy": 0.008568020330535041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6345368027687073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029195314273238182,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09986088275909424,
      "backward_entropy": 0.013711137904061211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.59450364112854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029223430901765823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09975661039352417,
      "backward_entropy": 0.013571605086326599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5971099138259888,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029251327738165855,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09965274333953858,
      "backward_entropy": 0.008313044905662537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7317289113998413,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029278777539730072,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09954661130905151,
      "backward_entropy": 0.008231303758091398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4548240900039673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029306530952453613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09943503141403198,
      "backward_entropy": 0.013160713844829135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48035869002342224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02933317981660366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09932258129119872,
      "backward_entropy": 0.013029403984546661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47002583742141724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029359031468629837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09920985102653504,
      "backward_entropy": 0.012901999884181552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5267640352249146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029384197667241096,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09909698963165284,
      "backward_entropy": 0.010771182676156362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4117591083049774,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02940918318927288,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09898319244384765,
      "backward_entropy": 0.012655539645089043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5220188498497009,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029433250427246094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09886891841888427,
      "backward_entropy": 0.012537687189049192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3070307672023773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029457036405801773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09875083565711976,
      "backward_entropy": 0.010476921995480856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38308772444725037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02947974018752575,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09863698482513428,
      "backward_entropy": 0.007655145393477546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5403992533683777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0295017808675766,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09852442145347595,
      "backward_entropy": 0.01220328195227517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3926072120666504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02952415868639946,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09840871095657348,
      "backward_entropy": 0.01209436274237103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2505725026130676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029546275734901428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09829514026641846,
      "backward_entropy": 0.010120330585373772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34441787004470825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029567314311861992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09818683862686158,
      "backward_entropy": 0.011885990699132284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3603915572166443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02958764135837555,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09807791113853455,
      "backward_entropy": 0.011788095864984725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3749609887599945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029607519507408142,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09796800017356873,
      "backward_entropy": 0.007309852374924554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36685818433761597,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02962711825966835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09785653352737426,
      "backward_entropy": 0.009798947307798598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19712084531784058,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02964615821838379,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0977412223815918,
      "backward_entropy": 0.011506828996870253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.324466347694397,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029664112254977226,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09763144254684449,
      "backward_entropy": 0.011420956916279264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34253162145614624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681788757443428,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0975221872329712,
      "backward_entropy": 0.011336210701200698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28599539399147034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029698941856622696,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09740856885910035,
      "backward_entropy": 0.011253695521089766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3633127212524414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02971581555902958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09729642868041992,
      "backward_entropy": 0.011172975103060404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27881208062171936,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02973269112408161,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09718084335327148,
      "backward_entropy": 0.009388317664464315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39972084760665894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029748868197202682,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09706341028213501,
      "backward_entropy": 0.011014414330323538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26457488536834717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029765570536255836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0969428539276123,
      "backward_entropy": 0.010933997730414072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36875468492507935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029781606048345566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09682179689407348,
      "backward_entropy": 0.01085695293214586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3913590610027313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02979765087366104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09669462442398072,
      "backward_entropy": 0.010779866741763221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3105108141899109,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02981403097510338,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09656171798706055,
      "backward_entropy": 0.006797771073049969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28450915217399597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029830284416675568,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09642707109451294,
      "backward_entropy": 0.010623008840613894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2766808271408081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984631061553955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09629230499267578,
      "backward_entropy": 0.010546484755145179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29805809259414673,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02986210398375988,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09615820646286011,
      "backward_entropy": 0.008909323977099525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2774413824081421,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02987794391810894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09602408409118653,
      "backward_entropy": 0.00885151657793257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2809470295906067,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02989359200000763,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0958892822265625,
      "backward_entropy": 0.006608355376455519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2618412673473358,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02990923821926117,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09575388431549073,
      "backward_entropy": 0.008739433354801603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20016774535179138,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029924653470516205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09561725854873657,
      "backward_entropy": 0.010170896848042807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22778721153736115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029939398169517517,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09548227787017823,
      "backward_entropy": 0.01010048637787501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20335660874843597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029953552410006523,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09534522294998168,
      "backward_entropy": 0.01003311574459076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2081250250339508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029967190697789192,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09520883560180664,
      "backward_entropy": 0.00996819966369205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20228268206119537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02998090162873268,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09507574439048767,
      "backward_entropy": 0.009903139538235135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19282807409763336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02999386563897133,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09494065046310425,
      "backward_entropy": 0.009841312964757284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20460572838783264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030006611719727516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09480708837509155,
      "backward_entropy": 0.00978058659368091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21041551232337952,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03001910075545311,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09467276930809021,
      "backward_entropy": 0.009721149173047807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17845410108566284,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030031763017177582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09453966617584228,
      "backward_entropy": 0.00830990407201979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1632167398929596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030044464394450188,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09440991282463074,
      "backward_entropy": 0.009600925776693556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19961117208003998,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030056754127144814,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09428122043609619,
      "backward_entropy": 0.008223834964964125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19640909135341644,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03006899356842041,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09415066242218018,
      "backward_entropy": 0.009485373066531287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2263370156288147,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008110821247101,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09401777386665344,
      "backward_entropy": 0.0094283198316892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1402633786201477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030093474313616753,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09388082027435303,
      "backward_entropy": 0.008098352286550734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12750540673732758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030105484649538994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09374683499336242,
      "backward_entropy": 0.008057366642687056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19293847680091858,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03011680208146572,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09361523389816284,
      "backward_entropy": 0.00801864763100942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14503565430641174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030128126963973045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09348191022872925,
      "backward_entropy": 0.009208021064599356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12693201005458832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030139045789837837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09334947466850281,
      "backward_entropy": 0.009156576461262174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14274492859840393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030149616301059723,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09321945905685425,
      "backward_entropy": 0.007904840012391409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10343203693628311,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030159935355186462,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09308950901031494,
      "backward_entropy": 0.006016818185647328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11375496536493301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03016979806125164,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0929632306098938,
      "backward_entropy": 0.007834765646192763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12338331341743469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03017919696867466,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09283798933029175,
      "backward_entropy": 0.007802414397398631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12740960717201233,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030188340693712234,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09271326661109924,
      "backward_entropy": 0.005959639118777381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1160406619310379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030197301879525185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09258806705474854,
      "backward_entropy": 0.008881837957435183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11962003260850906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0302062276750803,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09246461391448975,
      "backward_entropy": 0.00883988787730535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11865994334220886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030215168371796608,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09234180450439453,
      "backward_entropy": 0.00879799160692427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10209722071886063,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022405318915844,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09221873879432678,
      "backward_entropy": 0.005888432264328003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10669903457164764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0302327498793602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09209685921669006,
      "backward_entropy": 0.007620785799291398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11568620055913925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030241476371884346,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0919763445854187,
      "backward_entropy": 0.008675245775116814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08916337788105011,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03025032766163349,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09185620546340942,
      "backward_entropy": 0.005834593541092343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11040065437555313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03025868721306324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09173673391342163,
      "backward_entropy": 0.008595064282417297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11266951262950897,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03026697225868702,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09161584377288819,
      "backward_entropy": 0.005801739792029063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11213094741106033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03027523122727871,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09149309992790222,
      "backward_entropy": 0.008518047630786896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10019173473119736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030283549800515175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09136898517608642,
      "backward_entropy": 0.008479474319352044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08975853025913239,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03029145486652851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09124337434768677,
      "backward_entropy": 0.007428292598989274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09700106829404831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03029882162809372,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09111701250076294,
      "backward_entropy": 0.008407509161366357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09397982805967331,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03030622936785221,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09099141359329224,
      "backward_entropy": 0.005731114082866245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09540879726409912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030313516035676003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09086512923240661,
      "backward_entropy": 0.007356676790449355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08840826898813248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030320873484015465,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0907382309436798,
      "backward_entropy": 0.008303266432550218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05860993638634682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030327949672937393,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09060994386672974,
      "backward_entropy": 0.008269690805011325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07716381549835205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030334359034895897,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09048362970352172,
      "backward_entropy": 0.00823900600274404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05878861993551254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030340416356921196,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09035652875900269,
      "backward_entropy": 0.007271205385526021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08101412653923035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030346084386110306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09023182392120362,
      "backward_entropy": 0.008182458579540253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06861767172813416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0303519107401371,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09010753631591797,
      "backward_entropy": 0.008154255648454031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07176905125379562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03035794012248516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08998610973358154,
      "backward_entropy": 0.00812524308760961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0651266872882843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030363675206899643,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08986334800720215,
      "backward_entropy": 0.0080975451403194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06059100478887558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030369343236088753,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08974123597145081,
      "backward_entropy": 0.008070263597700331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048653971403837204,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030375106260180473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08962143659591675,
      "backward_entropy": 0.007163974146048228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06510023772716522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030380146577954292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08950209021568298,
      "backward_entropy": 0.008018508553504944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04882750287652016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03038492426276207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08938182592391967,
      "backward_entropy": 0.007995175818602243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03756755217909813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030389444902539253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.089263653755188,
      "backward_entropy": 0.007972788479593065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06815387308597565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03039383515715599,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0891504168510437,
      "backward_entropy": 0.007951012088192834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04167379066348076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03039834089577198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08903542757034302,
      "backward_entropy": 0.007928818464279175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04715120792388916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030402565374970436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08892254829406739,
      "backward_entropy": 0.007907970084084405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048192981630563736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030406581237912178,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0888102412223816,
      "backward_entropy": 0.00788801908493042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04174035042524338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030410446226596832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08869812488555909,
      "backward_entropy": 0.007868683172596825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04335616156458855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030414095148444176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08858717679977417,
      "backward_entropy": 0.0070449743005964495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042953457683324814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03041776828467846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08847846388816834,
      "backward_entropy": 0.007831859919759963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04159571975469589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030421532690525055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08837170600891113,
      "backward_entropy": 0.0078130132622189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03845074400305748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03042537346482277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08826678395271301,
      "backward_entropy": 0.007793889277511173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04296201840043068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030429136008024216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08816317319869996,
      "backward_entropy": 0.007775174246893989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03335992991924286,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030432764440774918,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0880588412284851,
      "backward_entropy": 0.007757133079899682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04044375196099281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030436493456363678,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08795825839042663,
      "backward_entropy": 0.00773850248919593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034217000007629395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030440350994467735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08785877227783204,
      "backward_entropy": 0.007719462116559346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041784074157476425,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030444277450442314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08776136636734008,
      "backward_entropy": 0.006951460407839881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028716200962662697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030448270961642265,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0876630961894989,
      "backward_entropy": 0.0076807149582439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03801481053233147,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030452141538262367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08756732940673828,
      "backward_entropy": 0.00692674931552675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03506460413336754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030456099659204483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08747138977050781,
      "backward_entropy": 0.007642758389314015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03574267029762268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030460093170404434,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0873757004737854,
      "backward_entropy": 0.006902034497923321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02652978152036667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03046405501663685,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08727891445159912,
      "backward_entropy": 0.005544391357236438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027115916833281517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030467908829450607,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08718394637107849,
      "backward_entropy": 0.007586181163787842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033231671899557114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030471457168459892,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08708889484405517,
      "backward_entropy": 0.007569121817747752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024368159472942352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030475115403532982,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08699383735656738,
      "backward_entropy": 0.007551660140355428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02642890252172947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030478741973638535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08690135478973389,
      "backward_entropy": 0.007534358236524794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020416075363755226,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030482308939099312,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0868097960948944,
      "backward_entropy": 0.0075173866417672895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02308599464595318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03048570267856121,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08672083616256714,
      "backward_entropy": 0.006829709228542116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028879908844828606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030489103868603706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08663418292999267,
      "backward_entropy": 0.007484940191109975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026683663949370384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030492618680000305,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08654764890670777,
      "backward_entropy": 0.006810135311550564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01755666919052601,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030496200546622276,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0864614188671112,
      "backward_entropy": 0.006799918909867604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0251214150339365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03049946390092373,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08637667298316956,
      "backward_entropy": 0.007435251441266801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01951296441257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03050285577774048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08629217147827148,
      "backward_entropy": 0.007419028215938144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022280093282461166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030506275594234467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08620977401733398,
      "backward_entropy": 0.007402737935384114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01796780712902546,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030509766191244125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0861279845237732,
      "backward_entropy": 0.006761378712124295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015858806669712067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030513016507029533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08604666590690613,
      "backward_entropy": 0.007370816336737739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016396665945649147,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03051616996526718,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0859673023223877,
      "backward_entropy": 0.0073558853732215036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01633283868432045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030519183725118637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08588879108428955,
      "backward_entropy": 0.0067348600261741215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013621664606034756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030522044748067856,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08581074476242065,
      "backward_entropy": 0.00672694088684188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019165856763720512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030524859204888344,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0857354998588562,
      "backward_entropy": 0.006718947655624813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015045994892716408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030527692288160324,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08566009402275085,
      "backward_entropy": 0.005468088305658764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010523390024900436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030530471354722977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08558581471443176,
      "backward_entropy": 0.0072880395584636265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01459900476038456,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030533116310834885,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08551428318023682,
      "backward_entropy": 0.006695205552710427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010603847913444042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030535738915205002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0854431927204132,
      "backward_entropy": 0.007263026303715176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010629570111632347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030538300052285194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08537470698356628,
      "backward_entropy": 0.007250890963607364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012583346106112003,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03054078295826912,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08530826568603515,
      "backward_entropy": 0.0066728902359803515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012100804597139359,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0305433701723814,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08524342775344848,
      "backward_entropy": 0.007226961354414622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010034198872745037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030546044930815697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08518016934394837,
      "backward_entropy": 0.007214461763699849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00839762482792139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030548639595508575,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08511850237846375,
      "backward_entropy": 0.005443388389216529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007793921511620283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030551178380846977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08505932688713073,
      "backward_entropy": 0.007190583480728997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01207512617111206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030553588643670082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08500208854675292,
      "backward_entropy": 0.007179468042320675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011413801461458206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030555980280041695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08494356870651246,
      "backward_entropy": 0.007168412208557129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010079891420900822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030558407306671143,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08488454222679138,
      "backward_entropy": 0.00715720984670851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0069097052328288555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030560826882719994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08482569456100464,
      "backward_entropy": 0.007146182987425063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008300071582198143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03056306578218937,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0847686767578125,
      "backward_entropy": 0.007135986453957028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009152204729616642,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030565327033400536,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08471348881721497,
      "backward_entropy": 0.005421547426117791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009623809717595577,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030567651614546776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08465936779975891,
      "backward_entropy": 0.0071148524681727094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007067019119858742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03057008981704712,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08460562229156494,
      "backward_entropy": 0.005414564162492752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007299421820789576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03057253360748291,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08455361127853393,
      "backward_entropy": 0.007092666294839647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006563668139278889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030574794858694077,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08450143337249756,
      "backward_entropy": 0.005407380561033885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007443897891789675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030576955527067184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08445007205009461,
      "backward_entropy": 0.007072438796361287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006464991252869368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030579015612602234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08439831733703614,
      "backward_entropy": 0.007062984009583791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007013001944869757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030581064522266388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08434765338897705,
      "backward_entropy": 0.0070535846882396275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0056740520521998405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030583109706640244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08429734706878662,
      "backward_entropy": 0.007044198612372081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005702458322048187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030585123226046562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08424835205078125,
      "backward_entropy": 0.00703496237595876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005433205980807543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03058711625635624,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08420037031173706,
      "backward_entropy": 0.007025836242569817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005570716690272093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030589058995246887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08415324687957763,
      "backward_entropy": 0.006527071197827657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005373855587095022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03059086576104164,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08410601615905762,
      "backward_entropy": 0.007008579042222764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004599692765623331,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030592577531933784,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08405891060829163,
      "backward_entropy": 0.005384741144047843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004974618554115295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030594272539019585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08401333689689636,
      "backward_entropy": 0.006993301212787628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004356771241873503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03059590607881546,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08396825790405274,
      "backward_entropy": 0.006986033585336473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005385386757552624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03059743344783783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08392378687858582,
      "backward_entropy": 0.006979140142599742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037359939888119698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03059900552034378,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08387944698333741,
      "backward_entropy": 0.006971926324897342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0039925049059093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03060057945549488,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08383715152740479,
      "backward_entropy": 0.0069646694593959385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003614710411056876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03060200996696949,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08379514813423157,
      "backward_entropy": 0.006957920061217414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029442221857607365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03060348518192768,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08375494480133057,
      "backward_entropy": 0.0069509173432985944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003282836638391018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03060489520430565,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08371635675430297,
      "backward_entropy": 0.005370676517486572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003304692218080163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03060627542436123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08367878198623657,
      "backward_entropy": 0.00693759239382214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026098203379660845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03060765564441681,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08364213705062866,
      "backward_entropy": 0.006930939025349087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024900909047573805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030608998611569405,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08360697031021118,
      "backward_entropy": 0.0069244590898354845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003023941069841385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030610261484980583,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08357292413711548,
      "backward_entropy": 0.00645835946003596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030147298239171505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030611472204327583,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08353900909423828,
      "backward_entropy": 0.006454007907046212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029067399445921183,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030612602829933167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08350495100021363,
      "backward_entropy": 0.006907004449102614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002573329024016857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030613720417022705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08347107172012329,
      "backward_entropy": 0.006901741027832031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002265763934701681,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03061484917998314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08343801498413086,
      "backward_entropy": 0.006896434558762444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028694025240838528,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03061603009700775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08340633511543274,
      "backward_entropy": 0.006890959209865994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026519307866692543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03061717376112938,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08337410688400268,
      "backward_entropy": 0.006885624594158596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00188809959217906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030618272721767426,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08334164619445801,
      "backward_entropy": 0.006430390808317397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024333966430276632,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030619334429502487,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08331035375595093,
      "backward_entropy": 0.0053535811603069305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002338275546208024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030620358884334564,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08327892422676086,
      "backward_entropy": 0.00642346011267768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002480593277141452,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030621418729424477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08324799537658692,
      "backward_entropy": 0.006865575909614563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015123423654586077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030622512102127075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08321703672409057,
      "backward_entropy": 0.0068604267305798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017401386285200715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030623609200119972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08318762183189392,
      "backward_entropy": 0.006855337984032101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015236865729093552,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030624648556113243,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08315864205360413,
      "backward_entropy": 0.006409277518590291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015934946713969111,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03062567114830017,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08313071727752686,
      "backward_entropy": 0.00684580331047376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013937752228230238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030626675114035606,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0831035017967224,
      "backward_entropy": 0.006402475966347588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015800893306732178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03062770888209343,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08307763934135437,
      "backward_entropy": 0.006836504571967655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015087100910022855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030628761276602745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08305233716964722,
      "backward_entropy": 0.0068316662477122415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00143944111187011,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030629828572273254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08302748203277588,
      "backward_entropy": 0.00682679232623842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014000042574480176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03063090331852436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08300296068191529,
      "backward_entropy": 0.006821983804305394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011594474781304598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0306318961083889,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08297820687294007,
      "backward_entropy": 0.006384467913044823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001255589653737843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030632883310317993,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08295426964759826,
      "backward_entropy": 0.006813065873252021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001269357861019671,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03063386306166649,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08293066024780274,
      "backward_entropy": 0.006377852625317044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001071072882041335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030634785071015358,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08290694952011109,
      "backward_entropy": 0.00680451426241133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011193352984264493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030635666102170944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08288375139236451,
      "backward_entropy": 0.006800533996687995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008474122732877731,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030636491253972054,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.082860666513443,
      "backward_entropy": 0.006369224852985806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000920661143027246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030637294054031372,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08283865451812744,
      "backward_entropy": 0.006366542643970913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008865291601978242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030638089403510094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08281735181808472,
      "backward_entropy": 0.006789549771282408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006990357069298625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030638862401247025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08279667496681213,
      "backward_entropy": 0.006785968111621009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007615015492774546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03063962236046791,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08277707099914551,
      "backward_entropy": 0.0067824630273713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008047731826081872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03064032830297947,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08275789022445679,
      "backward_entropy": 0.00677922988931338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006543723866343498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030641021206974983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08273904919624328,
      "backward_entropy": 0.006776024070050981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008401377708651125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03064168430864811,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08272084593772888,
      "backward_entropy": 0.006772951947318183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006176640745252371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306423157453537,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0827023983001709,
      "backward_entropy": 0.006770033803251054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005338208866305649,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030642937868833542,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08268464207649232,
      "backward_entropy": 0.006767171952459548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006124367355369031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030643552541732788,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08266777992248535,
      "backward_entropy": 0.006764338248305851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006652751471847296,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030644163489341736,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08265126943588257,
      "backward_entropy": 0.005323343806796604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004535755142569542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030644726008176804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08263458013534546,
      "backward_entropy": 0.006758910086419847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005288530956022441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030645303428173065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08261885046958924,
      "backward_entropy": 0.006756251056989034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005771950236521661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030645888298749924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08260358572006225,
      "backward_entropy": 0.006753564294841554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006019260617904365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030646467581391335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08258830308914185,
      "backward_entropy": 0.006750927203231388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004366433422546834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030647028237581253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08257277011871338,
      "backward_entropy": 0.006748380760351817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005006005521863699,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030647598206996918,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0825579285621643,
      "backward_entropy": 0.006745757742060555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040308089228346944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030648192390799522,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08254339694976806,
      "backward_entropy": 0.006743041177590688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003825081221293658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03064877912402153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08252938985824584,
      "backward_entropy": 0.006740389184819328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004030884010717273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03064933978021145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08251574039459228,
      "backward_entropy": 0.006737852262126075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038363272324204445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030649911612272263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08250237107276917,
      "backward_entropy": 0.006735275189081828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030154778505675495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065045364201069,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08248915672302246,
      "backward_entropy": 0.0067328231202231515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030586469802074134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030650971457362175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08247643709182739,
      "backward_entropy": 0.006730504747894075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000347323453752324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030651481822133064,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08246422410011292,
      "backward_entropy": 0.006315935817029741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003499426820781082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030651966109871864,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08245207071304321,
      "backward_entropy": 0.006726021567980449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003210471186321229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030652422457933426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08243985176086426,
      "backward_entropy": 0.006723949892653359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037923603667877614,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030652867630124092,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08242777585983277,
      "backward_entropy": 0.006310967107613881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024205405497923493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030653247609734535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08241521120071411,
      "backward_entropy": 0.006720172448290719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020372853032313287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065362758934498,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08240321278572083,
      "backward_entropy": 0.006718395484818352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021529417426791042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030654026195406914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08239198923110962,
      "backward_entropy": 0.006306742628415425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024387055600527674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065440244972706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08238120079040527,
      "backward_entropy": 0.006714770363436805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022368277132045478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065476007759571,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08237058520317078,
      "backward_entropy": 0.006713074528508716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020435381156858057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065512329339981,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08236019611358643,
      "backward_entropy": 0.006711390283372667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000222775197471492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030655479058623314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08235013484954834,
      "backward_entropy": 0.006301310327317979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002518242981750518,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030655834823846817,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08234012722969056,
      "backward_entropy": 0.006300011856688393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020634933025576174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065616264939308,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08232986330986022,
      "backward_entropy": 0.006706570585568746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018102387548424304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065647929906845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08231971263885499,
      "backward_entropy": 0.006705060187313292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020333229622337967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065679408609867,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08230977058410645,
      "backward_entropy": 0.006703602770964305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013334437971934676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030657093971967697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08229982852935791,
      "backward_entropy": 0.006702192955546909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017021359235513955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030657390132546425,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08229044079780579,
      "backward_entropy": 0.0053090718057420515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015799925313331187,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030657675117254257,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08228116035461426,
      "backward_entropy": 0.0062933605578210615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012041898298775777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030657954514026642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08227205276489258,
      "backward_entropy": 0.00669807278447681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011037087824661285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030658239498734474,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0822634220123291,
      "backward_entropy": 0.006696710156069862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001444678200641647,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030658526346087456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0822552502155304,
      "backward_entropy": 0.006695369879404704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011890383757418022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030658802017569542,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08224709033966064,
      "backward_entropy": 0.006694059818983078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010971634765155613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065907396376133,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08223915100097656,
      "backward_entropy": 0.006692797773414188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011827706475742161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030659345909953117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08223147392272949,
      "backward_entropy": 0.006691534072160721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012250941654201597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030659610405564308,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08222385644912719,
      "backward_entropy": 0.006690304726362228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011385280959075317,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030659865587949753,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0822161853313446,
      "backward_entropy": 0.005306952943404515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.50658941292204e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030660104006528854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08220853805541992,
      "backward_entropy": 0.006687988423638874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010366745118517429,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066035732626915,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08220111131668091,
      "backward_entropy": 0.00530659407377243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.282839164370671e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030660588294267654,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0821937382221222,
      "backward_entropy": 0.0053064533405833775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.403471631230786e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030660808086395264,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08218652009963989,
      "backward_entropy": 0.00668475694126553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.042047946015373e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066100925207138,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08217939138412475,
      "backward_entropy": 0.005306265420383877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010154133633477613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030661221593618393,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08217262029647827,
      "backward_entropy": 0.006682785434855355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.691931725479662e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030661407858133316,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08216567039489746,
      "backward_entropy": 0.006681860735019048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.968121306272224e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030661582946777344,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08215873837471008,
      "backward_entropy": 0.005306071705288357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.636000373167917e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030661754310131073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08215202689170838,
      "backward_entropy": 0.006680140064822303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.149253360694274e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030661914497613907,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08214534521102905,
      "backward_entropy": 0.0066793205009566415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.910581967327744e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066205233335495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0821387529373169,
      "backward_entropy": 0.00667859489719073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6059077905956656e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066219575703144,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08213241100311279,
      "backward_entropy": 0.005306212852398555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.177700950298458e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066234290599823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08212627768516541,
      "backward_entropy": 0.006677113473415375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8357596824644133e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066249191761017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08212037682533264,
      "backward_entropy": 0.005306249277459251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0835318436147645e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066263347864151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08211472034454345,
      "backward_entropy": 0.006675669716464149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.859462205786258e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066275827586651,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08210897445678711,
      "backward_entropy": 0.006675049662590027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.756348814931698e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066287375986576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08210335373878479,
      "backward_entropy": 0.00667444368203481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5426248107105494e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030662991106510162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08209808468818665,
      "backward_entropy": 0.006673847221665912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.790573464357294e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030663104727864265,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0820928931236267,
      "backward_entropy": 0.006673293809096019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.210724753444083e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066321834921837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08208789825439453,
      "backward_entropy": 0.006672724253601498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.403412119951099e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03066333942115307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08208323717117309,
      "backward_entropy": 0.006271858596139484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4058870369335636e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030663469806313515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08207876682281494,
      "backward_entropy": 0.006671479178799523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6807270842255093e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066359832882881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08207441568374634,
      "backward_entropy": 0.006670855813556247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9087481379974633e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066372498869896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08207035064697266,
      "backward_entropy": 0.006670259353187349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.409793705737684e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030663859099149704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08206641674041748,
      "backward_entropy": 0.006269641220569611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.299933839822188e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030663998797535896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08206272721290589,
      "backward_entropy": 0.006668981578614976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3558653992949985e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066413663327694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08205926418304443,
      "backward_entropy": 0.006668354074160258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.143200435966719e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03066427819430828,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08205595016479492,
      "backward_entropy": 0.0062678853670756025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2460117179434747e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030664414167404175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08205281496047974,
      "backward_entropy": 0.006667095339960522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.184661934734322e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066454827785492,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08204975128173828,
      "backward_entropy": 0.006666490187247594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.296257298439741e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030664680525660515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08204674124717712,
      "backward_entropy": 0.00666589124335183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.98208108486142e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030664809048175812,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08204371929168701,
      "backward_entropy": 0.006665313409434425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9520201021805406e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066493384540081,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08204075098037719,
      "backward_entropy": 0.006664757927258809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5896695913397707e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03066505677998066,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08203781843185425,
      "backward_entropy": 0.006264624496301015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.809897912607994e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066517971456051,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08203500509262085,
      "backward_entropy": 0.006663634131352107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.515443636890268e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066529519855976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08203221559524536,
      "backward_entropy": 0.0066631221108966405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5614303265465423e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030665412545204163,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08202952146530151,
      "backward_entropy": 0.0066625819438033635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6181989849428646e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030665526166558266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08202685713768006,
      "backward_entropy": 0.00666207406255934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3680916708835866e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030665632337331772,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08202416896820068,
      "backward_entropy": 0.006661585221687953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.205951048177667e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066573292016983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08202159404754639,
      "backward_entropy": 0.006661144395669301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0911976460192818e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066583350300789,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08201910257339477,
      "backward_entropy": 0.0066606903241740335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0813119843078312e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030665932223200798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08201673030853271,
      "backward_entropy": 0.006660247842470805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1388518032617867e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030666029080748558,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08201445937156678,
      "backward_entropy": 0.006260654578606288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1041279321943875e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066612407565117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08201220035552978,
      "backward_entropy": 0.006659386058648427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0651832781150006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030666213482618332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08200995922088623,
      "backward_entropy": 0.0062598685423533125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0799107258208096e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030666301026940346,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08200771808624267,
      "backward_entropy": 0.006658587604761124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.15656073630089e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030666381120681763,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0820054829120636,
      "backward_entropy": 0.0066582245959175956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73237968335161e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066645935177803,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08200325965881347,
      "backward_entropy": 0.005303975608613756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.750136319373269e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066653572022915,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08200109004974365,
      "backward_entropy": 0.00665753251976437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.041210094233975e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030666610226035118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08199899196624756,
      "backward_entropy": 0.006657193932268355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.777578164474107e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030666684731841087,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08199689388275147,
      "backward_entropy": 0.006656866520643234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.172448138386244e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030666761100292206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08199485540390014,
      "backward_entropy": 0.006656519654724333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.666383342235349e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030666839331388474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08199288845062255,
      "backward_entropy": 0.006257352315717273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.888636678719195e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030666913837194443,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08199095726013184,
      "backward_entropy": 0.006257060501310561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1868692025891505e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030666988343000412,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819890856742859,
      "backward_entropy": 0.0066555047200785745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.601334239850985e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030667060986161232,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08198732137680054,
      "backward_entropy": 0.0062564801838662885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.542176495509921e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667133629322052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08198565244674683,
      "backward_entropy": 0.006654845757616891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.184487690712558e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667202547192574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08198399543762207,
      "backward_entropy": 0.006654547734393014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.847663603868568e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667267739772797,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08198235034942628,
      "backward_entropy": 0.0066542501250902815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.382341896620346e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066732920706272,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08198075294494629,
      "backward_entropy": 0.006653965761264165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.989790002378868e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030667386949062347,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08197910189628602,
      "backward_entropy": 0.005303155216905806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7721738408436067e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030667442828416824,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08197749853134155,
      "backward_entropy": 0.005303108857737647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.449657353688963e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667496845126152,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08197596073150634,
      "backward_entropy": 0.006653197109699249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6350464850111166e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066754713654518,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819744348526001,
      "backward_entropy": 0.0066529665556218885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0902897378837224e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066759742796421,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08197301626205444,
      "backward_entropy": 0.0066527339319388075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.283098410771345e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066764771938324,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08197164535522461,
      "backward_entropy": 0.006652501722176869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3860987969092093e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066769801080227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08197040557861328,
      "backward_entropy": 0.006652270754178365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.56304497270321e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667744576931,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196917176246643,
      "backward_entropy": 0.006652058826552497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4271741949632997e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066778928041458,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196797966957092,
      "backward_entropy": 0.006651854349507226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.177901589879184e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667833983898163,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196682929992676,
      "backward_entropy": 0.006651662704017427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.799967208171438e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030667873099446297,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08196567893028259,
      "backward_entropy": 0.006253134045335982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.100104211422149e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066791407763958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196458816528321,
      "backward_entropy": 0.006651278999116685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7369897022945224e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667953193187714,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196350336074829,
      "backward_entropy": 0.006651099771261215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.912515017465921e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667992308735847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196250200271607,
      "backward_entropy": 0.006650921785169178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.148550493075163e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668029561638832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08196151852607728,
      "backward_entropy": 0.006650752905342314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6852468434080947e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030668064951896667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08196051120758056,
      "backward_entropy": 0.006252309100495445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6083066611827235e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030668098479509354,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08195955753326416,
      "backward_entropy": 0.0053026556140846675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3369012776820455e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066813200712204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195862770080567,
      "backward_entropy": 0.006650285588370429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5473160601686686e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668165534734726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195775747299194,
      "backward_entropy": 0.006650128298335605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6672803440087591e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668197199702263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195695877075196,
      "backward_entropy": 0.006649993360042572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9890924249921227e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306682251393795,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195613622665406,
      "backward_entropy": 0.006649861319197549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.785198037396185e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066824935376644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08195531368255615,
      "backward_entropy": 0.005302596009439892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5497371350647882e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668271705508232,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195446729660034,
      "backward_entropy": 0.006649644838439094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.867651442618808e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668292194604874,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195362091064454,
      "backward_entropy": 0.006649555017550786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.054358676810807e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668312683701515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195282220840454,
      "backward_entropy": 0.006649453606870439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.33072467178863e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668333172798157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08195205926895141,
      "backward_entropy": 0.006649359232849545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.411249154960387e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306683499366045,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819512963294983,
      "backward_entropy": 0.006649279759989845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.978337978580385e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668368563055992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819506049156189,
      "backward_entropy": 0.006649185799890094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.557635169381683e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030668387189507484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0819499671459198,
      "backward_entropy": 0.006250802427530289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2767960697601666e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668405815958977,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194935321807861,
      "backward_entropy": 0.006649014436536365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0390682518846006e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066842071712017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08194871544837952,
      "backward_entropy": 0.005302757024765015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.455175025621429e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668433755636215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194808959960938,
      "backward_entropy": 0.0066488757729530334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.575175911573751e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066844865679741,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194748759269714,
      "backward_entropy": 0.006648810373412238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.591415058210259e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668461695313454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194689750671387,
      "backward_entropy": 0.006648747871319453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.361977398228191e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306684747338295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194633722305297,
      "backward_entropy": 0.006648684955305523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.605878297705203e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668487772345543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194580078125,
      "backward_entropy": 0.006648623281055027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.607355883010314e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668500810861588,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194528818130493,
      "backward_entropy": 0.006648563676410251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.995311198603304e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668511986732483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194476366043091,
      "backward_entropy": 0.00664850738313463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.890666099934606e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066852316260338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194425702095032,
      "backward_entropy": 0.00664845605691274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.698578201598139e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668532475829124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194372653961182,
      "backward_entropy": 0.006648400591479408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.799442869327322e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066853992640972,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819432258605957,
      "backward_entropy": 0.006648357543680403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.779460477446264e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066854551434517,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08194271326065064,
      "backward_entropy": 0.00530304138859113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.914689040764642e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668549239635468,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819421648979187,
      "backward_entropy": 0.006648296283351051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.894947155913542e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030668552964925766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08194162845611572,
      "backward_entropy": 0.0062498003244400024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6558276406140067e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668556690216064,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194112777709961,
      "backward_entropy": 0.006648246198892593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.874711526601459e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030668562278151512,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08194063901901245,
      "backward_entropy": 0.0053032243417369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8322841671979404e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066856786608696,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08194022178649903,
      "backward_entropy": 0.006648182041115231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1733608213689877e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668575316667557,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819398283958435,
      "backward_entropy": 0.006648156378004286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.965509793284582e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668580904603004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.081939435005188,
      "backward_entropy": 0.006648112916284137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.894240651585278e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306685883551836,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193905353546142,
      "backward_entropy": 0.006648078560829163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8450778561127663e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306685958057642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193871974945069,
      "backward_entropy": 0.0066480545534027945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.708317197175347e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668601393699646,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193839192390442,
      "backward_entropy": 0.00664801730049981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3957141454266093e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030668606981635094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08193806409835816,
      "backward_entropy": 0.006249378124872844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.651582858310576e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066861256957054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193773031234741,
      "backward_entropy": 0.006647956040170457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.036375974512339e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066861629486084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819373905658722,
      "backward_entropy": 0.006647936171955532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7705667093869124e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066862002015114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819370687007904,
      "backward_entropy": 0.006647905541790856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3769752033331315e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668623745441437,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193674087524414,
      "backward_entropy": 0.006647882362206777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.435004293171005e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668627470731735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193644285202026,
      "backward_entropy": 0.006647870772414737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.668226019546637e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668633058667183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193614482879638,
      "backward_entropy": 0.006647837658723195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8139731139399373e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066863864660263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193587064743042,
      "backward_entropy": 0.006647813651296828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0309558124154137e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066864423453808,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193559646606445,
      "backward_entropy": 0.006647783021132152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.807195388892069e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668647959828377,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193532824516296,
      "backward_entropy": 0.006647764394680659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7690727815988794e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668651685118675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193506002426147,
      "backward_entropy": 0.006647748665677177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1130168076078917e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668655410408974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193480968475342,
      "backward_entropy": 0.0066477155519856345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.464502901171727e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066866099834442,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819346010684967,
      "backward_entropy": 0.006647697339455287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4927259428532125e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066866658627987,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193438649177551,
      "backward_entropy": 0.006647666295369466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1655924936349038e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668672174215317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819341778755188,
      "backward_entropy": 0.006647648082839118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.559090503013067e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668677762150764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193397521972656,
      "backward_entropy": 0.00664762987030877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.20277618975706e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668683350086212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193379640579224,
      "backward_entropy": 0.006647597170538372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.326462364038889e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066868893802166,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0819336235523224,
      "backward_entropy": 0.0066475773023234475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0255858029495357e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668694525957108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193346261978149,
      "backward_entropy": 0.006647546672158771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.519654670635646e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030668700113892555,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.08193331360816955,
      "backward_entropy": 0.006248661627372106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.760437708588142e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030668705701828003,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193316459655761,
      "backward_entropy": 0.00664749327633116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.675834095583923e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03066871128976345,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193303346633911,
      "backward_entropy": 0.006647475063800812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.383744981050768e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306687168776989,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.08193289041519165,
      "backward_entropy": 0.006647456851270463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.520929929365593e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030668722465634346,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08193275928497315,
      "backward_entropy": 0.005303772787253062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0021700559454985e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030668728053569794,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.08193262219429016,
      "backward_entropy": 0.005303776512543361,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.753537805837425e-06,
    "avg_log_Z": 0.030667935125529767,
    "success_rate": 1.0,
    "avg_reward": 58.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.1,
      "1": 0.11,
      "2": 0.79
    },
    "avg_forward_entropy": 0.08196029824018479,
    "avg_backward_entropy": 0.006472529661324288,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}