{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13846676349639891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.13852226734161377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16528606414795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1386146664619446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.4965181350708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279433250427246,
      "backward_entropy": 0.1384580612182617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.073357582092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00020004436373710632,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182784636815389,
      "backward_entropy": 0.1386099100112915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.490462303161621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0003000142751261592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827753186225891,
      "backward_entropy": 0.13850085735321044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.487442970275879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00040004897164180875,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276576201121011,
      "backward_entropy": 0.13849315643310547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.398080825805664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005001207464374602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275606632232666,
      "backward_entropy": 0.13842107057571412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.64028263092041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006001879228278995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274635076522827,
      "backward_entropy": 0.13841122388839722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.637042045593262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007003105129115283,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18273663520812988,
      "backward_entropy": 0.1384685754776001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.05924129486084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008004718692973256,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18272687991460165,
      "backward_entropy": 0.13859121799468993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.228523254394531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009004995226860046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827172040939331,
      "backward_entropy": 0.1383803129196167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4817476272583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010004898067563772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18270723025004068,
      "backward_entropy": 0.13836948871612548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.709874153137207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011002060491591692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826976736386617,
      "backward_entropy": 0.13835837841033935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37831974029541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012000914430245757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18268775939941406,
      "backward_entropy": 0.13842270374298096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.873734474182129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001300009316764772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18267770608266196,
      "backward_entropy": 0.13856987953186034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.614999771118164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014001252129673958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266711632410684,
      "backward_entropy": 0.13832318782806396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.36982536315918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015003002481535077,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826565663019816,
      "backward_entropy": 0.1383108139038086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76560115814209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016004495555534959,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18264645338058472,
      "backward_entropy": 0.1382981300354004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.341927528381348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001700689783319831,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18263641993204752,
      "backward_entropy": 0.13854892253875734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.120451927185059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018012187210842967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826258897781372,
      "backward_entropy": 0.1383596658706665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.033562660217285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019015779253095388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826153596242269,
      "backward_entropy": 0.13834843635559083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55085563659668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00200175354257226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18260498841603598,
      "backward_entropy": 0.13824403285980225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.97305965423584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002101609716191888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18259493509928384,
      "backward_entropy": 0.1382296323776245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.757651329040527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002202046336606145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18258408705393472,
      "backward_entropy": 0.1383129596710205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.244924545288086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023025553673505783,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257292111714682,
      "backward_entropy": 0.13830039501190186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.834212303161621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002403317019343376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256117900212607,
      "backward_entropy": 0.13828737735748292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.91389274597168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002504137344658375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254929780960083,
      "backward_entropy": 0.1382740020751953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.861685752868652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026050435844808817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18253684043884277,
      "backward_entropy": 0.13815007209777833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.215806007385254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002705613849684596,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825246810913086,
      "backward_entropy": 0.13824644088745117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.177515983581543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028063878417015076,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825122833251953,
      "backward_entropy": 0.1384718418121338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.89758586883545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029069604352116585,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250000476837158,
      "backward_entropy": 0.13821756839752197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.697052001953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003007645718753338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18248732884724936,
      "backward_entropy": 0.1382021427154541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.837791442871094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003107959870249033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18247505029042563,
      "backward_entropy": 0.13806073665618895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.48447322845459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00320875714533031,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18246213595072427,
      "backward_entropy": 0.13817002773284912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.117551803588867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033094638492912054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824491818745931,
      "backward_entropy": 0.13815313577651978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.713828086853027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034103442449122667,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18243577082951865,
      "backward_entropy": 0.13841493129730226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.027325630187988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003511204617097974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242226044336954,
      "backward_entropy": 0.13798058032989502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.17798137664795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036121737211942673,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240843216578165,
      "backward_entropy": 0.1380992650985718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.069581985473633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037132822908461094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239436546961466,
      "backward_entropy": 0.13808040618896483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.992253303527832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003814068855717778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18238067626953125,
      "backward_entropy": 0.1379150629043579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.224255561828613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0039145625196397305,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182367205619812,
      "backward_entropy": 0.1383575439453125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.295913696289062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004014887847006321,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18235377470652261,
      "backward_entropy": 0.13834493160247802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.372538566589355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004115070682018995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823405623435974,
      "backward_entropy": 0.13800019025802612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.997207641601562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00421516876667738,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18232736984888712,
      "backward_entropy": 0.13797898292541505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.99290943145752,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004315460100769997,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18231372038523355,
      "backward_entropy": 0.13795719146728516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.815285682678223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004415919538587332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822997728983561,
      "backward_entropy": 0.13793485164642333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.344828605651855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004516024142503738,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18228626251220703,
      "backward_entropy": 0.1382751703262329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654572486877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004615623503923416,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18227346738179526,
      "backward_entropy": 0.13826003074645996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80701732635498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004714914131909609,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822610100110372,
      "backward_entropy": 0.13769383430480958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.804449081420898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004813984502106905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18224889039993286,
      "backward_entropy": 0.1376665711402893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100987434387207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004912893287837505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18223675092061362,
      "backward_entropy": 0.13763875961303712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.954778671264648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005011334083974361,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18222540616989136,
      "backward_entropy": 0.13779010772705078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.183023452758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00510970875620842,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822142998377482,
      "backward_entropy": 0.1377643823623657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.189920425415039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0052081565372645855,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822029153505961,
      "backward_entropy": 0.13773813247680664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.180391311645508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005307102110236883,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18219067653020224,
      "backward_entropy": 0.13813973665237428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.872225761413574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005406023934483528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821786363919576,
      "backward_entropy": 0.13749101161956787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.241997718811035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00550525076687336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18216602007548013,
      "backward_entropy": 0.13765599727630615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.932150840759277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0056040240451693535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18215417861938477,
      "backward_entropy": 0.13742642402648925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.394539833068848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005702725611627102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18214227755864462,
      "backward_entropy": 0.13739321231842042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.467248916625977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005801563151180744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18212997913360596,
      "backward_entropy": 0.137359094619751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.234831809997559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005900091491639614,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18211831649144491,
      "backward_entropy": 0.1380154013633728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.002614974975586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005999161396175623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18210548162460327,
      "backward_entropy": 0.13750669956207276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.072356224060059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0060990480706095695,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820911169052124,
      "backward_entropy": 0.13796961307525635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.688607215881348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006198790390044451,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18207687139511108,
      "backward_entropy": 0.13721328973770142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.294817924499512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00629821652546525,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18206330140431723,
      "backward_entropy": 0.13792176246643068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.609341621398926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006397200748324394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18205042680104574,
      "backward_entropy": 0.13713607788085938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.228487968444824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006495910231024027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18203834692637125,
      "backward_entropy": 0.1373412251472473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981520652770996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006594186648726463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18202761809031168,
      "backward_entropy": 0.1373069167137146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.905557632446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006692457478493452,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18201684951782227,
      "backward_entropy": 0.13781960010528566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.206482887268066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006790681276470423,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820062796274821,
      "backward_entropy": 0.13723645210266114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.043829917907715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006889010313898325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18199549118677774,
      "backward_entropy": 0.13693366050720215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.037284851074219,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006987373344600201,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18198442459106445,
      "backward_entropy": 0.1371633529663086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.252251625061035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007086220663040876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18197226524353027,
      "backward_entropy": 0.13684637546539308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.889167785644531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007185172755271196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195929129918417,
      "backward_entropy": 0.13708667755126952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.891514301300049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007284003309905529,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18194677432378134,
      "backward_entropy": 0.1376454710960388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.875730514526367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007382265292108059,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18193554878234863,
      "backward_entropy": 0.13670728206634522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.258838653564453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007480940315872431,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18192370732625326,
      "backward_entropy": 0.13665827512741088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.627570152282715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007579254452139139,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18191242218017578,
      "backward_entropy": 0.13660862445831298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.040071487426758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007677438668906689,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18190101782480875,
      "backward_entropy": 0.13655799627304077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.121695518493652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007775187026709318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818908452987671,
      "backward_entropy": 0.13650696277618407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.694517135620117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007873603142797947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18187852700551352,
      "backward_entropy": 0.13679306507110595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840719223022461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007972358725965023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18186549345652261,
      "backward_entropy": 0.136398983001709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.664388656616211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008071038872003555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18185198307037354,
      "backward_entropy": 0.13670017719268798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.831504821777344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008170051500201225,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18183728059132895,
      "backward_entropy": 0.13733596801757814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.501410484313965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008268958888947964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18182241916656494,
      "backward_entropy": 0.13622708320617677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.509400367736816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008368546143174171,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18180604775746664,
      "backward_entropy": 0.1365527629852295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840376853942871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00846827682107687,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18178913990656534,
      "backward_entropy": 0.1361028552055359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.573486328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008567797020077705,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18177294731140137,
      "backward_entropy": 0.13717743158340454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.652678489685059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008667945861816406,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18175576130549112,
      "backward_entropy": 0.13713473081588745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.938385963439941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008768233470618725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18173821767171225,
      "backward_entropy": 0.13709094524383544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.594420433044434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008868345990777016,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18172033627827963,
      "backward_entropy": 0.13704631328582764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.609515190124512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008968092501163483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18170344829559326,
      "backward_entropy": 0.1362352728843689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.241416931152344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009068034589290619,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18168564637502035,
      "backward_entropy": 0.13617854118347167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.235596656799316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009167959913611412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816675861676534,
      "backward_entropy": 0.13612072467803954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.803058624267578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009267422370612621,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816502014795939,
      "backward_entropy": 0.1360613465309143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.478126525878906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009366687387228012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18163345257441202,
      "backward_entropy": 0.1360013723373413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.21798038482666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00946564506739378,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18161733945210776,
      "backward_entropy": 0.13675827980041505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.98582649230957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009564687497913837,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18160070975621542,
      "backward_entropy": 0.13587673902511596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.818467140197754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009663697332143784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18158388137817383,
      "backward_entropy": 0.13523657321929933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.811803817749023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009763060137629509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815661589304606,
      "backward_entropy": 0.1351550340652466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646429061889648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00986273493617773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18154762188593546,
      "backward_entropy": 0.1356735944747925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38161849975586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009962169453501701,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18152894576390585,
      "backward_entropy": 0.1349871873855591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.18018627166748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010061225853860378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18151132265726724,
      "backward_entropy": 0.13490229845046997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.976241111755371,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01016034372150898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18149290482203165,
      "backward_entropy": 0.13545668125152588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.327679634094238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010259912349283695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814725399017334,
      "backward_entropy": 0.1353816032409668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.384062767028809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010359548032283783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18145177761713663,
      "backward_entropy": 0.13463516235351564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37667179107666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01045928057283163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18143083651860556,
      "backward_entropy": 0.13522777557373047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.984528541564941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010559096932411194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18140939871470133,
      "backward_entropy": 0.1344467282295227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.609856128692627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010658811777830124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18138766288757324,
      "backward_entropy": 0.1350672125816345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.684412956237793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010757739655673504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18136882781982422,
      "backward_entropy": 0.13425328731536865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.631712913513184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010856510140001774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18135021130243936,
      "backward_entropy": 0.1348981261253357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.224529266357422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01095560472458601,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813302437464396,
      "backward_entropy": 0.13480961322784424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.986282348632812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011054303497076035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813110907872518,
      "backward_entropy": 0.1339525580406189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.951377868652344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011152999475598335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18129213651021323,
      "backward_entropy": 0.1346265435218811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.03264045715332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011252203024923801,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1812709371248881,
      "backward_entropy": 0.13557233810424804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.376554489135742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011351382359862328,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812498172124227,
      "backward_entropy": 0.13443604707717896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.974543571472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01145122293382883,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18122625350952148,
      "backward_entropy": 0.1354061484336853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.187156677246094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011550970375537872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18120193481445312,
      "backward_entropy": 0.13340015411376954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.78264045715332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011650738306343555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18117650349934897,
      "backward_entropy": 0.13327817916870116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.772224426269531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011750802397727966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18114976088205972,
      "backward_entropy": 0.13402788639068602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.599738121032715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01185112725943327,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18112208445866904,
      "backward_entropy": 0.13505029678344727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.588343620300293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011951107531785965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18109516302744547,
      "backward_entropy": 0.13380496501922606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.242148399353027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012051277793943882,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1810668706893921,
      "backward_entropy": 0.13485889434814452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.362679481506348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012151433154940605,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18103742599487305,
      "backward_entropy": 0.13262075185775757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.108236312866211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012251180596649647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1810083786646525,
      "backward_entropy": 0.13248236179351808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.497931480407715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012350876815617085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18097992738087973,
      "backward_entropy": 0.1333242416381836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.544724464416504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01245023775845766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18095260858535767,
      "backward_entropy": 0.13319542407989501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.535003662109375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012549331411719322,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1809259057044983,
      "backward_entropy": 0.13306378126144408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.126955032348633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012648181989789009,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18089975913365683,
      "backward_entropy": 0.13292930126190186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.441747665405273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01274713221937418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18087212244669595,
      "backward_entropy": 0.13175336122512818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10268497467041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012846310622990131,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18084315458933511,
      "backward_entropy": 0.13398517370224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65764045715332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01294554304331541,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18081291516621908,
      "backward_entropy": 0.1325061321258545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.298737525939941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013044572435319424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18078353007634482,
      "backward_entropy": 0.1323592782020569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85861873626709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01314373780041933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1807537873586019,
      "backward_entropy": 0.13220908641815185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625540733337402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013242777436971664,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1807265281677246,
      "backward_entropy": 0.133483624458313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.120185852050781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013341620564460754,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18070022265116373,
      "backward_entropy": 0.13335041999816893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.974878311157227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013441061601042747,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18066954612731934,
      "backward_entropy": 0.13176474571228028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79838752746582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013540461659431458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1806378165880839,
      "backward_entropy": 0.13039023876190187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.682880401611328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013639746233820915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1806055704752604,
      "backward_entropy": 0.13145146369934083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.161066055297852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013738855719566345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18057401974995932,
      "backward_entropy": 0.1312861680984497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.607100486755371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01383802480995655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18054266770680746,
      "backward_entropy": 0.1298222780227661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.740504264831543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013936986215412617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1805117925008138,
      "backward_entropy": 0.12962640523910524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.581718444824219,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014035328291356564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1804832617441813,
      "backward_entropy": 0.13076481819152833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.683394432067871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014133539982140064,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18045496940612793,
      "backward_entropy": 0.13218965530395507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.704982280731201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014231672510504723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18042733271916708,
      "backward_entropy": 0.13039004802703857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.440095901489258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014329255558550358,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18040176232655844,
      "backward_entropy": 0.1318679690361023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.748583793640137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01442723348736763,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18037386735280356,
      "backward_entropy": 0.13170191049575805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.891155242919922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014524680562317371,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18034905195236206,
      "backward_entropy": 0.12840142250061035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.018071174621582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014622247777879238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1803237795829773,
      "backward_entropy": 0.12818520069122313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.80103874206543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014720010571181774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1802961230278015,
      "backward_entropy": 0.12796496152877807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.096341133117676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014818338677287102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1802655259768168,
      "backward_entropy": 0.1277383804321289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.180397033691406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014916308224201202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18023576339085898,
      "backward_entropy": 0.12895299196243287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.998393058776855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01501451712101698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18020395437876383,
      "backward_entropy": 0.12727550268173218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.006749153137207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015112855471670628,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18017021814982095,
      "backward_entropy": 0.12850215435028076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.753386497497559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01521078310906887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18013803164164224,
      "backward_entropy": 0.12679498195648192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.14148998260498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015308747068047523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18010433514912924,
      "backward_entropy": 0.12654913663864137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.212778091430664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015406404621899128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18007218837738037,
      "backward_entropy": 0.12630066871643067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.404695510864258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01550383772701025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18004045883814493,
      "backward_entropy": 0.12754307985305785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429697036743164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015601171180605888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1800085504849752,
      "backward_entropy": 0.12579470872879028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.953237056732178,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01569843664765358,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17997596661249796,
      "backward_entropy": 0.12921457290649413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.060859680175781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01579538732767105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17994449536005655,
      "backward_entropy": 0.12527440786361693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.454309463500977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015892615541815758,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17991252740224203,
      "backward_entropy": 0.12877161502838136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.857606887817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015990326181054115,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17987636725107828,
      "backward_entropy": 0.12854347229003907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.384921073913574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01608813926577568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17984028657277426,
      "backward_entropy": 0.12444884777069092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366963386535645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016185792163014412,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1798056165377299,
      "backward_entropy": 0.1241633415222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787817001342773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016283292323350906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1797721783320109,
      "backward_entropy": 0.12387378215789795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.100561141967773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0163809135556221,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17973514397939047,
      "backward_entropy": 0.1251303434371948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.591981887817383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016478797420859337,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17969538768132529,
      "backward_entropy": 0.12483763694763184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.608587265014648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01657664030790329,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17965547243754068,
      "backward_entropy": 0.12454022169113159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.345830917358398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016674460843205452,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17961478233337402,
      "backward_entropy": 0.1242372751235962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8988618850708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01677211932837963,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17957444985707602,
      "backward_entropy": 0.1265450596809387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.447728157043457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0168699212372303,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17953385909398398,
      "backward_entropy": 0.1236075520515442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.483733177185059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016967641189694405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17949112256368002,
      "backward_entropy": 0.12168195247650146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.688737392425537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01706528663635254,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1794481078783671,
      "backward_entropy": 0.12571018934249878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.27796745300293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017162451520562172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17940680185953775,
      "backward_entropy": 0.1210094690322876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.846161842346191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017260029911994934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1793609062830607,
      "backward_entropy": 0.1206634521484375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.757272720336914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017357219010591507,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1793152093887329,
      "backward_entropy": 0.12191938161849976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.199572563171387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017454538494348526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17926857868830362,
      "backward_entropy": 0.1215660810470581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.008564949035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017551686614751816,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17922163009643555,
      "backward_entropy": 0.12420814037322998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.515543937683105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017648587003350258,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791746218999227,
      "backward_entropy": 0.11925255060195923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719706535339355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017745528370141983,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17912683884302774,
      "backward_entropy": 0.12046601772308349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.736635684967041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017842624336481094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17907744646072388,
      "backward_entropy": 0.12008869647979736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.271721839904785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017939332872629166,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17902823289235434,
      "backward_entropy": 0.12290329933166504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.702826499938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01803598180413246,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17897820472717285,
      "backward_entropy": 0.12256369590759278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.414460182189941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018132247030735016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1789326866467794,
      "backward_entropy": 0.11743522882461548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.323618412017822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018228581175208092,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1788853406906128,
      "backward_entropy": 0.12186493873596191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.328216075897217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018324369564652443,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1788419485092163,
      "backward_entropy": 0.11667450666427612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.692076206207275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018419675529003143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17880189418792725,
      "backward_entropy": 0.12112919092178345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.665783405303955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01851475238800049,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17876305182774863,
      "backward_entropy": 0.11728222370147705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.165306091308594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018609611317515373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17872526248296103,
      "backward_entropy": 0.11548147201538086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.419135093688965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018704544752836227,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17868775129318237,
      "backward_entropy": 0.11506779193878174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.339626312255859,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01879914104938507,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17865200837453207,
      "backward_entropy": 0.11958024501800538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.416297435760498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01889338530600071,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17861972252527872,
      "backward_entropy": 0.11420993804931641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.40287971496582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018987376242876053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17858693997065225,
      "backward_entropy": 0.11512640714645386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.477520942687988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019082263112068176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17854319016138712,
      "backward_entropy": 0.11331417560577392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.493708610534668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019177423790097237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1784963607788086,
      "backward_entropy": 0.11422346830368042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.030989646911621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019272278994321823,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17845048507054648,
      "backward_entropy": 0.1137622356414795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.984006404876709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019367165863513947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17840301990509033,
      "backward_entropy": 0.11189730167388916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.221923828125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019461479038000107,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17835994561513266,
      "backward_entropy": 0.11141731739044189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.162870407104492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01955600455403328,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1783115267753601,
      "backward_entropy": 0.11234245300292969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.731257915496826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019650686532258987,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1782591144243876,
      "backward_entropy": 0.11185413599014282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.325104236602783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01974526233971119,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17820550998051962,
      "backward_entropy": 0.10992107391357422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312469005584717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019839514046907425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17815248171488443,
      "backward_entropy": 0.10941098928451538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.235795497894287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01993347331881523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17809897661209106,
      "backward_entropy": 0.10889654159545899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.018000602722168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020027121528983116,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17804640531539917,
      "backward_entropy": 0.11391561031341553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.512690544128418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020120365545153618,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17799595991770426,
      "backward_entropy": 0.10929995775222778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.968523979187012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02021353505551815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17794587214787802,
      "backward_entropy": 0.10732928514480591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.332638740539551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020306330174207687,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1778965393702189,
      "backward_entropy": 0.11246269941329956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.748726844787598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02039840817451477,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17785425980885824,
      "backward_entropy": 0.11196678876876831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0066375732421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020490678027272224,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17781056960423788,
      "backward_entropy": 0.10714828968048096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.494502067565918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020582688972353935,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17776834964752197,
      "backward_entropy": 0.10659886598587036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6830363273620605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020675361156463623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17771675189336142,
      "backward_entropy": 0.1060418963432312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.669372081756592,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020768143236637115,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17766215403874716,
      "backward_entropy": 0.10987415313720703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.873648166656494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02086041122674942,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1776146094004313,
      "backward_entropy": 0.10491467714309692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.819812774658203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02095235325396061,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1775680979092916,
      "backward_entropy": 0.10291768312454223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.722164630889893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021043971180915833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17752357323964438,
      "backward_entropy": 0.10376613140106201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.470981121063232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021135231480002403,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17748532692591348,
      "backward_entropy": 0.10318876504898071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2001423835754395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021225418895483017,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17745929956436157,
      "backward_entropy": 0.10119508504867554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.200923442840576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021315695717930794,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1774324377377828,
      "backward_entropy": 0.10202258825302124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.185704231262207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021406065672636032,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.177401602268219,
      "backward_entropy": 0.10002965927124023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.557475566864014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021496517583727837,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17736502488454184,
      "backward_entropy": 0.10083473920822143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.53005838394165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021586649119853973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.177331805229187,
      "backward_entropy": 0.10023356676101684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8697614669799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021676482632756233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1773005723953247,
      "backward_entropy": 0.09823020100593567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6304755210876465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021766267716884613,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17726564407348633,
      "backward_entropy": 0.09761980175971985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.211461067199707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021855859085917473,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1772305965423584,
      "backward_entropy": 0.10294095277786255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.544114589691162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021945012733340263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17720097303390503,
      "backward_entropy": 0.09638853669166565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.186783313751221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022033991292119026,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1771709124247233,
      "backward_entropy": 0.09576735496520997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.305792331695557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022122593596577644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1771407127380371,
      "backward_entropy": 0.09514389038085938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.744772911071777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02221156656742096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1771029233932495,
      "backward_entropy": 0.09450731873512268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5530266761779785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022300520911812782,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17706344525019327,
      "backward_entropy": 0.0952303647994995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.154453754425049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02238934300839901,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1770214637120565,
      "backward_entropy": 0.09458446502685547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.124731540679932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02247779071331024,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17698152860005698,
      "backward_entropy": 0.09256184101104736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7451629638671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02256653644144535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.176932692527771,
      "backward_entropy": 0.09189380407333374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.872509002685547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022655310109257698,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17687880992889404,
      "backward_entropy": 0.09121729135513305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.014225006103516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02274354360997677,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17682711283365884,
      "backward_entropy": 0.09054295420646667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9463348388671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022831391543149948,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1767728328704834,
      "backward_entropy": 0.0958346426486969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0230278968811035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02291885018348694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17671827475229898,
      "backward_entropy": 0.08918979167938232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.481602668762207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023006005212664604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1766672134399414,
      "backward_entropy": 0.08981239795684814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.263455867767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023093203082680702,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17661072810490927,
      "backward_entropy": 0.08782191276550293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.710546016693115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023179618641734123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17656801144282022,
      "backward_entropy": 0.0871340274810791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.680900573730469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023265637457370758,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1765300432840983,
      "backward_entropy": 0.08767516016960145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.953781604766846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023351287469267845,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17649288972218832,
      "backward_entropy": 0.08695585131645203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.038025856018066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02343679592013359,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1764514446258545,
      "backward_entropy": 0.08505366444587707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.462240695953369,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023522237315773964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17640833059946695,
      "backward_entropy": 0.08550249338150025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9395623207092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02360791712999344,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17635643482208252,
      "backward_entropy": 0.08966758847236633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.136788845062256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023693455383181572,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1763014793395996,
      "backward_entropy": 0.0889615535736084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.815360069274902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023778313770890236,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17624694108963013,
      "backward_entropy": 0.08825783729553223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.330578327178955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023863036185503006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17619309822718301,
      "backward_entropy": 0.0825463891029358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.561072826385498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023947302252054214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17613657315572104,
      "backward_entropy": 0.08075273036956787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.655812740325928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024031322449445724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17607961098353067,
      "backward_entropy": 0.08002560138702393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.999195575714111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024115195497870445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1760197877883911,
      "backward_entropy": 0.08024404048919678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.395605564117432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024198466911911964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17596763372421265,
      "backward_entropy": 0.07856602668762207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.333929538726807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024281490594148636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1759111483891805,
      "backward_entropy": 0.07783493995666504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.422669410705566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024364247918128967,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1758542855580648,
      "backward_entropy": 0.07710179090499877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.93020486831665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024446837604045868,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17579219738642374,
      "backward_entropy": 0.07636438608169556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.304990291595459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02452891878783703,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17573422193527222,
      "backward_entropy": 0.076349937915802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.100444316864014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024610823020339012,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17567821343739828,
      "backward_entropy": 0.0755719542503357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.76139497756958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024692421779036522,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1756205161412557,
      "backward_entropy": 0.07415058612823486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.123663902282715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02477349527180195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17556796471277872,
      "backward_entropy": 0.07401188611984252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.36460542678833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024854373186826706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17551430066426596,
      "backward_entropy": 0.07266987562179565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.034283638000488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024934500455856323,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.175464928150177,
      "backward_entropy": 0.07244973182678223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.946713924407959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025013696402311325,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17542362213134766,
      "backward_entropy": 0.07166467905044556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.20277214050293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025092769414186478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1753804087638855,
      "backward_entropy": 0.07088186740875244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.166566371917725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025171153247356415,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17534283796946207,
      "backward_entropy": 0.07579787373542786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.505766868591309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025248892605304718,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17531657218933105,
      "backward_entropy": 0.06903273463249207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.83836030960083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025326324626803398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17529157797495523,
      "backward_entropy": 0.06831296682357788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.104137897491455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025403747335076332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17526008685429892,
      "backward_entropy": 0.06758732795715332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.445076942443848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025480572134256363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17522905270258585,
      "backward_entropy": 0.0668657124042511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.126339435577393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0255571398884058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17519408464431763,
      "backward_entropy": 0.06624386310577393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5807785987854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02563321962952614,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17515973250071207,
      "backward_entropy": 0.07124472856521606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.748627185821533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0257092397660017,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17511741320292154,
      "backward_entropy": 0.0704861342906952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.086901664733887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025784514844417572,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1750791072845459,
      "backward_entropy": 0.06393675208091736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.638506889343262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025860249996185303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17502411206563315,
      "backward_entropy": 0.06318602561950684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.809500217437744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025936029851436615,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17495954036712646,
      "backward_entropy": 0.06240490674972534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.15419864654541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026011141017079353,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17489429314931235,
      "backward_entropy": 0.06745961904525757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.419073104858398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02608596347272396,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1748292843500773,
      "backward_entropy": 0.06670377850532531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1424031257629395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02616075426340103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1747531294822693,
      "backward_entropy": 0.06012067198753357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9630095958709717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026235288009047508,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1746755838394165,
      "backward_entropy": 0.05941492319107056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.425557851791382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026309441775083542,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17459932963053384,
      "backward_entropy": 0.05866079330444336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.835301637649536,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026382775977253914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1745312213897705,
      "backward_entropy": 0.057880520820617676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.820725202560425,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026455746963620186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17446358998616537,
      "backward_entropy": 0.057146453857421876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3686466217041016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02652745693922043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17440678675969443,
      "backward_entropy": 0.05645562410354614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.398164987564087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026598548516631126,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17435503005981445,
      "backward_entropy": 0.061427950859069824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2334511280059814,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026669107377529144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17430259784062704,
      "backward_entropy": 0.06068530082702637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9681382179260254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026739036664366722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1742521325747172,
      "backward_entropy": 0.05424901247024536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2393176555633545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026808151975274086,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1742090384165446,
      "backward_entropy": 0.053537189960479736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0798375606536865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026876797899603844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17416687806447348,
      "backward_entropy": 0.05283164978027344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1129977703094482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026944871991872787,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17412835359573364,
      "backward_entropy": 0.05226799249649048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.133869171142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027012459933757782,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17408907413482666,
      "backward_entropy": 0.05702953338623047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1555066108703613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02707962691783905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17404377460479736,
      "backward_entropy": 0.050749993324279784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7475640773773193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027146469801664352,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17400318384170532,
      "backward_entropy": 0.05024726390838623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.747540235519409,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02721259370446205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17396738131841025,
      "backward_entropy": 0.04958657622337341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9410557746887207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027278056368231773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17392820119857788,
      "backward_entropy": 0.048730498552322386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.677828311920166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0273431446403265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17388800779978433,
      "backward_entropy": 0.048068785667419435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5922908782958984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02740761823952198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17384984095891318,
      "backward_entropy": 0.04741386771202087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7593634128570557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02747143991291523,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17381002505620322,
      "backward_entropy": 0.046989822387695314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.702732563018799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027534866705536842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17376826206843057,
      "backward_entropy": 0.04634881317615509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.599578857421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027597881853580475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17372467120488486,
      "backward_entropy": 0.04547999203205109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6872398853302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02766043320298195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17368688186009726,
      "backward_entropy": 0.04507816433906555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5344173908233643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02772265486419201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1736453374226888,
      "backward_entropy": 0.04444563686847687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1218113899230957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027784409001469612,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1736017862955729,
      "backward_entropy": 0.043617027997970584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.301252841949463,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027845272794365883,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17356459299723306,
      "backward_entropy": 0.04801612794399261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2062816619873047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027905525639653206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1735227902730306,
      "backward_entropy": 0.042591783404350284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.692566990852356,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027965141460299492,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17348418633143106,
      "backward_entropy": 0.04671301543712616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2932419776916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028023554012179375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1734547217686971,
      "backward_entropy": 0.04607559144496918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9763381481170654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028081629425287247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17342543601989746,
      "backward_entropy": 0.0454411119222641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.334423065185547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139010071754456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17340060075124106,
      "backward_entropy": 0.04025170803070068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1091768741607666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02819620817899704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17336906989415488,
      "backward_entropy": 0.039679741859436034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0396459102630615,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028252961114048958,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17333434025446573,
      "backward_entropy": 0.03892880082130432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6840498447418213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028309214860200882,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17329434553782144,
      "backward_entropy": 0.03855016827583313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8581339120864868,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02836456708610058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17325866222381592,
      "backward_entropy": 0.03782224655151367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.115863800048828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02841932699084282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1732192039489746,
      "backward_entropy": 0.03727917075157165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5432183742523193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028473898768424988,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17316834131876627,
      "backward_entropy": 0.04116382896900177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8824037313461304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028527580201625824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17313224077224731,
      "backward_entropy": 0.03637913763523102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8167555332183838,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028580885380506516,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17309051752090454,
      "backward_entropy": 0.040001145005226134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7944345474243164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028633754700422287,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17304160197575888,
      "backward_entropy": 0.0351858526468277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6640193462371826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028686221688985825,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17298916975657144,
      "backward_entropy": 0.03887156844139099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.634844422340393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02873813360929489,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17293389638264975,
      "backward_entropy": 0.03831860423088074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3664549589157104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028789518401026726,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17287790775299072,
      "backward_entropy": 0.03777232766151428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4670326709747314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028840016573667526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17282450199127197,
      "backward_entropy": 0.03329393267631531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.640163779258728,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028889872133731842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17277057965596518,
      "backward_entropy": 0.03280741274356842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3001773357391357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02893943525850773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17271292209625244,
      "backward_entropy": 0.0323241651058197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3502528667449951,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028988175094127655,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1726545294125875,
      "backward_entropy": 0.031788837909698484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0492632389068604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029036276042461395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17259687185287476,
      "backward_entropy": 0.03138629496097565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5202538967132568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02908330038189888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17254547278086343,
      "backward_entropy": 0.03093564510345459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.462585687637329,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029130147770047188,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17248773574829102,
      "backward_entropy": 0.030448129773139952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3107283115386963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029176734387874603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17242236932118735,
      "backward_entropy": 0.030036938190460206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.969899594783783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029222842305898666,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17235449949900308,
      "backward_entropy": 0.029591941833496095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9121702313423157,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02926791086792946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1722912391026815,
      "backward_entropy": 0.029159799218177795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0081390142440796,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931196801364422,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17223785320917764,
      "backward_entropy": 0.028740960359573364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0575822591781616,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0293552428483963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1721831758817037,
      "backward_entropy": 0.02836719751358032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2386720180511475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029397934675216675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17212931315104166,
      "backward_entropy": 0.027976584434509278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0862325429916382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944045141339302,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17206992705663046,
      "backward_entropy": 0.027525630593299866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2976264953613281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029482513666152954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17200728257497153,
      "backward_entropy": 0.027128663659095765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9531870484352112,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029524579644203186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17193281650543213,
      "backward_entropy": 0.026841229200363158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7922554612159729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02956596203148365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17185608545939127,
      "backward_entropy": 0.026338824629783632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9438090920448303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029606424272060394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17178434133529663,
      "backward_entropy": 0.026117867231369017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9117153882980347,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029646361246705055,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17170955737431845,
      "backward_entropy": 0.02894393801689148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7973462343215942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029685761779546738,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1716319521268209,
      "backward_entropy": 0.025218012928962707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6880295872688293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029724447056651115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17155579725901285,
      "backward_entropy": 0.02485896646976471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8058966398239136,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029762255027890205,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17148504654566446,
      "backward_entropy": 0.024510648846626282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5759061574935913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02979949302971363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1714088718096415,
      "backward_entropy": 0.024168193340301514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8438062071800232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029835697263479233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17133639256159464,
      "backward_entropy": 0.02383769750595093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8146279454231262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029871614649891853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17125763495763144,
      "backward_entropy": 0.023509810864925384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5596891045570374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029907213523983955,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1711731751759847,
      "backward_entropy": 0.023185107111930846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5727539658546448,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02994190715253353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1710930069287618,
      "backward_entropy": 0.022870884835720064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6008988618850708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029975811019539833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17101474603017172,
      "backward_entropy": 0.022565571963787077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3466794490814209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030009105801582336,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17093884944915771,
      "backward_entropy": 0.02266469895839691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5705720782279968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030041128396987915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1708707014719645,
      "backward_entropy": 0.021983161568641663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5534743070602417,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030072597786784172,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17079893747965494,
      "backward_entropy": 0.02483827918767929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6824744343757629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03010353446006775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1707245111465454,
      "backward_entropy": 0.02187761664390564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5131987929344177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0301344133913517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17064525683720908,
      "backward_entropy": 0.02115783542394638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5289518237113953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030164707452058792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17056391636530557,
      "backward_entropy": 0.020890580117702486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45022082328796387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030194537714123726,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17048011223475137,
      "backward_entropy": 0.02370527237653732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4627787172794342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03022371605038643,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17039688428243002,
      "backward_entropy": 0.023437249660491943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3341329097747803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030252354219555855,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17031302054723105,
      "backward_entropy": 0.020673272013664246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5183278918266296,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0302801001816988,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17023420333862305,
      "backward_entropy": 0.020452269911766054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2900540828704834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030307671055197716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17015190919240317,
      "backward_entropy": 0.01964213103055954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4221833050251007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030334336683154106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1700774828592936,
      "backward_entropy": 0.019412843883037566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4762052595615387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030360598117113113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17000035444895426,
      "backward_entropy": 0.019187334179878234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3358076214790344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030386673286557198,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16991599400838217,
      "backward_entropy": 0.021950963139533996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4011630415916443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03041207045316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16983101765314737,
      "backward_entropy": 0.01874527782201767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42199158668518066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030437150970101357,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16974353790283203,
      "backward_entropy": 0.019233988225460054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21411363780498505,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030461985617876053,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16964954137802124,
      "backward_entropy": 0.021279537677764894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33004921674728394,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03048582375049591,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16956166426340738,
      "backward_entropy": 0.021068692207336426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2907881736755371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03050921857357025,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16947174072265625,
      "backward_entropy": 0.020862910151481628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1668558120727539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03053201548755169,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1693796912829081,
      "backward_entropy": 0.0177228182554245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3107089400291443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030553793534636497,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16929431756337485,
      "backward_entropy": 0.01753951460123062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31764882802963257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030575264245271683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1692052682240804,
      "backward_entropy": 0.018198175728321074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23594167828559875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030596503987908363,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16911194721857706,
      "backward_entropy": 0.018041935563087464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22385676205158234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030617186799645424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16901971896489462,
      "backward_entropy": 0.017890673875808717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26830369234085083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030637288466095924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16892772912979126,
      "backward_entropy": 0.01774439662694931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0954529196023941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030657127499580383,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16883381207784018,
      "backward_entropy": 0.019584164023399353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1782444417476654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030675845220685005,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16874821980794272,
      "backward_entropy": 0.017466317117214202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23453950881958008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030693894252181053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16866177320480347,
      "backward_entropy": 0.01636572778224945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17002330720424652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030711686238646507,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1685715913772583,
      "backward_entropy": 0.01912001669406891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17838390171527863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030728936195373535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16848289966583252,
      "backward_entropy": 0.016074493527412415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1324145793914795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030745767056941986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1683948834737142,
      "backward_entropy": 0.01696905791759491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13642169535160065,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03076198138296604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1683109998703003,
      "backward_entropy": 0.016855457425117494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19520457088947296,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0307775866240263,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16822810967763266,
      "backward_entropy": 0.01674671918153763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23559243977069855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030793026089668274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1681419014930725,
      "backward_entropy": 0.015544968843460082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1432175487279892,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03080856241285801,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16804858048756918,
      "backward_entropy": 0.018305665254592894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17503346502780914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03082355298101902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16795432567596436,
      "backward_entropy": 0.015291503071784973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15604928135871887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030838387086987495,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16785860061645508,
      "backward_entropy": 0.015168310701847076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09763296693563461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0308529119938612,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16776160399119058,
      "backward_entropy": 0.017940627038478853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15493695437908173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030866743996739388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16766754786173502,
      "backward_entropy": 0.014932899177074433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13870780169963837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030880413949489594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16757182280222574,
      "backward_entropy": 0.014819461107254028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1512681096792221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03089379519224167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16747484604517618,
      "backward_entropy": 0.014708323776721955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11021494120359421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030906975269317627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16737447182337442,
      "backward_entropy": 0.01459856629371643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1060870960354805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030919697135686874,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16727477312088013,
      "backward_entropy": 0.015789929032325744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08561738580465317,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030931996181607246,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16717588901519775,
      "backward_entropy": 0.017299075424671174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10614297538995743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030943751335144043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16707932949066162,
      "backward_entropy": 0.014292269945144653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10213378816843033,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03095521777868271,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16698280970255533,
      "backward_entropy": 0.017112942039966585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09822937101125717,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03096642717719078,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16688668727874756,
      "backward_entropy": 0.017023302614688873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0946444496512413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030977364629507065,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16679076353708902,
      "backward_entropy": 0.015421037375926972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08437603712081909,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03098798356950283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.166694442431132,
      "backward_entropy": 0.013923744857311248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08789937198162079,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030998235568404198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16659865776697794,
      "backward_entropy": 0.01529063582420349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07832194864749908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031008172780275345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16650235652923584,
      "backward_entropy": 0.013754791021347046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09917119890451431,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031017763540148735,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16640655199686685,
      "backward_entropy": 0.016616064310073852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06163792684674263,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031027287244796753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16630868117014566,
      "backward_entropy": 0.013594204187393188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09188718348741531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03103630803525448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16621246933937073,
      "backward_entropy": 0.01647063493728638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06201246380805969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03104526922106743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1661143700281779,
      "backward_entropy": 0.013442336022853852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0799860805273056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031053859740495682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16601781050364176,
      "backward_entropy": 0.013369622826576232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052906714379787445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031062334775924683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16592017809549967,
      "backward_entropy": 0.013297756016254426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054858122020959854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03107038326561451,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16582455237706503,
      "backward_entropy": 0.014856740832328796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058773551136255264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03107813559472561,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16573060552279154,
      "backward_entropy": 0.016145770251750947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06506450474262238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031085586175322533,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16563692688941956,
      "backward_entropy": 0.01476893424987793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04607598856091499,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031092876568436623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1655425230662028,
      "backward_entropy": 0.014727437496185302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06326018273830414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031099790707230568,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16544976830482483,
      "backward_entropy": 0.015979301929473878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04395448416471481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031106680631637573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1653562585512797,
      "backward_entropy": 0.012918326258659362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05558795854449272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031113164499402046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1652639905611674,
      "backward_entropy": 0.012862089276313781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056955184787511826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031119557097554207,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16517138481140137,
      "backward_entropy": 0.014578880369663238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052328355610370636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031125910580158234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16507800420125326,
      "backward_entropy": 0.012751416862010955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05383509770035744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031132126227021217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16498426596323648,
      "backward_entropy": 0.012697258591651916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04383077844977379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03113824874162674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16488968332608542,
      "backward_entropy": 0.01447644978761673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040134720504283905,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031144071370363235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16479551792144775,
      "backward_entropy": 0.01444547027349472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04234629124403,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031149698421359062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16470236579577127,
      "backward_entropy": 0.014415696263313293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05228884890675545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03115515597164631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1646095315615336,
      "backward_entropy": 0.012494433671236038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040410496294498444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03116062469780445,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.164515088001887,
      "backward_entropy": 0.012445922195911407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03804312273859978,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031165875494480133,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16442092259724936,
      "backward_entropy": 0.015481625497341157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04108988493680954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031170954927802086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16432730356852213,
      "backward_entropy": 0.012353387475013734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03299335390329361,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031175976619124413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16423346598943075,
      "backward_entropy": 0.014279970526695251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03712982311844826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031180784106254578,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16414066155751547,
      "backward_entropy": 0.015371881425380707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03647737577557564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031185448169708252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1640478471914927,
      "backward_entropy": 0.012222521752119065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03457167372107506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031189946457743645,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16395498315493265,
      "backward_entropy": 0.015304908156394958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03647583723068237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031194308772683144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16386226812998453,
      "backward_entropy": 0.01214115098118782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031530559062957764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031198650598526,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16376914580663046,
      "backward_entropy": 0.015241514146327972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024778323248028755,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031202873215079308,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16367647051811218,
      "backward_entropy": 0.012062168121337891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028993679210543633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03120686113834381,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16358534495035806,
      "backward_entropy": 0.012024980038404465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026049068197607994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031210754066705704,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1634946664174398,
      "backward_entropy": 0.014113195240497589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025609539821743965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03121442347764969,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16340488195419312,
      "backward_entropy": 0.014096947014331817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031917206943035126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031217962503433228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16331585248311362,
      "backward_entropy": 0.011920124292373657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027439769357442856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03122149221599102,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16322606801986694,
      "backward_entropy": 0.011886417865753174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02007981762290001,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031224941834807396,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16313640276590982,
      "backward_entropy": 0.014051534235477448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022444898262619972,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03122810274362564,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16304837663968405,
      "backward_entropy": 0.014038993418216706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021657124161720276,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031231142580509186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16296111543973288,
      "backward_entropy": 0.014027160406112672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023905325680971146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03123406693339348,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16287467877070108,
      "backward_entropy": 0.01401604264974594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020845308899879456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031237009912729263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16278826196988425,
      "backward_entropy": 0.011734209954738617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019317148253321648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031239885836839676,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16270252068837485,
      "backward_entropy": 0.011705701053142548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012541957199573517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031242573633790016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1626177430152893,
      "backward_entropy": 0.013983534276485443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01786215417087078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031244942918419838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16253534952799478,
      "backward_entropy": 0.01491260826587677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019315848127007484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03124724142253399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16245372096697488,
      "backward_entropy": 0.011629736423492432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01612676866352558,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031249534338712692,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16237235069274902,
      "backward_entropy": 0.01488129049539566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013667173683643341,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031251706182956696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16229196389516196,
      "backward_entropy": 0.011582666635513305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016437305137515068,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03125370293855667,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16221300760904947,
      "backward_entropy": 0.014853182435035705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012773251160979271,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031255677342414856,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16213450829188028,
      "backward_entropy": 0.014839959144592286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013199808076024055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125749155879021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620574196179708,
      "backward_entropy": 0.011519253253936768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013174647465348244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03125925362110138,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16198130448659262,
      "backward_entropy": 0.013934662938117981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014101269654929638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031260885298252106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1619061827659607,
      "backward_entropy": 0.011480794847011566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015159186907112598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126252070069313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16183153788248697,
      "backward_entropy": 0.011462136358022689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012035311199724674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031264156103134155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175702214241028,
      "backward_entropy": 0.011443472653627395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011127917096018791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031265776604413986,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16168336073557535,
      "backward_entropy": 0.011425080895423888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011072680354118347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126728907227516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1616108218828837,
      "backward_entropy": 0.011407506465911866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012829565443098545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126874566078186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16153917709986368,
      "backward_entropy": 0.011390481144189835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01301101315766573,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03127021715044975,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16146780053774515,
      "backward_entropy": 0.011373370885848999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011614405550062656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03127172589302063,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1613965630531311,
      "backward_entropy": 0.014736132323741912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008604469709098339,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031273253262043,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16132577260335287,
      "backward_entropy": 0.01390388011932373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009020046330988407,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03127465769648552,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16125639279683432,
      "backward_entropy": 0.013900955021381379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006792863365262747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03127596527338028,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16118808587392172,
      "backward_entropy": 0.011306747794151306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01063497830182314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312771238386631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16112148761749268,
      "backward_entropy": 0.011292311549186706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01062515377998352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03127829357981682,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16105510791142783,
      "backward_entropy": 0.013895609974861145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009703556075692177,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03127950429916382,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1609888474146525,
      "backward_entropy": 0.013893797993659973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01094119343906641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031280774623155594,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.160922904809316,
      "backward_entropy": 0.011248131841421127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007852117531001568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03128219395875931,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1608567734559377,
      "backward_entropy": 0.01466953158378601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006285424344241619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128352388739586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16079161564509073,
      "backward_entropy": 0.011216833442449569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008231787011027336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03128470480442047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1607279380162557,
      "backward_entropy": 0.013882462680339814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007512248121201992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312858521938324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1606648067633311,
      "backward_entropy": 0.011188843101263047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007607829757034779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128702938556671,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16060233116149902,
      "backward_entropy": 0.011174876242876053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006953296717256308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128825128078461,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16054035226504007,
      "backward_entropy": 0.011160693317651748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006170791573822498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031289491802453995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16047908862431845,
      "backward_entropy": 0.01114652305841446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006839763838797808,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031290654093027115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604188084602356,
      "backward_entropy": 0.011132963746786118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00596069497987628,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129180893301964,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16035908460617065,
      "backward_entropy": 0.011119520664215088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00550497742369771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031292952597141266,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16030020515124002,
      "backward_entropy": 0.014600110054016114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004898617509752512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03129402548074722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16024228930473328,
      "backward_entropy": 0.013862305879592895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0048088147304952145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129498288035393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16018552581469217,
      "backward_entropy": 0.011081752181053162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006461891811341047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129582852125168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1601298451423645,
      "backward_entropy": 0.011070756614208222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006386359687894583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129677474498749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16007423400878906,
      "backward_entropy": 0.01105913370847702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005379003006964922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129782900214195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.160018652677536,
      "backward_entropy": 0.011046840250492096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004682268016040325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312989242374897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15996360778808594,
      "backward_entropy": 0.011034336686134339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0038866796530783176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031299956142902374,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15990938742955527,
      "backward_entropy": 0.014554964005947113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003745031077414751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03130093589425087,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1598562995592753,
      "backward_entropy": 0.01454862654209137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041409810073673725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130180761218071,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15980432430903116,
      "backward_entropy": 0.011000161617994308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036559130530804396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031302690505981445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15975306431452432,
      "backward_entropy": 0.013846197724342346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003322912147268653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031303517520427704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1597027083237966,
      "backward_entropy": 0.010979268699884415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003680942114442587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130428120493889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15965340534845987,
      "backward_entropy": 0.010969582945108414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031352885998785496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130503371357918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15960476795832315,
      "backward_entropy": 0.013843004405498505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034141510259360075,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031305719166994095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15955708424250284,
      "backward_entropy": 0.014518669247627259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030471927020698786,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031306371092796326,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15951007604599,
      "backward_entropy": 0.013842228055000304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003595995018258691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03130700811743736,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1594638725121816,
      "backward_entropy": 0.014510825276374817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028274492360651493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130771219730377,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15941797693570456,
      "backward_entropy": 0.010924837738275527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027546249330043793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0313083678483963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15937290589014688,
      "backward_entropy": 0.013840466737747192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034062808845192194,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03130900114774704,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15932859977086386,
      "backward_entropy": 0.014498506486415864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002275914652273059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130972385406494,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15928449233373007,
      "backward_entropy": 0.013838675618171693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025643236003816128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131038695573807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15924137830734253,
      "backward_entropy": 0.010890814661979675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024613053537905216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313110388815403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1591989000638326,
      "backward_entropy": 0.010882604122161865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002201684517785907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031311675906181335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15915709733963013,
      "backward_entropy": 0.01087452620267868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00206420524045825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131229057908058,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15911604960759482,
      "backward_entropy": 0.01086670532822609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019220856484025717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131284564733505,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15907581647237143,
      "backward_entropy": 0.01383465677499771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017649686196818948,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031313374638557434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15903645753860474,
      "backward_entropy": 0.010852257907390594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00153657968621701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131388500332832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15899791320165,
      "backward_entropy": 0.013834026455879212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002174587920308113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131430968642235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15896034240722656,
      "backward_entropy": 0.010839127004146576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019799196161329746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031314775347709656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15892308950424194,
      "backward_entropy": 0.01083265095949173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019021086627617478,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03131524473428726,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15888630350430807,
      "backward_entropy": 0.014460551738739013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014070288743823767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031315676867961884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15884999434153238,
      "backward_entropy": 0.010820000618696212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016224600840359926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031316064298152924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1588145395119985,
      "backward_entropy": 0.013834746181964874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013584693660959601,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031316474080085754,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15877965092658997,
      "backward_entropy": 0.01445322185754776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014966493472456932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031316835433244705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15874552726745605,
      "backward_entropy": 0.010802803933620453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015795737272128463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131718561053276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15871195991834006,
      "backward_entropy": 0.010797419399023057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012679955689236522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131754323840141,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15867876013120016,
      "backward_entropy": 0.010792019963264465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012431263457983732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031317900866270065,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1586462457974752,
      "backward_entropy": 0.010786688327789307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012052792590111494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131825476884842,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15861437718073526,
      "backward_entropy": 0.010781458020210266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010718192206695676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131861984729767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15858308474222818,
      "backward_entropy": 0.010776229202747345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013093318557366729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03131895884871483,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1585524876912435,
      "backward_entropy": 0.01077123060822487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012451345100998878,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031319331377744675,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15852219859759012,
      "backward_entropy": 0.013837561011314392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011835901532322168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031319718807935715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15849230686823526,
      "backward_entropy": 0.010760790854692458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009793585631996393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031320106238126755,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.158462792634964,
      "backward_entropy": 0.01383717656135559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010960212675854564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031320467591285706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15843385457992554,
      "backward_entropy": 0.01075059399008751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010022633941844106,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132084384560585,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15840532382329306,
      "backward_entropy": 0.014426796138286591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008954607183113694,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132122382521629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15837723016738892,
      "backward_entropy": 0.010740532726049423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009659004281274974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132160007953644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15834969282150269,
      "backward_entropy": 0.013836462795734406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009098091395571828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132195770740509,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1583225131034851,
      "backward_entropy": 0.010730795562267303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008240044699050486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132233768701553,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15829575061798096,
      "backward_entropy": 0.01441698670387268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007389729144051671,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031322721391916275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.158269464969635,
      "backward_entropy": 0.01072101593017578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006707400316372514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132307529449463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1582437256971995,
      "backward_entropy": 0.010716384649276734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007399843889288604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132343292236328,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15821861227353415,
      "backward_entropy": 0.013834883272647858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000604516186285764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132379800081253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15819388628005981,
      "backward_entropy": 0.010707204788923263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006761426338925958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132414072751999,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15816976626714072,
      "backward_entropy": 0.013833957910537719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006657559424638748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132449463009834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15814602375030518,
      "backward_entropy": 0.010698340833187103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000598887272644788,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031324874609708786,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15812266866366068,
      "backward_entropy": 0.014400136470794678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006161615019664168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031325239688158035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15809975067774454,
      "backward_entropy": 0.010689377784729004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005075117223896086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03132561594247818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1580771803855896,
      "backward_entropy": 0.013831056654453278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005621762829832733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132595866918564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1580551266670227,
      "backward_entropy": 0.01068073809146881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005470332107506692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132632374763489,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15803339083989462,
      "backward_entropy": 0.010676434636116028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000454616587376222,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132670000195503,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15801201264063516,
      "backward_entropy": 0.014387807250022889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004761098534800112,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031327053904533386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1579910715421041,
      "backward_entropy": 0.013827812671661378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004543749673757702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031327392905950546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15797050793965658,
      "backward_entropy": 0.010663904994726182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003948247176595032,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132772073149681,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15795030196507773,
      "backward_entropy": 0.010659977793693542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003339374379720539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132803365588188,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1579305628935496,
      "backward_entropy": 0.014378677308559417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039497061516158283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132830932736397,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15791134039560953,
      "backward_entropy": 0.010652685910463333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037529037217609584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03132857754826546,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15789244572321573,
      "backward_entropy": 0.014374998211860657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031854069675318897,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031328845769166946,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15787389874458313,
      "backward_entropy": 0.013824862241744996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034354120725765824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132910653948784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15785578886667886,
      "backward_entropy": 0.010642550885677338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002722482895478606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132938966155052,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1578380068143209,
      "backward_entropy": 0.010639150440692902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002839714870788157,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03132964298129082,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15782066186269125,
      "backward_entropy": 0.010635944455862046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023365077504422516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031329888850450516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15780372420946756,
      "backward_entropy": 0.010632868111133575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000251459568971768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133009001612663,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15778724352518717,
      "backward_entropy": 0.010630109906196594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026168866315856576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133028745651245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15777114033699036,
      "backward_entropy": 0.010627403855323792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002332698059035465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133045509457588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15775532523790994,
      "backward_entropy": 0.010624904185533524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002456976508256048,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133062645792961,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15773985783259073,
      "backward_entropy": 0.010622416436672211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025772277149371803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133080154657364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15772469838460287,
      "backward_entropy": 0.013823610544204713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002040163817582652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133099153637886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15770970781644186,
      "backward_entropy": 0.010617385059595108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020997664250899106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133116289973259,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15769505500793457,
      "backward_entropy": 0.010614977031946183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020573350775521249,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133133053779602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15768070022265115,
      "backward_entropy": 0.013823691010475158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019648352463264018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133149445056915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15766659379005432,
      "backward_entropy": 0.013823780417442321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016678031533956528,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031331662088632584,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15765277544657388,
      "backward_entropy": 0.014354343712329864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019287072063889354,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133183345198631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1576392650604248,
      "backward_entropy": 0.010605676472187043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001282577431993559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133199363946915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15762596329053244,
      "backward_entropy": 0.013823795318603515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017470029706601053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133213892579079,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15761305888493857,
      "backward_entropy": 0.010601364076137543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012699620856437832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133229538798332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15760037302970886,
      "backward_entropy": 0.010599227994680405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012934203550685197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133244067430496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15758803486824036,
      "backward_entropy": 0.01059718132019043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012992057600058615,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133257105946541,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15757598479588827,
      "backward_entropy": 0.013824073970317841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001122827161452733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133270516991615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1575642228126526,
      "backward_entropy": 0.010593341290950775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012380341649986804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031332824379205704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15755275885264078,
      "backward_entropy": 0.010591535270214081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012814128422178328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031332943588495255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.157541553179423,
      "backward_entropy": 0.010589773952960967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010760156874312088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031333077698946,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15753048658370972,
      "backward_entropy": 0.010587923973798753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012029629579046741,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133319318294525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15751968820889792,
      "backward_entropy": 0.013824620842933654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010811735410243273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313333235681057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1575090487798055,
      "backward_entropy": 0.010584422200918198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.430706657236442e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133346140384674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15749860803286234,
      "backward_entropy": 0.010582637041807175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.902722038328648e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133358061313629,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15748844544092813,
      "backward_entropy": 0.010580930858850479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.423749048030004e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133368119597435,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15747854113578796,
      "backward_entropy": 0.010579393804073333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.081937994575128e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133375942707062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1574688752492269,
      "backward_entropy": 0.010578005760908126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729362161830068e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133382275700569,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15745948751767477,
      "backward_entropy": 0.010576753318309784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.11613504588604e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031333886086940765,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1574502189954122,
      "backward_entropy": 0.0138260617852211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.325127080548555e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133394196629524,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15744125843048096,
      "backward_entropy": 0.010574345290660859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.783959204563871e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133399039506912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15743244687716165,
      "backward_entropy": 0.010573208332061768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.34602693025954e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133402392268181,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15742393334706625,
      "backward_entropy": 0.010572206974029542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.007667591096833e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133406117558479,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1574155886967977,
      "backward_entropy": 0.013828234374523162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8070501836482435e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133411705493927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1574073831240336,
      "backward_entropy": 0.010570097714662552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2875748224323615e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133418783545494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1573993762334188,
      "backward_entropy": 0.010568918287754058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.379272624850273e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133426979184151,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15739156802495322,
      "backward_entropy": 0.013829009234905243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2699593905126676e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133435174822807,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15738391876220703,
      "backward_entropy": 0.014335645735263825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.228770896792412e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133442625403404,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15737652778625488,
      "backward_entropy": 0.010565333068370819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.700442877947353e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133450075984001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15736925601959229,
      "backward_entropy": 0.013829442858695983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5876946387579665e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031334567815065384,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15736213326454163,
      "backward_entropy": 0.013829652965068818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.26138358307071e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031334634870290756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1573551595211029,
      "backward_entropy": 0.010562077909708024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3586893550818786e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133470565080643,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15734833478927612,
      "backward_entropy": 0.010561017692089081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.25311918661464e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313347727060318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1573417286078135,
      "backward_entropy": 0.010559997707605361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.597654358600266e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133483976125717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15733522176742554,
      "backward_entropy": 0.01383029818534851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.920636507042218e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031334906816482544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1573288639386495,
      "backward_entropy": 0.010557974874973296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.345795994391665e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133496269583702,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1573227047920227,
      "backward_entropy": 0.010557056963443756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.196581019437872e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031335026025772095,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1573166847229004,
      "backward_entropy": 0.014330658316612243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7323343601892702e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031335096806287766,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15731080373128256,
      "backward_entropy": 0.014330124855041504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9599841582239605e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335167586803436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15730504194895426,
      "backward_entropy": 0.010554154962301254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.76617101917509e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133523464202881,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15729943911234537,
      "backward_entropy": 0.01432906985282898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3083503037923947e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133530169725418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15729393561681113,
      "backward_entropy": 0.010552296787500382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6577221433399245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335365027189255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15728859106699625,
      "backward_entropy": 0.010551416873931884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0722829503938556e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133542463183403,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15728331605593363,
      "backward_entropy": 0.013831047713756562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2549047571374103e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133548051118851,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15727821985880533,
      "backward_entropy": 0.010549727082252502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.10340840567369e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133554011583328,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1572732130686442,
      "backward_entropy": 0.010548914968967437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.709236494207289e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133559599518776,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15726832548777261,
      "backward_entropy": 0.013831321895122529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9845627321046777e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133564814925194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1572636067867279,
      "backward_entropy": 0.010547377169132233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.534885996079538e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031335704028606415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15725896755854288,
      "backward_entropy": 0.013831499218940734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5899080608505756e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335752457380295,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15725447734196982,
      "backward_entropy": 0.010545872151851654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5636682292097248e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335800886154175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15725011626879373,
      "backward_entropy": 0.01054515242576599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.65579876920674e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335845589637756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15724583466847739,
      "backward_entropy": 0.010544468462467194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4605320757254958e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335894018411636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15724164247512817,
      "backward_entropy": 0.010543776303529739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4376672879734542e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335946172475815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15723753968874613,
      "backward_entropy": 0.010543064028024674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.309893104917137e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031335994601249695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15723353624343872,
      "backward_entropy": 0.010542409867048264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1023535080312286e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031336043030023575,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15722960233688354,
      "backward_entropy": 0.013831940293312073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0891002602875233e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336087733507156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15722578763961792,
      "backward_entropy": 0.010541100800037385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0234755791316275e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133613243699074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15722211201985678,
      "backward_entropy": 0.010540490597486496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0190859939029906e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133617714047432,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15721851587295532,
      "backward_entropy": 0.014321631193161011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.306297215516679e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0313362181186676,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15721503893534342,
      "backward_entropy": 0.013832122087478638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.260761544283014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336259096860886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15721164147059122,
      "backward_entropy": 0.01053873896598816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715354513493367e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133629262447357,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15720831354459128,
      "backward_entropy": 0.010538212209939956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.872974492784124e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336329877376556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15720510482788086,
      "backward_entropy": 0.010537664592266082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.999706783972215e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133636713027954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1572019855181376,
      "backward_entropy": 0.01053713634610176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718760571151506e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336404383182526,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.157198965549469,
      "backward_entropy": 0.010536624491214753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7033429331786465e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133643791079521,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15719600518544516,
      "backward_entropy": 0.013832440972328186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.707573447783943e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0313364714384079,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.157193124294281,
      "backward_entropy": 0.013832509517669678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.233069598238217e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133649751543999,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15719033281008402,
      "backward_entropy": 0.01431894451379776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.161783064977499e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336527317762375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15718760093053183,
      "backward_entropy": 0.010534799098968506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.744123998534633e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133655712008476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571849783261617,
      "backward_entropy": 0.010534372925758363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.77632044951315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133658692240715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15718241532643637,
      "backward_entropy": 0.013832785189151764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.608224116964266e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133661299943924,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15717992186546326,
      "backward_entropy": 0.013832870125770568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.987039119441761e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133663535118103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15717750787734985,
      "backward_entropy": 0.013832966983318328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.37794506069622e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133665397763252,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15717516342798868,
      "backward_entropy": 0.013833068311214447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.009847089037066e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133667632937431,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15717285871505737,
      "backward_entropy": 0.01053251251578331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8826051422802266e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031336694955825806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15717063347498575,
      "backward_entropy": 0.01383327841758728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7187057841947535e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031336709856987,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15716846783955893,
      "backward_entropy": 0.013833427429199218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.738775149031426e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133672475814819,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571663816769918,
      "backward_entropy": 0.01053156703710556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.083436922679539e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133673965930939,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15716432531674704,
      "backward_entropy": 0.013833662867546082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0847406833345303e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133675828576088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15716234842936197,
      "backward_entropy": 0.010530997812747956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3095227536250604e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133677691221237,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15716042121251425,
      "backward_entropy": 0.014316487312316894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.107172460659058e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031336795538663864,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571585237979889,
      "backward_entropy": 0.013833944499492646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.77865979114722e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133681043982506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571566661198934,
      "backward_entropy": 0.013834033906459809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.246116082460503e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133682534098625,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15715489784876505,
      "backward_entropy": 0.010529905557632446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8205161015648628e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031336840242147446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571531593799591,
      "backward_entropy": 0.013834227621555329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.698983735172078e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133685141801834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.157151460647583,
      "backward_entropy": 0.013834336400032043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8933153569378192e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336866319179535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15714977184931436,
      "backward_entropy": 0.010529152303934097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3017612420517253e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133688122034073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15714816252390543,
      "backward_entropy": 0.010528915375471116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.074428493870073e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336892396211624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15714658300081888,
      "backward_entropy": 0.010528686642646789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5553534922219114e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133690357208252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571450630823771,
      "backward_entropy": 0.010528479516506196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8226493239126285e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336914747953415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15714359283447266,
      "backward_entropy": 0.010528277605772018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5014563814474968e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133692219853401,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571421722571055,
      "backward_entropy": 0.013834919035434722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6873383401616593e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133693337440491,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571407914161682,
      "backward_entropy": 0.010527873039245605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4292432979345904e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313369445502758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15713945031166077,
      "backward_entropy": 0.010527712106704713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3555763871409e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0313369557261467,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15713812907536825,
      "backward_entropy": 0.010527517646551132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.563849650665361e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133696690201759,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15713687737782797,
      "backward_entropy": 0.013835231959819793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1806832844740711e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133697435259819,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571356455485026,
      "backward_entropy": 0.010527154803276062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1847706673506764e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031336985528469086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15713444352149963,
      "backward_entropy": 0.010526973009109496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1361752285665716e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133699670433998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571332812309265,
      "backward_entropy": 0.010526788234710694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1540671494003618e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133700415492058,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15713216861089072,
      "backward_entropy": 0.014314222335815429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.298356778534071e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337011605501175,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15713108579317728,
      "backward_entropy": 0.013835622370243073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.313090802403167e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133701905608177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15713000297546387,
      "backward_entropy": 0.01383572667837143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.691721061244607e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133702650666237,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15712896982828775,
      "backward_entropy": 0.013835801184177399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.719148010844947e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133703023195267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712795654932657,
      "backward_entropy": 0.010526074469089508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.730878218761063e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337033957242966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712698300679526,
      "backward_entropy": 0.010525953769683839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.177025397846592e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337037682533264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712600946426392,
      "backward_entropy": 0.010525840520858764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.250491762533784e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133704140782356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712509552637735,
      "backward_entropy": 0.010525690764188767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787249612396408e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133704513311386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712422132492065,
      "backward_entropy": 0.010525606572628021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.202160989232652e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133704885840416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15712336699167886,
      "backward_entropy": 0.013836367428302765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.078184924263041e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133705258369446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15712255239486694,
      "backward_entropy": 0.013836462795734406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.836550596744928e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337056308984756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712173779805502,
      "backward_entropy": 0.010525310039520263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.387020334841509e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337060034275055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15712096293767294,
      "backward_entropy": 0.010525215417146683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.870905172538187e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133706375956535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15712019801139832,
      "backward_entropy": 0.013836754858493805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.918238687423582e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133706748485565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711945295333862,
      "backward_entropy": 0.01052502691745758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.862606033384509e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133707121014595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711875756581625,
      "backward_entropy": 0.01052495539188385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.907240622742393e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133707493543625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571180820465088,
      "backward_entropy": 0.013836978375911713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.27487486579048e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133707866072655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711738665898642,
      "backward_entropy": 0.010524777323007583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.747050468267844e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337082386016846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571167508761088,
      "backward_entropy": 0.01052468940615654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6016558030714805e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571160852909088,
      "backward_entropy": 0.013837197422981262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.054959958921245e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711544950803122,
      "backward_entropy": 0.010524550080299377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.911580108706403e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15711485346158346,
      "backward_entropy": 0.014313016831874848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1057202793126635e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711424748102823,
      "backward_entropy": 0.01052442267537117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3128684978910314e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711365143458048,
      "backward_entropy": 0.010524353384971619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.780612871651101e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571130851904551,
      "backward_entropy": 0.013837648928165436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.288431287273852e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711249907811484,
      "backward_entropy": 0.010524246096611022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8881817115689046e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15711195270220438,
      "backward_entropy": 0.014312902092933654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.129161711967754e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711140632629395,
      "backward_entropy": 0.010524147003889085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7125005885864084e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15711086988449097,
      "backward_entropy": 0.010524114221334457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.417750977201649e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15711034337679544,
      "backward_entropy": 0.014312836527824401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8195922280028753e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710986653963724,
      "backward_entropy": 0.01052401289343834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2994699122591555e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15710937976837158,
      "backward_entropy": 0.013838262856006622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2271292721143254e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571089227994283,
      "backward_entropy": 0.013838312029838562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9979013643478538e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710850556691489,
      "backward_entropy": 0.010523872077465057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8196560347405466e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710805853207907,
      "backward_entropy": 0.010523810982704163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9142946428019059e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571076512336731,
      "backward_entropy": 0.010523778200149537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.855532190120357e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571072538693746,
      "backward_entropy": 0.01383858621120453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7509911742763506e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710687637329102,
      "backward_entropy": 0.010523690283298493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6078389819540462e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15710649887720743,
      "backward_entropy": 0.01431257426738739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2441219610082044e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710612138112387,
      "backward_entropy": 0.010523605346679687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2393928727760795e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710577368736267,
      "backward_entropy": 0.01052357405424118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2987780451112485e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15710545579592386,
      "backward_entropy": 0.013838875293731689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.232757114166816e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571051279703776,
      "backward_entropy": 0.010523487627506257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1007448108557583e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15710482994715372,
      "backward_entropy": 0.013838972151279449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1009276335016693e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571045219898224,
      "backward_entropy": 0.010523423552513123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2798146542536415e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571042239665985,
      "backward_entropy": 0.013839060068130493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.296656600099595e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571039358774821,
      "backward_entropy": 0.013839097321033477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0289327434520601e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710367759068808,
      "backward_entropy": 0.010523316264152528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.911204929518135e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571033795674642,
      "backward_entropy": 0.01383918672800064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.718989619183048e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571031411488851,
      "backward_entropy": 0.010523241013288498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.30638021195773e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15710288286209106,
      "backward_entropy": 0.01431223601102829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.953868674803743e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15710265437761942,
      "backward_entropy": 0.01431221067905426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.152512893071616e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571024258931478,
      "backward_entropy": 0.013839350640773773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.54693428966857e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337086111307144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571022073427836,
      "backward_entropy": 0.01052311360836029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.668997798442433e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133708983659744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710200866063437,
      "backward_entropy": 0.010523095726966858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.072899966762634e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133709356188774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15710182984670004,
      "backward_entropy": 0.013839416205883026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.23788309894735e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133709728717804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710165103276572,
      "backward_entropy": 0.010523013770580292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8638465699468725e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03133710101246834,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1571014622847239,
      "backward_entropy": 0.01383947730064392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.601616592798564e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337104737758636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.15710127353668213,
      "backward_entropy": 0.013839489221572876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.470013337254386e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031337108463048935,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15710111459096274,
      "backward_entropy": 0.014311914145946503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.911593265433112e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133711218833923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710095564524332,
      "backward_entropy": 0.010522880405187608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7692014842605204e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133711591362953,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710079669952393,
      "backward_entropy": 0.010522834956645966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9173198018715993e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133711963891983,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710065762201944,
      "backward_entropy": 0.010522812604904175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.307770140599132e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133712336421013,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.15710049867630005,
      "backward_entropy": 0.014311756193637847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.262434233874956e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133712708950043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15710036953290304,
      "backward_entropy": 0.010522736608982087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.561815020702852e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031337130814790726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1571002205212911,
      "backward_entropy": 0.010522714257240296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.54431115567877e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031337134540081024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.157100111246109,
      "backward_entropy": 0.013839611411094665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8975197352565374e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133713826537132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.15709997216860452,
      "backward_entropy": 0.010522665828466416,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.1676392357173882e-06,
    "avg_log_Z": 0.031336989291012286,
    "success_rate": 1.0,
    "avg_reward": 45.9,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.11,
      "1": 0.35,
      "2": 0.54
    },
    "avg_forward_entropy": 0.15712594509124758,
    "avg_backward_entropy": 0.012101164504885676,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}