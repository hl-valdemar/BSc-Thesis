{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09872657912118095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09872657912118095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09872657912118095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09872657912118095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09872657912118095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09872657912118095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09872657912118095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09870132378169469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.871395587921143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368759274482727,
      "backward_entropy": 0.09882559095110212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.869912147521973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136874258518219,
      "backward_entropy": 0.09881699936730522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.936633586883545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019999960204586387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368725299835205,
      "backward_entropy": 0.09868213960102626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.526041507720947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00030001692357473075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13686737418174744,
      "backward_entropy": 0.09867240701402936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.660008907318115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003999327018391341,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686448335647583,
      "backward_entropy": 0.09868847472327096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.931643009185791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004998393123969436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686054944992065,
      "backward_entropy": 0.09867873362132482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.862546443939209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005998112610541284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685569167137146,
      "backward_entropy": 0.09864297934940883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.409651756286621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006998024764470756,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368512213230133,
      "backward_entropy": 0.09876288686479841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.201175689697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007999552763067186,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368480920791626,
      "backward_entropy": 0.0987532649721418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.266656875610352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000900177052244544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684426248073578,
      "backward_entropy": 0.09863775968551636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198266983032227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010004764189943671,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683933019638062,
      "backward_entropy": 0.0986015796661377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329780578613281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011008073342964053,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683418929576874,
      "backward_entropy": 0.09859077419553484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.602689743041992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001201216597110033,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368280053138733,
      "backward_entropy": 0.0985799857548305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709676265716553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001301769632846117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13682125508785248,
      "backward_entropy": 0.09859405245099749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5760626792907715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014021473471075296,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368139535188675,
      "backward_entropy": 0.0986919913973127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32149887084961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001502318074926734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13680702447891235,
      "backward_entropy": 0.09854723726000104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399218559265137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016025896184146404,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13679948449134827,
      "backward_entropy": 0.0986703974860055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.332974433898926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017029454465955496,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13679324090480804,
      "backward_entropy": 0.09865925993238177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3753814697265625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018033405067399144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13678887486457825,
      "backward_entropy": 0.09851334776197161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.16332483291626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001903413562104106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678646087646484,
      "backward_entropy": 0.09852443422589983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.247475624084473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00200314330868423,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13678476214408875,
      "backward_entropy": 0.09849074908665248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65073013305664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021030099596828222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678231835365295,
      "backward_entropy": 0.0985001836504255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9683356285095215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0022031546104699373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367785632610321,
      "backward_entropy": 0.09859915290560041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729897499084473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023032724857330322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677410781383514,
      "backward_entropy": 0.0984749368258885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.580626487731934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002403636695817113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677027821540833,
      "backward_entropy": 0.09846195152827672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.578628540039062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025041750632226467,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676577806472778,
      "backward_entropy": 0.09844871929713658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72482681274414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002604861743748188,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676074147224426,
      "backward_entropy": 0.09843523161751884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.677600860595703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027057116385549307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13675636053085327,
      "backward_entropy": 0.09842150551932198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.123518943786621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028070707339793444,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13675251603126526,
      "backward_entropy": 0.09851908683776855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.087893009185791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029086624272167683,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367485672235489,
      "backward_entropy": 0.09850502014160156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.102730751037598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030096054542809725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674600422382355,
      "backward_entropy": 0.09837944167000907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.777798652648926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003110412508249283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674385845661163,
      "backward_entropy": 0.09836513655526298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.451845169067383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032113834749907255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674163818359375,
      "backward_entropy": 0.09846103191375732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.174243927001953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033127760980278254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13673903048038483,
      "backward_entropy": 0.09832692997796195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.045299530029297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0034144255332648754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673582673072815,
      "backward_entropy": 0.09832159110477992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642401695251465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003516226541250944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13673289120197296,
      "backward_entropy": 0.09829963956560407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366124153137207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00361797702498734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673081994056702,
      "backward_entropy": 0.09829153333391462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.373406410217285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037195677869021893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13672930002212524,
      "backward_entropy": 0.0982720937047686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.222732543945312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038214523810893297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13672763109207153,
      "backward_entropy": 0.09825810364314488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.813851356506348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0039235493168234825,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367248296737671,
      "backward_entropy": 0.09835077183587211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.686697006225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004025198984891176,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672217726707458,
      "backward_entropy": 0.09833423580442156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145779609680176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0041263774037361145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672059774398804,
      "backward_entropy": 0.09831733363015312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.541423797607422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004227363038808107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13671886920928955,
      "backward_entropy": 0.09819601263318743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.93280029296875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004328364506363869,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13671629130840302,
      "backward_entropy": 0.09817923818315778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.02027416229248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004429108463227749,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367129683494568,
      "backward_entropy": 0.09826487302780151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.680804252624512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004530538339167833,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367093175649643,
      "backward_entropy": 0.09824727262769427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.803943634033203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004631964024156332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670614361763,
      "backward_entropy": 0.09813717433384486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67566967010498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004733910318464041,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367020457983017,
      "backward_entropy": 0.09810921124049596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.153355598449707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004835781641304493,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13669845461845398,
      "backward_entropy": 0.09810434068952288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.524628639221191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004937316291034222,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13669681549072266,
      "backward_entropy": 0.09817393336977277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.602011680603027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005038774106651545,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13669437170028687,
      "backward_entropy": 0.09815478324890137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.187909126281738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005140630062669516,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13669200241565704,
      "backward_entropy": 0.0981353691646031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.993705749511719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005242206621915102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668909668922424,
      "backward_entropy": 0.0980158873966762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.266240119934082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005343888886272907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136686310172081,
      "backward_entropy": 0.0979962944984436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788567543029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005445309914648533,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13668449223041534,
      "backward_entropy": 0.09807496411459786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840307235717773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0055462936870753765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668277859687805,
      "backward_entropy": 0.09798399039677211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11505126953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005647401325404644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366800218820572,
      "backward_entropy": 0.09796559810638428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.442750930786133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0057482607662677765,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13667719066143036,
      "backward_entropy": 0.09801120417458671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.254401206970215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005849057342857122,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366741806268692,
      "backward_entropy": 0.09789557116372245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.449735641479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00594968069344759,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13667230308055878,
      "backward_entropy": 0.09796686683382307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.578691482543945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006049780640751123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13667088747024536,
      "backward_entropy": 0.09788918495178223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.91817045211792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006149945314973593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366700530052185,
      "backward_entropy": 0.09783179419381278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.635218620300293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00624984223395586,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13667023181915283,
      "backward_entropy": 0.09789741039276123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.818517684936523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006349863484501839,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667038083076477,
      "backward_entropy": 0.09778894696916852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50564956665039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006450111046433449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366693526506424,
      "backward_entropy": 0.0977669187954494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.580615520477295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006550362333655357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13666917383670807,
      "backward_entropy": 0.09778954301561628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.702555179595947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006650164257735014,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13667017221450806,
      "backward_entropy": 0.09779930114746094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.169126510620117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0067496453411877155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667142391204834,
      "backward_entropy": 0.09769977842058454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.105184555053711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006849050056189299,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667353987693787,
      "backward_entropy": 0.09767722232001168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.208392143249512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00694788433611393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667593896389008,
      "backward_entropy": 0.09765449592045375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.797420501708984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00704724807292223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667789101600647,
      "backward_entropy": 0.09763109683990479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.749238967895508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007147367112338543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667932152748108,
      "backward_entropy": 0.09760699101856776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.342698097229004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007247623056173325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668134808540344,
      "backward_entropy": 0.09758245944976807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.824533462524414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007347830571234226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668294250965118,
      "backward_entropy": 0.09762124504361834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.190912246704102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007447705138474703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668552041053772,
      "backward_entropy": 0.09759964261736188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.25033950805664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007547985762357712,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668754696846008,
      "backward_entropy": 0.09750621659415108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.708975791931152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007648665923625231,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366887390613556,
      "backward_entropy": 0.09755493913378034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115778923034668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007749905344098806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668964803218842,
      "backward_entropy": 0.09753204243523735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.436928749084473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00785134918987751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669034838676453,
      "backward_entropy": 0.09742452417101179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.623000144958496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00795313622802496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366906315088272,
      "backward_entropy": 0.09748412881578718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49082088470459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008055346086621284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136689692735672,
      "backward_entropy": 0.09736674172537667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.124547958374023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008157845586538315,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366882175207138,
      "backward_entropy": 0.09738082545144218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.960649490356445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008259894326329231,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366875320672989,
      "backward_entropy": 0.09740672792707171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76469612121582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008361995220184326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668611645698547,
      "backward_entropy": 0.09727561473846436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.470833778381348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00846401322633028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668495416641235,
      "backward_entropy": 0.09735257284981864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.012417793273926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008566326461732388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668324053287506,
      "backward_entropy": 0.0972121272768293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.815702438354492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008668691851198673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668057322502136,
      "backward_entropy": 0.09729608467647008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.908631324768066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008770973421633244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667796552181244,
      "backward_entropy": 0.09714510611125401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.029136657714844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008872763253748417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667452335357666,
      "backward_entropy": 0.0971098712512425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.866731643676758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008975145407021046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366705596446991,
      "backward_entropy": 0.09707364014216832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.349143028259277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009077471680939198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13666647672653198,
      "backward_entropy": 0.09717444011143275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.818065643310547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0091794952750206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13666214048862457,
      "backward_entropy": 0.09713959693908691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.283499717712402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00928194634616375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665813207626343,
      "backward_entropy": 0.09696074894496373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.231435775756836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009385550394654274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366528421640396,
      "backward_entropy": 0.09692105225154332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.054108619689941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0094891507178545,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13664698600769043,
      "backward_entropy": 0.09703264917646136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.410239219665527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009593150578439236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366405487060547,
      "backward_entropy": 0.09683906180518013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.46798324584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009697169996798038,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13663402199745178,
      "backward_entropy": 0.09685150214603969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.208377838134766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009801242500543594,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366269886493683,
      "backward_entropy": 0.09691810607910156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.441364288330078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009905233979225159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13661953806877136,
      "backward_entropy": 0.09670857872281756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75588607788086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010008732788264751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13661277294158936,
      "backward_entropy": 0.09666287047522408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.999137878417969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010111997835338116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13660520315170288,
      "backward_entropy": 0.09679515021187919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.933082580566406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010215125977993011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659805059432983,
      "backward_entropy": 0.09656836305345808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.111095428466797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010318131186068058,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13659065961837769,
      "backward_entropy": 0.09659504890441895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.67019271850586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010420610196888447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658323884010315,
      "backward_entropy": 0.09646981103079659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.475569725036621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010523348115384579,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13657566905021667,
      "backward_entropy": 0.09641931738172259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.282642364501953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010625741444528103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365683376789093,
      "backward_entropy": 0.09636802332741874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.153186798095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010728232562541962,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656102120876312,
      "backward_entropy": 0.09640014171600342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.395405769348145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010830767452716827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13655337691307068,
      "backward_entropy": 0.0962620462690081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.133070945739746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010933457873761654,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13654519617557526,
      "backward_entropy": 0.09629464149475098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.813165664672852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011036645621061325,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13653653860092163,
      "backward_entropy": 0.09623908996582031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.925600051879883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011140107177197933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365276724100113,
      "backward_entropy": 0.09608750683920723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929359436035156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011243843473494053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13651910424232483,
      "backward_entropy": 0.09602548394884382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.53991413116455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011347332037985325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13651083409786224,
      "backward_entropy": 0.09596232005528041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6689453125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011450919322669506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365022510290146,
      "backward_entropy": 0.09613756622586932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.864426612854004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011554141528904438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13649404048919678,
      "backward_entropy": 0.09607777425221034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.843548774719238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011656624265015125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648638129234314,
      "backward_entropy": 0.0957655736378261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261255264282227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011758975684642792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13647788763046265,
      "backward_entropy": 0.09569782870156425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.84782600402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011861404404044151,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13646896183490753,
      "backward_entropy": 0.09573704855782646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.432666778564453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011963164433836937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13646087050437927,
      "backward_entropy": 0.09555370467049736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.751177787780762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012065181508660316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645140826702118,
      "backward_entropy": 0.09575667551585607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.289971351623535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01216705422848463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13644182682037354,
      "backward_entropy": 0.09568752561296735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.065348625183105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012269076891243458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13643167912960052,
      "backward_entropy": 0.09561668975012642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.548762321472168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012370576150715351,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13642239570617676,
      "backward_entropy": 0.09524181059428624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.960381507873535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012471891939640045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13641257584095,
      "backward_entropy": 0.09547114372253418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.951803207397461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012573239393532276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364022195339203,
      "backward_entropy": 0.0952081595148359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.484641075134277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012674610130488873,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13639089465141296,
      "backward_entropy": 0.09512703759329659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.830181121826172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012776278890669346,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13637882471084595,
      "backward_entropy": 0.09504420416695732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.924610137939453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012878364883363247,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13636666536331177,
      "backward_entropy": 0.09495946339198522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.57602310180664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012980377301573753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13635417819023132,
      "backward_entropy": 0.09507650136947632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.544986724853516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013082682155072689,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1363404244184494,
      "backward_entropy": 0.09499011720929827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11551570892334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013184675015509129,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13632726669311523,
      "backward_entropy": 0.09469537224088397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.052972793579102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013286138884723186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363159567117691,
      "backward_entropy": 0.09443475518907819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456995964050293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01338712964206934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13630516827106476,
      "backward_entropy": 0.09433722496032715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.277255058288574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013487891294062138,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13629543781280518,
      "backward_entropy": 0.09441500902175903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438477516174316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013588884845376015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362851858139038,
      "backward_entropy": 0.09413659572601318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.55044174194336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013689638115465641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13627555966377258,
      "backward_entropy": 0.09445230449948992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.362465858459473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01379077322781086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13626518845558167,
      "backward_entropy": 0.09435745647975377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941354751586914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013892680406570435,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13625307381153107,
      "backward_entropy": 0.09401532581874303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.4002685546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01399399247020483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13624204695224762,
      "backward_entropy": 0.09391072818211146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.035213470458984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014095569029450417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13622957468032837,
      "backward_entropy": 0.09359380177089147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.842041969299316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014196611009538174,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13621893525123596,
      "backward_entropy": 0.09369584492274693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839488983154297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014297609217464924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13620880246162415,
      "backward_entropy": 0.0933633531842913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.587240219116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014398607425391674,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13619762659072876,
      "backward_entropy": 0.09347244671412877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.303984642028809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01449943520128727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13618706166744232,
      "backward_entropy": 0.0931241341999599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.864654541015625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01459942664951086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13617852330207825,
      "backward_entropy": 0.093003477369036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.769499778747559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014699548482894897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13616837561130524,
      "backward_entropy": 0.09341691221509661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.082982063293457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014800251461565495,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361561417579651,
      "backward_entropy": 0.09300823722566877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.675589561462402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014900553971529007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361444592475891,
      "backward_entropy": 0.09261362893240792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20962142944336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015000296756625175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361335813999176,
      "backward_entropy": 0.09306330340249198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.31466293334961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015100364573299885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361212432384491,
      "backward_entropy": 0.09233628000531878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.549201965332031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015200798399746418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13610708713531494,
      "backward_entropy": 0.09219122784478324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.595213890075684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015301111154258251,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1360933631658554,
      "backward_entropy": 0.09237826722008842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.865861892700195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01540135033428669,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13607937097549438,
      "backward_entropy": 0.09255501202174596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.016352653503418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015501674264669418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360645592212677,
      "backward_entropy": 0.09242194039481026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.388141632080078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015602142550051212,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13604936003684998,
      "backward_entropy": 0.09228674854551043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.043632507324219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015702422708272934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360340267419815,
      "backward_entropy": 0.0914215360369001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.687191009521484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01580287702381611,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13601849973201752,
      "backward_entropy": 0.0920080201966422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.625537872314453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015903281047940254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13600322604179382,
      "backward_entropy": 0.09186031137193952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.317038536071777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01600363664329052,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13598716259002686,
      "backward_entropy": 0.09139023508344378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52204418182373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01610373891890049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13597235083580017,
      "backward_entropy": 0.09074851444789342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.236759185791016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01620372198522091,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1359584778547287,
      "backward_entropy": 0.09139398166111537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.889616966247559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016304023563861847,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13594308495521545,
      "backward_entropy": 0.09092281545911517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.311162948608398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016403861343860626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13592877984046936,
      "backward_entropy": 0.0910685658454895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62830638885498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016503505408763885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1359153389930725,
      "backward_entropy": 0.09090205601283483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00154972076416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016603166237473488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13590127229690552,
      "backward_entropy": 0.08983608654567174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.827714920043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01670306921005249,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13588519394397736,
      "backward_entropy": 0.09025793416159493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.178155899047852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01680251583456993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1358703076839447,
      "backward_entropy": 0.09038101775305611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.241072654724121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016902321949601173,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13585326075553894,
      "backward_entropy": 0.08990870203290667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32163143157959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017001943662762642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13583579659461975,
      "backward_entropy": 0.08904782363346644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.33506965637207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01710142195224762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13581830263137817,
      "backward_entropy": 0.08884281771523612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456157684326172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017200225964188576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13580261170864105,
      "backward_entropy": 0.0886369262422834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.322073936462402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017299076542258263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13578550517559052,
      "backward_entropy": 0.08940987927573067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.034130096435547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01739787869155407,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357683390378952,
      "backward_entropy": 0.08820572921207973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225618362426758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017496472224593163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13575179874897003,
      "backward_entropy": 0.08899356637682233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.261933326721191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01759498380124569,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13573527336120605,
      "backward_entropy": 0.08861061504908971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.563071250915527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017693450674414635,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13571801781654358,
      "backward_entropy": 0.0884101220539638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.901776313781738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01779206283390522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13569898903369904,
      "backward_entropy": 0.08729267120361328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.462900638580322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01789097674190998,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1356782168149948,
      "backward_entropy": 0.08799878188541957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.439026832580566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017989354208111763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1356591284275055,
      "backward_entropy": 0.08789787973676409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.677430152893066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018087811768054962,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13563883304595947,
      "backward_entropy": 0.08757381779806954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.21437931060791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018186479806900024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1356169879436493,
      "backward_entropy": 0.08742288180759974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366830825805664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018285619094967842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13559341430664062,
      "backward_entropy": 0.0860459463936942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.396101951599121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018384721130132675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.135569229722023,
      "backward_entropy": 0.08578077384403773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.448357582092285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01848381571471691,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13554394245147705,
      "backward_entropy": 0.08667709997722081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39752197265625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018582366406917572,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13551974296569824,
      "backward_entropy": 0.08639144897460938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.316628456115723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018680980429053307,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354941427707672,
      "backward_entropy": 0.08618468046188354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.129533767700195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01877959817647934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1354674994945526,
      "backward_entropy": 0.08584085532597133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902309894561768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018878087401390076,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354411542415619,
      "backward_entropy": 0.0856719868523734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.674087524414062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01897633820772171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354154646396637,
      "backward_entropy": 0.08410561084747314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.294484615325928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019074803218245506,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13538886606693268,
      "backward_entropy": 0.08513879776000977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.665095329284668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01917266845703125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353653073310852,
      "backward_entropy": 0.08351479257856097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.840803146362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019270794466137886,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13534025847911835,
      "backward_entropy": 0.084585360118321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919830322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01936929114162922,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13531216979026794,
      "backward_entropy": 0.08430198260716029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6576080322265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019467590376734734,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13528358936309814,
      "backward_entropy": 0.08401481594358172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.706998825073242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019564958289265633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13525889813899994,
      "backward_entropy": 0.08227440289088658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.359251022338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019662098959088326,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1352345198392868,
      "backward_entropy": 0.08341004167284284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.325332641601562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019759424030780792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13520821928977966,
      "backward_entropy": 0.08282416207449776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.14893913269043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019856898114085197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13518010079860687,
      "backward_entropy": 0.08126745905194964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.163963317871094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019954415038228035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13515041768550873,
      "backward_entropy": 0.08091648987361363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.021233558654785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0200519897043705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13511893153190613,
      "backward_entropy": 0.08055894715445382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.182339668273926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020148904994130135,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13509072363376617,
      "backward_entropy": 0.08179995843342372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.679463863372803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020245935767889023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13506077229976654,
      "backward_entropy": 0.07983185563768659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1643829345703125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020342804491519928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13502973318099976,
      "backward_entropy": 0.08075221947261266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.228392601013184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020439177751541138,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13500094413757324,
      "backward_entropy": 0.08077268941061837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983025550842285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020535163581371307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13497325778007507,
      "backward_entropy": 0.0800232206072126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7601141929626465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020631248131394386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13494408130645752,
      "backward_entropy": 0.07965168782642909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.076938629150391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02072729542851448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13491399586200714,
      "backward_entropy": 0.07927523340497698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.223694801330566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02082289569079876,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13488557934761047,
      "backward_entropy": 0.07933010373796735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.415288925170898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02091818116605282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348581612110138,
      "backward_entropy": 0.07713710410254342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.385016441345215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021013306453824043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13483059406280518,
      "backward_entropy": 0.07672775643212455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.838150978088379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02110830880701542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13480152189731598,
      "backward_entropy": 0.07630915301186698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.491596698760986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02120281755924225,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347751021385193,
      "backward_entropy": 0.07778918743133545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.772174835205078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02129668928682804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347518116235733,
      "backward_entropy": 0.07692551612854004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.993391513824463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02139018289744854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347292810678482,
      "backward_entropy": 0.07503796475274223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.184233665466309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02148345299065113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13470719754695892,
      "backward_entropy": 0.07460640157972064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.562990188598633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02157668210566044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13468307256698608,
      "backward_entropy": 0.07416868209838867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.871203899383545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021670052781701088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346575766801834,
      "backward_entropy": 0.07372289044516427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.137979507446289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021763144060969353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13463275134563446,
      "backward_entropy": 0.0732729605266026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.048316478729248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021856173872947693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13460636138916016,
      "backward_entropy": 0.07281717232295445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.958403587341309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02194909006357193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13457903265953064,
      "backward_entropy": 0.07235599415642875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.340771198272705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022041840478777885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345513015985489,
      "backward_entropy": 0.07188989434923444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.744932174682617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022134697064757347,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13452090322971344,
      "backward_entropy": 0.07308034385953631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.898151397705078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022227277979254723,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134490504860878,
      "backward_entropy": 0.07262832777840751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.22508430480957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02231968194246292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13446028530597687,
      "backward_entropy": 0.0704579906804221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.26247501373291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022412139922380447,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13442839682102203,
      "backward_entropy": 0.07217093876429967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.416582107543945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022504691034555435,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13439390063285828,
      "backward_entropy": 0.0717022248676845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.87805700302124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022597433999180794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134355828166008,
      "backward_entropy": 0.06896779366901942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.490488052368164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02269001677632332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13431638479232788,
      "backward_entropy": 0.07031814541135516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.020468711853027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022782178595662117,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13427847623825073,
      "backward_entropy": 0.0698446375983102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.474340438842773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02287435159087181,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13423767685890198,
      "backward_entropy": 0.06936409217970711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.581812858581543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022965475916862488,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13420426845550537,
      "backward_entropy": 0.06929631744112287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3750200271606445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023056412115693092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13417010009288788,
      "backward_entropy": 0.06840115785598755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.130051612854004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02314705029129982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134135901927948,
      "backward_entropy": 0.06791419642312187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.535248279571533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023237917572259903,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13409754633903503,
      "backward_entropy": 0.06780671221869332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.744398593902588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02332792617380619,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1340642273426056,
      "backward_entropy": 0.06730309128761292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.911493301391602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023417292162775993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13403435051441193,
      "backward_entropy": 0.06644042900630406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.730815887451172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02350623533129692,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13400515913963318,
      "backward_entropy": 0.06594380310603551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.329477310180664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023594656959176064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13397808372974396,
      "backward_entropy": 0.06323500190462385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.33759069442749,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023682361468672752,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13395461440086365,
      "backward_entropy": 0.06526321598461696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.510624885559082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023770105093717575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13392791152000427,
      "backward_entropy": 0.0644362483705793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.014028549194336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023858021944761276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13389641046524048,
      "backward_entropy": 0.0639239421912602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.770117282867432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023945026099681854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13387086987495422,
      "backward_entropy": 0.061100900173187256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.507962703704834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024031061679124832,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13385167717933655,
      "backward_entropy": 0.06289998122623988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.818069934844971,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024116748943924904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13383276760578156,
      "backward_entropy": 0.06238436698913574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.275346755981445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024202357977628708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13381138443946838,
      "backward_entropy": 0.06186407804489136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.749101638793945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024287478998303413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13379189372062683,
      "backward_entropy": 0.0589704087802342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.337732315063477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02437254786491394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1337694525718689,
      "backward_entropy": 0.05843028851917812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.149197101593018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024457266554236412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13374710083007812,
      "backward_entropy": 0.06056476490838187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.578434467315674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024541541934013367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13372579216957092,
      "backward_entropy": 0.059759906360081265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.818562984466553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024625742807984352,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1337016522884369,
      "backward_entropy": 0.05922478437423706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6432905197143555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02470932900905609,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13368019461631775,
      "backward_entropy": 0.05897384030478341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.484994411468506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024792945012450218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13365493714809418,
      "backward_entropy": 0.05571556091308594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7719407081604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024876516312360764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1336263120174408,
      "backward_entropy": 0.05759912303515843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.549116611480713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02496025152504444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13359223306179047,
      "backward_entropy": 0.054606854915618896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.516195297241211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02504393644630909,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13355496525764465,
      "backward_entropy": 0.05404449360711234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.027416706085205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025127597153186798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133513942360878,
      "backward_entropy": 0.05594382541520255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.023314476013184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025210898369550705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13347256183624268,
      "backward_entropy": 0.05291380201067243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.716009616851807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025293827056884766,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13343095779418945,
      "backward_entropy": 0.05519398621150425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.82275128364563,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025376195088028908,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1333910971879959,
      "backward_entropy": 0.05427170651299613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.730358123779297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02545732632279396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13336092233657837,
      "backward_entropy": 0.05123723830495562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.177165508270264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025538066402077675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13333088159561157,
      "backward_entropy": 0.0531694803919111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.683657646179199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025618838146328926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332961767911911,
      "backward_entropy": 0.05013092926570347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.459615230560303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02569924294948578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332610845565796,
      "backward_entropy": 0.0495756779398237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9803967475891113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02577916719019413,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13322673738002777,
      "backward_entropy": 0.051938039915902276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.075767517089844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025858264416456223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13319715857505798,
      "backward_entropy": 0.05139802183423724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.80864143371582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025936704128980637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13317042589187622,
      "backward_entropy": 0.04793668644768851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.972789764404297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02601516619324684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1331387162208557,
      "backward_entropy": 0.04739189573696682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.624391794204712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026092924177646637,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13311032950878143,
      "backward_entropy": 0.049787657601492744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0044097900390625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02616974525153637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13308803737163544,
      "backward_entropy": 0.04631964223725455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.662508487701416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624606341123581,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13306677341461182,
      "backward_entropy": 0.04578964199338641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9750874042510986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632252499461174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13303887844085693,
      "backward_entropy": 0.047669359615870883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7543416023254395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0263985563069582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13301095366477966,
      "backward_entropy": 0.04711975370134626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.04985237121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02647397108376026,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13298514485359192,
      "backward_entropy": 0.04711235846791949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9887568950653076,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026549089699983597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1329575628042221,
      "backward_entropy": 0.046020959104810445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.76092791557312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02662389539182186,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13292834162712097,
      "backward_entropy": 0.04547342232295445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.208896636962891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02669820562005043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13289955258369446,
      "backward_entropy": 0.042615183762141635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.804896354675293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02677249163389206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328655481338501,
      "backward_entropy": 0.04438704252243042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5236613750457764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026846397668123245,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13283036649227142,
      "backward_entropy": 0.044473124401909966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2214765548706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02691967412829399,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1327970027923584,
      "backward_entropy": 0.043948394911629815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4800610542297363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026992136612534523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1327677071094513,
      "backward_entropy": 0.040528642279761176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3493247032165527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027064139023423195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1327381432056427,
      "backward_entropy": 0.040017741067068915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.570309638977051,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02713555097579956,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.132709801197052,
      "backward_entropy": 0.03951084188052586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4826204776763916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0272066667675972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326790302991867,
      "backward_entropy": 0.03900467497961862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.529817819595337,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027277499437332153,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13264575600624084,
      "backward_entropy": 0.040685138532093594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.400139570236206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027348093688488007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13260918855667114,
      "backward_entropy": 0.037996568850108554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.570807933807373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027418365702033043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325703263282776,
      "backward_entropy": 0.037494931902204244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2662174701690674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02748747169971466,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1325395405292511,
      "backward_entropy": 0.03986018896102905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.817915916442871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027556242421269417,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13250641524791718,
      "backward_entropy": 0.0365166962146759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2471940517425537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027624262496829033,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1324760764837265,
      "backward_entropy": 0.03886870401246207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.733396291732788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02769208699464798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1324417144060135,
      "backward_entropy": 0.03555428981781006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7907044887542725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027759181335568428,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13240981101989746,
      "backward_entropy": 0.03789447460855756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.152554750442505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02782568708062172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13237862288951874,
      "backward_entropy": 0.03461148909160069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9205307960510254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027892066165804863,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13234224915504456,
      "backward_entropy": 0.03611760480063302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.855046272277832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0279580969363451,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13230349123477936,
      "backward_entropy": 0.03562691807746887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.797348976135254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02802370674908161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13226287066936493,
      "backward_entropy": 0.033213670764650614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5756094455718994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028088880702853203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13222049176692963,
      "backward_entropy": 0.03466368360178811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6284520626068115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028153426945209503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13217881321907043,
      "backward_entropy": 0.034190974065235684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8118016719818115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02821751870214939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13213594257831573,
      "backward_entropy": 0.03185105536665235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5739450454711914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028281407430768013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1320885419845581,
      "backward_entropy": 0.031403343592371256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.592482328414917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834484353661537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1320396512746811,
      "backward_entropy": 0.030959993600845337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.671227216720581,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028407854959368706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13198845088481903,
      "backward_entropy": 0.03232810539858682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.612231969833374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028470609337091446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13193294405937195,
      "backward_entropy": 0.030082072530473982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4052133560180664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028533073142170906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1318735033273697,
      "backward_entropy": 0.03142522062574114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9847619533538818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028595037758350372,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1318127065896988,
      "backward_entropy": 0.03197606546538217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9545996189117432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028656013309955597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1317567527294159,
      "backward_entropy": 0.02879574043410165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9946331977844238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028716029599308968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13170506060123444,
      "backward_entropy": 0.030118461166109358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2579989433288574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028775284066796303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13165554404258728,
      "backward_entropy": 0.027980661817959378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2226288318634033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028834199532866478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13160255551338196,
      "backward_entropy": 0.02757982909679413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8176426887512207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028892740607261658,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1315462291240692,
      "backward_entropy": 0.029896725501332964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9195265769958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028950421139597893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13149303197860718,
      "backward_entropy": 0.026792473026684353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.775334119796753,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02900746837258339,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1314399391412735,
      "backward_entropy": 0.02909907272883824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.044247627258301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029063737019896507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13138875365257263,
      "backward_entropy": 0.02768511857305254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.887686848640442,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02911974862217903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13133326172828674,
      "backward_entropy": 0.027298331260681152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6554268598556519,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029175247997045517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13127592206001282,
      "backward_entropy": 0.02691857729639326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7922693490982056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029229972511529922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13122043013572693,
      "backward_entropy": 0.024926541107041494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0527803897857666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029284188523888588,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13116298615932465,
      "backward_entropy": 0.027191858206476485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6386523246765137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029338374733924866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13109776377677917,
      "backward_entropy": 0.025816349046570913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3534590005874634,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0293919388204813,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13103263080120087,
      "backward_entropy": 0.026458161217825755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6350016593933105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029444517567753792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1309727281332016,
      "backward_entropy": 0.025103641407830373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7930445671081543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029496613889932632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13091063499450684,
      "backward_entropy": 0.023178903119904653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2817661762237549,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954855188727379,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13084228336811066,
      "backward_entropy": 0.022842417870249068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5553427934646606,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029599493369460106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1307782083749771,
      "backward_entropy": 0.02407488865511758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2557218074798584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296500064432621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13071106374263763,
      "backward_entropy": 0.02219107747077942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1209744215011597,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029699666425585747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13064703345298767,
      "backward_entropy": 0.023419286523546492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0494458675384521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02974829450249672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13058796525001526,
      "backward_entropy": 0.021568470767566135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.266313076019287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02979588322341442,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13053441047668457,
      "backward_entropy": 0.021270960569381714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1270302534103394,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02984294854104519,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1304798722267151,
      "backward_entropy": 0.023450361830847605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0902371406555176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029889250174164772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13042668998241425,
      "backward_entropy": 0.020691384162221636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9664778113365173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029934847727417946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13037508726119995,
      "backward_entropy": 0.020410869802747453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.014681339263916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029979592189192772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13032734394073486,
      "backward_entropy": 0.020137867757252285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9597865343093872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030023636296391487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13028082251548767,
      "backward_entropy": 0.019870638847351074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8812636733055115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030066974461078644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13023623824119568,
      "backward_entropy": 0.021040499210357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0170875787734985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0301094651222229,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13019423186779022,
      "backward_entropy": 0.0193548606974738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7113458514213562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030151491984725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13015024363994598,
      "backward_entropy": 0.019103763358933584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7451279163360596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030192479491233826,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13011208176612854,
      "backward_entropy": 0.020235955715179443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9279324412345886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030232612043619156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13007760047912598,
      "backward_entropy": 0.018625468015670776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9945129752159119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030272342264652252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13004031777381897,
      "backward_entropy": 0.01839251603399004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0878167152404785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030311867594718933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12999790906906128,
      "backward_entropy": 0.018160717827933177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7311488389968872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030351417139172554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12994728982448578,
      "backward_entropy": 0.017928261842046465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8837725520133972,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030390214174985886,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12989869713783264,
      "backward_entropy": 0.019916078874043057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7112165689468384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030428703874349594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12984690070152283,
      "backward_entropy": 0.017477601766586304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7295670509338379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030466482043266296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1297961175441742,
      "backward_entropy": 0.017258782471929277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6986774206161499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030503667891025543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12974494695663452,
      "backward_entropy": 0.01704432496002742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6689876914024353,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030540237203240395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12969349324703217,
      "backward_entropy": 0.018053857343537465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.507247805595398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03057616762816906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1296418309211731,
      "backward_entropy": 0.016627357474395206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8439612984657288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030611127614974976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12959447503089905,
      "backward_entropy": 0.016427570155688694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6522474884986877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030646074563264847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1295396089553833,
      "backward_entropy": 0.017409690788814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6611590385437012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030680537223815918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12948337197303772,
      "backward_entropy": 0.017202387963022505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6030489206314087,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071458823978901,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1294248104095459,
      "backward_entropy": 0.016998742307935442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.606924295425415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03074810840189457,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1293652057647705,
      "backward_entropy": 0.017757916024753025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4407077431678772,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03078114613890648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1293036937713623,
      "backward_entropy": 0.016604323472295488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6556365489959717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03081331215798855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1292455792427063,
      "backward_entropy": 0.015276816274438585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5055829882621765,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03084527887403965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12918224930763245,
      "backward_entropy": 0.01509662824017661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5664441585540771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030876604840159416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1291183978319168,
      "backward_entropy": 0.014920602951731001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.497766375541687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030907606706023216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12905175983905792,
      "backward_entropy": 0.0147467383316585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4901435673236847,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03093813732266426,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12898457050323486,
      "backward_entropy": 0.016660881893975393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39752763509750366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030968166887760162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1289159655570984,
      "backward_entropy": 0.014409002448831285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43795475363731384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030997466295957565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12884901463985443,
      "backward_entropy": 0.015355067593710763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39809927344322205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031026259064674377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1287815421819687,
      "backward_entropy": 0.014087802597454615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4170070290565491,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03105447068810463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12871453166007996,
      "backward_entropy": 0.013932812426771437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5034095644950867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031082160770893097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12864604592323303,
      "backward_entropy": 0.01378098236663001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34612929821014404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031109722331166267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.128572478890419,
      "backward_entropy": 0.013629740902355738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.412285715341568,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031136607751250267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1284998059272766,
      "backward_entropy": 0.015556746295520238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3843740224838257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03116319514811039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284252554178238,
      "backward_entropy": 0.013337961265019007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4370521903038025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03118934854865074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1283489167690277,
      "backward_entropy": 0.013195711587156569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4206736385822296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031215349212288857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12826836109161377,
      "backward_entropy": 0.013054329369749342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34187930822372437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312411617487669,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1281840205192566,
      "backward_entropy": 0.012914074318749564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28611618280410767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312664732336998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12809880077838898,
      "backward_entropy": 0.012776912323066167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2505022883415222,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03129107877612114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12801440060138702,
      "backward_entropy": 0.01473061740398407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.263942688703537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031314995139837265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12793266773223877,
      "backward_entropy": 0.012515830142157418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24998930096626282,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133825585246086,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12785139679908752,
      "backward_entropy": 0.014483565730707986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1619255542755127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03136098384857178,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12777172029018402,
      "backward_entropy": 0.013369826333863395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3221323788166046,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0313827209174633,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12769638001918793,
      "backward_entropy": 0.014253014964716775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23184114694595337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03140438348054886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12761719524860382,
      "backward_entropy": 0.012040693845067705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2213348001241684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03142555058002472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12753839790821075,
      "backward_entropy": 0.011928129409040724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2831862270832062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03144620731472969,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12745988368988037,
      "backward_entropy": 0.013927765190601349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17651306092739105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03146670386195183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12737774848937988,
      "backward_entropy": 0.011709199420043401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.238176167011261,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031486544758081436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12729771435260773,
      "backward_entropy": 0.012708618172577449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1704862117767334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03150614723563194,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12721602618694305,
      "backward_entropy": 0.013621411153248377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1824703812599182,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03152507171034813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12713521718978882,
      "backward_entropy": 0.012508599885872431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23469100892543793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03154357150197029,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1270550787448883,
      "backward_entropy": 0.01130175803388868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17588597536087036,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03156197443604469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1269719898700714,
      "backward_entropy": 0.011204375752380915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17174847424030304,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03157989680767059,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12688861787319183,
      "backward_entropy": 0.012226368699754988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1426103413105011,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03159744292497635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12680549919605255,
      "backward_entropy": 0.011017022388322013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14513668417930603,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03161446750164032,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12672393023967743,
      "backward_entropy": 0.012049702661378043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15095305442810059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316309779882431,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12664267420768738,
      "backward_entropy": 0.010840655437537603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12372931838035583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031647127121686935,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12656141817569733,
      "backward_entropy": 0.012918767120156969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1653735637664795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031662698835134506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12648098170757294,
      "backward_entropy": 0.01067422011068889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1409856677055359,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167802840471268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12639805674552917,
      "backward_entropy": 0.01059363888842719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10948613286018372,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031692985445261,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12631411850452423,
      "backward_entropy": 0.011653404150690352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15567241609096527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03170739486813545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12623122334480286,
      "backward_entropy": 0.010439261794090271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10118313133716583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03172168880701065,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12614589929580688,
      "backward_entropy": 0.011510940534727914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08119326084852219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03173547610640526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12606194615364075,
      "backward_entropy": 0.010291589157921928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08590885996818542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174857422709465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12597984075546265,
      "backward_entropy": 0.010222770273685455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09693406522274017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176118806004524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1258995234966278,
      "backward_entropy": 0.010156620826039995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09317715466022491,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03177346661686897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1258198320865631,
      "backward_entropy": 0.011255896517208644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12290839105844498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03178543224930763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574082612991333,
      "backward_entropy": 0.010029592684337072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11821775883436203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0317973755300045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12565970420837402,
      "backward_entropy": 0.009966971618788583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09502886980772018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031809236854314804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1255764216184616,
      "backward_entropy": 0.009904661348887853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09708285331726074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03182082995772362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1254929006099701,
      "backward_entropy": 0.009843716663973672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09329502284526825,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03183222562074661,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12540876865386963,
      "backward_entropy": 0.010970528636659895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08391883969306946,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0318434052169323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12532402575016022,
      "backward_entropy": 0.009724995919636317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06507361680269241,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03185432031750679,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12523940205574036,
      "backward_entropy": 0.009667570037501199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07746679335832596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03186478465795517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12515616416931152,
      "backward_entropy": 0.010814865784985679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09355279803276062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031874991953372955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1250728815793991,
      "backward_entropy": 0.009558738342353277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07600447535514832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03188516944646835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12498784065246582,
      "backward_entropy": 0.00950508564710617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037791360169649124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031895123422145844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12490251660346985,
      "backward_entropy": 0.010671269680772508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06980974227190018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031904418021440506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12482038140296936,
      "backward_entropy": 0.009403452277183533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058624882251024246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03191354498267174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12473799288272858,
      "backward_entropy": 0.009355198059763228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0678103044629097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03192241117358208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12465642392635345,
      "backward_entropy": 0.010543234646320343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06505332887172699,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031931180506944656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12457451224327087,
      "backward_entropy": 0.010502390563488007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06315930932760239,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03193984180688858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1244923397898674,
      "backward_entropy": 0.009216112749917167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04949258640408516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03194835036993027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12440960109233856,
      "backward_entropy": 0.009171044187886375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045288216322660446,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03195658698678017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12432800233364105,
      "backward_entropy": 0.011536477931908198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046965282410383224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03196446970105171,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12424729764461517,
      "backward_entropy": 0.009085516844476973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04132934659719467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03197205066680908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12416693568229675,
      "backward_entropy": 0.009045098509107317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051529660820961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03197932615876198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12408771365880966,
      "backward_entropy": 0.009006208607128688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04560987651348114,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03198648616671562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12400797754526138,
      "backward_entropy": 0.01024819165468216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05250084400177002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03199351951479912,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12392878532409668,
      "backward_entropy": 0.011384804333959306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039456747472286224,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032000523060560226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12384867668151855,
      "backward_entropy": 0.010184668004512787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041684266179800034,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03200733661651611,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12376958131790161,
      "backward_entropy": 0.010154051440102714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03547617793083191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03201395273208618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12369053810834885,
      "backward_entropy": 0.008820602404219764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029192239046096802,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032020289450883865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12361215054988861,
      "backward_entropy": 0.008786368050745555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02868754416704178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03202629089355469,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12353530526161194,
      "backward_entropy": 0.0087538015629564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0384109765291214,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03203196078538895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.123459592461586,
      "backward_entropy": 0.010044095771653312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029126515612006187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032037608325481415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12338374555110931,
      "backward_entropy": 0.008692009108407157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02335289493203163,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03204295411705971,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.123308464884758,
      "backward_entropy": 0.011189234043870653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02916617877781391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032047975808382034,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1232348307967186,
      "backward_entropy": 0.009973490876810891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024789175018668175,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032052863389253616,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12316179275512695,
      "backward_entropy": 0.011152261069842748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029446860775351524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032057445496320724,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12308928370475769,
      "backward_entropy": 0.011135773999350411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02987573854625225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032061927020549774,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12301670014858246,
      "backward_entropy": 0.011119826563767024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025363938882946968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03206634521484375,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12294384837150574,
      "backward_entropy": 0.008531605558735984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029150644317269325,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03207063674926758,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12287162244319916,
      "backward_entropy": 0.009874699371201652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024320943281054497,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032074976712465286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12279945611953735,
      "backward_entropy": 0.00848274411899703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02138844132423401,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03207922726869583,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12272799760103226,
      "backward_entropy": 0.011058482740606581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016805551946163177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03208329901099205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.122657410800457,
      "backward_entropy": 0.0084355856691088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019686942920088768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03208709508180618,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12258847057819366,
      "backward_entropy": 0.01103077083826065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019862597808241844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032090671360492706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12251995503902435,
      "backward_entropy": 0.008392981652702605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019169572740793228,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032094087451696396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12245180457830429,
      "backward_entropy": 0.009774821145193917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018280787393450737,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03209734708070755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12238402664661407,
      "backward_entropy": 0.009761099304471697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023373054340481758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03210046887397766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12231680750846863,
      "backward_entropy": 0.008334923003401076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016802676022052765,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03210372477769852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1222492977976799,
      "backward_entropy": 0.008315690926143102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019866812974214554,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032106831669807434,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12218254804611206,
      "backward_entropy": 0.00972130788224084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011724789626896381,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03210998699069023,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12211602926254272,
      "backward_entropy": 0.009708136320114136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014882545918226242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032112766057252884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1220507100224495,
      "backward_entropy": 0.008261546492576599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018231432884931564,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03211548924446106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12198655307292938,
      "backward_entropy": 0.009685557867799486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015582541935145855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0321183055639267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12192253023386002,
      "backward_entropy": 0.010933434324605125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014141838066279888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03212109953165054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12185907363891602,
      "backward_entropy": 0.008211215159722738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012205943465232849,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03212383762001991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12179645895957947,
      "backward_entropy": 0.008194760552474431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01122400164604187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03212641179561615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12173477560281754,
      "backward_entropy": 0.008179083466529846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013414713554084301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032128751277923584,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12167377769947052,
      "backward_entropy": 0.010904510106359209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011818347498774529,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03213103115558624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12161299586296082,
      "backward_entropy": 0.00815016935978617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014472386799752712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03213319554924965,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1215527355670929,
      "backward_entropy": 0.010895006358623505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013965355232357979,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03213547170162201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12149254977703094,
      "backward_entropy": 0.008122182850326811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009676739573478699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03213779255747795,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12143217027187347,
      "backward_entropy": 0.010884893792016166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006500256713479757,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03213996812701225,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12137293815612793,
      "backward_entropy": 0.010880368096487862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008040064945816994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032141849398612976,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12131566554307938,
      "backward_entropy": 0.008081878934587752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009329674765467644,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032143484801054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1212591752409935,
      "backward_entropy": 0.008070713707378932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009388196282088757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032145045697689056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12120331823825836,
      "backward_entropy": 0.008059928459780557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00909335445612669,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03214656561613083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12114795297384262,
      "backward_entropy": 0.008049366197415761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008196603506803513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321480855345726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12109329551458359,
      "backward_entropy": 0.008038874715566635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008162927813827991,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032149579375982285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12103968113660812,
      "backward_entropy": 0.009552919438907079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00754200667142868,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321510024368763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12098655849695206,
      "backward_entropy": 0.008018644792693002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007895907387137413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03215233236551285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12093403935432434,
      "backward_entropy": 0.008009141044957297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007134597282856703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032153625041246414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12088192999362946,
      "backward_entropy": 0.007999855492796217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007244910579174757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032154861837625504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12083055078983307,
      "backward_entropy": 0.007990829114403044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006159360054880381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032156068831682205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12077968567609787,
      "backward_entropy": 0.007981998579842704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005782244727015495,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03215717896819115,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12072911858558655,
      "backward_entropy": 0.010864985840661185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0069522433914244175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03215813636779785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12067829072475433,
      "backward_entropy": 0.007965955351080214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006343132816255093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03215916454792023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12062768638134003,
      "backward_entropy": 0.007958035383905684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004844296257942915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321602039039135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12057743221521378,
      "backward_entropy": 0.007950124996049064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005281358491629362,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03216111660003662,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1205279603600502,
      "backward_entropy": 0.010867136929716383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005501856096088886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03216194733977318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12047888338565826,
      "backward_entropy": 0.007935917271035058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0048337671905756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032162778079509735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12043027579784393,
      "backward_entropy": 0.007929063269070216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004900702275335789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03216353803873062,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12038224190473557,
      "backward_entropy": 0.009506989802633013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004658514633774757,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032164283096790314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12033483386039734,
      "backward_entropy": 0.009504865322794234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004316960461437702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03216498717665672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202879324555397,
      "backward_entropy": 0.007909994572401047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004755808971822262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032165661454200745,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12024185061454773,
      "backward_entropy": 0.009501050625528609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004405024461448193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032166361808776855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12019620835781097,
      "backward_entropy": 0.00789796028818403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005367334932088852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032167065888643265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.120151087641716,
      "backward_entropy": 0.010877512395381927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004133352544158697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03216790407896042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.120106041431427,
      "backward_entropy": 0.007885356566735677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003285519313067198,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032168757170438766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1200617253780365,
      "backward_entropy": 0.007878803781100683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003348928177729249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03216952458024025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1200183555483818,
      "backward_entropy": 0.00787266663142613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032613102812319994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03217022866010666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11997572332620621,
      "backward_entropy": 0.009487048855849676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003390067256987095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217087313532829,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11993369460105896,
      "backward_entropy": 0.007861326847757612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003502305131405592,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032171498984098434,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11989214271306992,
      "backward_entropy": 0.010881736874580383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033091818913817406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217214345932007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1198509931564331,
      "backward_entropy": 0.007850497428859984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003032026579603553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032172802835702896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11981040239334106,
      "backward_entropy": 0.007845026041780199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021550122182816267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032173462212085724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11977055668830872,
      "backward_entropy": 0.007839593504156386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027768490836024284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321740098297596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11973178386688232,
      "backward_entropy": 0.00783473253250122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024959056172519922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217456862330437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11969377845525742,
      "backward_entropy": 0.007829873157399041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023084538988769054,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03217510133981705,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11965648829936981,
      "backward_entropy": 0.01088753981249673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020361740607768297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217559680342674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11961992084980011,
      "backward_entropy": 0.007820709475449153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002123407553881407,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032176025211811066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11958412081003189,
      "backward_entropy": 0.007816546197448457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020302014891058207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321764275431633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11954903602600098,
      "backward_entropy": 0.007812548960958208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001724423374980688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03217680752277374,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11951473355293274,
      "backward_entropy": 0.009469553828239441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017317323945462704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032177120447158813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11948113143444061,
      "backward_entropy": 0.00780516756432397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020493848714977503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321773923933506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11944819241762161,
      "backward_entropy": 0.007801873875515801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016697112005203962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217769414186478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1194157674908638,
      "backward_entropy": 0.007798480668238231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016804436454549432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217796981334686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11938398331403732,
      "backward_entropy": 0.007795240197862897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002193356864154339,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217823803424835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11935275048017502,
      "backward_entropy": 0.007792066782712936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018321438692510128,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0321786031126976,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.119321808218956,
      "backward_entropy": 0.009467840194702148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016913219587877393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217900171875954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11929123103618622,
      "backward_entropy": 0.007784868989671979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001690609147772193,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032179418951272964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11926105618476868,
      "backward_entropy": 0.009465899850640978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018139636376872659,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03217986598610878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11923136562108994,
      "backward_entropy": 0.007777381156172071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015515118138864636,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03218037262558937,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11920203268527985,
      "backward_entropy": 0.010902494192123413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014895847998559475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032180897891521454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1191730946302414,
      "backward_entropy": 0.00776929993714605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017127606552094221,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03218143805861473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11914461106061935,
      "backward_entropy": 0.009459906390735082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013208731543272734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03218204528093338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11911642551422119,
      "backward_entropy": 0.009457848966121674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001411808654665947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218264505267143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11908883601427078,
      "backward_entropy": 0.007756613194942474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011022237595170736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032183267176151276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11906163394451141,
      "backward_entropy": 0.007752273763929095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011852664174512029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218385949730873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1190350204706192,
      "backward_entropy": 0.007748122726167951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011527709430083632,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032184451818466187,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11900883913040161,
      "backward_entropy": 0.00944965545620237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010133595205843449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218504413962364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11898314207792282,
      "backward_entropy": 0.007739875997815814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009694999898783863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218561410903931,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1189579963684082,
      "backward_entropy": 0.00773590909583228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009013612871058285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218616172671318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11893336474895477,
      "backward_entropy": 0.007732062999691282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009716669446788728,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218667581677437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11890929937362671,
      "backward_entropy": 0.0077283983784062526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009639543714001775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032187189906835556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11888568103313446,
      "backward_entropy": 0.007724759301968983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007817074074409902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032187726348638535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11886240541934967,
      "backward_entropy": 0.009438755256789071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000697201699949801,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032188232988119125,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11883963644504547,
      "backward_entropy": 0.009437104421002524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007050582207739353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218870237469673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11881739646196365,
      "backward_entropy": 0.007714145417724337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007435914012603462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03218914940953255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11879563331604004,
      "backward_entropy": 0.007710904947349003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006146230734884739,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032189588993787766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11877429485321045,
      "backward_entropy": 0.0077077533517565045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000751594896428287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032189998775720596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11875343322753906,
      "backward_entropy": 0.009431533515453339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006966718356125057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032190416008234024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11873292922973633,
      "backward_entropy": 0.007701721574578967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007079779170453548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219084069132805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11871279776096344,
      "backward_entropy": 0.007698678544589451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005115793319419026,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03219129145145416,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11869294196367264,
      "backward_entropy": 0.01088935456105641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005834738258272409,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032191697508096695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11867360770702362,
      "backward_entropy": 0.0076926542179925105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044000556226819754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219210356473923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11865462362766266,
      "backward_entropy": 0.0076897793582507545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005165000911802053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219246491789818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186361312866211,
      "backward_entropy": 0.007687124290636608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005114051164127886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219282254576683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11861798167228699,
      "backward_entropy": 0.007684500621897834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044831601553596556,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03219316899776459,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11860021203756332,
      "backward_entropy": 0.010886483958789281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004633142380043864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219349682331085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11858280003070831,
      "backward_entropy": 0.0076794954282896856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041101238457486033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219381719827652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11856576800346375,
      "backward_entropy": 0.00767711124249867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000493902713060379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032194118946790695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11854906380176544,
      "backward_entropy": 0.009419568947383336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003711718018166721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219445049762726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11853261291980743,
      "backward_entropy": 0.007672404604298728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003770499024540186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219476342201233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11851652711629868,
      "backward_entropy": 0.007670097585235324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031846080673858523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032195061445236206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850077658891678,
      "backward_entropy": 0.007667889552456992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003405730240046978,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03219533711671829,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11848540604114532,
      "backward_entropy": 0.010882677776472909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036476898822002113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032195620238780975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847035586833954,
      "backward_entropy": 0.007663666137627193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036709659616462886,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032195910811424255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11845555901527405,
      "backward_entropy": 0.009415032608168466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033801497193053365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219621628522873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11844098567962646,
      "backward_entropy": 0.007659371410097394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031690008472651243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0321965254843235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11842668056488037,
      "backward_entropy": 0.00765720648424966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025045499205589294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219684213399887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11841262876987457,
      "backward_entropy": 0.007655029850346702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002694148861337453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219714015722275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11839891970157623,
      "backward_entropy": 0.00765294475214822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025482234195806086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032197434455156326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11838550865650177,
      "backward_entropy": 0.007650897971221379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002953091461677104,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03219772130250931,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1183723583817482,
      "backward_entropy": 0.009410030075481959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002221727481810376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03219803422689438,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11835940182209015,
      "backward_entropy": 0.009409116847174508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002511530474293977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219832852482796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11834675073623657,
      "backward_entropy": 0.007644817765269961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023008999414741993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219863027334213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11833430826663971,
      "backward_entropy": 0.007642798125743866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001983599941013381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219893202185631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11832209676504135,
      "backward_entropy": 0.00764078859772001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019217580847907811,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03219923377037048,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11831018328666687,
      "backward_entropy": 0.009405532053538732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016832808614708483,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032199520617723465,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11829852312803268,
      "backward_entropy": 0.010871921266828264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019581722153816372,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03219977393746376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11828713119029999,
      "backward_entropy": 0.007635128285203662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017298987950198352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220003843307495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11827594041824341,
      "backward_entropy": 0.009403213858604431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015334076306317002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220030292868614,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11826500296592712,
      "backward_entropy": 0.010869638196059636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017269082309212536,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032200541347265244,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11825429648160934,
      "backward_entropy": 0.01086893571274621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017133764049503952,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032200783491134644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11824377626180649,
      "backward_entropy": 0.00940116069146565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012810896441806108,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220104053616524,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11823342740535736,
      "backward_entropy": 0.009400429470198495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013349218352232128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220127150416374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11822333186864853,
      "backward_entropy": 0.007625012525490352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012022504961350933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032201506197452545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1182134747505188,
      "backward_entropy": 0.00762345056448664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001082574890460819,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032201722264289856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11820384114980698,
      "backward_entropy": 0.009398605142320906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011008302681148052,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220192715525627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11819444596767426,
      "backward_entropy": 0.007620552288634437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010742686572484672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220212832093239,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11818530410528183,
      "backward_entropy": 0.010864056646823883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.971275383373722e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220231458544731,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11817634105682373,
      "backward_entropy": 0.009397088416985102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92527459654957e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220248967409134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11816761642694473,
      "backward_entropy": 0.007616586983203888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.43398626986891e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220265358686447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11815911531448364,
      "backward_entropy": 0.007615387439727783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.92605637293309e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220280632376671,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11815078556537628,
      "backward_entropy": 0.009395982537950789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.186076931655407e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220297023653984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11814262717962265,
      "backward_entropy": 0.0076130543436322895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.805992597946897e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032203126698732376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11813460290431976,
      "backward_entropy": 0.007611932499068124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.010940993903205e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032203271985054016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11812680959701538,
      "backward_entropy": 0.007610846843038287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.060328400461003e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032203420996665955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11811915040016174,
      "backward_entropy": 0.007609762251377106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.91021850798279e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220357373356819,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11811164021492004,
      "backward_entropy": 0.009394264646938868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.54688517190516e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220372274518013,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11810430884361267,
      "backward_entropy": 0.00760760424392564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.406835356960073e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032203879207372665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11809709668159485,
      "backward_entropy": 0.007606516991342817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.606242095585912e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032204024493694305,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11809003353118896,
      "backward_entropy": 0.007605493068695068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.279769902699627e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220416605472565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11808307468891144,
      "backward_entropy": 0.007604476064443588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7906636357074603e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032204292714595795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11807632446289062,
      "backward_entropy": 0.0076035452740533015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.307167521095835e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032204415649175644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11806973069906235,
      "backward_entropy": 0.00939244031906128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.390882168081589e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032204534858465195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11806328594684601,
      "backward_entropy": 0.009392239153385162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.873692159890197e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220464289188385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.118057020008564,
      "backward_entropy": 0.007600942360503333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.891822780133225e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220473974943161,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11805088818073273,
      "backward_entropy": 0.009391948580741882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.254146188031882e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220483660697937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11804494261741638,
      "backward_entropy": 0.007599402751241412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.038860060973093e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220492601394653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11803914606571198,
      "backward_entropy": 0.007598685898951122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0561855712439865e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0322050005197525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11803348362445831,
      "backward_entropy": 0.009391680359840393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5683366149896756e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220507875084877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1180279403924942,
      "backward_entropy": 0.007597365549632481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.172895569354296e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032205160707235336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11802253127098083,
      "backward_entropy": 0.007596693400825773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2741598261054605e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220523148775101,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11801722645759583,
      "backward_entropy": 0.010855019092559814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0102375603746623e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220530226826668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11801205575466156,
      "backward_entropy": 0.007595452879156385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2061783713288605e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220537304878235,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11800701916217804,
      "backward_entropy": 0.010854629533631461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.054764965781942e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220544010400772,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11800210177898407,
      "backward_entropy": 0.010854436882904597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9683844331884757e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0322054959833622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11799727380275726,
      "backward_entropy": 0.007593777562890734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5255667424062267e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032205548137426376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11799255013465881,
      "backward_entropy": 0.007593266133751188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8281132472329773e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220559284090996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1179879754781723,
      "backward_entropy": 0.007592795682804925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4171929908334278e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220563754439354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11798346787691116,
      "backward_entropy": 0.009391618626458305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.099827517871745e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220567852258682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11797908693552017,
      "backward_entropy": 0.007591882986681802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4135732019203715e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220570832490921,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11797473579645157,
      "backward_entropy": 0.009391847465719496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3898433937574737e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032205741852521896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11797046661376953,
      "backward_entropy": 0.0075910985469818115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.049398608505726e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032205767929553986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11796629428863525,
      "backward_entropy": 0.007590748369693756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0828822016483173e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220579773187637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11796222627162933,
      "backward_entropy": 0.007590371051004955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.179379589506425e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032205820083618164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11795824766159058,
      "backward_entropy": 0.0075900474829333165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8032946172752418e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032205842435359955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11795434355735779,
      "backward_entropy": 0.00939264999968665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.817040356399957e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032205868512392044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11795053631067276,
      "backward_entropy": 0.007589376930679593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2486503692343831e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220590204000473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1179468035697937,
      "backward_entropy": 0.00939291502748217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4670218661194667e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032205939292907715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11794322729110718,
      "backward_entropy": 0.007588647305965424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6503490769537166e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0322059728205204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11793974041938782,
      "backward_entropy": 0.007588285420622144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5693398381699808e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206010073423386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11793632805347443,
      "backward_entropy": 0.007587943226099014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3681288692168891e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220604360103607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.117932990193367,
      "backward_entropy": 0.007587590387889317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3300630598678254e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220606967806816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11792971938848495,
      "backward_entropy": 0.007587283317531858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3028872672293801e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220609575510025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11792651563882828,
      "backward_entropy": 0.009393438696861267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1184765753569081e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220612555742264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11792339384555817,
      "backward_entropy": 0.007586692592927388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2066344424965791e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032206155359745026,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11792036145925522,
      "backward_entropy": 0.010852154876504625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2289383448660374e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220618516206741,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11791739612817764,
      "backward_entropy": 0.009393669664859772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.538938345736824e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0322062112390995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11791446805000305,
      "backward_entropy": 0.007585784154278892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.007998414745089e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220623731613159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11791165173053741,
      "backward_entropy": 0.007585494646004268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.92868286225712e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220625966787338,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11790891736745834,
      "backward_entropy": 0.009393951722553797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1796675911173224e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220628574490547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11790628731250763,
      "backward_entropy": 0.009394030485834395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.887284482421819e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220631554722786,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11790372431278229,
      "backward_entropy": 0.009394085833004542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.143369657569565e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220634534955025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1179012656211853,
      "backward_entropy": 0.009394113506589617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.995059604581911e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220637887716293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178988516330719,
      "backward_entropy": 0.007584138640335628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.425530384352896e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220641240477562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11789649724960327,
      "backward_entropy": 0.007583858711378915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.317870545695769e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206445932388306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11789418756961823,
      "backward_entropy": 0.007583591554846082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.923825367266545e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220647946000099,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11789197474718094,
      "backward_entropy": 0.007583306304046086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.54015514353523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220651298761368,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11788979172706604,
      "backward_entropy": 0.010850411440644945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.819232228532201e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032206542789936066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11788769066333771,
      "backward_entropy": 0.009394190141132899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2540661929233465e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206568866968155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11788563430309296,
      "backward_entropy": 0.007582577211516244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.378123660193523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220658749341965,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11788363754749298,
      "backward_entropy": 0.010850028267928533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.841793725063326e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220660611987114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178816705942154,
      "backward_entropy": 0.007582184459481921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.449982043297496e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220662474632263,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11787976324558258,
      "backward_entropy": 0.010849781334400177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.429812634043628e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220664709806442,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11787790060043335,
      "backward_entropy": 0.010849656803267342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.687443379225442e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032206665724515915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11787611246109009,
      "backward_entropy": 0.009394534996577672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.739396899822168e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220668062567711,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11787436157464981,
      "backward_entropy": 0.009394609502383642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.871655280818231e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206691801548004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11787262558937073,
      "backward_entropy": 0.007581272295543126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2855302833922906e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0322067067027092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11787094175815582,
      "backward_entropy": 0.007581113704613277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.990115146734752e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220672160387039,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1178693100810051,
      "backward_entropy": 0.010849159743104662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.637908548626001e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220673277974129,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11786772310733795,
      "backward_entropy": 0.0075808146170207435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4684287584241247e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220674395561218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178661659359932,
      "backward_entropy": 0.0075806986008371624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1077836410986492e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220675513148308,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11786464601755142,
      "backward_entropy": 0.009395122528076172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2993143577186856e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220676630735397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11786316335201263,
      "backward_entropy": 0.009395195969513484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5297224510723026e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220677748322487,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11786168813705444,
      "backward_entropy": 0.009395265153476171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6194493329967372e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206788659095764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11786027252674103,
      "backward_entropy": 0.007580151515347617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.739384854066884e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220679983496666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178589016199112,
      "backward_entropy": 0.0075800131474222454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.109078423018218e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206807285547256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11785756796598434,
      "backward_entropy": 0.007579889680658068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3636737296328647e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220681846141815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11785626411437988,
      "backward_entropy": 0.007579769939184189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1494233806151897e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220682963728905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1178550124168396,
      "backward_entropy": 0.009395608944552285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6512514068599558e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032206837087869644,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1178538054227829,
      "backward_entropy": 0.010848172008991241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0156560367468046e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220684453845024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1178525984287262,
      "backward_entropy": 0.009395768599850791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6803019207145553e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220685198903084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11785142123699188,
      "backward_entropy": 0.007579342595168522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.025393769145012e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032206859439611435,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11785030364990234,
      "backward_entropy": 0.010847947427204676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3567428140959237e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220686689019203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784917861223221,
      "backward_entropy": 0.007579160588128226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6195327816603822e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220687434077263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784814298152924,
      "backward_entropy": 0.007579064262764794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5545105043202057e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220687806606293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784711480140686,
      "backward_entropy": 0.007578982306378228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5115215319383424e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206885516643524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784611642360687,
      "backward_entropy": 0.007578895560332707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.566342803016596e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220689296722412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784515529870987,
      "backward_entropy": 0.007578814668314797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6111121112771798e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220689669251442,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11784420907497406,
      "backward_entropy": 0.009396344423294067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0836881756404182e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220690041780472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784327030181885,
      "backward_entropy": 0.0075786661888871875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1679162525979336e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206904143095016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784238368272781,
      "backward_entropy": 0.0075785986014774865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2952417591804988e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032206907868385315,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11784152686595917,
      "backward_entropy": 0.01084726516689573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1369604635547148e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220691159367561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11784067749977112,
      "backward_entropy": 0.0075784602335521156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.058954676926078e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220691531896591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783985793590546,
      "backward_entropy": 0.0075783974358013696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1670342701108893e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220691904425621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783907562494278,
      "backward_entropy": 0.007578324526548386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.166687734956213e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220692276954651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178383082151413,
      "backward_entropy": 0.0075782521494797295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.614036346443754e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206930220127106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783754825592041,
      "backward_entropy": 0.007578195205756596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.170810244540917e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0322069376707077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178368330001831,
      "backward_entropy": 0.007578123360872269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.607179668411845e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0322069451212883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178361102938652,
      "backward_entropy": 0.007578051515987941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919960237108171e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206952571868896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783540993928909,
      "backward_entropy": 0.007577978074550629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.075930963968858e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220696002244949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783473193645477,
      "backward_entropy": 0.007577905697481973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.428497153545322e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220696747303009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783405393362045,
      "backward_entropy": 0.007577833320413317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.845606546652562e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220697492361069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783339083194733,
      "backward_entropy": 0.007577765733003616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.901715892126958e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032206982374191284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178327351808548,
      "backward_entropy": 0.0075776976134095874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.119615593685012e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220698982477188,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783209443092346,
      "backward_entropy": 0.007577627897262573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.334989848255645e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220699727535248,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11783148348331451,
      "backward_entropy": 0.010846195476395743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.910049824502494e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032207004725933075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11783087253570557,
      "backward_entropy": 0.0075775086879730225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.243781172088347e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220701217651367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.117830291390419,
      "backward_entropy": 0.007577445358037949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.313300104920927e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220701962709427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11782971769571304,
      "backward_entropy": 0.009397322578089578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.091432058179635e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220702335238457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11782915890216827,
      "backward_entropy": 0.009397366217204503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.746269948758709e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032207027077674866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178286224603653,
      "backward_entropy": 0.0075772835740021294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.76243570801671e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032207030802965164,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11782807111740112,
      "backward_entropy": 0.010845782501356942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9495094483754656e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220703452825546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782754957675934,
      "backward_entropy": 0.007577192038297653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.313894521601469e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220703825354576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782702803611755,
      "backward_entropy": 0.007577133498021534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1713425957823347e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220704197883606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782652884721756,
      "backward_entropy": 0.0075771015669618335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6756446181461797e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220704570412636,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11782603710889816,
      "backward_entropy": 0.009397588670253754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7209281344985357e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032207049429416656,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11782553791999817,
      "backward_entropy": 0.009397619536944799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6697278460451344e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032207053154706955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11782506108283997,
      "backward_entropy": 0.00939766104732241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.525354941302794e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220705687999725,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11782459169626236,
      "backward_entropy": 0.010845397199903215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5606956316769356e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220706060528755,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11782412976026535,
      "backward_entropy": 0.010845358882631575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.396189415776462e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220706433057785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782369017601013,
      "backward_entropy": 0.007576836006981986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.006406359418179e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220706805586815,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782325804233551,
      "backward_entropy": 0.007576807269028255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.635077009927045e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220707178115845,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782282590866089,
      "backward_entropy": 0.00757676043680736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4772418782958994e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.032207075506448746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11782243102788925,
      "backward_entropy": 0.010845163038798742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5323092245344014e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032207079231739044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782205104827881,
      "backward_entropy": 0.007576711475849152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.401248764272168e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220708295702934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782166361808777,
      "backward_entropy": 0.007576671562024525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4039616164373e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220708295702934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782129853963852,
      "backward_entropy": 0.007576643356255123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.964401121767878e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220708295702934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782094836235046,
      "backward_entropy": 0.007576608232089451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6528771595858416e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220708295702934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1178206205368042,
      "backward_entropy": 0.009398052734988076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2174468483626697e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220708668231964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11782027781009674,
      "backward_entropy": 0.007576566189527512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8444247018578608e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220708668231964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781995743513107,
      "backward_entropy": 0.007576534790652139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2897618262286414e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220708668231964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1178196370601654,
      "backward_entropy": 0.007576510842357363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.333769006350849e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220709040760994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11781933903694153,
      "backward_entropy": 0.009398180459226881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8300600856946403e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220709413290024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781904101371765,
      "backward_entropy": 0.007576450705528259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.400238147652999e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032207097858190536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781876534223557,
      "backward_entropy": 0.007576429950339454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2486464129324304e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032207101583480835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781847476959229,
      "backward_entropy": 0.00757640866296632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5002201791958214e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710530877113,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781821399927139,
      "backward_entropy": 0.007576373538800648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.572791177295585e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1178179383277893,
      "backward_entropy": 0.009398306054728372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4965443995151873e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11781768500804901,
      "backward_entropy": 0.009398325213364192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.253721961802512e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11781741678714752,
      "backward_entropy": 0.009398350758211953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3026244971570122e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781717836856842,
      "backward_entropy": 0.007576294243335724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0484465207127869e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781692504882812,
      "backward_entropy": 0.0075762825352805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0389975813041019e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11781668663024902,
      "backward_entropy": 0.009398457195077623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2806941640519653e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781645566225052,
      "backward_entropy": 0.007576255926064083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.276241203475365e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11781622469425201,
      "backward_entropy": 0.01084434028182711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.468559542507137e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781599372625351,
      "backward_entropy": 0.007576220801898411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1132696187132751e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1178157776594162,
      "backward_entropy": 0.009398572146892548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.834442866145764e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781555414199829,
      "backward_entropy": 0.0075762080294745305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.28394056181969e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11781534552574158,
      "backward_entropy": 0.00939863920211792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.884053505018528e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11781513690948486,
      "backward_entropy": 0.009398679648126875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.70643842681784e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781492829322815,
      "backward_entropy": 0.00757618567773274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.036404715497156e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781472712755203,
      "backward_entropy": 0.007576177162783486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.775996842454333e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03220710903406143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781454086303711,
      "backward_entropy": 0.007576149489198413,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.5719359948818124e-06,
    "avg_log_Z": 0.032206924818456176,
    "success_rate": 1.0,
    "avg_reward": 50.1,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.14,
      "1": 0.23,
      "2": 0.63
    },
    "avg_forward_entropy": 0.11784054100513458,
    "avg_backward_entropy": 0.008454296908208302,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}