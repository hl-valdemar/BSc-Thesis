{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.09896467413221087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990004028592791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.805707931518555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730229437351227,
      "backward_entropy": 0.0990126643862043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.799988746643066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730409741401672,
      "backward_entropy": 0.09895908832550049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.794269561767578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0001999995147343725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730570673942566,
      "backward_entropy": 0.09895317043576922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.416777610778809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00029999823891557753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730710744857788,
      "backward_entropy": 0.0989468949181693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.239545822143555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00040011334931477904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730837404727936,
      "backward_entropy": 0.09901716027941022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.777079582214355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005002707475796342,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730931282043457,
      "backward_entropy": 0.09898337296077184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.675522804260254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006003386224620044,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731008768081665,
      "backward_entropy": 0.09897920063563756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.573590278625488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007003122591413558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731074333190918,
      "backward_entropy": 0.09891848904745919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.497021675109863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008001842652447522,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731130957603455,
      "backward_entropy": 0.099020140511649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.299205780029297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008999821729958057,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731160759925842,
      "backward_entropy": 0.09896498067038399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.845059394836426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009996526641771197,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373116821050644,
      "backward_entropy": 0.09889357430594307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.003512382507324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010993999894708395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731151819229126,
      "backward_entropy": 0.0988844462803432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.25706672668457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011992409126833081,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1373112052679062,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.277226448059082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012992246774956584,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1373107135295868,
      "backward_entropy": 0.09902083873748779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.754265785217285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001399034634232521,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731002807617188,
      "backward_entropy": 0.09893536567687988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.168510437011719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014985499437898397,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730916380882263,
      "backward_entropy": 0.09892846856798444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.06783676147461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015979335876181722,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730813562870026,
      "backward_entropy": 0.09892123086111886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.865503311157227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001697517465800047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730688393115997,
      "backward_entropy": 0.09901833534240723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.543065071105957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017971897032111883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730543851852417,
      "backward_entropy": 0.09880872283663068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.086370468139648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018968654330819845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730372488498688,
      "backward_entropy": 0.09901576382773263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.081546783447266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001996381673961878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730183243751526,
      "backward_entropy": 0.09901407786778041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.330450057983398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020957619417458773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729985058307648,
      "backward_entropy": 0.09876884732927595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.324976921081543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021951065864413977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729768991470337,
      "backward_entropy": 0.09875438894544329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.319443702697754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002294420963153243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729535043239594,
      "backward_entropy": 0.09873929194041661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.167400360107422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00239370996132493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372928023338318,
      "backward_entropy": 0.09872347967965263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.658082962036133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024932643864303827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729003071784973,
      "backward_entropy": 0.09870694364820208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.751076698303223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025928854010999203,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13728703558444977,
      "backward_entropy": 0.09882781335285731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.047249794006348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002692609094083309,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13728389143943787,
      "backward_entropy": 0.09899302891322545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.141871452331543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027921623550355434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728061318397522,
      "backward_entropy": 0.09865289075034005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.277054786682129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028916141018271446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13727723062038422,
      "backward_entropy": 0.09863344260624476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.221030235290527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002991348970681429,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372736394405365,
      "backward_entropy": 0.09861315999712263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.826794624328613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003091339021921158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726982474327087,
      "backward_entropy": 0.0985919748033796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.775903701782227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00319101894274354,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372658759355545,
      "backward_entropy": 0.09896598543439593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.852333068847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003290437860414386,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726185262203217,
      "backward_entropy": 0.09873430218015398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.910666465759277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033900218550115824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725757598876953,
      "backward_entropy": 0.0989518506186349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.350223541259766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034893909469246864,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725319504737854,
      "backward_entropy": 0.09870232854570661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.555789947509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035887586418539286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372486650943756,
      "backward_entropy": 0.0986854178564889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.722113609313965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036877961829304695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724404573440552,
      "backward_entropy": 0.09892657824925014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.88840103149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003786998800933361,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723915815353394,
      "backward_entropy": 0.09864955289023263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.224814414978027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038860298227518797,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723412156105042,
      "backward_entropy": 0.09890685762677874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.39638614654541,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0039850506000220776,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722889125347137,
      "backward_entropy": 0.09861138888767787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.1107816696167,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004083740990608931,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722370564937592,
      "backward_entropy": 0.09888476984841484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.728099822998047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004182410892099142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721829652786255,
      "backward_entropy": 0.09887283188956124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.449932098388672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004280935972929001,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721290230751038,
      "backward_entropy": 0.09824986117226737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.396854400634766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004379259888082743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372077763080597,
      "backward_entropy": 0.09821546077728271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.983752250671387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004477770533412695,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720248639583588,
      "backward_entropy": 0.09850774492536273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.47132396697998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004576231352984905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719694316387177,
      "backward_entropy": 0.098142751625606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.466798782348633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004674483090639114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719162344932556,
      "backward_entropy": 0.09880386931555611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.59572982788086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004772551357746124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718637824058533,
      "backward_entropy": 0.098788321018219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.365819931030273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004870495293289423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718116283416748,
      "backward_entropy": 0.09802613939557757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.81958293914795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004968680907040834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371757984161377,
      "backward_entropy": 0.09798504625047956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.353035926818848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005066823214292526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371702402830124,
      "backward_entropy": 0.09794272695268903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.603935241699219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005165186710655689,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716459274291992,
      "backward_entropy": 0.09833456788744245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.801507949829102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0052633751183748245,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715875148773193,
      "backward_entropy": 0.09870105130331856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.231175422668457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005361521616578102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371527463197708,
      "backward_entropy": 0.09780799491064888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.557703971862793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005459836684167385,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371465027332306,
      "backward_entropy": 0.09824778352464948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.780966758728027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005558450240641832,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371399611234665,
      "backward_entropy": 0.09863977772848946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.18648910522461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00565742002800107,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713319599628448,
      "backward_entropy": 0.0986177750996181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.993854522705078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005756032653152943,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712672889232635,
      "backward_entropy": 0.09859481028148107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.73664379119873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005855093710124493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13711954653263092,
      "backward_entropy": 0.09754964283534459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.612075805664062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005954029969871044,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711243867874146,
      "backward_entropy": 0.09809173004967826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.849908828735352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0060523622669279575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13710597157478333,
      "backward_entropy": 0.09743616410664149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.28602123260498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006150687579065561,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709929585456848,
      "backward_entropy": 0.09737968444824219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.97458267211914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006249643862247467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13709184527397156,
      "backward_entropy": 0.09845504590443202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.522987365722656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006348099559545517,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137084499001503,
      "backward_entropy": 0.09726071357727051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.701737403869629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006446357350796461,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707689940929413,
      "backward_entropy": 0.09838787146977016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.467101097106934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0065450104884803295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706883788108826,
      "backward_entropy": 0.09713556085314069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.254312515258789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00664391927421093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370604932308197,
      "backward_entropy": 0.09831483023507255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.12302017211914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0067429374903440475,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705171644687653,
      "backward_entropy": 0.09827621494020734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.566123008728027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006842015776783228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370428055524826,
      "backward_entropy": 0.09693283694131034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.319416999816895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006940899416804314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137034073472023,
      "backward_entropy": 0.09819487162998744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.096068382263184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007040377706289291,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13702426850795746,
      "backward_entropy": 0.0981522628239223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.851590156555176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007139857858419418,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370142549276352,
      "backward_entropy": 0.09763004098619733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.958699226379395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0072396742179989815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370036005973816,
      "backward_entropy": 0.09806290694645473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42431354522705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007339414209127426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699322938919067,
      "backward_entropy": 0.09801597254616874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.261506080627441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007438812404870987,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13698309659957886,
      "backward_entropy": 0.09796770981379918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.829673767089844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007538327481597662,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13697299361228943,
      "backward_entropy": 0.09791769300188337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.501190185546875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007637732196599245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369629204273224,
      "backward_entropy": 0.09631858553205218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.27579116821289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0077368831261992455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695301115512848,
      "backward_entropy": 0.09781160524913243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.572917938232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007835712283849716,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13694345951080322,
      "backward_entropy": 0.09730815887451172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.294892311096191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007934433408081532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693450391292572,
      "backward_entropy": 0.09606939554214478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.581135749816895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008032439276576042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13692690432071686,
      "backward_entropy": 0.09598425456455775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.927218437194824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008130371570587158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691885769367218,
      "backward_entropy": 0.09758045843669347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.383416175842285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008227955549955368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691113889217377,
      "backward_entropy": 0.09580108097621373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.797910690307617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008325961418449879,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13690313696861267,
      "backward_entropy": 0.09745367084230695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.802431106567383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008423574268817902,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368958204984665,
      "backward_entropy": 0.09700029236929757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.048871994018555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008520808070898056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688869774341583,
      "backward_entropy": 0.09551189626966204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.851032257080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008618319407105446,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13688093423843384,
      "backward_entropy": 0.09688959802900042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.977290153503418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008715931326150894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368720829486847,
      "backward_entropy": 0.09530971731458392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.557049751281738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008813281543552876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686364889144897,
      "backward_entropy": 0.09520538364137922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.382424354553223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008910181000828743,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13685576617717743,
      "backward_entropy": 0.09671413898468018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.217074394226074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00900708232074976,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13684764504432678,
      "backward_entropy": 0.09665329967226301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.922624588012695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009104358963668346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368381679058075,
      "backward_entropy": 0.09487526757376534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930410385131836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00920233316719532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368272304534912,
      "backward_entropy": 0.09475631373269218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.46088981628418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009299997240304947,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368168741464615,
      "backward_entropy": 0.0966809902872358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.294856071472168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009398149326443672,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368059515953064,
      "backward_entropy": 0.09638558115277972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.039295196533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009495657868683338,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367960274219513,
      "backward_entropy": 0.09631385122026716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.680020332336426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009593426249921322,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13678520917892456,
      "backward_entropy": 0.09624017987932477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485965728759766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009690801613032818,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677537441253662,
      "backward_entropy": 0.09412571362086705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.802719116210938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00978767778724432,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136765718460083,
      "backward_entropy": 0.09608852011816842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.582462310791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009884755127131939,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13675491511821747,
      "backward_entropy": 0.0960096802030291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854402542114258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009981916286051273,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13674336671829224,
      "backward_entropy": 0.09592887333461217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.446694374084473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01007880736142397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673196732997894,
      "backward_entropy": 0.09358254500797816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72273063659668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010175762698054314,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367201805114746,
      "backward_entropy": 0.09576227835246495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721321105957031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010272430256009102,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670895993709564,
      "backward_entropy": 0.09561213425227574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698884010314941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010368813760578632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669775426387787,
      "backward_entropy": 0.09314632415771484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.085487365722656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010464966297149658,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366870403289795,
      "backward_entropy": 0.09550049475261144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.17512035369873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010561616159975529,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13667535781860352,
      "backward_entropy": 0.09523947749819074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.361716270446777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01065873820334673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366627812385559,
      "backward_entropy": 0.09510648250579834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.357099533081055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010755879804491997,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665007054805756,
      "backward_entropy": 0.09522220066615514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.028451919555664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010852048173546791,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663968443870544,
      "backward_entropy": 0.09483305897031512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.716255187988281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010948669165372849,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366276890039444,
      "backward_entropy": 0.09222056184496198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.993621826171875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011045537889003754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13661448657512665,
      "backward_entropy": 0.09455406665802002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.570769309997559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011142774485051632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659988343715668,
      "backward_entropy": 0.09188977309635707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.05900764465332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011240176856517792,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13658519089221954,
      "backward_entropy": 0.09471946103232247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.54307746887207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011337910778820515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365687996149063,
      "backward_entropy": 0.09153498922075544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.227285385131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011435718275606632,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13655196130275726,
      "backward_entropy": 0.09449848106929234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.794943809509277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011533461511135101,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13653548061847687,
      "backward_entropy": 0.09379432031086513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.748726844787598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011631416156888008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365182250738144,
      "backward_entropy": 0.09363038199288505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.552568435668945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011728521436452866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13650310039520264,
      "backward_entropy": 0.09346321650913783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.680886268615723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0118247140198946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648924231529236,
      "backward_entropy": 0.09056234359741211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.185786247253418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011920721270143986,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13647572696208954,
      "backward_entropy": 0.09387707710266113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.838061332702637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012016315013170242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13646316528320312,
      "backward_entropy": 0.09015306404658727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.535614013671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012111867778003216,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13645027577877045,
      "backward_entropy": 0.09360676152365548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80118465423584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012207227759063244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364375203847885,
      "backward_entropy": 0.08972745282309395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.681883811950684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012302561663091183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364244669675827,
      "backward_entropy": 0.08950796297618321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.951786041259766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01239786297082901,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364123523235321,
      "backward_entropy": 0.08928502457482475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366660118103027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012493223883211613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13639943301677704,
      "backward_entropy": 0.08905603204454694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.907218933105469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012588358484208584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13638712465763092,
      "backward_entropy": 0.08882355690002441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.049821853637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012683586217463017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13637462258338928,
      "backward_entropy": 0.09271702596119472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.145819664001465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012778439559042454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13636311888694763,
      "backward_entropy": 0.08833951609475273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.217000007629395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012873523868620396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635030388832092,
      "backward_entropy": 0.08808422088623047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.832175254821777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012968837283551693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13633570075035095,
      "backward_entropy": 0.09095558098384313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.164255142211914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01306473184376955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13631942868232727,
      "backward_entropy": 0.08755007811955043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.231139183044434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013160781003534794,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13630229234695435,
      "backward_entropy": 0.09050450154713222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.657115936279297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013256989419460297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362837851047516,
      "backward_entropy": 0.09027189867837089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.993518829345703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01335306279361248,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13626541197299957,
      "backward_entropy": 0.09003439971378871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.696661949157715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013449212536215782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362469345331192,
      "backward_entropy": 0.08640385525567192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76086711883545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013545273803174496,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362287551164627,
      "backward_entropy": 0.09115023272378105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.019670486450195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01364127453416586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13621003925800323,
      "backward_entropy": 0.089299133845738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.061532974243164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013736829161643982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13619233667850494,
      "backward_entropy": 0.08549158913748604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589677810668945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013832561671733856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13617366552352905,
      "backward_entropy": 0.08877506426402501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.353720664978027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013928207568824291,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13615508377552032,
      "backward_entropy": 0.09036013058253697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62006950378418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014024145901203156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13613373041152954,
      "backward_entropy": 0.08452653884887695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.241865158081055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014119982719421387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13611197471618652,
      "backward_entropy": 0.08418723515101842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.915212631225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014215542003512383,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13609102368354797,
      "backward_entropy": 0.08972516230174474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183636665344238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014310171827673912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13607513904571533,
      "backward_entropy": 0.08737083843776158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.726474285125732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01440459955483675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360575556755066,
      "backward_entropy": 0.08707743883132935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.381251335144043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014498631469905376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360412985086441,
      "backward_entropy": 0.08677881104605538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52022647857666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014592645689845085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360248625278473,
      "backward_entropy": 0.08243985686983381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23313045501709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014686746522784233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360073685646057,
      "backward_entropy": 0.08207241126469203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.285852432250977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0147807402536273,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13598857820034027,
      "backward_entropy": 0.08584822927202497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.168018341064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01487473864108324,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13597053289413452,
      "backward_entropy": 0.08812062229428973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.965994834899902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014968614093959332,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359511911869049,
      "backward_entropy": 0.08093118667602539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.687052249908447,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015062822960317135,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13592836260795593,
      "backward_entropy": 0.08761799335479736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.804532051086426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015156659297645092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13590691983699799,
      "backward_entropy": 0.08013316563197545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.620906352996826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01525077223777771,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13588297367095947,
      "backward_entropy": 0.08709579706192017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.723055839538574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015344467014074326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585856556892395,
      "backward_entropy": 0.08383326871054513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.1188325881958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015438420698046684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358310878276825,
      "backward_entropy": 0.07888601507459368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.678822994232178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01553230732679367,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13580401241779327,
      "backward_entropy": 0.07845733846936907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6752290725708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015625866129994392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357782632112503,
      "backward_entropy": 0.07802504301071167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.867671012878418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0157197006046772,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1357509195804596,
      "backward_entropy": 0.08570912906101771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.544882774353027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015813902020454407,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13572034239768982,
      "backward_entropy": 0.0854182243347168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.072551727294922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015907054767012596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13569268584251404,
      "backward_entropy": 0.08160533223833356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.180746078491211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01600019261240959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13566362857818604,
      "backward_entropy": 0.07622827802385602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142855644226074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016092805191874504,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13563615083694458,
      "backward_entropy": 0.08082458802631923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9430718421936035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01618553139269352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13560742139816284,
      "backward_entropy": 0.07530692645481654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.052082061767578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016278231516480446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13557744026184082,
      "backward_entropy": 0.0748352152960641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.824819564819336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016370996832847595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13554635643959045,
      "backward_entropy": 0.07435614722115653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.769775867462158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01646425761282444,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355103701353073,
      "backward_entropy": 0.0832221337727138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.346830368041992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01655678264796734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13547857105731964,
      "backward_entropy": 0.07337571893419538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2007904052734375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01664956659078598,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13544327020645142,
      "backward_entropy": 0.07826168196541923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.463274002075195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01674192026257515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13540948927402496,
      "backward_entropy": 0.07237523794174194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.105647563934326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01683466136455536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13537269830703735,
      "backward_entropy": 0.07186365127563477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.050484657287598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016926905140280724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13533638417720795,
      "backward_entropy": 0.07135017429079328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.576291561126709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017019258812069893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13529559969902039,
      "backward_entropy": 0.07642172915594918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.690230369567871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01711145043373108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352531611919403,
      "backward_entropy": 0.07594951561519078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.406219482421875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01720297709107399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13521349430084229,
      "backward_entropy": 0.069771409034729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.671842098236084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017294354736804962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13517294824123383,
      "backward_entropy": 0.06923799855368477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.421525478363037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01738516055047512,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13513517379760742,
      "backward_entropy": 0.06870494144303459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.852516174316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017475301399827003,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1351012885570526,
      "backward_entropy": 0.07913451535361153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.317789077758789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017565133050084114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13507036864757538,
      "backward_entropy": 0.06763943604060582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.669209003448486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017654936760663986,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13503536581993103,
      "backward_entropy": 0.06709803002221244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4714226722717285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017744969576597214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13499638438224792,
      "backward_entropy": 0.07252192497253418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.904393196105957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01783507689833641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13495346903800964,
      "backward_entropy": 0.0659882937158857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.849268436431885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017924925312399864,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349109411239624,
      "backward_entropy": 0.06542654548372541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9950408935546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018014514818787575,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13486865162849426,
      "backward_entropy": 0.0766586320740836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.915402412414551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01810399815440178,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1348271667957306,
      "backward_entropy": 0.07043621369770595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.790050506591797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01819329708814621,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13478337228298187,
      "backward_entropy": 0.06371995806694031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.741693019866943,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018282350152730942,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13473758101463318,
      "backward_entropy": 0.06935725041798182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.758184432983398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018371181562542915,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1346912831068039,
      "backward_entropy": 0.07487343890326363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.854630470275879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0184598620980978,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13464631140232086,
      "backward_entropy": 0.061979127781731744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.846024990081787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01854843832552433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13459837436676025,
      "backward_entropy": 0.06769789968218122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.331387996673584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018636265769600868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13455574214458466,
      "backward_entropy": 0.06713880811418806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.336820602416992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01872444897890091,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13450968265533447,
      "backward_entropy": 0.060212011848177226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.213995933532715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018812300637364388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13446572422981262,
      "backward_entropy": 0.05961746828896659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.092251300811768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018899770453572273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1344234049320221,
      "backward_entropy": 0.05902292047228132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5376200675964355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018986817449331284,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13438251614570618,
      "backward_entropy": 0.07155991452080863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.981395244598389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0190731268376112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134348064661026,
      "backward_entropy": 0.0642456156866891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.296906471252441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019159091636538506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13431598246097565,
      "backward_entropy": 0.057251461914607456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8481221199035645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01924496330320835,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13428249955177307,
      "backward_entropy": 0.06306171417236328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.67378044128418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01933043822646141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13424964249134064,
      "backward_entropy": 0.05606612988880703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.137526988983154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01941542699933052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13421697914600372,
      "backward_entropy": 0.055474545274462016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.919843673706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019500307738780975,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13417968153953552,
      "backward_entropy": 0.06856735263551984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.644709587097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019584964960813522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13414087891578674,
      "backward_entropy": 0.054273511682237895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.722416877746582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019669225439429283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13410161435604095,
      "backward_entropy": 0.05366895028523037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.416797637939453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01975315809249878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13405756652355194,
      "backward_entropy": 0.05947244167327881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.90118408203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019836625084280968,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1340148150920868,
      "backward_entropy": 0.06647537435804095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.096270561218262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01992005668580532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1339702159166336,
      "backward_entropy": 0.05184786660330636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.840116500854492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02000286616384983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13392972946166992,
      "backward_entropy": 0.05766438586371286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.538911819458008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0200849249958992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13389411568641663,
      "backward_entropy": 0.05706172330038888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.280446529388428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020166834816336632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13385531306266785,
      "backward_entropy": 0.050043842622212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.443048477172852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020248418673872948,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13381461799144745,
      "backward_entropy": 0.06379541328975133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.96436882019043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02032984048128128,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13376961648464203,
      "backward_entropy": 0.06324932404926845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.54026985168457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020410774275660515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13372597098350525,
      "backward_entropy": 0.04823648078101022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.141127586364746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02049095369875431,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1336875855922699,
      "backward_entropy": 0.05402483258928571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.678403377532959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020570918917655945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1336459517478943,
      "backward_entropy": 0.04704681464603969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.214570999145508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020650334656238556,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13360506296157837,
      "backward_entropy": 0.06103963511330741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6326727867126465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02072969079017639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13355857133865356,
      "backward_entropy": 0.04585931982312884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.692102432250977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020808536559343338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13351187109947205,
      "backward_entropy": 0.04526718173708234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.501380920410156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020886998623609543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13346534967422485,
      "backward_entropy": 0.05097911613328116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.715496063232422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020964985713362694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13342219591140747,
      "backward_entropy": 0.04409112249101911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.286718368530273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021042706444859505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13337601721286774,
      "backward_entropy": 0.04976128680365426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.260274887084961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021119840443134308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333310306072235,
      "backward_entropy": 0.042924421174185615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.693760395050049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021196439862251282,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133287250995636,
      "backward_entropy": 0.04855467166219439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9762120246887207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021272927522659302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13323771953582764,
      "backward_entropy": 0.04176997286932809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.283864974975586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021348748356103897,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13319477438926697,
      "backward_entropy": 0.04735112615994045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.432603359222412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02142423391342163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1331520676612854,
      "backward_entropy": 0.04674858706338065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9622066020965576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02149956300854683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13310690224170685,
      "backward_entropy": 0.040062240191868374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.073477268218994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0215743500739336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13306504487991333,
      "backward_entropy": 0.039499065705708096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.969562530517578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021648740395903587,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13302139937877655,
      "backward_entropy": 0.044939986297062466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.587354898452759,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021722685545682907,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1329759955406189,
      "backward_entropy": 0.04434437411172049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.896040916442871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02179592289030552,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13293695449829102,
      "backward_entropy": 0.03783384816987174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5929934978485107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02186879701912403,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13289611041545868,
      "backward_entropy": 0.043168378727776666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3943960666656494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021941084414720535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13285809755325317,
      "backward_entropy": 0.042585134506225586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5984411239624023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022012675181031227,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13282577693462372,
      "backward_entropy": 0.050888857671192715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.130953788757324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022083809599280357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13279056549072266,
      "backward_entropy": 0.035690941980906894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.514514446258545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022154148668050766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13276547193527222,
      "backward_entropy": 0.03517433149474008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.167328119277954,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022224122658371925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1327388733625412,
      "backward_entropy": 0.040292322635650635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4311041831970215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022293448448181152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13271677494049072,
      "backward_entropy": 0.034153921263558526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.359161853790283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02236245945096016,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13269303739070892,
      "backward_entropy": 0.048145558152879984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0615530014038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02243109606206417,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13266423344612122,
      "backward_entropy": 0.04760365400995527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.80615234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02249910682439804,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.132635235786438,
      "backward_entropy": 0.047062656709126065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1478641033172607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022566327825188637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13261224329471588,
      "backward_entropy": 0.032155669161251614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.045382499694824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022633183747529984,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.132585808634758,
      "backward_entropy": 0.045990709747586934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.016709327697754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022699622437357903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13255780935287476,
      "backward_entropy": 0.031186331595693315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9515161514282227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022765660658478737,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13252824544906616,
      "backward_entropy": 0.03590843507221767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0014090538024902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022831277921795845,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13249951601028442,
      "backward_entropy": 0.035382549677576335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.82196307182312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02289658971130848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13246671855449677,
      "backward_entropy": 0.034859225153923035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.339808225631714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022961433976888657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1324315369129181,
      "backward_entropy": 0.029287904500961304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5697855949401855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02302534691989422,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.132405087351799,
      "backward_entropy": 0.03383113869598934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6652464866638184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023088674992322922,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1323787420988083,
      "backward_entropy": 0.03332713884966714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.36600399017334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023151598870754242,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13234949111938477,
      "backward_entropy": 0.041831178324563165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2212727069854736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023213813081383705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13232210278511047,
      "backward_entropy": 0.027492623244013106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.579319715499878,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023275235667824745,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1322994828224182,
      "backward_entropy": 0.040830369506563456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3477001190185547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023336373269557953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13227057456970215,
      "backward_entropy": 0.02663388422557286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6151130199432373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023396974429488182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1322389394044876,
      "backward_entropy": 0.026210759367261614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9785183668136597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02345743589103222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13219764828681946,
      "backward_entropy": 0.025787513170923506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.176725387573242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023517001420259476,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13216225802898407,
      "backward_entropy": 0.0388731232711247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3060967922210693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023576023057103157,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13212625682353973,
      "backward_entropy": 0.038394617182867866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0627710819244385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023634718731045723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.132083922624588,
      "backward_entropy": 0.024563582880156382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.896268367767334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02369282767176628,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1320415735244751,
      "backward_entropy": 0.03744642649378095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.054231643676758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023750199005007744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13200215995311737,
      "backward_entropy": 0.028188892773219516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.912333607673645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023807110264897346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13195818662643433,
      "backward_entropy": 0.023389475686209544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.316782832145691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023863431066274643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1319129467010498,
      "backward_entropy": 0.027339149798665727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7252044677734375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023918423801660538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13188424706459045,
      "backward_entropy": 0.022646412253379822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.838867425918579,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023972781375050545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13185584545135498,
      "backward_entropy": 0.0222892803805215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.628136396408081,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024026742205023766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13182340562343597,
      "backward_entropy": 0.026123753615788052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.751786231994629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02408004365861416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1317915916442871,
      "backward_entropy": 0.02158553046839578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.289609432220459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02413293905556202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13175472617149353,
      "backward_entropy": 0.025342528309140886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.476003646850586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024184798821806908,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13172732293605804,
      "backward_entropy": 0.024963180933679854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4919486045837402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02423601597547531,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13170132040977478,
      "backward_entropy": 0.02057467613901411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.384902000427246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024286676198244095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1316738873720169,
      "backward_entropy": 0.02421888496194567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4471156597137451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0243366826325655,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13164779543876648,
      "backward_entropy": 0.02385423013142177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3817533254623413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024386201053857803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13161885738372803,
      "backward_entropy": 0.0234943117414202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3812546730041504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024435173720121384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13158750534057617,
      "backward_entropy": 0.019298195838928223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.253353238105774,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024483665823936462,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1315525621175766,
      "backward_entropy": 0.031015010816710337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1914490461349487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024531515315175056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1315171718597412,
      "backward_entropy": 0.018687595214162554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.190439224243164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024578694254159927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13148251175880432,
      "backward_entropy": 0.01839152829987662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2056937217712402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024625275284051895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13144716620445251,
      "backward_entropy": 0.021795890160969326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9518702626228333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024671345949172974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13140869140625,
      "backward_entropy": 0.017814133848462785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.157997965812683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024716515094041824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13137637078762054,
      "backward_entropy": 0.017536321921007975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0310972929000854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024761246517300606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1313394010066986,
      "backward_entropy": 0.017261851046766554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.996552050113678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024805357679724693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13130198419094086,
      "backward_entropy": 0.016992748848029544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9643985033035278,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024848854169249535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1312641203403473,
      "backward_entropy": 0.016728887600558146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0578882694244385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024891741573810577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13122573494911194,
      "backward_entropy": 0.019957076225961958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8886458277702332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02493426576256752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13118106126785278,
      "backward_entropy": 0.016213804483413696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8240948915481567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024976134300231934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13113665580749512,
      "backward_entropy": 0.015963212719985416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7207675576210022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025017281994223595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13109396398067474,
      "backward_entropy": 0.015719166823795865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7396177649497986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025057567283511162,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13105624914169312,
      "backward_entropy": 0.018845351678984507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7604862451553345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025097116827964783,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13102073967456818,
      "backward_entropy": 0.01858442383153098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8481467366218567,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025136055424809456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13098469376564026,
      "backward_entropy": 0.01832874970776694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7684991955757141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02517464943230152,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13094231486320496,
      "backward_entropy": 0.014804439885275704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7176838517189026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025212757289409637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13089671730995178,
      "backward_entropy": 0.014584827635969435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6452804803848267,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02525031752884388,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13084912300109863,
      "backward_entropy": 0.024949542113712857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5369555950164795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025287216529250145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1308022141456604,
      "backward_entropy": 0.02466608158179692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5732840895652771,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025323254987597466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13076022267341614,
      "backward_entropy": 0.017119282058307102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6061720252037048,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025358613580465317,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.130718395113945,
      "backward_entropy": 0.02411856608731406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5446865558624268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025393446907401085,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13067393004894257,
      "backward_entropy": 0.016672055636133467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4666912257671356,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02542765438556671,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1306297481060028,
      "backward_entropy": 0.023595222405024936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49797534942626953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025461087003350258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13058915734291077,
      "backward_entropy": 0.013191004948956626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5091779828071594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025493910536170006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13054822385311127,
      "backward_entropy": 0.01301199197769165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43877893686294556,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025526221841573715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13050499558448792,
      "backward_entropy": 0.012836340282644545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45014774799346924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025557871907949448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13046298921108246,
      "backward_entropy": 0.012665430349963052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45930010080337524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02558896504342556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1304198056459427,
      "backward_entropy": 0.012498292539800917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42754632234573364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025619588792324066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1303734928369522,
      "backward_entropy": 0.01233400936637606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37863633036613464,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025649702176451683,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13032574951648712,
      "backward_entropy": 0.021932548710278103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36359143257141113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025679200887680054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1302785873413086,
      "backward_entropy": 0.014908168997083391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42258119583129883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02570810541510582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13023224472999573,
      "backward_entropy": 0.01186464514051165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34766802191734314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025736678391695023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13018079102039337,
      "backward_entropy": 0.011714232819420951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3133188486099243,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025764692574739456,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13012805581092834,
      "backward_entropy": 0.014401050550597054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31812822818756104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025792093947529793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13007664680480957,
      "backward_entropy": 0.011424374367509569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3340867757797241,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02581896260380745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13002437353134155,
      "backward_entropy": 0.011284921850476946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2892538607120514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025845417752861977,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1299685537815094,
      "backward_entropy": 0.011147739631789071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28530529141426086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025871338322758675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1299125850200653,
      "backward_entropy": 0.01377993928534644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24125467240810394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025896770879626274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12985564768314362,
      "backward_entropy": 0.01088336216551917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2931622862815857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025921586900949478,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1298004686832428,
      "backward_entropy": 0.019915401935577393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22292450070381165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025946075096726418,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12974107265472412,
      "backward_entropy": 0.019735821655818393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22982501983642578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025969963520765305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1296827793121338,
      "backward_entropy": 0.013220071792602539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18135908246040344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025993354618549347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12962406873703003,
      "backward_entropy": 0.010392518980162484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17502790689468384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02601606771349907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1295679360628128,
      "backward_entropy": 0.01027851871081761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1252223402261734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038149371743202,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12951436638832092,
      "backward_entropy": 0.010168506630829402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19028045237064362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026059405878186226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12946689128875732,
      "backward_entropy": 0.010063747210162026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20797008275985718,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026080260053277016,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12941721081733704,
      "backward_entropy": 0.012604975274630956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15550893545150757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02610085718333721,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12936289608478546,
      "backward_entropy": 0.009859456547669001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12479320913553238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02612093649804592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1293085515499115,
      "backward_entropy": 0.009760710809912001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12755461037158966,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02614038810133934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12925735116004944,
      "backward_entropy": 0.01227503695658275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12789547443389893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026159286499023438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12920761108398438,
      "backward_entropy": 0.009573964135987418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11489706486463547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026177700608968735,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12915892899036407,
      "backward_entropy": 0.018060192465782166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11997374147176743,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026195598766207695,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12911155819892883,
      "backward_entropy": 0.0179319190127509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09826362878084183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02621307596564293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12906457483768463,
      "backward_entropy": 0.011881945388657706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09944364428520203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02623003162443638,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12901979684829712,
      "backward_entropy": 0.011791574103491647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09246518462896347,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02624651789665222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12897536158561707,
      "backward_entropy": 0.011703929730824061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10163102298974991,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026262551546096802,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12893225252628326,
      "backward_entropy": 0.017450328384126936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09504804015159607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026278238743543625,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1288878321647644,
      "backward_entropy": 0.017337535108838762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06655839085578918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026293568313121796,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12884218990802765,
      "backward_entropy": 0.011456498077937536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05042877793312073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026308376342058182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12879985570907593,
      "backward_entropy": 0.008858070841857366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06623227149248123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632254734635353,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1287609189748764,
      "backward_entropy": 0.011305933552128928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058192066848278046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336293667554855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12872269749641418,
      "backward_entropy": 0.008726659630026137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05131214112043381,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02634957991540432,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12868553400039673,
      "backward_entropy": 0.011166016970361983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04817245155572891,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02636238932609558,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12864980101585388,
      "backward_entropy": 0.011099881359509059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05576512590050697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026374738663434982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12861524522304535,
      "backward_entropy": 0.011036311941487449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050683483481407166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026386771351099014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12858080863952637,
      "backward_entropy": 0.008490896650723048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04724852740764618,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026398450136184692,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1285461187362671,
      "backward_entropy": 0.01647379355771201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050652194768190384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026409775018692017,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12851116061210632,
      "backward_entropy": 0.010857395827770233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04003216698765755,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02642080932855606,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12847448885440826,
      "backward_entropy": 0.010801208870751517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03923406824469566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026431484147906303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128438338637352,
      "backward_entropy": 0.010747058050973075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033759038895368576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026441819965839386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12840217351913452,
      "backward_entropy": 0.008234183703150069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03802508860826492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026451801881194115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12836706638336182,
      "backward_entropy": 0.008187704852649145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03226105123758316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026461530476808548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12833188474178314,
      "backward_entropy": 0.010595731437206268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0370926633477211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026470929384231567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1282966136932373,
      "backward_entropy": 0.010548696986266546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023607715964317322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026480134576559067,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12826065719127655,
      "backward_entropy": 0.01589549652167729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03131633624434471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02648894488811493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12822583317756653,
      "backward_entropy": 0.008014697581529617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030123621225357056,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026497550308704376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281907707452774,
      "backward_entropy": 0.010416626930236816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029999421909451485,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026505939662456512,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281549632549286,
      "backward_entropy": 0.01037532729761941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020388640463352203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026514150202274323,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281183511018753,
      "backward_entropy": 0.010335061166967665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015742227435112,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026522045955061913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1280829906463623,
      "backward_entropy": 0.010296536343438285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016650699079036713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026529546827077866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12804892659187317,
      "backward_entropy": 0.010260057236467088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018893374130129814,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026536736637353897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12801611423492432,
      "backward_entropy": 0.015497086303574699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016763372346758842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026543691754341125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12798361480236053,
      "backward_entropy": 0.007759431110961097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012714143842458725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026550397276878357,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12795168161392212,
      "backward_entropy": 0.0101595510329519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014608845114707947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026556793600320816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12792105972766876,
      "backward_entropy": 0.007698550820350647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01252194307744503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026562944054603577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1278907209634781,
      "backward_entropy": 0.00766997252191816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01733921281993389,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02656886912882328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1278616189956665,
      "backward_entropy": 0.007642507020916257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012966074980795383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026574688032269478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12783177196979523,
      "backward_entropy": 0.007615448108741215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010018345899879932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026580287143588066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12780192494392395,
      "backward_entropy": 0.010017899530274528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01157354936003685,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026585618034005165,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12777280807495117,
      "backward_entropy": 0.015150987676211767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00759844807907939,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026590757071971893,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12774379551410675,
      "backward_entropy": 0.007540429277079446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010284512303769588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02659560739994049,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1277158260345459,
      "backward_entropy": 0.007517743323530469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008572735823690891,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026600277051329613,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12768779695034027,
      "backward_entropy": 0.015047062720571245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010352734476327896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02660474181175232,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12766021490097046,
      "backward_entropy": 0.009905284004552024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008723244071006775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02660910226404667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12763246893882751,
      "backward_entropy": 0.009885476103850774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007754173595458269,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026613309979438782,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1276049017906189,
      "backward_entropy": 0.009866443063531603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007331934291869402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02661735564470291,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12757772207260132,
      "backward_entropy": 0.007415185017245156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005188336130231619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026621244847774506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1275508999824524,
      "backward_entropy": 0.009830835674490248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004169175401329994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02662491798400879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12752510607242584,
      "backward_entropy": 0.00737927428313664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008246617391705513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026628322899341583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1275002658367157,
      "backward_entropy": 0.007363042128937585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007128673139959574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026631660759449005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12747465074062347,
      "backward_entropy": 0.009785091238362449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005766908638179302,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026634886860847473,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12744860351085663,
      "backward_entropy": 0.009771121399743217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0057733976282179356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02663794904947281,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12742257118225098,
      "backward_entropy": 0.007316553166934422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006958449259400368,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026640882715582848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12739653885364532,
      "backward_entropy": 0.009745559522083827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005229882895946503,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02664378471672535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12737002968788147,
      "backward_entropy": 0.009733242647988456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0047768717631697655,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026646560057997704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12734366953372955,
      "backward_entropy": 0.009721587811197554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005425977520644665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026649249717593193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12731775641441345,
      "backward_entropy": 0.009710317211491721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003999115899205208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02665187418460846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1272917538881302,
      "backward_entropy": 0.007247825818402427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003768023569136858,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026654353365302086,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12726618349552155,
      "backward_entropy": 0.014664414737905775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004415221977978945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026656702160835266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1272410899400711,
      "backward_entropy": 0.007223600255591529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004293728619813919,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026658983901143074,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12721607089042664,
      "backward_entropy": 0.014631875923701696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035228212364017963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026661185547709465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12719102203845978,
      "backward_entropy": 0.0072008658732686725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004699086770415306,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026663269847631454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.127166286110878,
      "backward_entropy": 0.009653257472174508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026359925977885723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02666539140045643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1271413266658783,
      "backward_entropy": 0.007179323051656995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028230443131178617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0266673993319273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12711718678474426,
      "backward_entropy": 0.007169013044663838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026020605582743883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026669258251786232,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12709343433380127,
      "backward_entropy": 0.0096295742051942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002953937975689769,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026670992374420166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12707020342350006,
      "backward_entropy": 0.0071502828172275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030098434071987867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026672638952732086,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1270471215248108,
      "backward_entropy": 0.009616893317018236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002489737467840314,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026674233376979828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12702414393424988,
      "backward_entropy": 0.009611033967563085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002401471370831132,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026675770059227943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1270015984773636,
      "backward_entropy": 0.007124888045447213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023323455825448036,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026677222922444344,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12697941064834595,
      "backward_entropy": 0.014504058020455497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022119213826954365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02667856775224209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12695744633674622,
      "backward_entropy": 0.007109719727720533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002171932952478528,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026679860427975655,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12693583965301514,
      "backward_entropy": 0.014485457113810949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020152097567915916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026681117713451385,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12691456079483032,
      "backward_entropy": 0.014476639883858817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020797618199139833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026682283729314804,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1268935650587082,
      "backward_entropy": 0.014468415507248469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001709242700599134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02668340690433979,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12687279284000397,
      "backward_entropy": 0.009579437119620187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018730254378169775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026684463024139404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12685246765613556,
      "backward_entropy": 0.007076791886772428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019535867031663656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026685448363423347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12683232128620148,
      "backward_entropy": 0.007071075694901603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015702740056440234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026686400175094604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12681227922439575,
      "backward_entropy": 0.007065518626144954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001414105761796236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026687322184443474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12679263949394226,
      "backward_entropy": 0.007060115358659199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017071198672056198,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026688173413276672,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1267734318971634,
      "backward_entropy": 0.014426761439868383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001371667254716158,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026688966900110245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12675431370735168,
      "backward_entropy": 0.007050209279571261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014449794543907046,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02668970637023449,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12673553824424744,
      "backward_entropy": 0.009561488670962197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014691113028675318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0266904104501009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1267170011997223,
      "backward_entropy": 0.007041221218449729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012875950196757913,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026691071689128876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12669861316680908,
      "backward_entropy": 0.009558433932917458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001178913633339107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026691706851124763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12668050825595856,
      "backward_entropy": 0.007032908499240875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013534941244870424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026692308485507965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1266627460718155,
      "backward_entropy": 0.009555911379201072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010959581704810262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026692917570471764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12664511799812317,
      "backward_entropy": 0.0070250289780753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012051622616127133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026693467050790787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12662778794765472,
      "backward_entropy": 0.007021359034946987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009757880470715463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02669399231672287,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1266106218099594,
      "backward_entropy": 0.007017813622951508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010645287111401558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026694467291235924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12659379839897156,
      "backward_entropy": 0.007014489599636623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009378223912790418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02669491618871689,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12657718360424042,
      "backward_entropy": 0.007011291704007557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007994854240678251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0266953743994236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12656089663505554,
      "backward_entropy": 0.0070080698600837165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008339357445947826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026695795357227325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1265450119972229,
      "backward_entropy": 0.009550594857760839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007815801654942334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026696238666772842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12652947008609772,
      "backward_entropy": 0.0070019688989434925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007402813644148409,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026696670800447464,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12651427090168,
      "backward_entropy": 0.01436568796634674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000892376818228513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02669707126915455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12649938464164734,
      "backward_entropy": 0.0069960808115346095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000744462653528899,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02669745869934559,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12648458778858185,
      "backward_entropy": 0.006993292697838375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007132117170840502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026697836816310883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12647002935409546,
      "backward_entropy": 0.006990542901413781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007641076808795333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02669820748269558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12645570933818817,
      "backward_entropy": 0.0069878654820578435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007819511229172349,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026698585599660873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12644150853157043,
      "backward_entropy": 0.00698516092130116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006732846377417445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02669897861778736,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12642738223075867,
      "backward_entropy": 0.014349430799484253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005987468757666647,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026699351146817207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1264134645462036,
      "backward_entropy": 0.014346812452588762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005731252022087574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026699693873524666,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12639978528022766,
      "backward_entropy": 0.014344384627682822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005035738577134907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026700016111135483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1263863742351532,
      "backward_entropy": 0.006974803017718452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005644839257001877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026700343936681747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.126373291015625,
      "backward_entropy": 0.00697239807673863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005216983845457435,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026700660586357117,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12636038661003113,
      "backward_entropy": 0.014337620564869471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004645179433282465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026700962334871292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12634767591953278,
      "backward_entropy": 0.006967772330556597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043343158904463053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026701241731643677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1263352334499359,
      "backward_entropy": 0.006965618048395429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004212774510961026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670148015022278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12632307410240173,
      "backward_entropy": 0.006963654288223812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003995156439486891,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670171484351158,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12631118297576904,
      "backward_entropy": 0.009543729679925101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035789646790362895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0267019122838974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12629954516887665,
      "backward_entropy": 0.006959979023252215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004411394475027919,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026702100411057472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12628819048404694,
      "backward_entropy": 0.009544064956051963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037877808790653944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026702262461185455,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12627694010734558,
      "backward_entropy": 0.0069567082183701655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003873657260555774,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026702402159571648,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12626589834690094,
      "backward_entropy": 0.014325389904635293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003971555852331221,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026702528819441795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12625497579574585,
      "backward_entropy": 0.009545284722532545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003273736801929772,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026702646166086197,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12624415755271912,
      "backward_entropy": 0.014323558126177107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002917608944699168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670275792479515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1262335628271103,
      "backward_entropy": 0.006951170308249337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003200315113645047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026702886447310448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12622320652008057,
      "backward_entropy": 0.0069497935473918915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029120442923158407,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026703014969825745,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12621299922466278,
      "backward_entropy": 0.01432083866425923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002901555271819234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026703152805566788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12620298564434052,
      "backward_entropy": 0.006947067167077746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028596731135621667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670329436659813,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1261931210756302,
      "backward_entropy": 0.014318860002926417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002622053725644946,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026703443378210068,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1261834055185318,
      "backward_entropy": 0.009547899876322066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024304428370669484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670357935130596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12617386877536774,
      "backward_entropy": 0.00954813723053251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002465519937686622,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670370042324066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1261645257472992,
      "backward_entropy": 0.009548444833074297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021275444305501878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026703834533691406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1261553168296814,
      "backward_entropy": 0.0069404297641345435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021274370374158025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026703955605626106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1261463165283203,
      "backward_entropy": 0.006939208933285305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000200889611733146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704061776399612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12613749504089355,
      "backward_entropy": 0.006938076445034572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019125155813526362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670416049659252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12612885236740112,
      "backward_entropy": 0.006936964711972645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001904707314679399,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670423872768879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12612038850784302,
      "backward_entropy": 0.006935957287039075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017008173745125532,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670428529381752,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12611208856105804,
      "backward_entropy": 0.009550708745207106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016777652490418404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704326272010803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1261039674282074,
      "backward_entropy": 0.009551332465239934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017674622358754277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704365387558937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12609602510929108,
      "backward_entropy": 0.009551943412848882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015056601841934025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704395189881325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1260882019996643,
      "backward_entropy": 0.006932729056903294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015931815141811967,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704417541623116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12608052790164948,
      "backward_entropy": 0.009553295161042894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014708662638440728,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704436168074608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1260729879140854,
      "backward_entropy": 0.006931335266147341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013523694360628724,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704438030719757,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12606559693813324,
      "backward_entropy": 0.014310401465211595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013002620835322887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704438030719757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12605834007263184,
      "backward_entropy": 0.009555535657065255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012806412996724248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704447343945503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12605124711990356,
      "backward_entropy": 0.006929554045200348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012362972483970225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704465970396996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12604425847530365,
      "backward_entropy": 0.009556867182254791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011101285053882748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704490184783936,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12603741884231567,
      "backward_entropy": 0.014309836285454887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010609706077957526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704514399170876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12603071331977844,
      "backward_entropy": 0.009558011378560747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001000762204057537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670452557504177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12602415680885315,
      "backward_entropy": 0.006927053311041423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.642315515317023e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704542338848114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1260177493095398,
      "backward_entropy": 0.014309346675872803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.90077605820261e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704570278525352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12601152062416077,
      "backward_entropy": 0.00692585323538099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730093395570293e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670459821820259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1260053813457489,
      "backward_entropy": 0.006925238030297416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.275375487050042e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704641059041023,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12599939107894897,
      "backward_entropy": 0.009560517966747284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.74568907218054e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670467272400856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1259934902191162,
      "backward_entropy": 0.006923975689070565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.333733810810372e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704689487814903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12598773837089539,
      "backward_entropy": 0.006923435521977288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.60800830903463e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704708114266396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1259821057319641,
      "backward_entropy": 0.0069229139813355035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.511426520068198e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704726740717888,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1259765923023224,
      "backward_entropy": 0.00692238871540342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.015318260528147e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704758405685425,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12597116827964783,
      "backward_entropy": 0.006921826728752681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.803345655091107e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670479565858841,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12596586346626282,
      "backward_entropy": 0.006921250373125076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.220464274520054e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704823598265648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12596072256565094,
      "backward_entropy": 0.006920710206031799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.170375152374618e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670484222471714,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1259557008743286,
      "backward_entropy": 0.014307130660329546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6134995247703046e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704858988523483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12595079839229584,
      "backward_entropy": 0.014307014644145966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6239070798037574e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704872027039528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12594600021839142,
      "backward_entropy": 0.009564585983753204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.355657413019799e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670488879084587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12594133615493774,
      "backward_entropy": 0.006918901311499732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.336190249887295e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704909279942513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12593674659729004,
      "backward_entropy": 0.014306704912866865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.806952711078338e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704924181103706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12593227624893188,
      "backward_entropy": 0.014306617634637015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.302589513827115e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670493721961975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1259278804063797,
      "backward_entropy": 0.00956599840096065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3313913920428604e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704944670200348,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12592360377311707,
      "backward_entropy": 0.009566375187465124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0151298890123144e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670494094491005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125919371843338,
      "backward_entropy": 0.006916917860507965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4604490792844445e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670493721961975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12591524422168732,
      "backward_entropy": 0.006916600146463939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.169018236803822e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0267049428075552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12591122090816498,
      "backward_entropy": 0.009567603468894958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.837897384073585e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0267049428075552,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125907301902771,
      "backward_entropy": 0.0069159407700811115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.167868999298662e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704946532845497,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1259034425020218,
      "backward_entropy": 0.014306492039135523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.229803405702114e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704955846071243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12589968740940094,
      "backward_entropy": 0.006915262767246791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3038537367247045e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026704955846071243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12589599192142487,
      "backward_entropy": 0.0069149886923176905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6593466827762313e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670496702194214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12589237093925476,
      "backward_entropy": 0.006914639047213963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6768757379613817e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026704980060458183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12588879466056824,
      "backward_entropy": 0.009569576808384486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7461692297947593e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670498751103878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12588533759117126,
      "backward_entropy": 0.006913990846702031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4983233743114397e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670498751103878,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12588194012641907,
      "backward_entropy": 0.014306241912501199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4700488211237825e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670499123632908,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12587860226631165,
      "backward_entropy": 0.014306217432022095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.274272083013784e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026704994961619377,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1258753389120102,
      "backward_entropy": 0.014306196144648961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3192578737507574e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705000549554825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12587213516235352,
      "backward_entropy": 0.006912879113640104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2122616428532638e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670501358807087,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1258690059185028,
      "backward_entropy": 0.014306069484778814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.755090670485515e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670503407716751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12586592137813568,
      "backward_entropy": 0.006912269762584141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0758907339768484e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705052703619003,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12586292624473572,
      "backward_entropy": 0.009571699159485953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.657858410908375e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705073192715645,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12585997581481934,
      "backward_entropy": 0.009571880102157593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7614900571061298e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705093681812286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12585711479187012,
      "backward_entropy": 0.00691130810550281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7325792214251123e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705116033554077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12585429847240448,
      "backward_entropy": 0.00957218770469938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.817214797483757e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670513652265072,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12585154175758362,
      "backward_entropy": 0.0069106875785759515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.461918236600468e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670515887439251,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12584882974624634,
      "backward_entropy": 0.0069103847656931195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.589265048096422e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705175638198853,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12584614753723145,
      "backward_entropy": 0.006910111755132675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2351697478152346e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705192402005196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12584353983402252,
      "backward_entropy": 0.006909822246858052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3506734831025824e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670520916581154,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12584097683429718,
      "backward_entropy": 0.014304750732013158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3585603483079467e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670522779226303,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1258384883403778,
      "backward_entropy": 0.014304626200880324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0042026588052977e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705242693424225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12583602964878082,
      "backward_entropy": 0.006909015455416271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1140711649204604e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705250144004822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1258336454629898,
      "backward_entropy": 0.006908793534551348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.631545253796503e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670525573194027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12583130598068237,
      "backward_entropy": 0.009573692721979958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0806530553963967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705263182520866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1258290410041809,
      "backward_entropy": 0.009573868342808314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.572539056534879e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705272495746613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12582682073116302,
      "backward_entropy": 0.0069081517202513555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.237403901352081e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670528180897236,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12582464516162872,
      "backward_entropy": 0.01430421429021018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.097713700612076e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705294847488403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125822514295578,
      "backward_entropy": 0.006907735552106585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.344382993323961e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705309748649597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12582042813301086,
      "backward_entropy": 0.009574460131781442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.123376574076246e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705322787165642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1258184015750885,
      "backward_entropy": 0.009574579341070992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.306734343932476e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705337688326836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12581641972064972,
      "backward_entropy": 0.006907074579170772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.900159860379063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705356314778328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12581446766853333,
      "backward_entropy": 0.006906846804278237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.632573447655886e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670537494122982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1258125752210617,
      "backward_entropy": 0.006906612110989434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.528485871764133e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705389842391014,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12581072747707367,
      "backward_entropy": 0.01430348094020571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.381569735618541e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670540288090706,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1258089393377304,
      "backward_entropy": 0.014303398983819144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.162326033314457e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705414056777954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12580721080303192,
      "backward_entropy": 0.009575149842670985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.708695880457526e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670542523264885,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12580552697181702,
      "backward_entropy": 0.014303240392889296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.05694379171473e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705438271164894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1258038580417633,
      "backward_entropy": 0.006905650986092431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.516413355304394e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670544944703579,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12580223381519318,
      "backward_entropy": 0.006905483348029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.554729457595386e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705460622906685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12580065429210663,
      "backward_entropy": 0.0069053130490439275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.112640337756602e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670547366142273,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12579911947250366,
      "backward_entropy": 0.01430296472140721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.619919764081715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705488562583923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12579761445522308,
      "backward_entropy": 0.009575625615460532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5671089335664874e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705505326390266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257961243391037,
      "backward_entropy": 0.009575673512050084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.228253146720817e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670552022755146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257946789264679,
      "backward_entropy": 0.0069045690553528926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.213589252482052e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705536991357803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12579326331615448,
      "backward_entropy": 0.006904393434524536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5532664242055034e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705551892518997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12579187750816345,
      "backward_entropy": 0.00690422419990812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1645472517993767e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670556679368019,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125790536403656,
      "backward_entropy": 0.006904052836554391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1150391350820428e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705581694841385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12578922510147095,
      "backward_entropy": 0.006903889455965587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.103803692283691e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670559659600258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12578792870044708,
      "backward_entropy": 0.006903718624796186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.935869815701153e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705611497163773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257866621017456,
      "backward_entropy": 0.0069035568407603675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5316610390291316e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705630123615265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12578542530536652,
      "backward_entropy": 0.006903385477406638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.223849151050672e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705646887421608,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12578421831130981,
      "backward_entropy": 0.014301849263054984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2919375624042004e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705661788582802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257830560207367,
      "backward_entropy": 0.009575967277799333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9804735984507715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705674827098846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12578192353248596,
      "backward_entropy": 0.006902921412672315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.104888835674501e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705686002969742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12578082084655762,
      "backward_entropy": 0.006902776126350675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.992541911022272e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705697178840637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12577971816062927,
      "backward_entropy": 0.006902640419346946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8940687596114003e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705708354711533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257786750793457,
      "backward_entropy": 0.009576103516987391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7905708773469087e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705719530582428,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12577764689922333,
      "backward_entropy": 0.014301419258117676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7138604562205728e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705730706453323,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12577664852142334,
      "backward_entropy": 0.014301354331629617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6490565712956595e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670574188232422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12577566504478455,
      "backward_entropy": 0.006902134844235012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4053264294489054e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705751195549965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12577469646930695,
      "backward_entropy": 0.006902004991258893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.366136643810023e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705758646130562,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12577375769615173,
      "backward_entropy": 0.014301196805068426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5592564750477322e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670576423406601,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257728636264801,
      "backward_entropy": 0.01430115635905947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1813443734354223e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705773547291756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12577195465564728,
      "backward_entropy": 0.006901685680661883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2392691814966383e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705780997872353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12577109038829803,
      "backward_entropy": 0.006901587758745466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1624631497397786e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670578844845295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12577024102210999,
      "backward_entropy": 0.006901494094303676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0029364148067543e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705795899033546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12576942145824432,
      "backward_entropy": 0.009576415377003806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0315084182366263e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705801486968994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12576861679553986,
      "backward_entropy": 0.00690131847347532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0429871508677024e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705807074904442,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12576782703399658,
      "backward_entropy": 0.014300937099116189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0005140893554199e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670581266283989,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257670670747757,
      "backward_entropy": 0.006901150303227561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.366497693008569e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705820113420486,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257663071155548,
      "backward_entropy": 0.00690104386636189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.312653901361045e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705827564001083,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257655918598175,
      "backward_entropy": 0.006900954459394727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.2301187376288e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670583501458168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257648766040802,
      "backward_entropy": 0.0069008634558745795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.40879443128506e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705844327807426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257641613483429,
      "backward_entropy": 0.0069007836282253265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.125085860730906e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705851778388023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12576347589492798,
      "backward_entropy": 0.006900696349995477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.980712896620389e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670585922896862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12576282024383545,
      "backward_entropy": 0.006900614925793239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.375032057803764e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705866679549217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12576216459274292,
      "backward_entropy": 0.006900527647563389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8644388900575e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705874130129814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12576153874397278,
      "backward_entropy": 0.006900443030255181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.757617600465892e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670588158071041,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12576094269752502,
      "backward_entropy": 0.014300524124077387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.803491719940212e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705889031291008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12576034665107727,
      "backward_entropy": 0.0069002871002469745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.900905423710356e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705894619226456,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257597655057907,
      "backward_entropy": 0.014300464519432612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.016098612031783e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705900207161903,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12575919926166534,
      "backward_entropy": 0.014300445360796792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.048460707257618e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670590579509735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575864791870117,
      "backward_entropy": 0.006900069969041007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.661899595248542e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0267059113830328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257581114768982,
      "backward_entropy": 0.009576716593333654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.166757889834116e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705916970968246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575757503509521,
      "backward_entropy": 0.006899927875825337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.588297943224461e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705922558903694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575705349445343,
      "backward_entropy": 0.006899875721761158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.414159550629847e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705928146839142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12575656175613403,
      "backward_entropy": 0.009576750653130668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5785859608949977e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670593373477459,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575605511665344,
      "backward_entropy": 0.0068997421434947425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.442785043716867e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705939322710037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575559318065643,
      "backward_entropy": 0.006899682538849967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1787280363460013e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705944910645485,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12575513124465942,
      "backward_entropy": 0.009576765554291862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.063124722757493e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705950498580933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257546842098236,
      "backward_entropy": 0.006899567054850715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.658143500866572e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670595608651638,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257542371749878,
      "backward_entropy": 0.006899501596178327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7564371407606814e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705961674451828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575380504131317,
      "backward_entropy": 0.0068994419915335515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.529878315726819e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705967262387276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575338780879974,
      "backward_entropy": 0.006899398352418627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2067246163715026e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705972850322723,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575297057628632,
      "backward_entropy": 0.006899340876511165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2381813380434323e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026705976575613022,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12575258314609528,
      "backward_entropy": 0.01430010689156396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.193786343696047e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670598030090332,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12575219571590424,
      "backward_entropy": 0.014300083475453513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9645896998099488e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670598402619362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257518231868744,
      "backward_entropy": 0.006899196654558182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.787259975571942e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705987751483917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575145065784454,
      "backward_entropy": 0.0068991535476275855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8746725061191682e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705991476774216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257510930299759,
      "backward_entropy": 0.006899104586669377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7062646406884596e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026705995202064514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12575075030326843,
      "backward_entropy": 0.00957683048077992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.562070934824078e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026705998927354813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12575039267539978,
      "backward_entropy": 0.006899015711886542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4023838446064474e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670600265264511,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12575006484985352,
      "backward_entropy": 0.00957683367388589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4313980045699282e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670600637793541,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574973702430725,
      "backward_entropy": 0.01429999726159232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3252086716875056e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026706010103225708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574943900108337,
      "backward_entropy": 0.009576842188835144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2339249622073112e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026706013828516006,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257491260766983,
      "backward_entropy": 0.014299965330532618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2240498392657173e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706015691161156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574882805347443,
      "backward_entropy": 0.006898829979555947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1320644688339598e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026706019416451454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574854493141174,
      "backward_entropy": 0.009576850703784398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0610395406729367e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706023141741753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574826180934906,
      "backward_entropy": 0.006898753345012665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.941392420387274e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706025004386902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574797868728638,
      "backward_entropy": 0.006898715027741024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69805995509887e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670602686703205,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257477104663849,
      "backward_entropy": 0.01429993552821023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95556553359711e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0267060287296772,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257474422454834,
      "backward_entropy": 0.014299928077629634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.36667410908376e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670603059232235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257472038269043,
      "backward_entropy": 0.0068986208311149055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.947490132664825e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0267060324549675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125746950507164,
      "backward_entropy": 0.006898595286267144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.44742294500611e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026706034317612648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257467120885849,
      "backward_entropy": 0.009576867733682905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.03167870597099e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706036180257797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257464736700058,
      "backward_entropy": 0.006898536213806697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.667598029252986e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706038042902946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257462352514267,
      "backward_entropy": 0.00689851918390819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.393993601250259e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026706039905548096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574602663516998,
      "backward_entropy": 0.014299923820155007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.973723915531082e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706041768193245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574580311775208,
      "backward_entropy": 0.006898463836738041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.607460451528823e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026706043630838394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574559450149536,
      "backward_entropy": 0.009576915630272456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.372652367441333e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706045493483543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574538588523865,
      "backward_entropy": 0.006898430841309684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0614090696399217e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026706047356128693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574519217014313,
      "backward_entropy": 0.006898404232093266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.765166039533142e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026706049218773842,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257449984550476,
      "backward_entropy": 0.00957693053143365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5179398000527726e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257447898387909,
      "backward_entropy": 0.00689837389758655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.246000173679931e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574461102485657,
      "backward_entropy": 0.009576935853276933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.035690537307346e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574443221092224,
      "backward_entropy": 0.009576942239488875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7993196144725516e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574425339698792,
      "backward_entropy": 0.006898309503282819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.574857032617729e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574408948421478,
      "backward_entropy": 0.006898295134305954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.357934019732056e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574392557144165,
      "backward_entropy": 0.006898283958435059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.180899099675116e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257437765598297,
      "backward_entropy": 0.006898250963006701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0049804422560555e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574361264705658,
      "backward_entropy": 0.009576975234917231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9487909003478308e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574344873428345,
      "backward_entropy": 0.006898229675633567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6608697467622733e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257433146238327,
      "backward_entropy": 0.0068982211606843135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.550796907030417e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574316561222076,
      "backward_entropy": 0.006898209452629089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3290340323001146e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574303150177002,
      "backward_entropy": 0.006898198808942523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1687839080186677e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574288249015808,
      "backward_entropy": 0.0068981652813298365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.116030373144895e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574274837970734,
      "backward_entropy": 0.006898156766380582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0134422129558516e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574262917041779,
      "backward_entropy": 0.009577007165976934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.898009394096789e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574249505996704,
      "backward_entropy": 0.014300011098384857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8100884346949897e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257423758506775,
      "backward_entropy": 0.014300015355859483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6534109192889446e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574225664138794,
      "backward_entropy": 0.009577012487820216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5939413344767672e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257421374320984,
      "backward_entropy": 0.006898113659449986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6835237204304576e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574203312397003,
      "backward_entropy": 0.00957704016140529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4355419963862914e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574192881584167,
      "backward_entropy": 0.009577045483248574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3072423143967171e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574180960655212,
      "backward_entropy": 0.009577053998197829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3008488508603477e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574172019958496,
      "backward_entropy": 0.006898071616888046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.204307409352623e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257416158914566,
      "backward_entropy": 0.01430007176739829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2321585529662116e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574151158332825,
      "backward_entropy": 0.006898060441017151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0368573555297189e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257414072751999,
      "backward_entropy": 0.006898055651358196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49417966467081e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574131786823273,
      "backward_entropy": 0.006898049797330584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.171600368063082e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574124336242676,
      "backward_entropy": 0.006898045539855957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.216488822654355e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257411390542984,
      "backward_entropy": 0.0068980370249067035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.496598979945702e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574106454849243,
      "backward_entropy": 0.01430011966398784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.022013275876816e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574097514152527,
      "backward_entropy": 0.014300132436411721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.700919013586827e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257409006357193,
      "backward_entropy": 0.006898007754768644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8619101512013e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574082612991333,
      "backward_entropy": 0.006898003497294017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.152884506922419e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574073672294617,
      "backward_entropy": 0.014300148401941572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.069285518606193e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257406622171402,
      "backward_entropy": 0.014300171818052019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8258464719074254e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574058771133423,
      "backward_entropy": 0.009577144469533647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.655181212205207e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574052810668945,
      "backward_entropy": 0.009577147662639618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.596913072418829e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574045360088348,
      "backward_entropy": 0.006897990192685809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.979998191600998e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574037909507751,
      "backward_entropy": 0.009577158306326185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.638373241050431e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574031949043274,
      "backward_entropy": 0.0068979816777365545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7123904778345604e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12574025988578796,
      "backward_entropy": 0.01430020374911172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.382911811262602e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257402002811432,
      "backward_entropy": 0.009577187044279916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.037120498485592e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257401406764984,
      "backward_entropy": 0.006897975291524615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.394678398966789e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12574008107185364,
      "backward_entropy": 0.006897973162787301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.754102806396986e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12574003636837006,
      "backward_entropy": 0.00957719555922917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.805951109825401e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573997676372528,
      "backward_entropy": 0.006897970501865659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5247467167209834e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257399320602417,
      "backward_entropy": 0.014300255903175898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4401708148834587e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573987245559692,
      "backward_entropy": 0.006897966244391033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0241977810874232e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12573982775211334,
      "backward_entropy": 0.014300267611231123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.226420020041587e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573978304862976,
      "backward_entropy": 0.009577218975339617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2275124794978183e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573972344398499,
      "backward_entropy": 0.006897959858179092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5911361944963573e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257396638393402,
      "backward_entropy": 0.00957722110407693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3742785515423748e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12573963403701782,
      "backward_entropy": 0.014300305928502764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8321273387300607e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573958933353424,
      "backward_entropy": 0.006897956132888794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.067432447461215e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12573954463005066,
      "backward_entropy": 0.014300314443452018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6327526825298264e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573948502540588,
      "backward_entropy": 0.009577229619026184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9732180334131044e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257394701242447,
      "backward_entropy": 0.014300330408981867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.114951769272011e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257394254207611,
      "backward_entropy": 0.006897931120225361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8302017679161509e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573938071727753,
      "backward_entropy": 0.006897931120225361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3601777482108446e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573935091495514,
      "backward_entropy": 0.009577251970767975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4417409488487465e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573932111263275,
      "backward_entropy": 0.006897924201829093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.605167554430409e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573927640914917,
      "backward_entropy": 0.006897922605276108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2990497566534032e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573924660682678,
      "backward_entropy": 0.006897922605276108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1717311565462296e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257392019033432,
      "backward_entropy": 0.006897922605276108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1085141693456535e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125739187002182,
      "backward_entropy": 0.006897922605276108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4757457478253855e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573914229869843,
      "backward_entropy": 0.006897920476538795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.072807620516869e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12573912739753723,
      "backward_entropy": 0.014300388949257987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.432952197130362e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573908269405365,
      "backward_entropy": 0.006897917815617153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1528289434181715e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12573906779289246,
      "backward_entropy": 0.01430039746420724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.325304972662707e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573903799057007,
      "backward_entropy": 0.006897914090326854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.817977459329995e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573900818824768,
      "backward_entropy": 0.009577275386878423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.148184183984995e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257389783859253,
      "backward_entropy": 0.006897911429405212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.826326170994435e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257389485836029,
      "backward_entropy": 0.006897909300667899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.380975747788398e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257389336824417,
      "backward_entropy": 0.009577277515615736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.198028922379308e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573891878128052,
      "backward_entropy": 0.009577277515615736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.85417944623623e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12573888897895813,
      "backward_entropy": 0.014300440038953508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.692530891110437e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573887407779694,
      "backward_entropy": 0.006897907171930585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.664269219276321e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573884427547455,
      "backward_entropy": 0.009577280708721705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6260416891309433e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573881447315216,
      "backward_entropy": 0.009577280708721705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.218048215738236e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573879957199097,
      "backward_entropy": 0.006897904511008944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.459508400917912e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573878467082977,
      "backward_entropy": 0.006897904511008944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.082672143747914e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573876976966858,
      "backward_entropy": 0.006897904511008944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.010392101212346e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257387399673462,
      "backward_entropy": 0.014300460261957986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.04684294355684e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257387399673462,
      "backward_entropy": 0.006897900785718646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.412186171975918e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257387101650238,
      "backward_entropy": 0.009577286030564989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.24723359312884e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257386952638626,
      "backward_entropy": 0.006897900785718646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1035264075617306e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573868036270142,
      "backward_entropy": 0.009577286030564989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.637339318629529e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12573865056037903,
      "backward_entropy": 0.01430048793554306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.276347998986239e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573865056037903,
      "backward_entropy": 0.006897900785718646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6498626343473006e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573863565921783,
      "backward_entropy": 0.006897900785718646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.587388164305594e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573862075805664,
      "backward_entropy": 0.009577286030564989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8814107483631233e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573862075805664,
      "backward_entropy": 0.006897900785718646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.014548610735801e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573859095573425,
      "backward_entropy": 0.00689789599605969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.650821784300206e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573857605457306,
      "backward_entropy": 0.00689789599605969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0167512932166574e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573856115341187,
      "backward_entropy": 0.00689789599605969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7064395169418276e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573854625225067,
      "backward_entropy": 0.009577286030564989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8629187909245957e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573853135108948,
      "backward_entropy": 0.009577286030564989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.184066261179396e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573853135108948,
      "backward_entropy": 0.006897894399506705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5414692572667263e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12573851644992828,
      "backward_entropy": 0.009577286030564989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0247625798219815e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257385015487671,
      "backward_entropy": 0.014300512416022164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.390763143012009e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1257384866476059,
      "backward_entropy": 0.0068978917385850635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0398260858200956e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02670605108141899,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1257384717464447,
      "backward_entropy": 0.014300514544759477,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 7.234910386344495e-09,
    "avg_log_Z": 0.02670605108141899,
    "success_rate": 1.0,
    "avg_reward": 44.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.2,
      "1": 0.27,
      "2": 0.53
    },
    "avg_forward_entropy": 0.1257402342557907,
    "avg_backward_entropy": 0.009101836771837301,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}