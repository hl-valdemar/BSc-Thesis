{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693943712446424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693943712446424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693943712446424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693943712446424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693943712446424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693943712446424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693943712446424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07693913910124037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.962803840637207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958095788955688,
      "backward_entropy": 0.07685611645380656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.558322429656982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958478450775147,
      "backward_entropy": 0.07693486081229316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.847593307495117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019992637680843472,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958731174468994,
      "backward_entropy": 0.07693057590060765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.956724643707275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0002998916315846145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959050655364991,
      "backward_entropy": 0.07683459255430433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.733503341674805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003999107866548002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959389209747314,
      "backward_entropy": 0.07691727744208442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.842336654663086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004998823278583586,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959751605987549,
      "backward_entropy": 0.07691669464111328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.131667137145996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000599865335971117,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960122346878051,
      "backward_entropy": 0.07690480020311144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.657680988311768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006999318720772862,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10960527658462524,
      "backward_entropy": 0.07680273056030273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.836999893188477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007999424124136567,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096086859703064,
      "backward_entropy": 0.0769011378288269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.635892868041992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000899948354344815,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961213111877441,
      "backward_entropy": 0.07678535249498156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.760923862457275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010002026101574302,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10961594581604003,
      "backward_entropy": 0.07687808407677545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.122359275817871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011003976687788963,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961923599243165,
      "backward_entropy": 0.07688438230090672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5389485359191895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012006241595372558,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096227765083313,
      "backward_entropy": 0.07675773567623562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.71937370300293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013006923254579306,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962587594985962,
      "backward_entropy": 0.07687245474921332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.717750549316406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014006737619638443,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962895154953003,
      "backward_entropy": 0.07686617639329699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.425511360168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015005834866315126,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963201522827148,
      "backward_entropy": 0.07685966624153985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.930189609527588,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016003357013687491,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963470935821533,
      "backward_entropy": 0.07671701908111572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.637576580047607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017001621890813112,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963739156723022,
      "backward_entropy": 0.07670612467659844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.323921203613281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017999517731368542,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963972806930541,
      "backward_entropy": 0.07669498523076375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.12841796875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018999630119651556,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964237451553345,
      "backward_entropy": 0.07683227459589641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0499372482299805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019996892660856247,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964429378509521,
      "backward_entropy": 0.07667191823323567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.607592582702637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020991796627640724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964539051055908,
      "backward_entropy": 0.07678782939910889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314499855041504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021990477107465267,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964713096618653,
      "backward_entropy": 0.0767783456378513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.390585899353027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022991353180259466,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964915752410889,
      "backward_entropy": 0.07676855723063152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.119462490081787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002399403601884842,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965166091918946,
      "backward_entropy": 0.0767974058787028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.514184951782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024993347469717264,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965352058410645,
      "backward_entropy": 0.07678984933429295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.406734943389893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002599143423140049,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965511798858643,
      "backward_entropy": 0.07659725348154704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.510200500488281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00269878632389009,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965652465820312,
      "backward_entropy": 0.07658420668707953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.298162460327148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027983449399471283,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965771675109863,
      "backward_entropy": 0.07676631874508327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.40261173248291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002897709608078003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965875387191773,
      "backward_entropy": 0.07655710644192165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.108497619628906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002997433999553323,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966007709503174,
      "backward_entropy": 0.07654380798339844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.815429210662842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030968838836997747,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096609354019165,
      "backward_entropy": 0.0765301783879598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.103621482849121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003195974277332425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966116189956665,
      "backward_entropy": 0.07667340172661676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08072280883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032953531481325626,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966148376464843,
      "backward_entropy": 0.07672410541110569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.413825511932373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003394918981939554,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966222286224366,
      "backward_entropy": 0.0766499572330051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.681857109069824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003493916941806674,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966209173202515,
      "backward_entropy": 0.07670615116755168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.57321834564209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003592971246689558,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966216325759888,
      "backward_entropy": 0.0766968462202284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.364943504333496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036925042513757944,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966286659240723,
      "backward_entropy": 0.07644199662738377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.297889232635498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003792332950979471,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10966415405273437,
      "backward_entropy": 0.07667708396911621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.776788234710693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003891992848366499,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966500043869018,
      "backward_entropy": 0.07658490207460192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.380282402038574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003991688601672649,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966591835021973,
      "backward_entropy": 0.07639343871010675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.166574478149414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0040912264958024025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966668128967286,
      "backward_entropy": 0.07637659708658855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.252320289611816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004191003739833832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966776609420777,
      "backward_entropy": 0.07654082775115967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.263436317443848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004290989600121975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096693754196167,
      "backward_entropy": 0.07652510537041558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.664003372192383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004391223657876253,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967113971710205,
      "backward_entropy": 0.07632479402754042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.549763679504395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004491356201469898,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096729040145874,
      "backward_entropy": 0.07630687289767796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.255187034606934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004591844510287046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967508554458619,
      "backward_entropy": 0.07628892527686225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0743632316589355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004692518152296543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967739820480346,
      "backward_entropy": 0.07646077209048802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.251414775848389,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004792770836502314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967912673950195,
      "backward_entropy": 0.0764444801542494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.739790916442871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004892647732049227,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968095064163208,
      "backward_entropy": 0.07655744420157538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.952779769897461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004993038717657328,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968308448791504,
      "backward_entropy": 0.07641075717078315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.748931884765625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005093493964523077,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968509912490845,
      "backward_entropy": 0.07639388905631171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719619750976562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005193872377276421,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968705415725707,
      "backward_entropy": 0.07651986016167535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33536148071289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005294638220220804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968958139419556,
      "backward_entropy": 0.0763590998119778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.003613471984863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005395614542067051,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969223976135253,
      "backward_entropy": 0.07634107271830241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.889629364013672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005497034173458815,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096954584121704,
      "backward_entropy": 0.07611213790045844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.947079658508301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005599356722086668,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10969910621643067,
      "backward_entropy": 0.07609100474251641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.054202079772949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005700899753719568,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970239639282227,
      "backward_entropy": 0.076070679558648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.499749183654785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005801881663501263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970504283905029,
      "backward_entropy": 0.07626819610595703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704463958740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005903030280023813,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970813035964966,
      "backward_entropy": 0.07642220126258002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.147777080535889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006004521157592535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971126556396485,
      "backward_entropy": 0.07623208231396145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.235883712768555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006105512380599976,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971375703811645,
      "backward_entropy": 0.07639161745707194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.081416130065918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006206057500094175,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971593856811523,
      "backward_entropy": 0.07619533273908827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907098293304443,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006307207979261875,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971840620040893,
      "backward_entropy": 0.07636009322272407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.155496597290039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006408225279301405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972092151641846,
      "backward_entropy": 0.07592760192023383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.584026336669922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006509724073112011,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972404479980469,
      "backward_entropy": 0.0763276153140598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.313502311706543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006611444987356663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972720384597778,
      "backward_entropy": 0.07611686653561062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100777626037598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006714216899126768,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973103046417236,
      "backward_entropy": 0.0758610831366645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.334254264831543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006816853303462267,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973435640335083,
      "backward_entropy": 0.07583809561199611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.371797561645508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0069198994897305965,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973808765411378,
      "backward_entropy": 0.07581486966874865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.564258575439453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007022836245596409,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974171161651611,
      "backward_entropy": 0.07579127947489421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.666598320007324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0071258037351071835,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097452163696289,
      "backward_entropy": 0.07622418138715956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.121098518371582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007228925358504057,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974828004837037,
      "backward_entropy": 0.07598649130927192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.598821640014648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0073313033208251,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975071191787719,
      "backward_entropy": 0.07571732997894287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.304924964904785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007433286868035793,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975269079208375,
      "backward_entropy": 0.07616957028706868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.647638320922852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0075357272289693356,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097551703453064,
      "backward_entropy": 0.07566554016537136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823479652404785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007638361770659685,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975731611251831,
      "backward_entropy": 0.07563881079355876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.863234996795654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007741166744381189,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975955724716187,
      "backward_entropy": 0.07611166106330024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.479292392730713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007843580096960068,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976173877716064,
      "backward_entropy": 0.07558406723870172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145730018615723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007945436984300613,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.109763765335083,
      "backward_entropy": 0.07606975899802314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.708966255187988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008047200739383698,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976566076278686,
      "backward_entropy": 0.07604849338531494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.896658897399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00814914982765913,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976767539978027,
      "backward_entropy": 0.0757600466410319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.512799263000488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008251393213868141,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976977348327636,
      "backward_entropy": 0.07600484953986274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.276942729949951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00835369061678648,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977184772491455,
      "backward_entropy": 0.07598246468438043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.599259376525879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008455351926386356,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977356433868408,
      "backward_entropy": 0.07595956987804836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.984605312347412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008557191118597984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977524518966675,
      "backward_entropy": 0.07564699649810791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.175537586212158,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008658234030008316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977675914764404,
      "backward_entropy": 0.07534178098042806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.923183917999268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00875876285135746,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977776050567627,
      "backward_entropy": 0.07558849122789171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052152633666992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008859180845320225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977877378463745,
      "backward_entropy": 0.07555860943264431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.633693218231201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008960173465311527,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10977981090545655,
      "backward_entropy": 0.07552787992689344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.663698196411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009060858748853207,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978071689605713,
      "backward_entropy": 0.07581228680080837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034683227539062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009161816909909248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10978187322616577,
      "backward_entropy": 0.07546484470367432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65401554107666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009263219311833382,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978329181671143,
      "backward_entropy": 0.07513096597459581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.211688995361328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009364807978272438,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978488922119141,
      "backward_entropy": 0.07509350114398533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.392645835876465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009466894902288914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097866177558899,
      "backward_entropy": 0.07536433802710639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731792449951172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009569491259753704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978859663009644,
      "backward_entropy": 0.07501626014709473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.099559783935547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009672194719314575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979058742523193,
      "backward_entropy": 0.07529322306315105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.906649589538574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00977519154548645,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979263782501221,
      "backward_entropy": 0.07493609852261013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.924653053283691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009878371842205524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979454517364502,
      "backward_entropy": 0.07489465342627631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05706787109375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009982249699532986,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979659557342529,
      "backward_entropy": 0.0751803716023763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.258455276489258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010085728950798512,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979840755462647,
      "backward_entropy": 0.07480903466542561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.04752254486084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010189521126449108,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980014801025391,
      "backward_entropy": 0.07549320326911078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.243890762329102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010292851366102695,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10980191230773925,
      "backward_entropy": 0.07546057303746541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.68277359008789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010396497324109077,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980359315872193,
      "backward_entropy": 0.07501928011576335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.953606605529785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010500085540115833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980517864227295,
      "backward_entropy": 0.07462814119127062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.763358116149902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010603752918541431,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980688333511353,
      "backward_entropy": 0.07458102040820652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.929111957550049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010707354173064232,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980875492095947,
      "backward_entropy": 0.07488647434446546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.116966247558594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010810418985784054,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981073379516601,
      "backward_entropy": 0.07528747452629937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.38084888458252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010913672856986523,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981286764144897,
      "backward_entropy": 0.07479388846291436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.458114624023438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01101734209805727,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981467962265015,
      "backward_entropy": 0.07521292898390028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.629204273223877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011120839975774288,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981621742248535,
      "backward_entropy": 0.07433429691526625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.811768531799316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01122370921075344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981745719909668,
      "backward_entropy": 0.0746479762925042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.165999412536621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011326626874506474,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981878042221069,
      "backward_entropy": 0.07422890928056505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.795663833618164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01142924278974533,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098199725151062,
      "backward_entropy": 0.07505746682484944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.153087615966797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01153138093650341,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982105731964112,
      "backward_entropy": 0.07412045531802708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.509392738342285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011633290909230709,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098220944404602,
      "backward_entropy": 0.07406487729814318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.047226905822754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01173519529402256,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982313156127929,
      "backward_entropy": 0.07400831911298963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.577319145202637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011836878955364227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982390642166137,
      "backward_entropy": 0.07433709833357069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.761788845062256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011939232237637043,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982455015182495,
      "backward_entropy": 0.07483902242448595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.584162712097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012041167356073856,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982483625411987,
      "backward_entropy": 0.07422627343071832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.820524215698242,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012142482213675976,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982551574707031,
      "backward_entropy": 0.07474574777815077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.553923606872559,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012244625948369503,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982611179351806,
      "backward_entropy": 0.07469780577553643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.816293716430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012346770614385605,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982666015625,
      "backward_entropy": 0.07464888360765246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360737800598145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012449048459529877,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982723236083984,
      "backward_entropy": 0.07357861598332723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.975537300109863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012551173567771912,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982785224914551,
      "backward_entropy": 0.07351291179656982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.905688285827637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012653549201786518,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982835292816162,
      "backward_entropy": 0.07344565126630995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5192975997924805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01275505218654871,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098282814025879,
      "backward_entropy": 0.07337692711088392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5228047370910645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012856164947152138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10982762575149536,
      "backward_entropy": 0.07373913129170735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8911824226379395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012956814840435982,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982687473297119,
      "backward_entropy": 0.07323458459642199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.40040111541748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01305670477449894,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098259687423706,
      "backward_entropy": 0.07360874281989203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.283713340759277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01315673254430294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982517004013062,
      "backward_entropy": 0.07308784458372328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.446992874145508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013257354497909546,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098246693611145,
      "backward_entropy": 0.07301286856333415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.303829669952393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013358627445995808,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982425212860107,
      "backward_entropy": 0.07293670707278782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.623696327209473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013459321111440659,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982358455657959,
      "backward_entropy": 0.07406086391872829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919296741485596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013560234569013119,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982279777526856,
      "backward_entropy": 0.07400365670522054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.615778923034668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013660886324942112,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982215404510498,
      "backward_entropy": 0.07394524415334065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.817966938018799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013761701062321663,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982165336608887,
      "backward_entropy": 0.07388563950856526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.687678813934326,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013862191699445248,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10982130765914917,
      "backward_entropy": 0.07253774007161458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84030818939209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013962473720312119,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10982048511505127,
      "backward_entropy": 0.07376331753200954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.597419261932373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01406312920153141,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10981957912445069,
      "backward_entropy": 0.0737000306447347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.699467658996582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014163435436785221,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098184585571289,
      "backward_entropy": 0.07363521390491062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.207884788513184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014264575205743313,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098175048828125,
      "backward_entropy": 0.07219050990210639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220982074737549,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01436559297144413,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098167896270752,
      "backward_entropy": 0.07350075244903564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.99009370803833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014466003514826298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10981591939926147,
      "backward_entropy": 0.07256323761410183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.202629089355469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014566328376531601,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098146915435791,
      "backward_entropy": 0.07247764534420437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.371489524841309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01466610748320818,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981320142745972,
      "backward_entropy": 0.07181570265028211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.421019554138184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01476660743355751,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981169939041138,
      "backward_entropy": 0.07171647416220771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.847145080566406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014867163263261318,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10981051921844483,
      "backward_entropy": 0.07161592112647162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.872308254241943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014966885559260845,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10980950593948365,
      "backward_entropy": 0.07212048768997192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.234985828399658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015066457912325859,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1098085880279541,
      "backward_entropy": 0.07202757729424371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.588350296020508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015165595337748528,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980727672576904,
      "backward_entropy": 0.07130557298660278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.162190437316895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015264494344592094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1098060131072998,
      "backward_entropy": 0.07119845019446479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.727337837219238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015363556332886219,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980443954467774,
      "backward_entropy": 0.07108885712093777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.897928237915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015462497249245644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1098026990890503,
      "backward_entropy": 0.07266611523098415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.624316215515137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015561403706669807,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10980101823806762,
      "backward_entropy": 0.07086340586344402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6674580574035645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015660133212804794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097993016242981,
      "backward_entropy": 0.0707474946975708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4428606033325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015758797526359558,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10979704856872559,
      "backward_entropy": 0.07240280840131971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.024863243103027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01585717871785164,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10979504585266113,
      "backward_entropy": 0.07050957282384236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33146858215332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015956273302435875,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979275703430176,
      "backward_entropy": 0.07110809617572361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.118853569030762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016055602580308914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10979028940200805,
      "backward_entropy": 0.07099260224236383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.549591064453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0161544568836689,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978765487670898,
      "backward_entropy": 0.07202544477250841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.884592056274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016253098845481873,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10978515148162842,
      "backward_entropy": 0.07192524274190266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.966329574584961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0163523368537426,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097825050354004,
      "backward_entropy": 0.07182284196217854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.84454345703125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016451530158519745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10978007316589355,
      "backward_entropy": 0.06974265310499403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.391633033752441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01655065082013607,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977760553359986,
      "backward_entropy": 0.07161090109083387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.770001411437988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016650069504976273,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977474451065064,
      "backward_entropy": 0.07150199678209093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983343124389648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016748690977692604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10977252721786498,
      "backward_entropy": 0.06932727495829265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.817519187927246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016847359016537666,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10977036952972412,
      "backward_entropy": 0.07127874427371556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.549432277679443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016946537420153618,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097683310508728,
      "backward_entropy": 0.069040404425727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010124206542969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01704483851790428,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097667932510376,
      "backward_entropy": 0.07104655106862386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654898643493652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0171432513743639,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976519584655761,
      "backward_entropy": 0.0709271960788303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5368757247924805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017242148518562317,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976337194442749,
      "backward_entropy": 0.07080535756217109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.044933795928955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017340853810310364,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097611665725708,
      "backward_entropy": 0.07068146599663629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.613187789916992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017439067363739014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975898504257202,
      "backward_entropy": 0.06828257772657606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.523681640625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01753717102110386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975680351257325,
      "backward_entropy": 0.06895538833406237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.997379779815674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017635108903050423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975474119186401,
      "backward_entropy": 0.06879631015989515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.146682262420654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017732609063386917,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975269079208375,
      "backward_entropy": 0.06779566076066759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.701751708984375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017829230055212975,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975062847137451,
      "backward_entropy": 0.06762819157706366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.498862266540527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017926542088389397,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1097485065460205,
      "backward_entropy": 0.06745696730083889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.071597099304199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018024377524852753,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974608659744263,
      "backward_entropy": 0.06813586420483059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.871160507202148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018121859058737755,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974340438842774,
      "backward_entropy": 0.06796229547924465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.356379985809326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018218928948044777,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097402811050415,
      "backward_entropy": 0.0694515307744344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.276350021362305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01831590011715889,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973687171936035,
      "backward_entropy": 0.06673899624082777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.088787078857422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018412049859762192,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973430871963501,
      "backward_entropy": 0.0665540960099962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.434215068817139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01850849576294422,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973265171051025,
      "backward_entropy": 0.06899600558810765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.251847743988037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018604984506964684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973029136657715,
      "backward_entropy": 0.0670573976304796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50429916381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01870131492614746,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097281813621521,
      "backward_entropy": 0.06867827309502496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.667176723480225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01879827119410038,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972585678100585,
      "backward_entropy": 0.06851458549499512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4391632080078125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0188947394490242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972321033477783,
      "backward_entropy": 0.06647578875223796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.18272590637207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01899115741252899,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972075462341309,
      "backward_entropy": 0.06538229518466526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02375602722168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01908801682293415,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971801280975342,
      "backward_entropy": 0.0680070850584242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.191576957702637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019185150042176247,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971524715423583,
      "backward_entropy": 0.0658595429526435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.055102825164795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019282041117548943,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971252918243408,
      "backward_entropy": 0.06474839978747898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.390575885772705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019378671422600746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970956087112427,
      "backward_entropy": 0.06453002823723687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.142922878265381,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01947522722184658,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970666408538818,
      "backward_entropy": 0.06728563706080119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1868391036987305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019571000710129738,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970382690429688,
      "backward_entropy": 0.06498755349053277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.456732273101807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019666112959384918,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970091819763184,
      "backward_entropy": 0.06385757525761922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.214593887329102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019760742783546448,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969841480255127,
      "backward_entropy": 0.06453702847162883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.765460014343262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019856031984090805,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969550609588623,
      "backward_entropy": 0.06430349085066053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.367623805999756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01995166949927807,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096920132637024,
      "backward_entropy": 0.06631948550542195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.743950366973877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02004735916852951,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968838930130005,
      "backward_entropy": 0.0661160945892334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.705385208129883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02014276571571827,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968421697616577,
      "backward_entropy": 0.06591020027796428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.897709846496582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020237833261489868,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968024730682373,
      "backward_entropy": 0.062415122985839844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.634324073791504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020332109183073044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096766471862793,
      "backward_entropy": 0.06306905216640896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.749338150024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020425520837306976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10967339277267456,
      "backward_entropy": 0.06281775236129761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.782454013824463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02051885798573494,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966989994049073,
      "backward_entropy": 0.06256207492616442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.277960300445557,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020612163469195366,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966606140136718,
      "backward_entropy": 0.06138802899254693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9610371589660645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020705142989754677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966188907623291,
      "backward_entropy": 0.06203787856631809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2850141525268555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02079823613166809,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1096573829650879,
      "backward_entropy": 0.06176780992084079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.899345397949219,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020891595631837845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109652841091156,
      "backward_entropy": 0.060572312937842474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.397407054901123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020984934642910957,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964864492416382,
      "backward_entropy": 0.06120947996775309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.660740375518799,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0210779570043087,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964494943618774,
      "backward_entropy": 0.06366292635599773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6204328536987305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02117086760699749,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964138507843017,
      "backward_entropy": 0.060635010401407875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.60209846496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02126432955265045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096369743347168,
      "backward_entropy": 0.06316294935014513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.910348415374756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021357541903853416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963345766067505,
      "backward_entropy": 0.05913213226530287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.987730026245117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02145080640912056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962963104248047,
      "backward_entropy": 0.0597206089231703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986065864562988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021544193848967552,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962512493133544,
      "backward_entropy": 0.06237831380632189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.945724010467529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021638328209519386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096195936203003,
      "backward_entropy": 0.058216591676076256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.260269641876221,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0217317882925272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961450338363647,
      "backward_entropy": 0.05790287256240845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.552761554718018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021824806928634644,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961015224456787,
      "backward_entropy": 0.0575843784544203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.952568054199219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02191769704222679,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960527658462524,
      "backward_entropy": 0.0580619043774075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.657871723175049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022010071203112602,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096003770828247,
      "backward_entropy": 0.05692174037297567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8316497802734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0221030842512846,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959469079971314,
      "backward_entropy": 0.06070123778449164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.737864017486572,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022196130827069283,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958870649337768,
      "backward_entropy": 0.06040707561704847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4726152420043945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022287825122475624,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095837950706482,
      "backward_entropy": 0.060111403465270996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.379786491394043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022379452362656593,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957875251770019,
      "backward_entropy": 0.05554589960310194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.102865219116211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022470949217677116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957374572753906,
      "backward_entropy": 0.05591674645741781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.296326160430908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022562207654118538,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10956807136535644,
      "backward_entropy": 0.059185955259535045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9683308601379395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02265332266688347,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10956248044967651,
      "backward_entropy": 0.05517008900642395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.708677291870117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022744139656424522,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095564603805542,
      "backward_entropy": 0.05411090122328864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.950732707977295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022834524512290955,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955013036727905,
      "backward_entropy": 0.05820788277520074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.893676280975342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02292463555932045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10954395532608033,
      "backward_entropy": 0.0533687969048818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.104285717010498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023015204817056656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10953676700592041,
      "backward_entropy": 0.053629438082377114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7433013916015625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02310495637357235,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952974557876587,
      "backward_entropy": 0.057187285688188344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.597282409667969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02319509908556938,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952153205871581,
      "backward_entropy": 0.052218970325258046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.471110820770264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02328547090291977,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951260328292847,
      "backward_entropy": 0.056486580106947154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.706601142883301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023375242948532104,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10950437784194947,
      "backward_entropy": 0.05201691389083862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.725885391235352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023463938385248184,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949757099151611,
      "backward_entropy": 0.05161075128449334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.263069152832031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023552414029836655,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949052572250366,
      "backward_entropy": 0.0512007474899292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4525909423828125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023641759529709816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094820737838745,
      "backward_entropy": 0.05077877309587267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.243760585784912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023730581626296043,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094744086265564,
      "backward_entropy": 0.054663399855295815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.586253643035889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023818805813789368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946731567382813,
      "backward_entropy": 0.04993152618408203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.128698348999023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02390604093670845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946110486984253,
      "backward_entropy": 0.049017217424180776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.302820205688477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02399349771440029,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945402383804322,
      "backward_entropy": 0.05352393786112467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.453041076660156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024080533534288406,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944733619689942,
      "backward_entropy": 0.04819704426659478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.044721603393555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024167297407984734,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944089889526368,
      "backward_entropy": 0.047785003980000816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.98630952835083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02425430528819561,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10943306684494018,
      "backward_entropy": 0.05235526959101359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.554336071014404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024341493844985962,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942397117614747,
      "backward_entropy": 0.05195864372783237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6209397315979,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02442777343094349,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10941550731658936,
      "backward_entropy": 0.05156112379497952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1137261390686035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024513255804777145,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10940804481506347,
      "backward_entropy": 0.046421580844455294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.135307312011719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02459842525422573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10940021276473999,
      "backward_entropy": 0.045973393652174205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.878713607788086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024683291092514992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10939257144927979,
      "backward_entropy": 0.04552265008290609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9506144523620605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024768495932221413,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938330888748168,
      "backward_entropy": 0.044817692703670926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.746736526489258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0248532984405756,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937378406524659,
      "backward_entropy": 0.04460446039835612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.209543228149414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02493753843009472,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936474800109863,
      "backward_entropy": 0.043954590956370033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.78320837020874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025021666660904884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935486555099487,
      "backward_entropy": 0.04352143738004896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.090340614318848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025105377659201622,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934466123580933,
      "backward_entropy": 0.04308689302868313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8076272010803223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02518894337117672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933382511138916,
      "backward_entropy": 0.04275215996636285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.508316516876221,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02527136355638504,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10932457447052002,
      "backward_entropy": 0.04221690363354153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.920828104019165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025353295728564262,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10931566953659058,
      "backward_entropy": 0.041832294729020864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.640197277069092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025434337556362152,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930776596069336,
      "backward_entropy": 0.04137666357888116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2285852432250977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025515155866742134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10929940938949585,
      "backward_entropy": 0.04091856877009074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.83695650100708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025594625622034073,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10929324626922607,
      "backward_entropy": 0.040491335921817355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.539519309997559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02567417547106743,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10928621292114257,
      "backward_entropy": 0.04001604517300924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.874966621398926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02575354091823101,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10927906036376953,
      "backward_entropy": 0.039632558822631836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.715027332305908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025833090767264366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10926990509033203,
      "backward_entropy": 0.03909674617979261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.349139213562012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02591264620423317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10925955772399902,
      "backward_entropy": 0.03863044579823812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.452289581298828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025991925969719887,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10924832820892334,
      "backward_entropy": 0.04344020287195841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.786113262176514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02607104368507862,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923603773117066,
      "backward_entropy": 0.04299034674962362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.394839763641357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026150254532694817,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109222674369812,
      "backward_entropy": 0.037454177935918175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.199626445770264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02622923068702221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920878648757934,
      "backward_entropy": 0.03674754169252184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.252699851989746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263078473508358,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091943621635437,
      "backward_entropy": 0.04162640041775174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.099680423736572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026386233046650887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10917853116989136,
      "backward_entropy": 0.03580062256919013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.120112895965576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026464249938726425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10916204452514648,
      "backward_entropy": 0.03532801071802775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.204934120178223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02654198929667473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10914427042007446,
      "backward_entropy": 0.03485584921307034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5569586753845215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026619555428624153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10912485122680664,
      "backward_entropy": 0.034383181068632335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6625938415527344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02669726312160492,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10910331010818482,
      "backward_entropy": 0.0393470823764801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.281463384628296,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02677428163588047,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1090818166732788,
      "backward_entropy": 0.03889160023795234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.392643690109253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026850327849388123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10906133651733399,
      "backward_entropy": 0.032970296012030706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.730879306793213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02692561037838459,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10904190540313721,
      "backward_entropy": 0.037987066639794245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4866883754730225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02700049988925457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10902252197265624,
      "backward_entropy": 0.03268175986078051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.210232734680176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027074862271547318,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10900242328643799,
      "backward_entropy": 0.037083817852867976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.124166488647461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027148457244038582,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10898276567459106,
      "backward_entropy": 0.031834165255228676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5059170722961426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02722223289310932,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10896067619323731,
      "backward_entropy": 0.030674139658610027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.29226016998291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027294602245092392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10894142389297486,
      "backward_entropy": 0.030227379666434392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.402944564819336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027366481721401215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10892181396484375,
      "backward_entropy": 0.029782884650760226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.166139841079712,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027437031269073486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10890486240386962,
      "backward_entropy": 0.03017949726846483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1263976097106934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027507150545716286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1088871955871582,
      "backward_entropy": 0.028918547762764826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.210336208343506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027576856315135956,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10886861085891723,
      "backward_entropy": 0.03394875923792521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0229315757751465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02764628827571869,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1088484764099121,
      "backward_entropy": 0.02897527813911438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3918397426605225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027715284377336502,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1088273286819458,
      "backward_entropy": 0.028577738338046603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.576253652572632,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027783190831542015,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10880800485610961,
      "backward_entropy": 0.028186344438129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.837092399597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027850303798913956,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10879024267196655,
      "backward_entropy": 0.03220526377360026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9115867614746094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02791702188551426,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10877224206924438,
      "backward_entropy": 0.03177746136983236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5615110397338867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02798347920179367,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10875232219696045,
      "backward_entropy": 0.03135199679268731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4838201999664307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028049286454916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10873224735260009,
      "backward_entropy": 0.025580637984805636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.394252061843872,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02811441197991371,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10871223211288453,
      "backward_entropy": 0.026272959179348417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.408088445663452,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028178870677947998,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10869190692901612,
      "backward_entropy": 0.02590005099773407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.15755033493042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028242718428373337,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10867118835449219,
      "backward_entropy": 0.025530964136123657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.859392523765564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028305739164352417,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10865098237991333,
      "backward_entropy": 0.02928390105565389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2407069206237793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02836764231324196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10863287448883056,
      "backward_entropy": 0.02363910774389903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2210845947265625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02842899039387703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10861412286758423,
      "backward_entropy": 0.024452121721373662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7003321647644043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028489839285612106,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10859439373016358,
      "backward_entropy": 0.024100053641531203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0965232849121094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0285495575517416,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10857690572738647,
      "backward_entropy": 0.02254627313878801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8187810182571411,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028608771041035652,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10855846405029297,
      "backward_entropy": 0.027342432075076632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0872390270233154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028667159378528595,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10854076147079468,
      "backward_entropy": 0.021845978167321947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6147273778915405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028725160285830498,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10852150917053223,
      "backward_entropy": 0.021501345766915217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6324844360351562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02878217026591301,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10850377082824707,
      "backward_entropy": 0.021164576212565105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.246452808380127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028838278725743294,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1084871768951416,
      "backward_entropy": 0.02587315771314833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.838484287261963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028894472867250443,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1084666132926941,
      "backward_entropy": 0.021767139434814453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8301395177841187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028950130566954613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10844519138336181,
      "backward_entropy": 0.020174538095792133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6353343725204468,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02900533191859722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842238664627075,
      "backward_entropy": 0.019849636488490634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0546300411224365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0290598776191473,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10839914083480835,
      "backward_entropy": 0.02082772718535529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5167300701141357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0291143748909235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10837259292602539,
      "backward_entropy": 0.019210255808300443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1432812213897705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029168086126446724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10834622383117676,
      "backward_entropy": 0.018897210558255512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.74334716796875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02922201342880726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10831544399261475,
      "backward_entropy": 0.01858113209406535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6144753694534302,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02927553467452526,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1082829475402832,
      "backward_entropy": 0.023108326726489596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.554248332977295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029328500851988792,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1082492470741272,
      "backward_entropy": 0.02277865343623691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1472735404968262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029380865395069122,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10821454524993897,
      "backward_entropy": 0.019037945402993098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6980233192443848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02943207137286663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10818183422088623,
      "backward_entropy": 0.018753192491001554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3328839540481567,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02948310598731041,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10814598798751832,
      "backward_entropy": 0.021822200881110296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1220459938049316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029533367604017258,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10810995101928711,
      "backward_entropy": 0.016784788833724126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2190905809402466,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029582548886537552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10807532072067261,
      "backward_entropy": 0.017924911446041532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1409800052642822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029630912467837334,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10804078578948975,
      "backward_entropy": 0.017661927474869624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1116223335266113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02967844158411026,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10800641775131226,
      "backward_entropy": 0.020615110794703167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1104434728622437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029725179076194763,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10797202587127686,
      "backward_entropy": 0.017151610718833074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9064105749130249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02977115660905838,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10793735980987548,
      "backward_entropy": 0.015453192922804091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.11288583278656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02981610596179962,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10790430307388306,
      "backward_entropy": 0.016663375828001235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8504205942153931,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029860498383641243,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10787005424499511,
      "backward_entropy": 0.019491800003581576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9178577661514282,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029903912916779518,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10783696174621582,
      "backward_entropy": 0.014726933505800035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1372777223587036,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02994653768837452,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10780391693115235,
      "backward_entropy": 0.01896524926026662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.152917742729187,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029988925904035568,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1077678918838501,
      "backward_entropy": 0.018707591626379225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9237117767333984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03003113716840744,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10772857666015626,
      "backward_entropy": 0.018452490369478863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8875424861907959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030072776600718498,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10768831968307495,
      "backward_entropy": 0.018203048242463007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5192250609397888,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030113710090517998,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10764734745025635,
      "backward_entropy": 0.01795805162853665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7636409401893616,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030153261497616768,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10760997533798218,
      "backward_entropy": 0.01772220598326789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44013407826423645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030192015692591667,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10757232904434204,
      "backward_entropy": 0.01468554139137268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6804234981536865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03022930771112442,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10753843784332276,
      "backward_entropy": 0.01449378165933821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5429375171661377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030265875160694122,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1075042724609375,
      "backward_entropy": 0.014306621419058906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6643730401992798,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0303015299141407,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10747158527374268,
      "backward_entropy": 0.016839404900868733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4272807240486145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030336542055010796,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10743792057037353,
      "backward_entropy": 0.016632434394624498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7518547177314758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030370403081178665,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10740656852722168,
      "backward_entropy": 0.01377347277270423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.464065819978714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03040403313934803,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10737202167510987,
      "backward_entropy": 0.016234760483105976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4731374680995941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030436677858233452,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10733851194381713,
      "backward_entropy": 0.011928085651662614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5399937033653259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030468540266156197,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10730570554733276,
      "backward_entropy": 0.011767484247684479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5030715465545654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030499892309308052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10727204084396362,
      "backward_entropy": 0.011610005464818742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44774818420410156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030530614778399467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1072378158569336,
      "backward_entropy": 0.011455996168984307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3988271653652191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03056061454117298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1072035551071167,
      "backward_entropy": 0.011306253572305044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3794719874858856,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030589831992983818,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10716981887817383,
      "backward_entropy": 0.012656831079059176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5290567874908447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03061826340854168,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10713653564453125,
      "backward_entropy": 0.012512619296709696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3403516113758087,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030646389350295067,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1071004867553711,
      "backward_entropy": 0.01237099700503879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41189852356910706,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030673645436763763,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10706502199172974,
      "backward_entropy": 0.014673908551534018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3788129985332489,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070044331252575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1070287585258484,
      "backward_entropy": 0.01061497131983439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3044698238372803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030726613476872444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10699172019958496,
      "backward_entropy": 0.011969411538706886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3905015289783478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030751975253224373,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10695515871047974,
      "backward_entropy": 0.010362284051047431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31668907403945923,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030776945874094963,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10691711902618409,
      "backward_entropy": 0.011719469394948747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40083378553390503,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03080129623413086,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1068789005279541,
      "backward_entropy": 0.013951164152887132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18309573829174042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030825477093458176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10683872699737548,
      "backward_entropy": 0.011479394303427802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46554630994796753,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030848614871501923,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10680098533630371,
      "backward_entropy": 0.00989196863439348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08941689133644104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030871840193867683,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10675898790359498,
      "backward_entropy": 0.009778970645533668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26490846276283264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03089371882379055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10672118663787841,
      "backward_entropy": 0.009673852059576247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2992905080318451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030915111303329468,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10668306350708008,
      "backward_entropy": 0.011034660869174533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24331870675086975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03093615174293518,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10664339065551758,
      "backward_entropy": 0.01093009610970815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2949104607105255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03095667064189911,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10660344362258911,
      "backward_entropy": 0.010828197002410889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19939179718494415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03097682259976864,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10656130313873291,
      "backward_entropy": 0.012988504436280992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21188907325267792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030996285378932953,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10651950836181641,
      "backward_entropy": 0.009182199835777283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28845635056495667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031015150249004364,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10647730827331543,
      "backward_entropy": 0.010540326436360678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15659648180007935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031033840030431747,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10643260478973389,
      "backward_entropy": 0.00900220705403222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3079221844673157,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031051747500896454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10638878345489503,
      "backward_entropy": 0.008916604850027297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20314830541610718,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031069686636328697,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10634170770645142,
      "backward_entropy": 0.010274900330437554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19674387574195862,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031087171286344528,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1062941312789917,
      "backward_entropy": 0.010190430614683364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2765876054763794,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031104251742362976,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10624630451202392,
      "backward_entropy": 0.010108051200707754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19748300313949585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03112133778631687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10619555711746216,
      "backward_entropy": 0.008582027422057258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22432006895542145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031137997284531593,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10614405870437622,
      "backward_entropy": 0.012138177951176962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13494856655597687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031154489144682884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10609095096588135,
      "backward_entropy": 0.009868234395980835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14467354118824005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031170256435871124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1060386061668396,
      "backward_entropy": 0.0083465576171875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16980427503585815,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031185373663902283,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1059863805770874,
      "backward_entropy": 0.011896055605676439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20648346841335297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031200146302580833,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10593345165252685,
      "backward_entropy": 0.009652140239874521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11583304405212402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031214861199259758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10587871074676514,
      "backward_entropy": 0.008131922119193606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1514759063720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031228886917233467,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10582472085952759,
      "backward_entropy": 0.011676710512903001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1844712346792221,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031242484226822853,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10576980113983155,
      "backward_entropy": 0.009453793366750082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10338788479566574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03125592693686485,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1057126760482788,
      "backward_entropy": 0.009391380680931939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18284693360328674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03126874938607216,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10565654039382935,
      "backward_entropy": 0.009331890278392367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11863866448402405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03128156438469887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1055980920791626,
      "backward_entropy": 0.007809625731574165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07050976902246475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129393979907036,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10553984642028809,
      "backward_entropy": 0.0077496071656545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14213089644908905,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03130553662776947,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10548347234725952,
      "backward_entropy": 0.00916252119673623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10621500760316849,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131698817014694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10542585849761962,
      "backward_entropy": 0.009110073248545328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11167683452367783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031328048557043076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10536853075027466,
      "backward_entropy": 0.007584248152044084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08120158314704895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03133884072303772,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10531126260757447,
      "backward_entropy": 0.007531490590837266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14171439409255981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031349025666713715,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10525469779968262,
      "backward_entropy": 0.007481772038671706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10172214359045029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031359218060970306,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10519583225250244,
      "backward_entropy": 0.007431808445188735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0816296860575676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03136907517910004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10513651371002197,
      "backward_entropy": 0.007383329172929128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10220033675432205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03137844055891037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10507751703262329,
      "backward_entropy": 0.007337105770905812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06061108037829399,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031387608498334885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10501782894134522,
      "backward_entropy": 0.007291716006067064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06496220827102661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03139616176486015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10495930910110474,
      "backward_entropy": 0.007249148355589973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09316134452819824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031404267996549606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10490171909332276,
      "backward_entropy": 0.007208842370245192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08066200464963913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03141219913959503,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.104843270778656,
      "backward_entropy": 0.007169072826703389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055209580808877945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031419962644577026,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10478496551513672,
      "backward_entropy": 0.007129971351888444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10313420742750168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031427133828401566,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10472737550735474,
      "backward_entropy": 0.01074086626370748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04487687721848488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031434401869773865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1046680212020874,
      "backward_entropy": 0.007056640254126655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07918764650821686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031441058963537216,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10461000204086304,
      "backward_entropy": 0.007022435466448466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06981867551803589,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03144758939743042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10455119609832764,
      "backward_entropy": 0.008524190220567916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06347788870334625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031453948467969894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10449224710464478,
      "backward_entropy": 0.008496339122454325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07490283250808716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031460028141736984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443323850631714,
      "backward_entropy": 0.00692402571439743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06167680397629738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031466126441955566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1043737769126892,
      "backward_entropy": 0.006892062723636627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06241133064031601,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03147188574075699,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10431387424468994,
      "backward_entropy": 0.008418213989999559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054606880992650986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031477462500333786,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10425367355346679,
      "backward_entropy": 0.006831802841689851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058101192116737366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03148282319307327,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10419378280639649,
      "backward_entropy": 0.006803094926807616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07985493540763855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031488023698329926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1041337251663208,
      "backward_entropy": 0.006775059219863679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054460689425468445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031493354588747025,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10407164096832275,
      "backward_entropy": 0.006746396422386169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055939849466085434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0314985029399395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10400983095169067,
      "backward_entropy": 0.008303460975488028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044810689985752106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03150355815887451,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10394816398620606,
      "backward_entropy": 0.008281902306609683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06003367528319359,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03150826320052147,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10388693809509278,
      "backward_entropy": 0.006665027803844876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04774622619152069,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03151301294565201,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.103825044631958,
      "backward_entropy": 0.006638892408874299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03504718840122223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03151758760213852,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1037632703781128,
      "backward_entropy": 0.00822232249710295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06144683063030243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03152183070778847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.103702712059021,
      "backward_entropy": 0.00658971443772316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035499218851327896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03152622655034065,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10364091396331787,
      "backward_entropy": 0.008186254236433241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03594064339995384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0315302237868309,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10357975959777832,
      "backward_entropy": 0.006542626354429457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03788904473185539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03153395652770996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10351934432983398,
      "backward_entropy": 0.0065210676855511135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03576212748885155,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0315374955534935,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10345935821533203,
      "backward_entropy": 0.01030129525396559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03274483606219292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03154074773192406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10339958667755127,
      "backward_entropy": 0.006480765839417775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037693753838539124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0315437875688076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10334057807922363,
      "backward_entropy": 0.006462090545230442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03568685054779053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03154684975743294,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10328207015991211,
      "backward_entropy": 0.010271499554316202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028430985286831856,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03154982253909111,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10322375297546386,
      "backward_entropy": 0.008089310593075223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044337302446365356,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03155263140797615,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10316646099090576,
      "backward_entropy": 0.010252730713950263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03612016141414642,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0315556563436985,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10310840606689453,
      "backward_entropy": 0.010242133504814573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03491277992725372,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03155870363116264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10305025577545165,
      "backward_entropy": 0.008053892188602023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026885991916060448,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03156176209449768,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10299206972122192,
      "backward_entropy": 0.010220294197400412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029365312308073044,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031564682722091675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10293481349945069,
      "backward_entropy": 0.006334769229094188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02392967976629734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03156748786568642,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1028778076171875,
      "backward_entropy": 0.010200043519337973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03656035289168358,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03156999126076698,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10282130241394043,
      "backward_entropy": 0.010192144248220656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028730159625411034,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03157265856862068,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1027639627456665,
      "backward_entropy": 0.010183321105109321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025976119562983513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03157525509595871,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10270649194717407,
      "backward_entropy": 0.006269070009390513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02399233728647232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03157773241400719,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1026486873626709,
      "backward_entropy": 0.006253481325176027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021502623334527016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031580131500959396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10259140729904175,
      "backward_entropy": 0.007972086469332377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01762879453599453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031582318246364594,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10253455638885497,
      "backward_entropy": 0.010152714120017158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025477392598986626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03158422186970711,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10247886180877686,
      "backward_entropy": 0.006210755142900679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02314426191151142,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03158615157008171,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10242315530776977,
      "backward_entropy": 0.007949590682983398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026132039725780487,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03158805891871452,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10236740112304688,
      "backward_entropy": 0.007942448059717814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018853873014450073,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03159007802605629,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1023112416267395,
      "backward_entropy": 0.010131463408470154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02407420240342617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03159197419881821,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10225455760955811,
      "backward_entropy": 0.01012608740064833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01547264214605093,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03159397840499878,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10219736099243164,
      "backward_entropy": 0.010119924942652384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021550459787249565,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031595759093761444,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10214066505432129,
      "backward_entropy": 0.010115034050411649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016921285539865494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031597595661878586,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10208349227905274,
      "backward_entropy": 0.006119685868422191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016652317717671394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031599294394254684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10202648639678955,
      "backward_entropy": 0.006107815437846714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021933864802122116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03160092979669571,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10196990966796875,
      "backward_entropy": 0.006096311741405063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012720052152872086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03160267323255539,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10191256999969482,
      "backward_entropy": 0.00788882209195031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011944250203669071,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03160422295331955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10185625553131103,
      "backward_entropy": 0.006073353191216786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012746458873152733,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03160553425550461,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10180075168609619,
      "backward_entropy": 0.007878863977061378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010904775001108646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031606726348400116,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10174607038497925,
      "backward_entropy": 0.007874901096026102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011974661611020565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031607795506715775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10169262886047363,
      "backward_entropy": 0.006045004973808925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013667339459061623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031608764082193375,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10163984298706055,
      "backward_entropy": 0.006036584162049823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014123480767011642,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03160976245999336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10158729553222656,
      "backward_entropy": 0.006028089672327042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011887653730809689,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03161081299185753,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10153396129608154,
      "backward_entropy": 0.010084290471341874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012601860798895359,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0316118523478508,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10148086547851562,
      "backward_entropy": 0.00785900569624371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011846762150526047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031612955033779144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10142800807952881,
      "backward_entropy": 0.006002063138617409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009331080131232738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03161406144499779,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10137535333633423,
      "backward_entropy": 0.010078143742349412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012303940020501614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031615015119314194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10132311582565308,
      "backward_entropy": 0.00598529146777259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010415169410407543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03161604702472687,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10127086639404297,
      "backward_entropy": 0.00784553587436676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010000521317124367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03161709010601044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1012190818786621,
      "backward_entropy": 0.005968792984882991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007435542065650225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0316181443631649,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10116778612136841,
      "backward_entropy": 0.007838811311456893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010547765530645847,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03161913529038429,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10111780166625976,
      "backward_entropy": 0.010069191455841064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007890242151916027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162018582224846,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10106782913208008,
      "backward_entropy": 0.005944780177540249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006341482978314161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162117674946785,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10101860761642456,
      "backward_entropy": 0.005937051028013229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0068888370878994465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031622011214494705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10097026824951172,
      "backward_entropy": 0.005930029683642917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007825282402336597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162277117371559,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10092270374298096,
      "backward_entropy": 0.005923366794983546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007383896503597498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031623560935258865,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10087573528289795,
      "backward_entropy": 0.005916602081722683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007449416909366846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162438049912453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10082948207855225,
      "backward_entropy": 0.005909782730870777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005800309590995312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031625207513570786,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10078353881835937,
      "backward_entropy": 0.007816973659727309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006686283275485039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162601962685585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10073871612548828,
      "backward_entropy": 0.005896339813868205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007792674470692873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162684664130211,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10069432258605956,
      "backward_entropy": 0.00588972700966729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0045706722885370255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031627800315618515,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10065008401870727,
      "backward_entropy": 0.005882682899634044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008382560685276985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162865713238716,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10060696601867676,
      "backward_entropy": 0.005876125146945317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005626955069601536,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031629692763090134,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10056363344192505,
      "backward_entropy": 0.007802828318542904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0049939933232963085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163071721792221,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10052095651626587,
      "backward_entropy": 0.005861683852142758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005722105503082275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316317081451416,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1004790186882019,
      "backward_entropy": 0.005854734116130405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00295193656347692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031632740050554276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1004374623298645,
      "backward_entropy": 0.005847700354125764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004808247555047274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163363039493561,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10039740800857544,
      "backward_entropy": 0.005841327624188529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005542854778468609,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031634509563446045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10035773515701293,
      "backward_entropy": 0.0077870819303724505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004532964900135994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163547441363335,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10031830072402954,
      "backward_entropy": 0.005828406247827742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036016011144965887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031636446714401245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10027939081192017,
      "backward_entropy": 0.005821814139684041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041006216779351234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163735941052437,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10024129152297974,
      "backward_entropy": 0.005815540750821431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004207783378660679,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03163827955722809,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1002037525177002,
      "backward_entropy": 0.007774506178167131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028744814917445183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0316392220556736,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10016658306121826,
      "backward_entropy": 0.00777133885357115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028178992215543985,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03164009004831314,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10013036727905274,
      "backward_entropy": 0.0077685291568438215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022497852332890034,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03164088353514671,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10009496212005616,
      "backward_entropy": 0.007765980230437385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021012350916862488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03164157643914223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10006061792373658,
      "backward_entropy": 0.005786349376042684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002344044391065836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031642183661460876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10002733469009399,
      "backward_entropy": 0.005781643092632294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00315466383472085,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03164275363087654,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09999492168426513,
      "backward_entropy": 0.007760559519131978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024339230731129646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031643372029066086,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09996284246444702,
      "backward_entropy": 0.005772453215387132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002212243853136897,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03164399042725563,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09993151426315308,
      "backward_entropy": 0.0077569567494922215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024529164656996727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031644586473703384,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09990094900131226,
      "backward_entropy": 0.007755272090435028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002895647892728448,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031645189970731735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09987088441848754,
      "backward_entropy": 0.005758860872851478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033683942165225744,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031645867973566055,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09984104633331299,
      "backward_entropy": 0.010003046029143862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021231852006167173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031646665185689926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09981107115745544,
      "backward_entropy": 0.005748901930120256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022792802192270756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031647417694330215,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09978141188621521,
      "backward_entropy": 0.005743956400288476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016885549994185567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316481851041317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09975218772888184,
      "backward_entropy": 0.005738995141453213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017144449520856142,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316489078104496,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09972368478775025,
      "backward_entropy": 0.0057342371178997886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019748806953430176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03164960443973541,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09969581961631775,
      "backward_entropy": 0.007738751669724782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019120738143101335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165031597018242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09966830611228943,
      "backward_entropy": 0.005725021577543682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001750574680045247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165103495121002,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09964107275009156,
      "backward_entropy": 0.005720398492283291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013995441840961576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165176510810852,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0996143102645874,
      "backward_entropy": 0.005715803967581855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009683582466095686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165246173739433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09958820343017578,
      "backward_entropy": 0.0057113998466067845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012828090693801641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165308013558388,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0995630145072937,
      "backward_entropy": 0.00570735376742151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012020893627777696,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165367245674133,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09953837990760803,
      "backward_entropy": 0.005703433520264096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013109269784763455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031654246151447296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09951434135437012,
      "backward_entropy": 0.005699624203973346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015171121340245008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165481984615326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09949071407318115,
      "backward_entropy": 0.005695834755897522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009442224982194602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031655438244342804,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0994673490524292,
      "backward_entropy": 0.005691857801543342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008429657318629324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03165602311491966,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09944466352462769,
      "backward_entropy": 0.007717253433333503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011034064227715135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165656328201294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09942266345024109,
      "backward_entropy": 0.005684487521648407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012375488877296448,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03165711462497711,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0994010329246521,
      "backward_entropy": 0.007713621689213647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001075067324563861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03165770322084427,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09937962293624877,
      "backward_entropy": 0.009962767362594604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00101793825160712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165830299258232,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09935845732688904,
      "backward_entropy": 0.005673457350995805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009226612746715546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03165891021490097,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09933755397796631,
      "backward_entropy": 0.005669759379492866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00085599155863747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031659506261348724,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09931692481040955,
      "backward_entropy": 0.005666109422842662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006615162128582597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166009858250618,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09929667115211487,
      "backward_entropy": 0.005662533144156138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008403557003475726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166066110134125,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09927700161933899,
      "backward_entropy": 0.005659103807475831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006190568674355745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166123479604721,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09925763607025147,
      "backward_entropy": 0.005655652532974879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006678050267510116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166177123785019,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09923872947692872,
      "backward_entropy": 0.0056523602041933275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006970600807107985,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03166230395436287,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09922023415565491,
      "backward_entropy": 0.009945521752039591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006059809820726514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031662847846746445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09920209646224976,
      "backward_entropy": 0.005645862883991665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005947244935669005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031663380563259125,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09918431639671325,
      "backward_entropy": 0.009941387507650588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005342523218132555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031663909554481506,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09916690587997437,
      "backward_entropy": 0.0076896581384870745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041725384653545916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166442736983299,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09914987087249756,
      "backward_entropy": 0.005636487156152725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005283441278152168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03166491165757179,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09913337230682373,
      "backward_entropy": 0.009935377372635735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005588728818111122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03166539967060089,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09911712408065795,
      "backward_entropy": 0.009933456778526306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004092408635187894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166591003537178,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09910109043121337,
      "backward_entropy": 0.005627678914202584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003456340346019715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031666405498981476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09908548593521119,
      "backward_entropy": 0.005624762011898888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027873521321453154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031666871160268784,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09907034635543824,
      "backward_entropy": 0.005622004055314594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003197400947101414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166729211807251,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09905568957328796,
      "backward_entropy": 0.005619477894571092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034959855838678777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03166768327355385,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0990413784980774,
      "backward_entropy": 0.0076763373282220625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033576757414266467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031668078154325485,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09902739524841309,
      "backward_entropy": 0.009922722147570716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023259207955561578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03166847303509712,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09901366233825684,
      "backward_entropy": 0.00992117573817571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022781504958402365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031668830662965775,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09900038838386535,
      "backward_entropy": 0.00991981393761105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022705989249516279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166916221380234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09898749589920045,
      "backward_entropy": 0.005607953088151084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023219874128699303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166947513818741,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09897497892379761,
      "backward_entropy": 0.005605965024895138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018993414414580911,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031669773161411285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09896275997161866,
      "backward_entropy": 0.00560404939783944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018289923900738358,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167004883289337,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09895090460777282,
      "backward_entropy": 0.005602245943413841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015491577505599707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167030215263367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09893937706947327,
      "backward_entropy": 0.005600532723797692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001458981860196218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167051821947098,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09892816543579101,
      "backward_entropy": 0.005598969757556915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000185744182090275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0316707119345665,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09891729354858399,
      "backward_entropy": 0.007666723595725166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013299087004270405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167090564966202,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09890666007995605,
      "backward_entropy": 0.005596105423238542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016329075151588768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167107701301575,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09889631271362305,
      "backward_entropy": 0.00559477342499627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012526212958618999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031671252101659775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09888620376586914,
      "backward_entropy": 0.005593452188703749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015604986401740462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167140856385231,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0988763689994812,
      "backward_entropy": 0.005592195524109734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.037202107720077e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167157247662544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09886671304702759,
      "backward_entropy": 0.005590943826569451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001227639295393601,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031671710312366486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09885739088058472,
      "backward_entropy": 0.005589801404211257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.353335917694494e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167184442281723,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09884828925132752,
      "backward_entropy": 0.009910631510946486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.938984683481976e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167196735739708,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09883947372436523,
      "backward_entropy": 0.005587639080153571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.014145325636491e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031672071665525436,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09883090257644653,
      "backward_entropy": 0.0099103268649843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878924563759938e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031672172248363495,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09882259368896484,
      "backward_entropy": 0.00991025235917833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.319131352938712e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031672269105911255,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09881448745727539,
      "backward_entropy": 0.009910157985157438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.428396540693939e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167234733700752,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0988066852092743,
      "backward_entropy": 0.009910157985157438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.013458525761962e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167243301868439,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09879908561706544,
      "backward_entropy": 0.009910100036197238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907826511655003e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167251497507095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09879171252250671,
      "backward_entropy": 0.005582356618510352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.638148235855624e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031672608107328415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09878451824188232,
      "backward_entropy": 0.007661852571699355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.452812133124098e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031672701239585876,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09877746105194092,
      "backward_entropy": 0.007661595940589905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.443072586786002e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167280554771423,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09877056479454041,
      "backward_entropy": 0.007661299573050605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.706159597844817e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167290613055229,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09876389503479004,
      "backward_entropy": 0.009909300340546502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.242734525585547e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031672995537519455,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09875745177268982,
      "backward_entropy": 0.009909137255615659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3377822041511536e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031673088669776917,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0987511157989502,
      "backward_entropy": 0.009908954302469889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1987546612508595e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031673185527324677,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09874495267868041,
      "backward_entropy": 0.009908740719159445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.171283944742754e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167328983545303,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09873896837234497,
      "backward_entropy": 0.007659923699167039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.235024607623927e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167338669300079,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09873312711715698,
      "backward_entropy": 0.0076596347822083365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.015985905425623e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167348355054855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09872745871543884,
      "backward_entropy": 0.0055744217501746286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.840942372335121e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031673580408096313,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0987219512462616,
      "backward_entropy": 0.005573704010910458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9078513509593904e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031673673540353775,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09871658086776733,
      "backward_entropy": 0.00557299330830574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.783727722999174e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031673770397901535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09871134161949158,
      "backward_entropy": 0.005572302473915948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.553016929596197e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316738598048687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09870628714561462,
      "backward_entropy": 0.005571632335583369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2347001251764596e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167394548654556,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09870142936706543,
      "backward_entropy": 0.0076579492953088545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.720933480304666e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031674034893512726,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09869667291641235,
      "backward_entropy": 0.009906644622484842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6531877665547654e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167412057518959,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09869205951690674,
      "backward_entropy": 0.007657424443297916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5761319193406962e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031674209982156754,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09868761301040649,
      "backward_entropy": 0.005569122731685638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0846218831138685e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167429938912392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09868324995040893,
      "backward_entropy": 0.005568507230944104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.958820030267816e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167438134551048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09867901802062988,
      "backward_entropy": 0.007656590806113349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6423546185251325e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167446330189705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09867494702339172,
      "backward_entropy": 0.005567360669374466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4996506251918618e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167453780770302,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09867103099822998,
      "backward_entropy": 0.009905185964372423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1081941667944193e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167460486292839,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0986672282218933,
      "backward_entropy": 0.00556632462475035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6529244021512568e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167467936873436,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09866352677345276,
      "backward_entropy": 0.00990478860007392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2462755876185838e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167475014925003,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09865992069244385,
      "backward_entropy": 0.005565291477574242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5675848771934398e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031674813479185104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09865645170211793,
      "backward_entropy": 0.00765518844127655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4497026313620154e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167488053441048,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0986530601978302,
      "backward_entropy": 0.005564342770311568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0729067071224563e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167494758963585,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09864976406097412,
      "backward_entropy": 0.007654733128017849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.447857908322476e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167501091957092,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09864656329154968,
      "backward_entropy": 0.005563437524769042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0689059308788273e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316750667989254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09864349365234375,
      "backward_entropy": 0.005563026914993922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.810465260467026e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167512267827988,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09864053130149841,
      "backward_entropy": 0.007654175990157657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0635299986461177e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031675174832344055,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09863766431808471,
      "backward_entropy": 0.005562249571084976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.80037953518331e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167523071169853,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0986348807811737,
      "backward_entropy": 0.0055618758002916975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.580495210073423e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167528286576271,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09863218665122986,
      "backward_entropy": 0.00990313622686598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4966559370514e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167533129453659,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09862961769104003,
      "backward_entropy": 0.00556115640534295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.93847869115416e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167537972331047,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09862710237503051,
      "backward_entropy": 0.0076533713274531895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.529160939157009e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167542815208435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09862467050552368,
      "backward_entropy": 0.005560473021533754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.805351065646391e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167547658085823,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09862229824066163,
      "backward_entropy": 0.009902565843529172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.48775824427139e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167552128434181,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09862000346183777,
      "backward_entropy": 0.00990243007739385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1418815019133035e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031675565987825394,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09861780405044555,
      "backward_entropy": 0.005559504859977298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.682563030655729e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167560696601868,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09861565828323364,
      "backward_entropy": 0.005559207250674565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.242624749575043e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167564794421196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09861359596252442,
      "backward_entropy": 0.005558924542533027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.434712991496781e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167569264769554,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09861158132553101,
      "backward_entropy": 0.009901896946960025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.384502517496003e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031675733625888824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09860963821411133,
      "backward_entropy": 0.007652217315302955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.884126272168942e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167577460408211,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09860775470733643,
      "backward_entropy": 0.007652069131533305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9053757063811645e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167581558227539,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09860592484474182,
      "backward_entropy": 0.00990146729681227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.793438625303679e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031675856560468674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09860415458679199,
      "backward_entropy": 0.005557522177696228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.419532731641084e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167589381337166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09860243797302246,
      "backward_entropy": 0.007651671767234802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7594443256239174e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167593106627464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09860077500343323,
      "backward_entropy": 0.00765155338578754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5567726374429185e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167596831917763,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09859915375709534,
      "backward_entropy": 0.007651426725917392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.228122411906952e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167601302266121,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09859753847122192,
      "backward_entropy": 0.00990079508887397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.527485548853292e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676050275564194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09859598875045776,
      "backward_entropy": 0.005556282897790273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.127631205439684e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167608752846718,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09859449863433838,
      "backward_entropy": 0.007650998731454213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.353655645492836e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167612478137016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09859305024147033,
      "backward_entropy": 0.005555811441606945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7222099586433615e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167616203427315,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09859166145324708,
      "backward_entropy": 0.005555597444375356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0973029677406885e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031676195561885834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09859031438827515,
      "backward_entropy": 0.007650621235370636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8095840914611472e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167622908949852,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09858900904655457,
      "backward_entropy": 0.005555172761281331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6315901802954613e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676262617111206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09858774542808532,
      "backward_entropy": 0.005554972423447503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5704644056313555e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676292419433594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09858652353286743,
      "backward_entropy": 0.00555477456914054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3609213738163817e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167632222175598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985853374004364,
      "backward_entropy": 0.00555458664894104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3065866824035766e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167635202407837,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09858419895172119,
      "backward_entropy": 0.0076500723759333296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4470111864284263e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167637810111046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09858309030532837,
      "backward_entropy": 0.005554242680470149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.107630489779694e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167640417814255,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09858201146125793,
      "backward_entropy": 0.009899403485986922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1093808325313148e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167643025517464,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09858098030090331,
      "backward_entropy": 0.005553900367683834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2154515616202843e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676456332206726,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0985799789428711,
      "backward_entropy": 0.009899230466948615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.918822575447848e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676482409238815,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09857898950576782,
      "backward_entropy": 0.009899137748612298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37232869091531e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676504760980606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857805371284485,
      "backward_entropy": 0.005553448779715432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.895228802430211e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316765271127224,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857714176177979,
      "backward_entropy": 0.00555331301358011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.638184342795284e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167654946446419,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985762596130371,
      "backward_entropy": 0.0055531660715738935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.938088634138694e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167657181620598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857540130615235,
      "backward_entropy": 0.005553034444650014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.446280735872278e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167659044265747,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857457876205444,
      "backward_entropy": 0.0055529090265433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.993974466240616e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167660906910896,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857378005981446,
      "backward_entropy": 0.0055527885754903155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.835338470205897e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676627695560455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857300519943238,
      "backward_entropy": 0.0055526668826739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.604760531241482e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167664632201195,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857224822044372,
      "backward_entropy": 0.005552549329068925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.700708811673394e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167666494846344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857152700424195,
      "backward_entropy": 0.00555244709054629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.451900963431399e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167668357491493,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09857081174850464,
      "backward_entropy": 0.005552334090073903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.375106072984636e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676698476076126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985701322555542,
      "backward_entropy": 0.0055522239870495265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.80676362712984e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167671337723732,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856947660446166,
      "backward_entropy": 0.005552120506763458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.283279793071415e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676728278398514,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09856880903244018,
      "backward_entropy": 0.009898301627900865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.745789515756769e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167674317955971,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09856818914413452,
      "backward_entropy": 0.007648699813418918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1323816074291244e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316767580807209,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856758117675782,
      "backward_entropy": 0.005551833659410477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0739474254914967e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676772981882095,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09856700301170349,
      "backward_entropy": 0.009898145993550619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5698648187244544e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167678788304329,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856643676757812,
      "backward_entropy": 0.005551653603712718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5829933747445466e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676799058914185,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856588840484619,
      "backward_entropy": 0.005551562541060978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2023240831003932e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167681023478508,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09856537580490113,
      "backward_entropy": 0.00989801436662674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.117474764418148e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676821410655975,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856486320495605,
      "backward_entropy": 0.005551415185133616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.161657306487541e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167683258652687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856438636779785,
      "backward_entropy": 0.005551346474223667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.932629913881101e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676843762397766,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09856390357017517,
      "backward_entropy": 0.009897909230656095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9784646099196834e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167685493826866,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0985634446144104,
      "backward_entropy": 0.00989787197775311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7172446575841604e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167686611413956,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856300354003907,
      "backward_entropy": 0.005551134960518943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5901910899174254e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167687729001045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09856257438659669,
      "backward_entropy": 0.009897804922527738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3923663289006072e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167688846588135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09856215119361877,
      "backward_entropy": 0.0076481882068845965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1855911452585133e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167689964175224,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09856175184249878,
      "backward_entropy": 0.009897742006513808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1648000963759841e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167690709233284,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856137037277221,
      "backward_entropy": 0.005550880812936359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.28526210119162e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167691454291344,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856098890304565,
      "backward_entropy": 0.005550822450055016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.154650288361154e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676921993494034,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.098560631275177,
      "backward_entropy": 0.009897648460335202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89325733055557e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167692944407463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856027364730835,
      "backward_entropy": 0.0055507272481918335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.908511179266497e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167693689465523,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855994582176208,
      "backward_entropy": 0.005550673024521934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.46932605263828e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676944345235825,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0985596239566803,
      "backward_entropy": 0.009897584716478983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220255326956249e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167695179581642,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855930209159851,
      "backward_entropy": 0.005550576580895318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.054381884723625e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167695924639702,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855899810791016,
      "backward_entropy": 0.005550543467203776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1161382685904755e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676966696977615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855871200561524,
      "backward_entropy": 0.005550496694114473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3290765578140054e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676970422267914,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855843782424926,
      "backward_entropy": 0.005550454888078902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.808097114368138e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167697414755821,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855817556381226,
      "backward_entropy": 0.009897497793038687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5919804847471823e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167697787284851,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855791926383972,
      "backward_entropy": 0.005550385349326664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.746161863522502e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167698159813881,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855767488479614,
      "backward_entropy": 0.005550360927979152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.176288032591401e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167698532342911,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855743646621704,
      "backward_entropy": 0.007647833062542809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.499645728766154e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031676989048719406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855719804763793,
      "backward_entropy": 0.005550292630990346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9227302295330446e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031676992774009705,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0985569715499878,
      "backward_entropy": 0.009897443155447641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8247649552781695e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316769964993,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855676293373108,
      "backward_entropy": 0.005550238821241591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.590023839843525e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316770002245903,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855654835700989,
      "backward_entropy": 0.005550202396180894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0608052153647805e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0316770039498806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855635166168213,
      "backward_entropy": 0.007647772630055745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5944389747678542e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316770076751709,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855615496635436,
      "backward_entropy": 0.005550165557199054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1802549099447788e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316770114004612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855597019195557,
      "backward_entropy": 0.005550136168797811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.160750689483848e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677015125751495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855579733848571,
      "backward_entropy": 0.005550116300582886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0721749649510457e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677018851041794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855563044548035,
      "backward_entropy": 0.007647745311260223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4712058238330883e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167702257633209,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855546951293945,
      "backward_entropy": 0.0055500662161244285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3821577660166895e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03167702630162239,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855530261993409,
      "backward_entropy": 0.007647714681095547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3490066841370663e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03167703002691269,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855515360832215,
      "backward_entropy": 0.00989738769001431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1646250186458929e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167703375220299,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855500459671021,
      "backward_entropy": 0.005550009095006519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.776169124757871e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855486154556274,
      "backward_entropy": 0.007647698124249776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722366828806116e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855474233627319,
      "backward_entropy": 0.009897380239433713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.111282395224407e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985546052455902,
      "backward_entropy": 0.0055499594244692065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.091376457741717e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855448603630065,
      "backward_entropy": 0.00989736451043023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.975245353009086e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855437278747559,
      "backward_entropy": 0.00554993748664856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.170264216758369e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855425357818604,
      "backward_entropy": 0.007647684878773159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.970782979147771e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855414628982544,
      "backward_entropy": 0.005549919688039356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.558213445056026e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855403900146484,
      "backward_entropy": 0.007647678256034851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.700943634361465e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985539436340332,
      "backward_entropy": 0.005549889885716968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.967485895373102e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855384826660156,
      "backward_entropy": 0.00554988326297866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.736701614798221e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855375289916993,
      "backward_entropy": 0.007647663354873657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0802703438203025e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855368137359619,
      "backward_entropy": 0.005549870431423187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5736781594787317e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855358600616455,
      "backward_entropy": 0.005549865464369456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1921914001031837e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855351448059083,
      "backward_entropy": 0.007647663354873657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.071782828101277e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855342507362366,
      "backward_entropy": 0.005549839387337367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6179876044807315e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855336546897889,
      "backward_entropy": 0.005549835662047069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0689938651230477e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855328798294068,
      "backward_entropy": 0.009897385206487443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3088659872883e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0985532283782959,
      "backward_entropy": 0.00989738769001431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.879492117495829e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855316281318664,
      "backward_entropy": 0.00989738769001431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8507080312701873e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855310320854187,
      "backward_entropy": 0.007647658387819926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5427374933096871e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855304956436158,
      "backward_entropy": 0.005549811240699556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3378880225900502e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985529899597168,
      "backward_entropy": 0.005549808343251546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2877166000180296e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855294227600098,
      "backward_entropy": 0.005549803376197815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2794245662917092e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855288863182068,
      "backward_entropy": 0.005549797995222939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.068009680693649e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855284094810486,
      "backward_entropy": 0.005549797995222939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.576055504112446e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855279922485352,
      "backward_entropy": 0.007647658387819926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.271943213207123e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0985527515411377,
      "backward_entropy": 0.005549776471323437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.838050126134476e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855272173881531,
      "backward_entropy": 0.00989739348491033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.020180075618555e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855268001556397,
      "backward_entropy": 0.005549773159954283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.644338330057508e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855263829231262,
      "backward_entropy": 0.005549769434663985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.613145503957639e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855259656906128,
      "backward_entropy": 0.005549767778979408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.966622668689524e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855257272720337,
      "backward_entropy": 0.009897396796279483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.006626224712818e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855253100395203,
      "backward_entropy": 0.007647656732135349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3512216052477015e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855250120162964,
      "backward_entropy": 0.005549760742319955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9336356394414906e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855247735977173,
      "backward_entropy": 0.009897400107648637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.736033704626607e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855245351791382,
      "backward_entropy": 0.005549757430950801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.212861088286445e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855241775512695,
      "backward_entropy": 0.009897400107648637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0020430585864233e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09855239391326905,
      "backward_entropy": 0.009897400107648637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1878321376789245e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855237007141113,
      "backward_entropy": 0.007647654248608483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.786446546248044e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855234622955322,
      "backward_entropy": 0.007647656732135349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4499513529008254e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855232238769532,
      "backward_entropy": 0.005549747082922194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1441337594296783e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0985522985458374,
      "backward_entropy": 0.007647656732135349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.538467131467769e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09855228066444396,
      "backward_entropy": 0.0055497437715530396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3648104868480004e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031677037477493286,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09855226278305054,
      "backward_entropy": 0.007647656732135349,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.4462638607604107e-07,
    "avg_log_Z": 0.03167692728340626,
    "success_rate": 1.0,
    "avg_reward": 46.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.24,
      "1": 0.18,
      "2": 0.58
    },
    "avg_forward_entropy": 0.0985591408610344,
    "avg_backward_entropy": 0.006971507680912811,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}