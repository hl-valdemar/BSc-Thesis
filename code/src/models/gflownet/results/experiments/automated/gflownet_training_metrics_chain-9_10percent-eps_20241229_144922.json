{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701475752724542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.0769914918475681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.584858894348145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971839427947998,
      "backward_entropy": 0.07701630062527126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.45834732055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972088575363159,
      "backward_entropy": 0.07701634698443943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.332240104675293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019997591152787209,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972243547439575,
      "backward_entropy": 0.07701634698443943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.087627410888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00029991159681230783,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972332954406738,
      "backward_entropy": 0.07701629400253296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.720046043395996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0003997757739853114,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972422361373901,
      "backward_entropy": 0.07701183689965142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.965084075927734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004994978080503643,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972511768341064,
      "backward_entropy": 0.07701081699795193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.716678619384766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005992210353724658,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972663164138793,
      "backward_entropy": 0.07697123951382107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.321015357971191,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006988553795963526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972805023193359,
      "backward_entropy": 0.07700843281216091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.082039833068848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007986009586602449,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972909927368164,
      "backward_entropy": 0.07700704203711616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.684808731079102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008983948500826955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973061323165893,
      "backward_entropy": 0.0769586894247267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.318534851074219,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009983986383304,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973224639892579,
      "backward_entropy": 0.07700390285915798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.589655876159668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010984544642269611,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973397493362427,
      "backward_entropy": 0.07694931825002034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82857894897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011983125004917383,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973581075668334,
      "backward_entropy": 0.07701179716322157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.826651573181152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012980833416804671,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973758697509765,
      "backward_entropy": 0.07701077726152208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.67103099822998,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013977837515994906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973932743072509,
      "backward_entropy": 0.0769960085550944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.78974437713623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014977245591580868,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974109172821045,
      "backward_entropy": 0.07700843943489923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66532039642334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015979139134287834,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974292755126953,
      "backward_entropy": 0.07700709501902263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.420208930969238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016982576344162226,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974472761154175,
      "backward_entropy": 0.07700563801659478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.213888168334961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017986241728067398,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974631309509278,
      "backward_entropy": 0.07691012488471137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.853320598602295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018985527567565441,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974761247634887,
      "backward_entropy": 0.07700230015648736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.174095153808594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001998001942411065,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974903106689453,
      "backward_entropy": 0.07689650853474934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.05042839050293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020975724328309298,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975061655044556,
      "backward_entropy": 0.07688933610916138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.808175086975098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002197157358750701,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097520112991333,
      "backward_entropy": 0.07699627346462673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.405632972717285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002296639606356621,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975301265716553,
      "backward_entropy": 0.07687379916508992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.924223899841309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023962906561791897,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097538948059082,
      "backward_entropy": 0.07686542140112983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.879057884216309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002495853928849101,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975425243377686,
      "backward_entropy": 0.0769888162612915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.039505004882812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002595741767436266,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975435972213746,
      "backward_entropy": 0.0769859751065572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.395269393920898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026955667417496443,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975418090820313,
      "backward_entropy": 0.07698298162884182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.273259162902832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027954818215221167,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975371599197388,
      "backward_entropy": 0.07694662279552883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31744384765625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028954497538506985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975313186645508,
      "backward_entropy": 0.07681547933154637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720216274261475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029950786847621202,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975258350372315,
      "backward_entropy": 0.07680402199427287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.503759384155273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003094130428507924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975191593170167,
      "backward_entropy": 0.07693048318227132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787243843078613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031934762373566628,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975136756896972,
      "backward_entropy": 0.07677988211313884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.666858673095703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032927407883107662,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10975067615509033,
      "backward_entropy": 0.07696086168289185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.783780097961426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0033919087145477533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975003242492676,
      "backward_entropy": 0.07675386137432522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.08399486541748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034910570830106735,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974950790405273,
      "backward_entropy": 0.076951887872484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.60749340057373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035907018464058638,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974873304367065,
      "backward_entropy": 0.07672546969519721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.48544692993164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036906024906784296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097478985786438,
      "backward_entropy": 0.07671013143327501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24803638458252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003790662856772542,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974693298339844,
      "backward_entropy": 0.07693669531080458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.243328094482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00389080960303545,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974617004394531,
      "backward_entropy": 0.07693115870157878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.765753746032715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003990992903709412,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097453236579895,
      "backward_entropy": 0.07666018274095324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.472149848937988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004090944305062294,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10974414348602295,
      "backward_entropy": 0.07685771253373888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.290494918823242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004191047511994839,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10974287986755371,
      "backward_entropy": 0.07662353912989299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.289450645446777,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004290735349059105,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097414493560791,
      "backward_entropy": 0.07690644264221191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75959587097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004390989430248737,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973999500274659,
      "backward_entropy": 0.07658460405137804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.3395357131958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004491074476391077,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973870754241943,
      "backward_entropy": 0.07689265410105388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.691173553466797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0045912256464362144,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973725318908692,
      "backward_entropy": 0.07680924733479817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.514800071716309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004691635258495808,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973582267761231,
      "backward_entropy": 0.07687783241271973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.912382125854492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0047917147167027,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097344160079956,
      "backward_entropy": 0.07687001758151585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.509442329406738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004892114084213972,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097327470779419,
      "backward_entropy": 0.07686189810434978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.13996696472168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004992179572582245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10973107814788818,
      "backward_entropy": 0.076458474000295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.785334587097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005092700477689505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972932577133179,
      "backward_entropy": 0.07643528779347737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.387859344482422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005193458404392004,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972746610641479,
      "backward_entropy": 0.07641132672627766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.427379608154297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005293803755193949,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10972580909729004,
      "backward_entropy": 0.07638698154025608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.310779571533203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005394238978624344,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972406864166259,
      "backward_entropy": 0.07681617471906874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72237491607666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005494724493473768,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972238779067993,
      "backward_entropy": 0.07680620087517633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02297592163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005594946444034576,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10972062349319459,
      "backward_entropy": 0.07679589589436848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.908674240112305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005694594234228134,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10971884727478028,
      "backward_entropy": 0.07628020313051012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.676952838897705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005793703719973564,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971721410751342,
      "backward_entropy": 0.07665204339557224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.473064422607422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005892234388738871,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971583127975464,
      "backward_entropy": 0.07676314645343357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.660555839538574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005990580189973116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097142219543457,
      "backward_entropy": 0.07619371679094103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.348217964172363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0060898056253790855,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971214771270751,
      "backward_entropy": 0.07660391595628527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.698307991027832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006188693456351757,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970985889434814,
      "backward_entropy": 0.07672696643405491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23098373413086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006287497468292713,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970757007598878,
      "backward_entropy": 0.07656921280754937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.918129920959473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006385982036590576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970522165298462,
      "backward_entropy": 0.07606391112009685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149947166442871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006484528537839651,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970278978347778,
      "backward_entropy": 0.07668693198098077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.82541275024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006583275273442268,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10970041751861573,
      "backward_entropy": 0.07599323987960815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787006378173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006682497914880514,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969780683517456,
      "backward_entropy": 0.07665863964292738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24435043334961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006781625095754862,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969505310058594,
      "backward_entropy": 0.07591762807634142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.013879776000977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006880912929773331,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10969222784042358,
      "backward_entropy": 0.07587810357411702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.588530540466309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006980242673307657,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968940258026123,
      "backward_entropy": 0.07642027404573229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89777946472168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007079926785081625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968669652938842,
      "backward_entropy": 0.0757958557870653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.77503490447998,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007179578300565481,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968413352966308,
      "backward_entropy": 0.07636904716491699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.441744804382324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007279126439243555,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968165397644043,
      "backward_entropy": 0.07570964097976685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.814498901367188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007378880865871906,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10967890024185181,
      "backward_entropy": 0.07631374730004205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.678691864013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0074795507825911045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096760392189026,
      "backward_entropy": 0.07652485370635986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.969688892364502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007580488920211792,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967333316802978,
      "backward_entropy": 0.07650576697455512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.65253734588623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007680792361497879,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967093706130981,
      "backward_entropy": 0.07648622989654541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.207315444946289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007781352382153273,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966837406158447,
      "backward_entropy": 0.07618914710150824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.182112693786621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007882407866418362,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966556072235108,
      "backward_entropy": 0.07615564266840617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.74974536895752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007983381859958172,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10966258049011231,
      "backward_entropy": 0.07536763615078396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.169063568115234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008084599860012531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965954065322876,
      "backward_entropy": 0.07531339592403835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.059905052185059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008185709826648235,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10965638160705567,
      "backward_entropy": 0.07604955302344428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.503952980041504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008286694064736366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965325832366943,
      "backward_entropy": 0.07520086897744073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827689170837402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008388279937207699,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964986085891723,
      "backward_entropy": 0.0763323704401652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.477413177490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00848957896232605,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10964663028717041,
      "backward_entropy": 0.07630803849962023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35231876373291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008590917102992535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964322090148926,
      "backward_entropy": 0.07502032650841607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.925657272338867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008692211471498013,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963954925537109,
      "backward_entropy": 0.0758504072825114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.787919044494629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00879331212490797,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963616371154786,
      "backward_entropy": 0.07489293151431614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.445307731628418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008894634433090687,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10963252782821656,
      "backward_entropy": 0.07620399528079563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.887051582336426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008995975367724895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962873697280884,
      "backward_entropy": 0.074759046236674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.998966693878174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009097575210034847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10962479114532471,
      "backward_entropy": 0.07567368613349067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876372814178467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009198430925607681,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962108373641968,
      "backward_entropy": 0.0761191447575887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.196557998657227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009298543445765972,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961751937866211,
      "backward_entropy": 0.07558039824167888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.428878784179688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009398690424859524,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10961387157440186,
      "backward_entropy": 0.07553223768870036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.975268840789795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009498490951955318,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961045026779175,
      "backward_entropy": 0.0760309894879659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.725826263427734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009597728960216045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960723161697387,
      "backward_entropy": 0.07599850495656331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.633482456207275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009696838445961475,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1096038579940796,
      "backward_entropy": 0.07596507337358263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840169906616211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009795278310775757,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10960075855255128,
      "backward_entropy": 0.0759308934211731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.920355796813965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009893218986690044,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10959773063659668,
      "backward_entropy": 0.07409512996673584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.445869445800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009991840459406376,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10959453582763672,
      "backward_entropy": 0.07586110962761773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841479778289795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010090765543282032,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095908522605896,
      "backward_entropy": 0.07516581482357448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.563602447509766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010189183987677097,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958764553070069,
      "backward_entropy": 0.07510651482476129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.43745231628418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010288049466907978,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095842957496643,
      "backward_entropy": 0.0750452611181471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.543634414672852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01038665696978569,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10958064794540405,
      "backward_entropy": 0.07498284180959065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5111985206604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010485685430467129,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095768928527832,
      "backward_entropy": 0.07491844230228001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.247198104858398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010584061034023762,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957401990890503,
      "backward_entropy": 0.07485257254706489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002779006958008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010682228021323681,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957154035568237,
      "backward_entropy": 0.07339804702334934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.97082805633545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010780633427202702,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956934690475464,
      "backward_entropy": 0.07471532291836208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.523000717163086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010879196226596832,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956711769104004,
      "backward_entropy": 0.07464381059010823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.158548355102539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010977644473314285,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956484079360962,
      "backward_entropy": 0.07457069555918376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82613754272461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011076338589191437,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10956236124038696,
      "backward_entropy": 0.07541500859790379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.265748023986816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011175072751939297,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955977439880371,
      "backward_entropy": 0.075368775261773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.675249099731445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011273511685431004,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955700874328614,
      "backward_entropy": 0.07532140281465319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.07451343536377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011372511275112629,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955414772033692,
      "backward_entropy": 0.07527236806021796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.734258651733398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011472202837467194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10955090522766113,
      "backward_entropy": 0.0725897020763821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.999777793884277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01157126110047102,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10954809188842773,
      "backward_entropy": 0.07409432199266222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.216388702392578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011670450679957867,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095453143119812,
      "backward_entropy": 0.0751130117310418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.228187561035156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011769275180995464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10954235792160034,
      "backward_entropy": 0.07391919692357381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.421223640441895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011867821216583252,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1095395565032959,
      "backward_entropy": 0.0749960806634691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.522612571716309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011966213583946228,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10953664779663086,
      "backward_entropy": 0.07202127244737414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.623340606689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012064540758728981,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953361988067627,
      "backward_entropy": 0.0748659438557095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3296356201171875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01216287910938263,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953073501586914,
      "backward_entropy": 0.07479762368732029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.409601211547852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01226047147065401,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952799320220948,
      "backward_entropy": 0.07344706853230794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.079204559326172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012357416562736034,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952513217926026,
      "backward_entropy": 0.07465606265597874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.260708808898926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012454730458557606,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10952177047729492,
      "backward_entropy": 0.07139831119113499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9132399559021,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012551972642540932,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951863527297974,
      "backward_entropy": 0.07314064105351765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.901145935058594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012648919597268105,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095154881477356,
      "backward_entropy": 0.07303388913472493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.066787242889404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012745598331093788,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1095123052597046,
      "backward_entropy": 0.07292422321107653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.366517543792725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012841581366956234,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950950384140015,
      "backward_entropy": 0.07426696353488499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4660491943359375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012937115505337715,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10950692892074584,
      "backward_entropy": 0.07269851366678874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.454083442687988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013032319955527782,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10950464010238647,
      "backward_entropy": 0.07258212566375732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.835867881774902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013127225451171398,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10950264930725098,
      "backward_entropy": 0.07246322102016872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.662879943847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013222743757069111,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950126647949218,
      "backward_entropy": 0.0739192697736952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.008612632751465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013318623416125774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949974060058594,
      "backward_entropy": 0.07015171315934923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.434885025024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013414418324828148,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949796438217163,
      "backward_entropy": 0.06999997960196601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.169867992401123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013510435819625854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949622392654419,
      "backward_entropy": 0.06984403398301867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.375875949859619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013605893589556217,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10949451923370361,
      "backward_entropy": 0.07181913322872585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.995423793792725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013700997456908226,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1094930648803711,
      "backward_entropy": 0.0734309090508355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.129473686218262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013796184211969376,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949199199676514,
      "backward_entropy": 0.06936256753073798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.355102062225342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01389143243432045,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10949051380157471,
      "backward_entropy": 0.07321764363182916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.617237091064453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013986385427415371,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10948972702026367,
      "backward_entropy": 0.07310724258422852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.993349075317383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014081739820539951,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948830842971802,
      "backward_entropy": 0.06884804036882189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.796082496643066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01417709793895483,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948657989501953,
      "backward_entropy": 0.06866774294111463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.764306545257568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014272951520979404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948450565338134,
      "backward_entropy": 0.06848194864061144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.274473667144775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014368642121553421,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948238372802735,
      "backward_entropy": 0.0682928827073839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.049625396728516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014463958330452442,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10948100090026855,
      "backward_entropy": 0.07043768299950494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.517396926879883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014559379778802395,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947995185852051,
      "backward_entropy": 0.07026549180348714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372718811035156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014654562808573246,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947898626327515,
      "backward_entropy": 0.07009094953536987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.246450901031494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014749996364116669,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10947730541229247,
      "backward_entropy": 0.07211988502078587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73175048828125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014844970777630806,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947517156600953,
      "backward_entropy": 0.06973499721950954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.116170883178711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01494044903665781,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10947248935699463,
      "backward_entropy": 0.06705235110388862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.924615859985352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015036020427942276,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10946985483169555,
      "backward_entropy": 0.06682436996036106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.620797634124756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015131618827581406,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094675064086914,
      "backward_entropy": 0.06659260723325941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52917766571045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015226459130644798,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10946602821350097,
      "backward_entropy": 0.0714018742243449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.544955253601074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015321702696383,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946369171142578,
      "backward_entropy": 0.06877695189581977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.414528846740723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015417398884892464,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10946140289306641,
      "backward_entropy": 0.07109245989057753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890179634094238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015513413585722446,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945909023284912,
      "backward_entropy": 0.06835920943154229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4721174240112305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015609378926455975,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945670604705811,
      "backward_entropy": 0.06814347373114692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.838437080383301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015705041587352753,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945432186126709,
      "backward_entropy": 0.0679243869251675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.335981845855713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01580066792666912,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945186614990235,
      "backward_entropy": 0.0676996906598409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.274636745452881,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015895282849669456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944935083389282,
      "backward_entropy": 0.06747344467375013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.858543395996094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015989573672413826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10944633483886719,
      "backward_entropy": 0.06427645683288574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3235087394714355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016084009781479836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944340229034424,
      "backward_entropy": 0.06700993908776177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.498083591461182,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0161781907081604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10944010019302368,
      "backward_entropy": 0.06677213642332289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.979598045349121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016272278502583504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1094366431236267,
      "backward_entropy": 0.06340506341722277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.640586853027344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016367200762033463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10943235158920288,
      "backward_entropy": 0.06309958961274889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6892619132995605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016462072730064392,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942816734313965,
      "backward_entropy": 0.06914186477661133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1082563400268555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016556909307837486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10942370891571045,
      "backward_entropy": 0.06576761934492323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.992712020874023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016650794073939323,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942062139511108,
      "backward_entropy": 0.06873952680163914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.983643054962158,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016744349151849747,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941786766052246,
      "backward_entropy": 0.061840679910447865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.678773403167725,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016837647184729576,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10941586494445801,
      "backward_entropy": 0.0683238837454054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621026992797852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016930527985095978,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10941472053527831,
      "backward_entropy": 0.06811132695939806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1431565284729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01702418364584446,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941236019134522,
      "backward_entropy": 0.06086217694812351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.651596546173096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017117641866207123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10941009521484375,
      "backward_entropy": 0.06052349011103312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.422253608703613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017211247235536575,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10940755605697632,
      "backward_entropy": 0.06382104423311022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.159658908843994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01730482093989849,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940457582473755,
      "backward_entropy": 0.06721394591861302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.291616916656494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017397623509168625,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10940262079238891,
      "backward_entropy": 0.05947574641969469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.875547885894775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017490467056632042,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10940096378326417,
      "backward_entropy": 0.06290307309892443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.951911926269531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01758303865790367,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10939922332763671,
      "backward_entropy": 0.05875875552495321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.516162395477295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01767546869814396,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939791202545165,
      "backward_entropy": 0.062266561720106334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2136430740356445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01776811294257641,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939630270004272,
      "backward_entropy": 0.0619405640496148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1566619873046875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017860760912299156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10939457416534423,
      "backward_entropy": 0.05764424138598972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4481520652771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01795334182679653,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10939228534698486,
      "backward_entropy": 0.06548591454823811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.485632419586182,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018045460805296898,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939064025878906,
      "backward_entropy": 0.060934364795684814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.048403739929199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018137168139219284,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938917398452759,
      "backward_entropy": 0.06059122085571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.974987506866455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018228890374302864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10938756465911866,
      "backward_entropy": 0.060241242249806724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3684892654418945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01831989176571369,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093861699104309,
      "backward_entropy": 0.05569828218883938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.403013229370117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018410533666610718,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938493013381959,
      "backward_entropy": 0.0641127626101176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7870192527771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018500855192542076,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10938345193862915,
      "backward_entropy": 0.06382291184531318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.077663898468018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018591172993183136,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938173532485962,
      "backward_entropy": 0.05449136098225912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.450700283050537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01868169941008091,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937968492507935,
      "backward_entropy": 0.0584354731771681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.577587604522705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01877198927104473,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937769412994384,
      "backward_entropy": 0.05365775691138373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.032945156097412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018862180411815643,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10937588214874268,
      "backward_entropy": 0.06261656019422743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.231433391571045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018951883539557457,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1093741774559021,
      "backward_entropy": 0.052809953689575195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.789486885070801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019041290506720543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10937235355377198,
      "backward_entropy": 0.05238181021478441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.700219631195068,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019130146130919456,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937095880508423,
      "backward_entropy": 0.056505719820658364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.702340602874756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019219134002923965,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936907529830933,
      "backward_entropy": 0.06134192148844401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5358076095581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019307563081383705,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936763286590576,
      "backward_entropy": 0.061012989944881864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.619063854217529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019396129995584488,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936652421951294,
      "backward_entropy": 0.06068019072214762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.870733261108398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019484801217913628,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093644380569458,
      "backward_entropy": 0.06034191449483236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.671656608581543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01957305148243904,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936217308044434,
      "backward_entropy": 0.0599994593196445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.852299213409424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01966080069541931,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936005115509033,
      "backward_entropy": 0.059653282165527344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.248769760131836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019748233258724213,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935781002044678,
      "backward_entropy": 0.0536351568169064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.302201271057129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019835632294416428,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10935454368591309,
      "backward_entropy": 0.05321319897969564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.885199069976807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019922368228435516,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10935174226760865,
      "backward_entropy": 0.05857929256227282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.585638046264648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020008224993944168,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934997797012329,
      "backward_entropy": 0.05236697196960449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.084202289581299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020093848928809166,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093489646911621,
      "backward_entropy": 0.05784555276234945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.482173442840576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020178833976387978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934815406799317,
      "backward_entropy": 0.04655453231599596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.36338472366333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020263612270355225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934799909591675,
      "backward_entropy": 0.05107430617014567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.513729572296143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02034883387386799,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934706926345825,
      "backward_entropy": 0.050631668832567006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.309206962585449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020433811470866203,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934598445892334,
      "backward_entropy": 0.04516389634874132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.26621675491333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02051916904747486,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10934383869171142,
      "backward_entropy": 0.04973469840155707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9030256271362305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020604142919182777,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934242010116577,
      "backward_entropy": 0.04421145386166043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.084503650665283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02068919874727726,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10934009552001953,
      "backward_entropy": 0.04372999734348721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.052056789398193,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020773764699697495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933843851089478,
      "backward_entropy": 0.043250474664900035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.58020544052124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02085859887301922,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933573246002197,
      "backward_entropy": 0.047894169886906944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.714471817016602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02094332128763199,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10933252573013305,
      "backward_entropy": 0.04742610454559326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.387291431427002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021027281880378723,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932984352111816,
      "backward_entropy": 0.04179036617279053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0582356452941895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021111110225319862,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932700634002686,
      "backward_entropy": 0.04130337304539151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.588912487030029,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02119462937116623,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10932517051696777,
      "backward_entropy": 0.052718791696760386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.681504726409912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02127819135785103,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10932214260101318,
      "backward_entropy": 0.045539511574639216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.007839679718018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02136113867163658,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10931977033615112,
      "backward_entropy": 0.04506344927681817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.878438949584961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021443765610456467,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10931707620620727,
      "backward_entropy": 0.03935291369756063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.821940898895264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0215260311961174,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1093144416809082,
      "backward_entropy": 0.05103849040137397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.877243995666504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02160790003836155,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093113899230957,
      "backward_entropy": 0.04363160663180881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.696656703948975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021689487621188164,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10930809974670411,
      "backward_entropy": 0.0501840975549486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.567781448364258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02177065797150135,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10930445194244384,
      "backward_entropy": 0.04267521036995782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.803841590881348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021851377561688423,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10930085182189941,
      "backward_entropy": 0.03692410720719232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.441318511962891,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021931886672973633,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10929667949676514,
      "backward_entropy": 0.04888659715652466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.843168258666992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02201192080974579,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10929259061813354,
      "backward_entropy": 0.035957117875417076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9068427085876465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02209186553955078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10928771495819092,
      "backward_entropy": 0.035472853316201106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.31432580947876,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02217096835374832,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10928400754928588,
      "backward_entropy": 0.04027261998918322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.237031936645508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022249627858400345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10927999019622803,
      "backward_entropy": 0.039793703291151256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.628436326980591,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022327864542603493,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092760682106018,
      "backward_entropy": 0.04669544431898329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.171550273895264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022405177354812622,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10927309989929199,
      "backward_entropy": 0.04625635676913791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.77855110168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022482138127088547,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10926976203918456,
      "backward_entropy": 0.04581608374913534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9778966903686523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02255927212536335,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10926408767700195,
      "backward_entropy": 0.03789352046118842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.021938800811768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02263593301177025,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925862789154053,
      "backward_entropy": 0.03741897145907084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4771783351898193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022712208330631256,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10925302505493165,
      "backward_entropy": 0.044477230972713895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.236720561981201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0227876715362072,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10924861431121827,
      "backward_entropy": 0.036471539073520236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5670316219329834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022863099351525307,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10924342870712281,
      "backward_entropy": 0.04358656538857354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.073797225952148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022937875241041183,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10923866033554078,
      "backward_entropy": 0.035524600081973605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.541335344314575,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023012585937976837,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923352241516113,
      "backward_entropy": 0.04269692301750183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8874025344848633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02308662049472332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10922759771347046,
      "backward_entropy": 0.029444492525524564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3139054775238037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023160496726632118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10922130346298217,
      "backward_entropy": 0.028995987441804674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1904191970825195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023233655840158463,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10921549797058105,
      "backward_entropy": 0.02855373091167874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9382383823394775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023306075483560562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10921049118041992,
      "backward_entropy": 0.028118265999688044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9925661087036133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02337752841413021,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10920608043670654,
      "backward_entropy": 0.04047771626048618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.281245231628418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023448200896382332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10920231342315674,
      "backward_entropy": 0.032284541262520686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6494977474212646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02351842261850834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10919771194458008,
      "backward_entropy": 0.03183980120552911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3290297985076904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023587651550769806,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10919443368911744,
      "backward_entropy": 0.0391597416665819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3131988048553467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02365669421851635,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10919036865234374,
      "backward_entropy": 0.026035600238376193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.039276361465454,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02372550219297409,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1091848373413086,
      "backward_entropy": 0.025627583265304565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5514588356018066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023793866857886314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10917901992797852,
      "backward_entropy": 0.02522290249665578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.730806827545166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023861326277256012,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10917425155639648,
      "backward_entropy": 0.03740353054470486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.790590286254883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02392813377082348,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10916938781738281,
      "backward_entropy": 0.029244840145111084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.643998861312866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023994427174329758,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10916411876678467,
      "backward_entropy": 0.02882728311750624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.616245985031128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02406010963022709,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10915877819061279,
      "backward_entropy": 0.023665563927756414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.303363800048828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024125266820192337,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1091537594795227,
      "backward_entropy": 0.028002791934543185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.885138988494873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024189583957195282,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10914969444274902,
      "backward_entropy": 0.022917598485946655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7123663425445557,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024253783747553825,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10914411544799804,
      "backward_entropy": 0.034834222661124334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.647458791732788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024317683652043343,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10913751125335694,
      "backward_entropy": 0.026790130469534133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.144305944442749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024381287395954132,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10913028717041015,
      "backward_entropy": 0.021812780035866633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0918028354644775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024443967267870903,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091234564781189,
      "backward_entropy": 0.03358138269848294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2657618522644043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024505754932761192,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10911699533462524,
      "backward_entropy": 0.03317082590527005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1745102405548096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024566972628235817,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10911016464233399,
      "backward_entropy": 0.032763239410188466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.028461217880249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02462763525545597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10910369157791137,
      "backward_entropy": 0.020417077673806086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3275766372680664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024687575176358223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909750461578369,
      "backward_entropy": 0.02008224858178033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0171053409576416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024747293442487717,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1090906023979187,
      "backward_entropy": 0.0315669145849016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1773316860198975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024806378409266472,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10908365249633789,
      "backward_entropy": 0.03117583195368449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6517341136932373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02486508898437023,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10907566547393799,
      "backward_entropy": 0.030787209669748943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7324669361114502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02492273971438408,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10906842947006226,
      "backward_entropy": 0.01878000133567386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4563297033309937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024979569017887115,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1090614914894104,
      "backward_entropy": 0.018470505873362224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.643552303314209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02503524161875248,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10905556678771973,
      "backward_entropy": 0.022359836432668898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8764058351516724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025090215727686882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10905014276504517,
      "backward_entropy": 0.017876300546858046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7435005903244019,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025144876912236214,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904383659362793,
      "backward_entropy": 0.021698610650168523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3118937015533447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02519906871020794,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10903701782226563,
      "backward_entropy": 0.02137282325161828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5988847017288208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025252200663089752,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10903143882751465,
      "backward_entropy": 0.028194208939870197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3540416955947876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025304779410362244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10902528762817383,
      "backward_entropy": 0.016739389962620206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7040343284606934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025356503203511238,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10901961326599122,
      "backward_entropy": 0.016469889216952853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0356329679489136,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025407975539565086,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10901237726211548,
      "backward_entropy": 0.02714582946565416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9109516143798828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02545822598040104,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10900707244873047,
      "backward_entropy": 0.02680731647544437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2068363428115845,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025508742779493332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10899927616119384,
      "backward_entropy": 0.019538609517945185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4303746223449707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025558380410075188,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10899161100387574,
      "backward_entropy": 0.01542752981185913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4231476783752441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025607597082853317,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10898303985595703,
      "backward_entropy": 0.015175913770993551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1994668245315552,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025656457990407944,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10897362232208252,
      "backward_entropy": 0.02548489636845059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.307733178138733,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025704577565193176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10896416902542114,
      "backward_entropy": 0.018396718634499445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9665494561195374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02575218863785267,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10895372629165649,
      "backward_entropy": 0.01444295048713684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1160928010940552,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025798792019486427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10894429683685303,
      "backward_entropy": 0.014210239052772522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.287474274635315,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025844763964414597,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10893473625183106,
      "backward_entropy": 0.017593943410449557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.109906554222107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025890467688441277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10892376899719239,
      "backward_entropy": 0.013755417532391019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1386562585830688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02593558095395565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10891220569610596,
      "backward_entropy": 0.0135327966676818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7765268087387085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025980236008763313,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10889973640441894,
      "backward_entropy": 0.013313233024544187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7354795932769775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602376602590084,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10888844728469849,
      "backward_entropy": 0.01310167047712538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8409189581871033,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026066238060593605,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10887842178344727,
      "backward_entropy": 0.022781398561265733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0880448818206787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026107948273420334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10886859893798828,
      "backward_entropy": 0.012698614762889015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0587748289108276,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026149462908506393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10885705947875976,
      "backward_entropy": 0.015891889731089275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0638771057128906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026190761476755142,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10884394645690917,
      "backward_entropy": 0.01230349474483066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8436342477798462,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026231881231069565,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10882911682128907,
      "backward_entropy": 0.021704301238059998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8249148726463318,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0262723620980978,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10881390571594238,
      "backward_entropy": 0.021443737877739802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6086165904998779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026312248781323433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1087983250617981,
      "backward_entropy": 0.01172767248418596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6882572770118713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263510849326849,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1087836742401123,
      "backward_entropy": 0.020938826931847468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6282783150672913,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026389190927147865,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1087691307067871,
      "backward_entropy": 0.014602157804701064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6604785323143005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026426438242197037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10875483751296997,
      "backward_entropy": 0.011199152304066552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.704708456993103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026463022455573082,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10874036550521851,
      "backward_entropy": 0.011032096213764615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3866748809814453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026499111205339432,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10872514247894287,
      "backward_entropy": 0.014026340511110093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5752609372138977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0265339482575655,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10871167182922363,
      "backward_entropy": 0.013845625850889418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5264933109283447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026568196713924408,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10869810581207276,
      "backward_entropy": 0.01366776062382592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6710205674171448,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026601728051900864,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10868453979492188,
      "backward_entropy": 0.01934335298008389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6032999753952026,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026635000482201576,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10866954326629638,
      "backward_entropy": 0.01913399000962575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.531240701675415,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026667915284633636,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10865367650985717,
      "backward_entropy": 0.013154224389129214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5095580816268921,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670026756823063,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10863736867904664,
      "backward_entropy": 0.012988233731852638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43526631593704224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026732051745057106,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10862065553665161,
      "backward_entropy": 0.009833659562799666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4498465657234192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02676312066614628,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1086040735244751,
      "backward_entropy": 0.009698079691992866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5611005425453186,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026793602854013443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10858731269836426,
      "backward_entropy": 0.009565712677107917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39859551191329956,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026823876425623894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10856904983520507,
      "backward_entropy": 0.012359884877999624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43154075741767883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02685343474149704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1085507869720459,
      "backward_entropy": 0.009306370384163327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23368822038173676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02688244730234146,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1085319995880127,
      "backward_entropy": 0.009180635213851929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3445732295513153,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026910295709967613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10851464271545411,
      "backward_entropy": 0.009061141146553887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2590310275554657,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026937467977404594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10849720239639282,
      "backward_entropy": 0.011795729398727417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25460007786750793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026963725686073303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10848048925399781,
      "backward_entropy": 0.00883345471488105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3974023759365082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026989169418811798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10846436023712158,
      "backward_entropy": 0.00872608439789878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3553827106952667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02701440081000328,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10844689607620239,
      "backward_entropy": 0.008619416919019487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30298909544944763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027039265260100365,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842856168746948,
      "backward_entropy": 0.008514316545592414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32894933223724365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02706362120807171,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10840985774993897,
      "backward_entropy": 0.011183256904284159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18330597877502441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0270876195281744,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10839033126831055,
      "backward_entropy": 0.008310546477635702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2256767600774765,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02711072750389576,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10837173461914062,
      "backward_entropy": 0.016222064693768818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3054443895816803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027133168652653694,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10835329294204712,
      "backward_entropy": 0.010851070284843445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1864825189113617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027155349031090736,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10833377838134765,
      "backward_entropy": 0.010746122234397464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14378079771995544,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027176758274435997,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10831468105316162,
      "backward_entropy": 0.010644842353132036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20542344450950623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02719726599752903,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1082964539527893,
      "backward_entropy": 0.010547864768240187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22906798124313354,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02721727453172207,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10827802419662476,
      "backward_entropy": 0.010453396373324923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15841834247112274,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02723696082830429,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10825892686843872,
      "backward_entropy": 0.015472125675943162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19345073401927948,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027256004512310028,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10824012756347656,
      "backward_entropy": 0.007614110906918843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21265234053134918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727462351322174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10822093486785889,
      "backward_entropy": 0.007538010676701863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19117245078086853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027292948216199875,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10820090770721436,
      "backward_entropy": 0.015144338210423788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19687704741954803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027310915291309357,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1081803560256958,
      "backward_entropy": 0.015039892660246955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1606733649969101,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732861042022705,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1081591010093689,
      "backward_entropy": 0.007317095167107052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11938736587762833,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0273458119481802,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10813758373260499,
      "backward_entropy": 0.009853661060333252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12370225787162781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02736237645149231,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10811649560928345,
      "backward_entropy": 0.009777531027793884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1309533566236496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02737833932042122,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10809557437896729,
      "backward_entropy": 0.009704488019148508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11416416615247726,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02739383839070797,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10807456970214843,
      "backward_entropy": 0.014562909801801046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13055457174777985,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02740880474448204,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10805370807647705,
      "backward_entropy": 0.014477723174624972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13493146002292633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02742340974509716,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10803256034851075,
      "backward_entropy": 0.009499081306987338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1197991594672203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027437712997198105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10801093578338623,
      "backward_entropy": 0.006873793486091826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0864405557513237,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027451656758785248,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10798908472061157,
      "backward_entropy": 0.014235665400822958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10050386935472488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02746501937508583,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10796761512756348,
      "backward_entropy": 0.014160768853293525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10517420619726181,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027477938681840897,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10794603824615479,
      "backward_entropy": 0.01408862074216207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08427774161100388,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027490507811307907,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10792419910430909,
      "backward_entropy": 0.01401869124836392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05678579583764076,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027502601966261864,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10790250301361085,
      "backward_entropy": 0.009142722520563338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10856985300779343,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0275140181183815,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10788145065307617,
      "backward_entropy": 0.00656479224562645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10431423038244247,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027525270357728004,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10785970687866211,
      "backward_entropy": 0.009041973286204867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10024853050708771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027536364272236824,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1078373670578003,
      "backward_entropy": 0.013765984111362033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08253798633813858,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02754727378487587,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10781447887420655,
      "backward_entropy": 0.008945050338904062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07287095487117767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027557862922549248,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10779142379760742,
      "backward_entropy": 0.006386221283011966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07639271020889282,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02756805345416069,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1077683687210083,
      "backward_entropy": 0.013593595888879564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06722558289766312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027577921748161316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10774511098861694,
      "backward_entropy": 0.008811421692371368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07631070166826248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027587424963712692,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10772190093994141,
      "backward_entropy": 0.013489358127117157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09002850204706192,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027596700936555862,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10769839286804199,
      "backward_entropy": 0.008730428914229075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04908544197678566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276059377938509,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10767415761947632,
      "backward_entropy": 0.006188591321309407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07329916208982468,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02761468105018139,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10765037536621094,
      "backward_entropy": 0.006152415027221044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05089881643652916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027623243629932404,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10762614011764526,
      "backward_entropy": 0.013298539651764764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026018483564257622,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027631377801299095,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10760213136672973,
      "backward_entropy": 0.006082936293549008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060996249318122864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027638789266347885,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10757901668548583,
      "backward_entropy": 0.006051859507958095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03345300257205963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027646025642752647,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10755558013916015,
      "backward_entropy": 0.0085216975874371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044568195939064026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027652710676193237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10753265619277955,
      "backward_entropy": 0.00599297218852573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027714556083083153,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02765907347202301,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1075098156929016,
      "backward_entropy": 0.005965782122479545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.057365480810403824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02766488306224346,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10748753547668458,
      "backward_entropy": 0.005940673665867912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055111147463321686,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02767065539956093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10746471881866455,
      "backward_entropy": 0.008419892854160733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036322202533483505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02767639234662056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1074414849281311,
      "backward_entropy": 0.005890614456600613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04515807703137398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027681773528456688,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10741841793060303,
      "backward_entropy": 0.008374656240145365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04389053210616112,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02768700197339058,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10739519596099853,
      "backward_entropy": 0.005843802044788997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04235019162297249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027692075818777084,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10737178325653077,
      "backward_entropy": 0.012949330111344656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05616652965545654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276970025151968,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10734829902648926,
      "backward_entropy": 0.005799140367243025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03703942522406578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027702057734131813,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10732402801513671,
      "backward_entropy": 0.005776538617081112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039118167012929916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027706880122423172,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10729987621307373,
      "backward_entropy": 0.012877042922708724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04037823900580406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027711523696780205,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10727553367614746,
      "backward_entropy": 0.012854765686723921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03648604825139046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027716051787137985,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1072509765625,
      "backward_entropy": 0.005712969849507014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04022631421685219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027720410376787186,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10722639560699462,
      "backward_entropy": 0.005692852867974175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04141687974333763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02772471122443676,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10720157623291016,
      "backward_entropy": 0.005672949055830638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028797851875424385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02772899530827999,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10717631578445434,
      "backward_entropy": 0.012772172689437866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03025106154382229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02773299627006054,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10715141296386718,
      "backward_entropy": 0.005634269366661708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03148839250206947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027736777439713478,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10712661743164062,
      "backward_entropy": 0.012736161549886068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0305679552257061,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027740400284528732,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10710177421569825,
      "backward_entropy": 0.005598882420195473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031488217413425446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277438685297966,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10707693099975586,
      "backward_entropy": 0.005582043694125282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025408988818526268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02774723991751671,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10705196857452393,
      "backward_entropy": 0.00556554314162996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03466470167040825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02775035984814167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10702713727951049,
      "backward_entropy": 0.005549901889430152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027095632627606392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027753544971346855,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10700193643569947,
      "backward_entropy": 0.012662611073917814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026351509615778923,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0277565848082304,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1069769024848938,
      "backward_entropy": 0.012649647063679166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02124965749680996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027759481221437454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10695196390151977,
      "backward_entropy": 0.005503825843334198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027682656422257423,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027762096375226974,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10692734718322754,
      "backward_entropy": 0.005490008327696059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028190886601805687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027764689177274704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1069025993347168,
      "backward_entropy": 0.008055061101913452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020968081429600716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027767300605773926,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10687763690948486,
      "backward_entropy": 0.005462572806411319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020411701872944832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02776968665421009,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10685291290283203,
      "backward_entropy": 0.008037418954902224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024523556232452393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027771862223744392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10682841539382934,
      "backward_entropy": 0.005437506569756402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026042930781841278,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277740266174078,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1068037509918213,
      "backward_entropy": 0.005425404343340132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015602003782987595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027776261791586876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10677882432937622,
      "backward_entropy": 0.005413062870502472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02242840640246868,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027778154239058495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10675431489944458,
      "backward_entropy": 0.005401945776409573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02285456657409668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027780041098594666,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1067297101020813,
      "backward_entropy": 0.005390875041484833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01645570434629917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027781955897808075,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10670503377914428,
      "backward_entropy": 0.007995643549495272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018728239461779594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027783634141087532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10668066740036011,
      "backward_entropy": 0.007990282442834642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015756288543343544,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027785222977399826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10665637254714966,
      "backward_entropy": 0.005359511822462082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016870878636837006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02778659760951996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1066324234008789,
      "backward_entropy": 0.005350357128514184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015466227196156979,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027787864208221436,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10660860538482667,
      "backward_entropy": 0.005341612630420261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016765128821134567,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02778899297118187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10658489465713501,
      "backward_entropy": 0.007974630428685082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014046400785446167,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027790069580078125,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.106561279296875,
      "backward_entropy": 0.007971710628933378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016044875606894493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0277909804135561,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10653791427612305,
      "backward_entropy": 0.005317856868108113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014093666337430477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02779185026884079,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1065146803855896,
      "backward_entropy": 0.005310571855968899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017148856073617935,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027792608365416527,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10649164915084838,
      "backward_entropy": 0.01252714710103141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017742929980158806,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027793454006314278,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1064685583114624,
      "backward_entropy": 0.012526063455475701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01282835565507412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027794454246759415,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10644519329071045,
      "backward_entropy": 0.007961713605456881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01622237265110016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027795275673270226,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10642224550247192,
      "backward_entropy": 0.007960225145022074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012454488314688206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027796203270554543,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10639914274215698,
      "backward_entropy": 0.005274724629190233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012765008956193924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027797002345323563,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.106376314163208,
      "backward_entropy": 0.00526793466673957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013598185032606125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027797715738415718,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10635368824005127,
      "backward_entropy": 0.007956002321508195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011415150947868824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027798417955636978,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.106331205368042,
      "backward_entropy": 0.012517553236749437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013998443260788918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027799010276794434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1063089370727539,
      "backward_entropy": 0.0052492134273052216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011799165979027748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027799712494015694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10628656148910523,
      "backward_entropy": 0.0052429259651237065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010575451888144016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780037187039852,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10626435279846191,
      "backward_entropy": 0.00795366366704305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01128334365785122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027800919488072395,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10624239444732667,
      "backward_entropy": 0.012514687246746488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010565065778791904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027801429852843285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10622062683105468,
      "backward_entropy": 0.005225614955027898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010162959806621075,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027801919728517532,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10619890689849854,
      "backward_entropy": 0.00795373817284902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01032182201743126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027802346274256706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10617738962173462,
      "backward_entropy": 0.00521505582663748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008792147040367126,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027802789583802223,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1061558723449707,
      "backward_entropy": 0.00795422163274553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009073765017092228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780310995876789,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10613464117050171,
      "backward_entropy": 0.00520513289504581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008008044213056564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027803391218185425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10611354112625122,
      "backward_entropy": 0.00520056900050905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009200293570756912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027803489938378334,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10609292984008789,
      "backward_entropy": 0.005196770860089196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008456324227154255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027803592383861542,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10607246160507203,
      "backward_entropy": 0.007959028085072836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008054893463850021,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780367247760296,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10605214834213257,
      "backward_entropy": 0.012522818313704597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00880370195955038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278036966919899,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1060319185256958,
      "backward_entropy": 0.005185970829592811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008376293815672398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027803758159279823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10601168870925903,
      "backward_entropy": 0.00518245581123564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00840558111667633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780386246740818,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10599145889282227,
      "backward_entropy": 0.012528699305322435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0077850366942584515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780403383076191,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10597119331359864,
      "backward_entropy": 0.005174970461262597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007977809756994247,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027804238721728325,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10595096349716186,
      "backward_entropy": 0.0079683189590772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006471175234764814,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780449576675892,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10593076944351196,
      "backward_entropy": 0.012531975077258216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007567788939923048,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027804655954241753,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10591086149215698,
      "backward_entropy": 0.007970043354564242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006614312529563904,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027804868295788765,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10589098930358887,
      "backward_entropy": 0.012534227636125352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006412412505596876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027805082499980927,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10587121248245239,
      "backward_entropy": 0.005155464427338706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006484227254986763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027805259451270103,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10585165023803711,
      "backward_entropy": 0.007972457342677645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006896515376865864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780546434223652,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1058321475982666,
      "backward_entropy": 0.005148000187344021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006246836390346289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780577540397644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10581262111663818,
      "backward_entropy": 0.012537822127342224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006211479194462299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780609391629696,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10579321384429932,
      "backward_entropy": 0.007973142796092562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005760950036346912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780640870332718,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10577398538589478,
      "backward_entropy": 0.0079732413093249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0057332138530910015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027806732803583145,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10575486421585083,
      "backward_entropy": 0.007973243792851767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005881944205611944,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027807055041193962,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10573588609695435,
      "backward_entropy": 0.01253868473900689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004912274889647961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780742570757866,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10571699142456055,
      "backward_entropy": 0.007973087330659231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004707615356892347,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027807744219899178,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10569829940795898,
      "backward_entropy": 0.007973089814186096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00441568810492754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027808019891381264,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10567985773086548,
      "backward_entropy": 0.00797323054737515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004787393379956484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027808230370283127,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10566166639328003,
      "backward_entropy": 0.007973624600304497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036366863641887903,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027808450162410736,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10564364194869995,
      "backward_entropy": 0.012540141741434732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004488745704293251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027808576822280884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1056259036064148,
      "backward_entropy": 0.005105917652448018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004346737638115883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027808718383312225,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1056083083152771,
      "backward_entropy": 0.007975088225470649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004419646691530943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780887298285961,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1055908441543579,
      "backward_entropy": 0.012543479601542154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041362992487847805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809057384729385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10557348728179931,
      "backward_entropy": 0.005096416506502364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003987286705523729,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027809275314211845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10555622577667237,
      "backward_entropy": 0.00797605597310596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036021636333316565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809493243694305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10553910732269287,
      "backward_entropy": 0.00508985709812906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003163564018905163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809644117951393,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1055222749710083,
      "backward_entropy": 0.005086866931782829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035690278746187687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780972607433796,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10550572872161865,
      "backward_entropy": 0.007977565129597982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034980925265699625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780982293188572,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10548932552337646,
      "backward_entropy": 0.007978291975127326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029548590537160635,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027809930965304375,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1054730772972107,
      "backward_entropy": 0.007978983223438263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003150421194732189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780997008085251,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1054571270942688,
      "backward_entropy": 0.005076173279020522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029266299679875374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027810007333755493,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10544133186340332,
      "backward_entropy": 0.007980980806880526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002824591239914298,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027810025960206985,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10542576313018799,
      "backward_entropy": 0.012553099128935073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002780814655125141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810052037239075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10541033744812012,
      "backward_entropy": 0.005069050110048718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002690894529223442,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810057625174522,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10539507865905762,
      "backward_entropy": 0.005066815763711929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026724119670689106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810046449303627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10538004636764527,
      "backward_entropy": 0.005064670824342304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027686471585184336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781003899872303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10536515712738037,
      "backward_entropy": 0.005062543269660737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002588769653812051,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810044586658478,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10535043478012085,
      "backward_entropy": 0.005060419854190614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002355801872909069,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027810024097561836,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1053359031677246,
      "backward_entropy": 0.007988769974973466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002434859285131097,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780999056994915,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10532157421112061,
      "backward_entropy": 0.007990117702219222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020376199390739202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809979394078255,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10530737638473511,
      "backward_entropy": 0.005054492503404617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002390697132796049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780994586646557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1052934169769287,
      "backward_entropy": 0.007992656694518195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021462785080075264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780996821820736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10527950525283813,
      "backward_entropy": 0.005050583432118098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018247886328026652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027809988707304,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10526576042175292,
      "backward_entropy": 0.012567022608386146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019223489798605442,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027810007333755493,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10525221824645996,
      "backward_entropy": 0.00799561705854204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019074612064287066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781001292169094,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10523885488510132,
      "backward_entropy": 0.007996610469288297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017650953959673643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810022234916687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.105225670337677,
      "backward_entropy": 0.005042860077487098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016893427819013596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810022234916687,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10521266460418702,
      "backward_entropy": 0.0050410545534557765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016324467724189162,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780999429523945,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10519987344741821,
      "backward_entropy": 0.012572278579076132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016357136191800237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780994400382042,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1051872968673706,
      "backward_entropy": 0.0050377849903371595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016361300367861986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809906750917435,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10517486333847045,
      "backward_entropy": 0.005036196360985438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014861754607409239,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809875085949898,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10516257286071777,
      "backward_entropy": 0.005034600694974263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015010935021564364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780984155833721,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10515047311782837,
      "backward_entropy": 0.005033040212260352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00161849451251328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809780091047287,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10513856410980224,
      "backward_entropy": 0.005031609286864598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015886329347267747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780977077782154,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1051267147064209,
      "backward_entropy": 0.005030043009254668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013163061812520027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809804305434227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10511493682861328,
      "backward_entropy": 0.00502833765414026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013993619941174984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027809826657176018,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10510332584381103,
      "backward_entropy": 0.012580123212602403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010789287043735385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027809878811240196,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10509183406829833,
      "backward_entropy": 0.012580545412169563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001085006515495479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027809884399175644,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10508060455322266,
      "backward_entropy": 0.012581239144007364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012489327928051353,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02780984342098236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10506961345672608,
      "backward_entropy": 0.008011271556218466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00122643553186208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027809856459498405,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10505869388580322,
      "backward_entropy": 0.012582785553402372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001204508007504046,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02780991420149803,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10504785776138306,
      "backward_entropy": 0.012583153115378486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011515960795804858,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027809977531433105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10503714084625244,
      "backward_entropy": 0.005017385300662782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011846282286569476,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781006135046482,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1050265073776245,
      "backward_entropy": 0.005015727960401111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011597853153944016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781018801033497,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1050159215927124,
      "backward_entropy": 0.0080142542719841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000807793578132987,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810348197817802,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10500540733337402,
      "backward_entropy": 0.0050120846264892155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011886657448485494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027810456231236458,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1049951434135437,
      "backward_entropy": 0.005010427700148689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000977455754764378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781064249575138,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10498486757278443,
      "backward_entropy": 0.005008522007200453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010156676871702075,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027810847386717796,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10497469902038574,
      "backward_entropy": 0.012581770618756613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008792498847469687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781108394265175,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10496461391448975,
      "backward_entropy": 0.012580883999665579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000721106247510761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027811307460069656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10495467185974121,
      "backward_entropy": 0.005002581824858983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007479854393750429,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781146764755249,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10494498014450074,
      "backward_entropy": 0.012579574353165097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006100512691773474,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027811601758003235,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10493546724319458,
      "backward_entropy": 0.012579225831561618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007727444171905518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027811691164970398,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10492620468139649,
      "backward_entropy": 0.004997752606868744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007714079110883176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027811814099550247,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10491702556610108,
      "backward_entropy": 0.008015149997340308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006853369413875043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027811961248517036,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1049079418182373,
      "backward_entropy": 0.008015195528666178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006992173730395734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812102809548378,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10489898920059204,
      "backward_entropy": 0.00801526258389155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006207433762028813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812255546450615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10489012002944946,
      "backward_entropy": 0.004991399331225289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006082316976971924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812402695417404,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1048813819885254,
      "backward_entropy": 0.004989850024382274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005054636276327074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812553569674492,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10487277507781982,
      "backward_entropy": 0.008015318049324883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000494746258482337,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812663465738297,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10486437082290649,
      "backward_entropy": 0.012576294442017874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048289858386851847,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812758460640907,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10485613346099854,
      "backward_entropy": 0.008015704651673635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044873898150399327,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812805026769638,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10484811067581176,
      "backward_entropy": 0.008016141752401987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004342931497376412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812832966446877,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10484024286270141,
      "backward_entropy": 0.004983341528309716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004777507856488228,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812834829092026,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10483255386352539,
      "backward_entropy": 0.012576747271749709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004240415873937309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781282179057598,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10482499599456788,
      "backward_entropy": 0.008017955554856194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043363356962800026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781282365322113,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10481754541397095,
      "backward_entropy": 0.004980531417661243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042400966049171984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781285159289837,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10481020212173461,
      "backward_entropy": 0.008018975456555685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003441940061748028,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781287394464016,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10480296611785889,
      "backward_entropy": 0.004978530936770969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037497226730920374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278128944337368,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10479588508605957,
      "backward_entropy": 0.004977575192848842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036706458195112646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781287580728531,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10478895902633667,
      "backward_entropy": 0.004976773841513528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003599540505092591,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812868356704712,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1047821283340454,
      "backward_entropy": 0.012578854958216349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003379704721737653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812842279672623,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1047754168510437,
      "backward_entropy": 0.004975189765294393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030298857018351555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781280130147934,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10476882457733154,
      "backward_entropy": 0.012579786280790964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003465087793301791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812743559479713,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1047623872756958,
      "backward_entropy": 0.012580361631181505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003046233032364398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781272679567337,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10475598573684693,
      "backward_entropy": 0.012580699390835233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002802555973175913,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812711894512177,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10474969148635864,
      "backward_entropy": 0.012581020593643188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003187978873029351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812693268060684,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10474350452423095,
      "backward_entropy": 0.0049717016518116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021805247524753213,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812693268060684,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10473740100860596,
      "backward_entropy": 0.00802569008535809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021208991529420018,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812667191028595,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10473146438598632,
      "backward_entropy": 0.012581957711113824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002730378182604909,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812641113996506,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1047256588935852,
      "backward_entropy": 0.01258235341972775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002530073397792876,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781262807548046,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10471992492675782,
      "backward_entropy": 0.008027441799640656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024137055152095854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812615036964417,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1047142744064331,
      "backward_entropy": 0.008027974102232192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022570953296963125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812616899609566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10470869541168212,
      "backward_entropy": 0.004967632393042247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002382575039518997,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812596410512924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10470322370529175,
      "backward_entropy": 0.008029008077250587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014437278150580823,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812594547867775,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10469781160354615,
      "backward_entropy": 0.008029495676358541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016642910486552864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812570333480835,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10469257831573486,
      "backward_entropy": 0.004965796238846249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016341540322173387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0278125312179327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10468747615814208,
      "backward_entropy": 0.008030671212408278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021356545039452612,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812493965029716,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10468249320983887,
      "backward_entropy": 0.0049647945496771075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019322693697176874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812473475933075,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10467753410339356,
      "backward_entropy": 0.004964244034555223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001694172533461824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781245857477188,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10467264652252198,
      "backward_entropy": 0.012585215270519257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017437846690881997,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812449261546135,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10466784238815308,
      "backward_entropy": 0.004963141762548023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017145420133601874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027812452986836433,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10466309785842895,
      "backward_entropy": 0.012585533989800347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001430035918019712,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812467887997627,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10465841293334961,
      "backward_entropy": 0.008033521473407745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001303210883634165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812479063868523,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10465382337570191,
      "backward_entropy": 0.008033870822853513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012521495227701962,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781248651444912,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10464932918548583,
      "backward_entropy": 0.004960780756341087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015271648589987308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781248278915882,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10464494228363037,
      "backward_entropy": 0.0049602629409896005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013414457498583943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781248651444912,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10464060306549072,
      "backward_entropy": 0.012585921419991387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014399793872144073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812492102384567,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1046363353729248,
      "backward_entropy": 0.004959195852279663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010322514572180808,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812521904706955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1046320915222168,
      "backward_entropy": 0.0049585844907495714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010477170144440606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812546119093895,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10462796688079834,
      "backward_entropy": 0.00495800996820132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011117233225377277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812587097287178,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10462391376495361,
      "backward_entropy": 0.00495740854077869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86912748683244e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812642976641655,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10461993217468261,
      "backward_entropy": 0.004956740885972977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012454039824660867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781268209218979,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10461605787277221,
      "backward_entropy": 0.008036318752500746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010743935126811266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027812741696834564,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10461218357086181,
      "backward_entropy": 0.008036369250880348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.538347174180672e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812812477350235,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10460835695266724,
      "backward_entropy": 0.004954828984207577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.472063978435472e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027812868356704712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10460462570190429,
      "backward_entropy": 0.004954218450519774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.790488209342584e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0278128981590271,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10460103750228882,
      "backward_entropy": 0.008036596907509698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.65499280532822e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781294472515583,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10459748506546021,
      "backward_entropy": 0.012584390739599863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.608722469536588e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781299687922001,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10459401607513427,
      "backward_entropy": 0.012584197852346633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.285919804824516e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781304344534874,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10459063053131104,
      "backward_entropy": 0.012584037250942655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.274950621649623e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813101187348366,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1045872449874878,
      "backward_entropy": 0.004951424068874783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.10773456376046e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781316265463829,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10458393096923828,
      "backward_entropy": 0.0049508317477173274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.262270082719624e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813231572508812,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10458066463470458,
      "backward_entropy": 0.004950233631663852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.128915993031114e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813296765089035,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10457744598388671,
      "backward_entropy": 0.004949654969904158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.447672058129683e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781335823237896,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10457427501678467,
      "backward_entropy": 0.012582639853159586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.457434235722758e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781340852379799,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1045711874961853,
      "backward_entropy": 0.008036750058333078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.027131555834785e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781345695257187,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10456814765930175,
      "backward_entropy": 0.004948073791133033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.19692875968758e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813497930765152,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1045652151107788,
      "backward_entropy": 0.004947606888082292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.249028617981821e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781352587044239,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10456233024597168,
      "backward_entropy": 0.0049471813771459795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.82409268443007e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781355194747448,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10455949306488037,
      "backward_entropy": 0.008037145766947005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2412600780371577e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813579887151718,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1045567274093628,
      "backward_entropy": 0.004946370919545491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5736131141893566e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781360223889351,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10455400943756103,
      "backward_entropy": 0.008037435511747995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3523239583009854e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813633903861046,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10455131530761719,
      "backward_entropy": 0.0049455757770273424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8116195102920756e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027813659980893135,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10454869270324707,
      "backward_entropy": 0.012581369943088956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9421520341420546e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813687920570374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10454609394073486,
      "backward_entropy": 0.004944812506437302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4759799746098e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781372144818306,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10454354286193848,
      "backward_entropy": 0.012581069436338212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.826944521279074e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027813751250505447,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10454105138778687,
      "backward_entropy": 0.01258092870314916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.237296550651081e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027813777327537537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10453861951828003,
      "backward_entropy": 0.012580819427967072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0650458686286584e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027813797816634178,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10453623533248901,
      "backward_entropy": 0.00803826500972112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.198273407178931e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027813825756311417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1045338749885559,
      "backward_entropy": 0.004942968073818419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7331259843776934e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027813859283924103,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10453156232833863,
      "backward_entropy": 0.008038434717390273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.691875670279842e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781389281153679,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10452930927276612,
      "backward_entropy": 0.008038495149877336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9786022423650138e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027813930064439774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10452710390090943,
      "backward_entropy": 0.008038530747095743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4044455130933784e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781396545469761,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1045249342918396,
      "backward_entropy": 0.0049414994815985365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6220661311526783e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027813993394374847,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10452282428741455,
      "backward_entropy": 0.00803864167796241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.198848051193636e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814026921987534,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10452075004577636,
      "backward_entropy": 0.004940814442104763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4204804503824562e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814045548439026,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10451874732971192,
      "backward_entropy": 0.012579528821839226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1883875888306648e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814071625471115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10451675653457641,
      "backward_entropy": 0.008038854433430566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1192126951063983e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814099565148354,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10451481342315674,
      "backward_entropy": 0.004939892225795322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.423781370453071e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814125642180443,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10451291799545288,
      "backward_entropy": 0.008038964536454942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0079520254512317e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781415730714798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10451103448867798,
      "backward_entropy": 0.004939276725053787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6773137758718804e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814194560050964,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10450918674468994,
      "backward_entropy": 0.008038979437616136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.721776970953215e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814222499728203,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10450738668441772,
      "backward_entropy": 0.012578643030590482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8393757272860967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781425043940544,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10450563430786133,
      "backward_entropy": 0.008039048976368375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7479664165875874e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781427837908268,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10450390577316285,
      "backward_entropy": 0.00803908540142907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.857715324149467e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781430259346962,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10450220108032227,
      "backward_entropy": 0.004937807304991616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3546063200919889e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781432680785656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10450053215026855,
      "backward_entropy": 0.00493752873606152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3357228453969583e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814345434308052,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10449891090393067,
      "backward_entropy": 0.004937278727690379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4777321666770149e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814354747533798,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10449733734130859,
      "backward_entropy": 0.012577962544229295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3859774298907723e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814369648694992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10449577569961548,
      "backward_entropy": 0.0049368345903025735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4339375411509536e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814382687211037,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10449424982070923,
      "backward_entropy": 0.004936627215809292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1875833479280118e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781439758837223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10449274778366088,
      "backward_entropy": 0.004936419013473723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0849696991499513e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814416214823723,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10449126958847046,
      "backward_entropy": 0.012577638857894473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.071336828317726e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814436703920364,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10448982715606689,
      "backward_entropy": 0.008039784928162893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1047356565541122e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814457193017006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044884204864502,
      "backward_entropy": 0.004935729006926219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.801289939379785e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814479544758797,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10448703765869141,
      "backward_entropy": 0.01257728785276413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.997354027291294e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814500033855438,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10448569059371948,
      "backward_entropy": 0.004935284869538413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.597428288543597e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814527973532677,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10448436737060547,
      "backward_entropy": 0.004935042725669013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.742038855620194e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814552187919617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10448306798934937,
      "backward_entropy": 0.004934825830989414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.340669410245027e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814578264951706,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10448179244995118,
      "backward_entropy": 0.008039924833509658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.689293852308765e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814604341983795,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1044805407524109,
      "backward_entropy": 0.008039929800563388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.381992872979026e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814628556370735,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10447932481765747,
      "backward_entropy": 0.0049341585901048444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6812576733354945e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814649045467377,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10447814464569091,
      "backward_entropy": 0.004933960735797882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.495465186162619e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781466767191887,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10447697639465332,
      "backward_entropy": 0.012576282852225833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.935639703442575e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781468816101551,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10447584390640259,
      "backward_entropy": 0.004933580342266295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.555729669344146e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814704924821854,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10447473526000976,
      "backward_entropy": 0.004933415601650874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.848254659213126e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10447365045547485,
      "backward_entropy": 0.008040118548605178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.112801318318816e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781473658978939,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044725775718689,
      "backward_entropy": 0.004933066666126251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.220639650360681e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814753353595734,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10447154045104981,
      "backward_entropy": 0.012575816777017381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.843518127017887e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781476452946663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10447053909301758,
      "backward_entropy": 0.008040233618683286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.162654360901797e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814773842692375,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044695496559143,
      "backward_entropy": 0.004932607627577252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8267546592105646e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814779430627823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10446858406066895,
      "backward_entropy": 0.004932482623391681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.198497663310263e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814779430627823,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10446765422821044,
      "backward_entropy": 0.004932370036840439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.725966962520033e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814777567982674,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10446672439575196,
      "backward_entropy": 0.0049322860108481515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.939607267966494e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814773842692375,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10446584224700928,
      "backward_entropy": 0.00804069721036487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.751050599021255e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814771980047226,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10446497201919555,
      "backward_entropy": 0.012575685977935791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.705410790644237e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814771980047226,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10446412563323974,
      "backward_entropy": 0.012575679355197482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.281480869394727e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814770117402077,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10446329116821289,
      "backward_entropy": 0.012575685977935791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.040880301341531e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781476452946663,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10446248054504395,
      "backward_entropy": 0.00804113182756636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6766103928821394e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814755216240883,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044616937637329,
      "backward_entropy": 0.004931780199209849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0946096103434684e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814745903015137,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10446093082427979,
      "backward_entropy": 0.004931718938880497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3747792258509435e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781473658978939,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10446016788482666,
      "backward_entropy": 0.008041520085599687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.805624035318033e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814725413918495,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10445945262908936,
      "backward_entropy": 0.008041669925053915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0944515856390353e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0278147142380476,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1044587254524231,
      "backward_entropy": 0.01257596082157559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.213341531387414e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814701199531555,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10445802211761475,
      "backward_entropy": 0.012576020426220365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3000905002845684e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781469002366066,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10445733070373535,
      "backward_entropy": 0.004931483417749405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.760370080068242e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814678847789764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10445666313171387,
      "backward_entropy": 0.004931447406609853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8019671870206366e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781466767191887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10445601940155029,
      "backward_entropy": 0.004931408498022292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5438799891853705e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814656496047974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10445537567138671,
      "backward_entropy": 0.008042502734396193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6529280628674314e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814645320177078,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10445476770401001,
      "backward_entropy": 0.008042631877793206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7781193264454487e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814634144306183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044541835784912,
      "backward_entropy": 0.004931297153234482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7778270375856664e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814624831080437,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10445361137390137,
      "backward_entropy": 0.012576397922303941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7363322513119783e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781461365520954,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10445303916931152,
      "backward_entropy": 0.012576462494002448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.470180791329767e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814602479338646,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10445250272750854,
      "backward_entropy": 0.008043121960428026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6471967683173716e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278145931661129,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10445195436477661,
      "backward_entropy": 0.004931169251600902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2976971675016102e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814587578177452,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10445141792297363,
      "backward_entropy": 0.004931136551830504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3590068874691497e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814581990242004,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10445091724395753,
      "backward_entropy": 0.008043425778547922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2936651501149754e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814576402306557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1044504165649414,
      "backward_entropy": 0.008043501112196181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.230407860930427e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781457081437111,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444992780685425,
      "backward_entropy": 0.004931017756462097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0515634585317457e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781456522643566,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444945096969604,
      "backward_entropy": 0.004930978847874535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.992030527428142e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814561501145363,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10444899797439575,
      "backward_entropy": 0.01257666614320543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.04418631963199e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814561501145363,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10444854497909546,
      "backward_entropy": 0.008043824798531003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.607188076188322e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814563363790512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444810390472412,
      "backward_entropy": 0.004930830664104885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66461925600015e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781456522643566,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10444767475128174,
      "backward_entropy": 0.012576622267564138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372745128326642e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781456708908081,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10444725751876831,
      "backward_entropy": 0.012576608194245232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.81518155640515e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781456895172596,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444684028625488,
      "backward_entropy": 0.004930682066414092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.337973665424215e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781457081437111,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444644689559937,
      "backward_entropy": 0.0049306245313750375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220116344797134e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814574539661407,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10444605350494385,
      "backward_entropy": 0.01257653534412384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.942315167179913e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814578264951706,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444567203521729,
      "backward_entropy": 0.004930513600508372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.816890388312459e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814580127596855,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444530248641967,
      "backward_entropy": 0.0049304622742864825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.482162007159786e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814581990242004,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10444494485855102,
      "backward_entropy": 0.008044179115030501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.419684837055684e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814585715532303,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444458723068237,
      "backward_entropy": 0.004930371625555886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.823523909180949e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0278145894408226,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10444424152374268,
      "backward_entropy": 0.008044246170255873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.415743089542957e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278145931661129,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444390773773193,
      "backward_entropy": 0.004930265247821808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.515338668577897e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814596891403198,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10444358587265015,
      "backward_entropy": 0.012576343284712898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.599947598966537e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814602479338646,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10444326400756836,
      "backward_entropy": 0.008044311569796668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.098522137814143e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814608067274094,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444295406341553,
      "backward_entropy": 0.004930126584238476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.331756713327195e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814611792564392,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1044426441192627,
      "backward_entropy": 0.008044338060749901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.967039330949774e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781461551785469,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444235801696777,
      "backward_entropy": 0.004930028484927284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.08610304702961e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781461924314499,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10444207191467285,
      "backward_entropy": 0.008044386075602638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.413476008518046e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814624831080437,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10444178581237792,
      "backward_entropy": 0.012576140463352203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.575965135700244e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814630419015884,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444151163101197,
      "backward_entropy": 0.0049298906491862405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.242191439767339e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814634144306183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444124937057495,
      "backward_entropy": 0.00492985670765241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6604519121065096e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781463973224163,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10444098711013794,
      "backward_entropy": 0.008044437401824527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.966997953990358e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781464345753193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444073677062989,
      "backward_entropy": 0.004929759436183506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5071809634246165e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814647182822227,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444049835205078,
      "backward_entropy": 0.004929731289545695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.225181899324525e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814650908112526,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10444025993347168,
      "backward_entropy": 0.008044489555888705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.000072013037425e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814652770757675,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444003343582153,
      "backward_entropy": 0.004929666303926044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.162048104992209e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814654633402824,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443980693817138,
      "backward_entropy": 0.004929625739653905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.889523500471114e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814656496047974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1044395923614502,
      "backward_entropy": 0.008044541709952883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.611936338325904e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814660221338272,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443938970565796,
      "backward_entropy": 0.012575862308343252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2172683600274468e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781466394662857,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443917512893677,
      "backward_entropy": 0.004929535090923309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1724835619352234e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781466767191887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443897247314453,
      "backward_entropy": 0.004929495354493459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4989893177007616e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814671397209167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044387698173523,
      "backward_entropy": 0.004929453548457887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0365959585433302e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814675122499466,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443856716156005,
      "backward_entropy": 0.008044597175386217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7339739599719906e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814678847789764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443838834762573,
      "backward_entropy": 0.004929386493232515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1523047166738252e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814684435725212,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443819761276245,
      "backward_entropy": 0.012575672732459174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9854513766404125e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781468816101551,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443801879882812,
      "backward_entropy": 0.008044608765178256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0501035180586769e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02781469188630581,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443782806396484,
      "backward_entropy": 0.012575603193706937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.608921280649156e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814695611596107,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443764925003052,
      "backward_entropy": 0.004929251968860626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.910823925754812e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814699336886406,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443748235702514,
      "backward_entropy": 0.012575547728273604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.444306434450482e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814701199531555,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443730354309082,
      "backward_entropy": 0.012575528687900968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2856168041253113e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814703062176704,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443714857101441,
      "backward_entropy": 0.00804465264081955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3446226887481316e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814704924821854,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443698167800904,
      "backward_entropy": 0.008044666714138456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0447222820175739e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814706787467003,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443682670593261,
      "backward_entropy": 0.008044693205091689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3362347317524836e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814708650112152,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443668365478516,
      "backward_entropy": 0.008044710589779748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.383199474958019e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278147105127573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443654060363769,
      "backward_entropy": 0.0049290888839297825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3548603305935103e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278147105127573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443639755249023,
      "backward_entropy": 0.004929063634739982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0442209230632216e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278147105127573,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443624258041381,
      "backward_entropy": 0.004929050803184509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.740886497411338e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781471237540245,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443611145019531,
      "backward_entropy": 0.008044772677951388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.542205248180835e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781471237540245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044359803199768,
      "backward_entropy": 0.0049290214147832655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.007619183876159e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781471237540245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044358491897583,
      "backward_entropy": 0.004928992854224311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.07986148490636e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278147142380476,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044357180595398,
      "backward_entropy": 0.00492898209227456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.665967416414787e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02781471610069275,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443558692932128,
      "backward_entropy": 0.008044832282596164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.724080492404028e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814717963337898,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443546772003173,
      "backward_entropy": 0.004928941528002421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.418782471153463e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443534851074218,
      "backward_entropy": 0.01257534407907062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.455342571598521e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044352412223816,
      "backward_entropy": 0.0049289121396011775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4283200035552e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443512201309205,
      "backward_entropy": 0.0049289026194148594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.704246319737649e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443501472473145,
      "backward_entropy": 0.004928893513149685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.070920477441177e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1044349193572998,
      "backward_entropy": 0.008044925000932481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.331094226652567e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044348120689392,
      "backward_entropy": 0.004928860399458144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.248916406548233e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443470478057862,
      "backward_entropy": 0.00492885129319297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.238211997493636e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443462133407592,
      "backward_entropy": 0.012575278679529825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.416976378569416e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10443452596664429,
      "backward_entropy": 0.00804499453968472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.337433523460277e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1044344425201416,
      "backward_entropy": 0.004928832666741477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.899440770283036e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10443434715270997,
      "backward_entropy": 0.00492881072892083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3707817809490734e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027814719825983047,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10443426370620727,
      "backward_entropy": 0.012575267917580076,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.1676776929903099e-06,
    "avg_log_Z": 0.027814670708030464,
    "success_rate": 1.0,
    "avg_reward": 42.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.22,
      "1": 0.29,
      "2": 0.49
    },
    "avg_forward_entropy": 0.10444625008106229,
    "avg_backward_entropy": 0.007515183881753021,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}