{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09893580845424108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09901642799377441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.607009887695312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137108713388443,
      "backward_entropy": 0.09900828770228795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.519379615783691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371147632598877,
      "backward_entropy": 0.09900580133710589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.601558685302734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019998224161099643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712133467197418,
      "backward_entropy": 0.0990133285522461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.393739700317383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00029998182435519993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371276080608368,
      "backward_entropy": 0.09901143823351179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.68167495727539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00039995217230170965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713319599628448,
      "backward_entropy": 0.09900925840650286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38969612121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004999734810553491,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713854551315308,
      "backward_entropy": 0.09899333545139857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.927152156829834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005999550339765847,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371435523033142,
      "backward_entropy": 0.09898950372423444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471593856811523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006997621385380626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714861869812012,
      "backward_entropy": 0.09900116920471191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.261564254760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007996289059519768,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715320825576782,
      "backward_entropy": 0.09898081847599574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38172435760498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008991350186988711,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371575891971588,
      "backward_entropy": 0.09897591386522565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.407691955566406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009987447410821915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716188073158264,
      "backward_entropy": 0.09883777584348406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.544776916503906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0010984123218804598,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716654479503632,
      "backward_entropy": 0.09896503176007952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.629842758178711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011978556867688894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717113435268402,
      "backward_entropy": 0.09898180621010917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74666976928711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012971602845937014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717550039291382,
      "backward_entropy": 0.09879852192742485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.999318599700928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013967454433441162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717970252037048,
      "backward_entropy": 0.09878427641732353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28247356414795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014962999848648906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718374073505402,
      "backward_entropy": 0.09896630900246757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.164041519165039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015959242591634393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13718780875205994,
      "backward_entropy": 0.09896041665758405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.169320106506348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016951850848272443,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371917724609375,
      "backward_entropy": 0.09895417519978114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.627363204956055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017945575527846813,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719525933265686,
      "backward_entropy": 0.09891461474554879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902137756347656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018942065071314573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371982842683792,
      "backward_entropy": 0.09870326519012451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.988245010375977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00199377560056746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720139861106873,
      "backward_entropy": 0.09893291337149483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.968499183654785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002093321643769741,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720451295375824,
      "backward_entropy": 0.09892496040889195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.878810405731201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021928823553025723,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720689713954926,
      "backward_entropy": 0.09891655615397862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.618049621582031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022924107033759356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720883429050446,
      "backward_entropy": 0.09890770060675484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.157402992248535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023922084365040064,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721050322055817,
      "backward_entropy": 0.09885295799800328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.348410606384277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002492043422535062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721197843551636,
      "backward_entropy": 0.09858519690377372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.507061958312988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0025919685140252113,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721366226673126,
      "backward_entropy": 0.09887851136071342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41638469696045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026921003591269255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721461594104767,
      "backward_entropy": 0.09881503241402763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.694430351257324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027923632878810167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721507787704468,
      "backward_entropy": 0.09885668754577637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.88366413116455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0028928446117788553,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721531629562378,
      "backward_entropy": 0.0988450220652989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.792520523071289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029935725033283234,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721561431884766,
      "backward_entropy": 0.09877238954816546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.407002925872803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030944650061428547,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721606135368347,
      "backward_entropy": 0.09882010732378278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.139781951904297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031949125695973635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721632957458496,
      "backward_entropy": 0.09880685806274414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.783334732055664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032952914480119944,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721653819084167,
      "backward_entropy": 0.09872395651681083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.855981826782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003395878942683339,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721691071987152,
      "backward_entropy": 0.09870639869144984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.410846710205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034962627105414867,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721702992916107,
      "backward_entropy": 0.09868815967014857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.757535934448242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003596691647544503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721728324890137,
      "backward_entropy": 0.09874518428530012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.309054851531982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036973583046346903,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721710443496704,
      "backward_entropy": 0.09864908456802368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.116528034210205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037975325249135494,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372169852256775,
      "backward_entropy": 0.09862835918154035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.860342979431152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003897205926477909,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721658289432526,
      "backward_entropy": 0.09820738860539027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39002799987793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003996737767010927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721662759780884,
      "backward_entropy": 0.09817375455583845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.474692344665527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00409596087411046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721656799316406,
      "backward_entropy": 0.09865214143480573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.385416507720947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004194964654743671,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721628487110138,
      "backward_entropy": 0.09853737694876534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.573103904724121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0042937216348946095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721594214439392,
      "backward_entropy": 0.0986097880772182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.557774543762207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004392328672111034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721588253974915,
      "backward_entropy": 0.0980297497340611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.277873992919922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004491310101002455,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137215718626976,
      "backward_entropy": 0.09845951625279017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.459301471710205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0045905024744570255,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137215256690979,
      "backward_entropy": 0.09854059559958321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4612398147583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004688999615609646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721434772014618,
      "backward_entropy": 0.09851644720349993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.008723258972168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004787835292518139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372135579586029,
      "backward_entropy": 0.09786782945905413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730533599853516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004886741284281015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721297681331635,
      "backward_entropy": 0.09782419885907855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.536968231201172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0049860612489283085,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721264898777008,
      "backward_entropy": 0.09843827996935163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722628593444824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005085678771138191,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721220195293427,
      "backward_entropy": 0.09827784129551478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.822854042053223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005185625981539488,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721199333667755,
      "backward_entropy": 0.0983809062412807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.073265075683594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005285399500280619,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721224665641785,
      "backward_entropy": 0.09763307230813163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8845391273498535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005386129021644592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372128278017044,
      "backward_entropy": 0.09758073943001884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42998218536377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005486682057380676,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721297681331635,
      "backward_entropy": 0.09828552177974156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.048643112182617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005587324034422636,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372131109237671,
      "backward_entropy": 0.09825141089303153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.506556510925293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005687904078513384,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721254467964172,
      "backward_entropy": 0.09821621009281703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.432833671569824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005788619630038738,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372118890285492,
      "backward_entropy": 0.098019540309906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.043414115905762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005889356601983309,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372118443250656,
      "backward_entropy": 0.09797779151371547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.057694911956787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005990453530102968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721193373203278,
      "backward_entropy": 0.09810444286891393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.594295024871826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0060908910818398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721176981925964,
      "backward_entropy": 0.09717784609113421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.493616580963135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006190540734678507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721095025539398,
      "backward_entropy": 0.09802552631923131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.204361915588379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0062899282202124596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720986247062683,
      "backward_entropy": 0.09705744470868792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.471559524536133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006389447953552008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720853626728058,
      "backward_entropy": 0.09794236932482038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.46625804901123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006489209830760956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720715045928955,
      "backward_entropy": 0.09789885793413435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.104215621948242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006589184515178204,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720570504665375,
      "backward_entropy": 0.0978532178061349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.811327934265137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006689161993563175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720425963401794,
      "backward_entropy": 0.09780621528625488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.719621658325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006789505481719971,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720279932022095,
      "backward_entropy": 0.09775776522500175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.985811233520508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006889660377055407,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720068335533142,
      "backward_entropy": 0.09770811455590385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.91410493850708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00699022738263011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719889521598816,
      "backward_entropy": 0.09657892159053258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.245188236236572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007090605329722166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13719740509986877,
      "backward_entropy": 0.09760487079620361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.341170310974121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00719057722017169,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13719484210014343,
      "backward_entropy": 0.09642672538757324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.044576644897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007290661800652742,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137192502617836,
      "backward_entropy": 0.09726408549717494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495199203491211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007390753831714392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371896117925644,
      "backward_entropy": 0.0962670019694737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.301019668579102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0074910507537424564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718664646148682,
      "backward_entropy": 0.09618131603513445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.58817720413208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007591452915221453,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718336820602417,
      "backward_entropy": 0.09707823821476527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.226188659667969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007691572420299053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717976212501526,
      "backward_entropy": 0.09600380488804408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.735931396484375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007791715674102306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371767818927765,
      "backward_entropy": 0.09720363787242345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.349157333374023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00789217371493578,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13717390596866608,
      "backward_entropy": 0.09687763452529907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.176590919494629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00799322035163641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717129826545715,
      "backward_entropy": 0.0957161613873073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360851287841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008094673976302147,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716919720172882,
      "backward_entropy": 0.09673269305910383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.465640544891357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008196094073355198,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13716711103916168,
      "backward_entropy": 0.09693752016339983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.702340126037598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008297031745314598,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13716475665569305,
      "backward_entropy": 0.0965831024306161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.987375259399414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008397703059017658,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371617615222931,
      "backward_entropy": 0.09650758334568568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10580062866211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008498226292431355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715887069702148,
      "backward_entropy": 0.09672009093420846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.275277137756348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008599226363003254,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371559053659439,
      "backward_entropy": 0.09664366926465716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.454800128936768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008699657395482063,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715310394763947,
      "backward_entropy": 0.0962651116507394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38182544708252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008799652568995953,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715076446533203,
      "backward_entropy": 0.09648605755397252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.719139099121094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00889979675412178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714829087257385,
      "backward_entropy": 0.09471007755824498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469779014587402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009000255726277828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371457278728485,
      "backward_entropy": 0.09632010970796857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.359940052032471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009100822731852531,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714353740215302,
      "backward_entropy": 0.09445498670850482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.149686336517334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0092003857716918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714128732681274,
      "backward_entropy": 0.09432567868913923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.892168998718262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009299448691308498,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713952898979187,
      "backward_entropy": 0.09605344704219274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.244768142700195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009398968890309334,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371387541294098,
      "backward_entropy": 0.0956322465624128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.705577373504639,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009498605504631996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713805377483368,
      "backward_entropy": 0.09586530072348458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.881386756896973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009598076343536377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713683187961578,
      "backward_entropy": 0.09576804297310966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.899578094482422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009697471745312214,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371356099843979,
      "backward_entropy": 0.09532691751207624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.651627540588379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009797357954084873,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713428378105164,
      "backward_entropy": 0.09349758284432548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.167734622955322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009897509589791298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713346421718597,
      "backward_entropy": 0.09334895440510341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.420769691467285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009997116401791573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371326744556427,
      "backward_entropy": 0.09319870812552315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.694363594055176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010096365585923195,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713207840919495,
      "backward_entropy": 0.09524667263031006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.740312576293945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010195988230407238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371316760778427,
      "backward_entropy": 0.09513636146272932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.59072494506836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010295429266989231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713137805461884,
      "backward_entropy": 0.0927260092326573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.118452072143555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010395156219601631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371314376592636,
      "backward_entropy": 0.0925588948386056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.902535438537598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010494355112314224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371314376592636,
      "backward_entropy": 0.09238986458097186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.850652694702148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010594041086733341,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371316909790039,
      "backward_entropy": 0.09221534218106951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.795365333557129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010693625546991825,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713154196739197,
      "backward_entropy": 0.09413152081625802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.513234615325928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010793586261570454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713183999061584,
      "backward_entropy": 0.09185479368482317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.969393253326416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010893176309764385,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713254034519196,
      "backward_entropy": 0.0938568115234375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.570572853088379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010992767289280891,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713239133358002,
      "backward_entropy": 0.09147960799080986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.789361953735352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011092635802924633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713234663009644,
      "backward_entropy": 0.09403660467692784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.106799125671387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011192912235856056,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713175058364868,
      "backward_entropy": 0.09108625139508929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.77782154083252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011293729767203331,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13713064789772034,
      "backward_entropy": 0.09375817435128349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.231618881225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011394796893000603,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13712982833385468,
      "backward_entropy": 0.0931201662336077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.827152729034424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011495851911604404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712824881076813,
      "backward_entropy": 0.0934661797114781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.141592979431152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011596606113016605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712698221206665,
      "backward_entropy": 0.09024182387760707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62826156616211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011697269044816494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371259093284607,
      "backward_entropy": 0.09316229820251465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.435738563537598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011798102408647537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712525367736816,
      "backward_entropy": 0.08979329041072301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.83941650390625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011899003759026527,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712464272975922,
      "backward_entropy": 0.09284470762525286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.515639305114746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011999636888504028,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712400197982788,
      "backward_entropy": 0.09268108436039516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.70512580871582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012099269777536392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712365925312042,
      "backward_entropy": 0.08908926589148385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.499003410339355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01219925470650196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137123242020607,
      "backward_entropy": 0.08884673459189278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.247852325439453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012299510650336742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371217519044876,
      "backward_entropy": 0.08859978403363909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.366710662841797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012399828061461449,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13711988925933838,
      "backward_entropy": 0.08834839718682426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.73189115524292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012500817887485027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13711775839328766,
      "backward_entropy": 0.09181262765611921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.545285701751709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012601467780768871,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371157467365265,
      "backward_entropy": 0.09093262468065534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654178619384766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012701730243861675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137113556265831,
      "backward_entropy": 0.09144282341003418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.584234237670898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012802264653146267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711123168468475,
      "backward_entropy": 0.09051509414400373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.443099021911621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012902457267045975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13710863888263702,
      "backward_entropy": 0.09105822018214635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.190908432006836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013002833351492882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13710567355155945,
      "backward_entropy": 0.09085965156555176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.13134765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013103189878165722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13710293173789978,
      "backward_entropy": 0.09065704686301095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8832197189331055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013202945701777935,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13710014522075653,
      "backward_entropy": 0.08616374220166888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.40632438659668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013301979750394821,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709798455238342,
      "backward_entropy": 0.08587318658828735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259757041931152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013400714844465256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709565997123718,
      "backward_entropy": 0.08557897806167603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.485173225402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013499626889824867,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709376752376556,
      "backward_entropy": 0.08889658110482353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.341243267059326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01359941903501749,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13709183037281036,
      "backward_entropy": 0.08864382335117885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.705234050750732,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013698793947696686,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13708969950675964,
      "backward_entropy": 0.08838747228894915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5295257568359375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013797366991639137,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13708829879760742,
      "backward_entropy": 0.08812623364584786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.35414457321167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013895752839744091,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708674907684326,
      "backward_entropy": 0.08400556870869227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.714743137359619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013993843458592892,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370854377746582,
      "backward_entropy": 0.08865143571581159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.456254005432129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01409128587692976,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13708460330963135,
      "backward_entropy": 0.08731515066964286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6613922119140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014188621193170547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370835304260254,
      "backward_entropy": 0.08302727767399379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.548925399780273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014285974204540253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708235323429108,
      "backward_entropy": 0.08269073281969343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.518634796142578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014383881352841854,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13708071410655975,
      "backward_entropy": 0.08646200384412493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.882350444793701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014482268132269382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707862794399261,
      "backward_entropy": 0.08738418987819127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.757759094238281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014580699615180492,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707637786865234,
      "backward_entropy": 0.08711441925593785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.747160911560059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014679656364023685,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707420229911804,
      "backward_entropy": 0.08555884872164045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.088878631591797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014778506010770798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707199692726135,
      "backward_entropy": 0.08090053285871233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.057329177856445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014877433888614178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707004487514496,
      "backward_entropy": 0.08052095345088414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.502193927764893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014976464211940765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13706767559051514,
      "backward_entropy": 0.08598307200840541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.249440670013428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015075208619236946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370655596256256,
      "backward_entropy": 0.08568860803331647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.848750591278076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015173555351793766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370636373758316,
      "backward_entropy": 0.07935030119759696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.968103408813477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01527128554880619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370622217655182,
      "backward_entropy": 0.0850888660975865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.946318626403809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015368564985692501,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706088066101074,
      "backward_entropy": 0.08324941567012242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1956634521484375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015465478412806988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705898821353912,
      "backward_entropy": 0.07815095356532506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.225969314575195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01556217297911644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370570808649063,
      "backward_entropy": 0.08415929760251727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8544392585754395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015658654272556305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13705553114414215,
      "backward_entropy": 0.08384054899215698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.968317031860352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01575480028986931,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370534747838974,
      "backward_entropy": 0.08351715121950422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.360721111297607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015851356089115143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705040514469147,
      "backward_entropy": 0.07649414028440203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.741638660430908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015947895124554634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704673945903778,
      "backward_entropy": 0.08285048178264073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0069403648376465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016043975949287415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704326748847961,
      "backward_entropy": 0.07563889026641846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.327753067016602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016139870509505272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703911006450653,
      "backward_entropy": 0.07520650965826851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.186112403869629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016235819086432457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703426718711853,
      "backward_entropy": 0.07476856027330671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.233450889587402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016332333907485008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702860474586487,
      "backward_entropy": 0.0743201460157122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.382742881774902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016428733244538307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702282309532166,
      "backward_entropy": 0.07386598416737147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.585882186889648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016524527221918106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701701164245605,
      "backward_entropy": 0.08072585718972343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.712997913360596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01662112958729267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370105743408203,
      "backward_entropy": 0.08035108872822352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.816550254821777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016717299818992615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700412213802338,
      "backward_entropy": 0.07997242041996547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.020458698272705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016813773661851883,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699722290039062,
      "backward_entropy": 0.07958737441471644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.719501972198486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016909362748265266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699087500572205,
      "backward_entropy": 0.07151937484741211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.288337707519531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01700461097061634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698461651802063,
      "backward_entropy": 0.07103862507002694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.854677200317383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017099296674132347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697850704193115,
      "backward_entropy": 0.07632262366158622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.125482559204102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01719387248158455,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697198033332825,
      "backward_entropy": 0.07589840888977051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.745019435882568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01728849671781063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13696515560150146,
      "backward_entropy": 0.0695785539490836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.083897590637207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017382901161909103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13695847988128662,
      "backward_entropy": 0.06908077001571655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.177470684051514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017476018518209457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13695292174816132,
      "backward_entropy": 0.06858922328267779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.953042984008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017569374293088913,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369468867778778,
      "backward_entropy": 0.07414990663528442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.824520587921143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017662083730101585,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13694164156913757,
      "backward_entropy": 0.07595007760184151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4776458740234375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017754845321178436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693606853485107,
      "backward_entropy": 0.0670767171042306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.096742153167725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0178474560379982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13693013787269592,
      "backward_entropy": 0.07509544066020421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.217635631561279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017940301448106766,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13692381978034973,
      "backward_entropy": 0.0660414525440761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.630954742431641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0180327370762825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13691793382167816,
      "backward_entropy": 0.06551551818847656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.261972904205322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01812513917684555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13691169023513794,
      "backward_entropy": 0.07377724136625018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.530194282531738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018217243254184723,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369054913520813,
      "backward_entropy": 0.07332984038761683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.667214870452881,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01830928772687912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13689890503883362,
      "backward_entropy": 0.0728773900440761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.452033042907715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01840074732899666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13689225912094116,
      "backward_entropy": 0.07242156778063093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.346097469329834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01849145069718361,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688626885414124,
      "backward_entropy": 0.06283881408827645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.808919906616211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018582846969366074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687869906425476,
      "backward_entropy": 0.062292286327907016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.408605575561523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018673798069357872,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136870875954628,
      "backward_entropy": 0.07103016546794347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9814910888671875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018764778971672058,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368623822927475,
      "backward_entropy": 0.0679714126246316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.702761650085449,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01885545440018177,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13685384392738342,
      "backward_entropy": 0.07007879870278495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.109946250915527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018946407362818718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13684433698654175,
      "backward_entropy": 0.06959507295063563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.756129264831543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019037164747714996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683456182479858,
      "backward_entropy": 0.06910676615578788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.199640274047852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01912747509777546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13682496547698975,
      "backward_entropy": 0.06861441476004464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.165805816650391,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019217776134610176,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13681462407112122,
      "backward_entropy": 0.06545149428503853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.342194080352783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01930728182196617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13680483400821686,
      "backward_entropy": 0.05782077993665423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.646364212036133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019396211951971054,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136795312166214,
      "backward_entropy": 0.06711781876427787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.839463710784912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01948488876223564,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13678541779518127,
      "backward_entropy": 0.06391356672559466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.502330303192139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019573455676436424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13677507638931274,
      "backward_entropy": 0.0561305752822331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.676540851593018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019660944119095802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676583766937256,
      "backward_entropy": 0.0555738593850817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.082742691040039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01974841207265854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367558240890503,
      "backward_entropy": 0.0650806086403983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3319010734558105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0198353361338377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367460936307907,
      "backward_entropy": 0.05445836271558489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.316032886505127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01992194727063179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673631846904755,
      "backward_entropy": 0.053899015699114115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.516520977020264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020008325576782227,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672620058059692,
      "backward_entropy": 0.06081071070262364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.745387077331543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020094580948352814,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13671573996543884,
      "backward_entropy": 0.052774207932608466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.608680248260498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02018013969063759,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367058902978897,
      "backward_entropy": 0.059757036822182794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.233633041381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020264990627765656,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13669659197330475,
      "backward_entropy": 0.05922930581229074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.806314945220947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020349739119410515,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13668671250343323,
      "backward_entropy": 0.05870029330253601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.51115083694458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02043483406305313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667550683021545,
      "backward_entropy": 0.05052616340773446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.295746326446533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020519215613603592,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13666482269763947,
      "backward_entropy": 0.060336947441101074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.501580715179443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020603539422154427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665355741977692,
      "backward_entropy": 0.05979949235916138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.212591171264648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020687161013484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13664281368255615,
      "backward_entropy": 0.048831126519611905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8360915184021,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020769992843270302,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13663271069526672,
      "backward_entropy": 0.05600904566901071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.316556930541992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02085258811712265,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13662226498126984,
      "backward_entropy": 0.05818884287561689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.640958309173584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020934555679559708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366121768951416,
      "backward_entropy": 0.047159084251948764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.507940292358398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021016249433159828,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13660171627998352,
      "backward_entropy": 0.05438345670700073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.281839847564697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021097617223858833,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13659095764160156,
      "backward_entropy": 0.053842050688607354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.589028358459473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0211793165653944,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13657866418361664,
      "backward_entropy": 0.05601743289402553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.092350006103516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021260734647512436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365659534931183,
      "backward_entropy": 0.04492985776492527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.658382415771484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021341489627957344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365535855293274,
      "backward_entropy": 0.054921669619424004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.456791877746582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02142210118472576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13654053211212158,
      "backward_entropy": 0.0543739242213113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.636035442352295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02150246500968933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365268975496292,
      "backward_entropy": 0.04325858610016959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.209701061248779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02158275619149208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13651230931282043,
      "backward_entropy": 0.042697791542325704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2250688076019287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02166263572871685,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364974081516266,
      "backward_entropy": 0.04214032632963998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.541780471801758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021741246804594994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13648435473442078,
      "backward_entropy": 0.05217771019254412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.306761264801025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021819939836859703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13646993041038513,
      "backward_entropy": 0.041050263813563755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7448315620422363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02189849503338337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13645455241203308,
      "backward_entropy": 0.04050394466945103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.685643434524536,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02197638712823391,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364394724369049,
      "backward_entropy": 0.05053300942693438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7798662185668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022053634747862816,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13642463088035583,
      "backward_entropy": 0.04732888085501535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5097992420196533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022130446508526802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13640964031219482,
      "backward_entropy": 0.04944495643888201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2454118728637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022206589579582214,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13639503717422485,
      "backward_entropy": 0.04627131564276559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.070975303649902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02228284627199173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13637882471084595,
      "backward_entropy": 0.048359496252877374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.238571882247925,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022359054535627365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13636136054992676,
      "backward_entropy": 0.03731929404394967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4294869899749756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02243436872959137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13634470105171204,
      "backward_entropy": 0.047273831708090644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5723729133605957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02250911481678486,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13632813096046448,
      "backward_entropy": 0.044174398694719584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5988354682922363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022583484649658203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13631106913089752,
      "backward_entropy": 0.04620099067687988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3961856365203857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02265762723982334,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13629338145256042,
      "backward_entropy": 0.0431444559778486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.049842357635498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022731315344572067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13627547025680542,
      "backward_entropy": 0.045130014419555664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.852776288986206,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022804224863648415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13625821471214294,
      "backward_entropy": 0.044600073780332296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3532233238220215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02287622168660164,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13624195754528046,
      "backward_entropy": 0.041631111076899936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.876830577850342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022947967052459717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362248957157135,
      "backward_entropy": 0.043552394424165995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6003613471984863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023019002750515938,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362084299325943,
      "backward_entropy": 0.04303268449647086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.345343828201294,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023089056834578514,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361932009458542,
      "backward_entropy": 0.04015923823629107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.675318479537964,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023159105330705643,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13617652654647827,
      "backward_entropy": 0.03967684081622532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.967435359954834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023228341713547707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13616043329238892,
      "backward_entropy": 0.03143852523394993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0415821075439453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02329718880355358,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13614368438720703,
      "backward_entropy": 0.04099265592438834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.72055983543396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023365743458271027,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13612580299377441,
      "backward_entropy": 0.03824715954916818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.507756233215332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0234337467700243,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361078917980194,
      "backward_entropy": 0.037772923707962036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6095266342163086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023500937968492508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13609041273593903,
      "backward_entropy": 0.029636919498443604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3595564365386963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023567596450448036,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13607285916805267,
      "backward_entropy": 0.03683594720704215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.62353777885437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023633437231183052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360558718442917,
      "backward_entropy": 0.02877157287938254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2580764293670654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023698873817920685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13603821396827698,
      "backward_entropy": 0.03805388297353472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.740554094314575,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023763496428728104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13602110743522644,
      "backward_entropy": 0.037581724779946465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0465574264526367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023828020319342613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13600245118141174,
      "backward_entropy": 0.03711092472076416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2596025466918945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023891551420092583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359848529100418,
      "backward_entropy": 0.027101763657161167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3512539863586426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02395445480942726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13596710562705994,
      "backward_entropy": 0.026698565908840725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.192013740539551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02401694655418396,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13594865798950195,
      "backward_entropy": 0.03368909018380301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.383681297302246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02407885529100895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13592997193336487,
      "backward_entropy": 0.03528668625014169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1987738609313965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02414054051041603,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13591010868549347,
      "backward_entropy": 0.03282718999045236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1468935012817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024201709777116776,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13588951528072357,
      "backward_entropy": 0.03240118707929339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.856964349746704,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02426235005259514,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13586825132369995,
      "backward_entropy": 0.03396150044032505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9700208902359009,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024322176352143288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13584759831428528,
      "backward_entropy": 0.024362638592720032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0213308334350586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0243814829736948,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13582690060138702,
      "backward_entropy": 0.03310424940926688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9120290279388428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02444036491215229,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13580551743507385,
      "backward_entropy": 0.023626340287072316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.61384117603302,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024498673155903816,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13578370213508606,
      "backward_entropy": 0.030349303569112505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7189465761184692,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02455606870353222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13576290011405945,
      "backward_entropy": 0.031852155923843384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7388414144515991,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024612855166196823,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1357424110174179,
      "backward_entropy": 0.029571367161614553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.516480565071106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024669067934155464,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357216238975525,
      "backward_entropy": 0.031043299606868198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4488089084625244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024724457412958145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13570167124271393,
      "backward_entropy": 0.030647460903440202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3479325771331787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024778978899121284,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1356825828552246,
      "backward_entropy": 0.02845152573926108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.487932562828064,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024832621216773987,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13566485047340393,
      "backward_entropy": 0.028093646679605757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.603973388671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024885565042495728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13564682006835938,
      "backward_entropy": 0.020945282919066294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6698747873306274,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024938149377703667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13562776148319244,
      "backward_entropy": 0.029125839471817017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6443896293640137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02499050833284855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356070637702942,
      "backward_entropy": 0.02033099745001112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.170175552368164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025042707100510597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1355850100517273,
      "backward_entropy": 0.020026321922029768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.140985131263733,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02509390562772751,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13556426763534546,
      "backward_entropy": 0.02635659490312849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1296656131744385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025144096463918686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13554446399211884,
      "backward_entropy": 0.019443073443004062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3151524066925049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025193380191922188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13552545011043549,
      "backward_entropy": 0.027329238397734507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2992825508117676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025242166593670845,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355055719614029,
      "backward_entropy": 0.025380794491086687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1735872030258179,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025290504097938538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13548484444618225,
      "backward_entropy": 0.01861196117741721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.179399013519287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025338171049952507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13546380400657654,
      "backward_entropy": 0.01834279085908617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.255285620689392,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02538529597222805,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354423314332962,
      "backward_entropy": 0.018077818410737172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.982980489730835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02543208748102188,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13541966676712036,
      "backward_entropy": 0.025664874485560825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9087461829185486,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025478020310401917,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353975385427475,
      "backward_entropy": 0.023844723190580095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3553649187088013,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02552304044365883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353762447834015,
      "backward_entropy": 0.01731052143233163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.095790147781372,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025568179786205292,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13535219430923462,
      "backward_entropy": 0.02326511059488569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0791075229644775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02561287023127079,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13532719016075134,
      "backward_entropy": 0.02297979167529515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1019666194915771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025657154619693756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13530123233795166,
      "backward_entropy": 0.01656923017331532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.876564621925354,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025701144710183144,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352739930152893,
      "backward_entropy": 0.023822848285947527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9104799628257751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025744229555130005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13524658977985382,
      "backward_entropy": 0.016091569193771908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9043614864349365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02578667923808098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13521873950958252,
      "backward_entropy": 0.02324830208505903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8301840424537659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025828661397099495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13519039750099182,
      "backward_entropy": 0.022967117173331126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0007615089416504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025869978591799736,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13516192138195038,
      "backward_entropy": 0.015411218362195151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7194493412971497,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025911172851920128,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1351318359375,
      "backward_entropy": 0.022417132343564714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.74819016456604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025951415300369263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13510185480117798,
      "backward_entropy": 0.022150814533233643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6569561958312988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025990979745984077,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13507188856601715,
      "backward_entropy": 0.014765079532350813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6402994990348816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602972835302353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350427269935608,
      "backward_entropy": 0.014560367379869734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6851102709770203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02606763318181038,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1350138932466507,
      "backward_entropy": 0.014361259128366197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5957891941070557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026104969903826714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13498499989509583,
      "backward_entropy": 0.014166200799601418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6153472065925598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026141485199332237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13495653867721558,
      "backward_entropy": 0.02090126701763698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5036313533782959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026177331805229187,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1349279284477234,
      "backward_entropy": 0.01949447180543627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45064061880111694,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02621219865977764,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13489997386932373,
      "backward_entropy": 0.020441089357648577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48455360531806946,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02624610625207424,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1348734200000763,
      "backward_entropy": 0.01908499641077859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5435198545455933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026279395446181297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1348482221364975,
      "backward_entropy": 0.013271724539143699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4704555869102478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026312168687582016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13482257723808289,
      "backward_entropy": 0.013107265744890486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5387000441551208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634417451918125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347968578338623,
      "backward_entropy": 0.01294719853571483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4635152816772461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026375699788331985,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13476985692977905,
      "backward_entropy": 0.01832673805100577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4865604043006897,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026406653225421906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13474293053150177,
      "backward_entropy": 0.01918432116508484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48487186431884766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02643711306154728,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1347152292728424,
      "backward_entropy": 0.018989771604537964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41471603512763977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026467083021998405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1346863955259323,
      "backward_entropy": 0.01879931560584477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4881538152694702,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026496367529034615,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13465724885463715,
      "backward_entropy": 0.017631596752575467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3776775598526001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026525355875492096,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13462677597999573,
      "backward_entropy": 0.017466204507010325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29419922828674316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026553701609373093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13459652662277222,
      "backward_entropy": 0.018252913440976824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39743226766586304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026581164449453354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13456761837005615,
      "backward_entropy": 0.011771778975214277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27965912222862244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026608223095536232,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13453808426856995,
      "backward_entropy": 0.017910523074013845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38091686367988586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026634380221366882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13450929522514343,
      "backward_entropy": 0.01774682743208749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30766192078590393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02666027843952179,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13447995483875275,
      "backward_entropy": 0.017585033816950663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25995758175849915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02668553777039051,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13445062935352325,
      "backward_entropy": 0.01742764243057796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2729026675224304,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02671004831790924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13442206382751465,
      "backward_entropy": 0.011148808257920402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3366039991378784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02673395909368992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1343938112258911,
      "backward_entropy": 0.011034964450768061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26913511753082275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02675759047269821,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13436436653137207,
      "backward_entropy": 0.010922357439994812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2724883258342743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026780517771840096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1343342810869217,
      "backward_entropy": 0.010813048907688685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24278661608695984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026803098618984222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343044638633728,
      "backward_entropy": 0.016699086342539107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22238346934318542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682504430413246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13427451252937317,
      "backward_entropy": 0.010601623782089778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3030865490436554,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026846367865800858,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1342448890209198,
      "backward_entropy": 0.016432917543819973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24695247411727905,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026867616921663284,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13421399891376495,
      "backward_entropy": 0.015589678926127297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21299467980861664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02688835747539997,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13418230414390564,
      "backward_entropy": 0.015480271407536097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26320359110832214,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02690853364765644,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1341506391763687,
      "backward_entropy": 0.015374521059649331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19993799924850464,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026928668841719627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341184377670288,
      "backward_entropy": 0.010109569345201765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19294041395187378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026948487386107445,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13408714532852173,
      "backward_entropy": 0.015810038362230574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21960626542568207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026967765763401985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13405591249465942,
      "backward_entropy": 0.009925812482833862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23350858688354492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026986852288246155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13402436673641205,
      "backward_entropy": 0.01557708638054984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24466480314731598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027005786076188087,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1339917629957199,
      "backward_entropy": 0.009747603109904699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19657838344573975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02702454663813114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13395731151103973,
      "backward_entropy": 0.009659170040062495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1525825560092926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027042776346206665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13392192125320435,
      "backward_entropy": 0.009573041328362055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1614280343055725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027060531079769135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13388749957084656,
      "backward_entropy": 0.015134451644761222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18405230343341827,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02707766555249691,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13385272026062012,
      "backward_entropy": 0.015032017869608743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16576740145683289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027094686403870583,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13381731510162354,
      "backward_entropy": 0.009329591478620256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11900787800550461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027111457660794258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13378176093101501,
      "backward_entropy": 0.00925131035702569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10240474343299866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027127644047141075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13374653458595276,
      "backward_entropy": 0.009176268109253474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13695132732391357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027143005281686783,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13371194899082184,
      "backward_entropy": 0.014181723552090781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1500675231218338,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027158012613654137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133677139878273,
      "backward_entropy": 0.014552989176341466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16092398762702942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027172876521945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13364170491695404,
      "backward_entropy": 0.008967466652393341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16296285390853882,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027187630534172058,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1336049735546112,
      "backward_entropy": 0.014377267232963018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12524649500846863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0272023007273674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13356676697731018,
      "backward_entropy": 0.014290784086499895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1277933418750763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02721639908850193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13352787494659424,
      "backward_entropy": 0.014207810163497925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0733860582113266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723030559718609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13348878920078278,
      "backward_entropy": 0.008700740124498094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09847545623779297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027243247255682945,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13345074653625488,
      "backward_entropy": 0.014049839760575975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09606514871120453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027255645021796227,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13341274857521057,
      "backward_entropy": 0.01397669528211866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0718872994184494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027267422527074814,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13337451219558716,
      "backward_entropy": 0.013589649328163691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06379373371601105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727861888706684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13333742320537567,
      "backward_entropy": 0.008475754410028458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07423403114080429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027289168909192085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333015412092209,
      "backward_entropy": 0.00842674555523055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10791641473770142,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729921229183674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332661360502243,
      "backward_entropy": 0.008380024560860224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08994907885789871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027309061959385872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332293152809143,
      "backward_entropy": 0.008333780935832433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09421321749687195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027318812906742096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13319236040115356,
      "backward_entropy": 0.008288005633013589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07316261529922485,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027328401803970337,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1331547498703003,
      "backward_entropy": 0.013544521161488124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07025349885225296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027337444946169853,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13311710953712463,
      "backward_entropy": 0.008199944027832575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07956039905548096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027346022427082062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13307958841323853,
      "backward_entropy": 0.008159049387489046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08477655053138733,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027354488149285316,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13304190337657928,
      "backward_entropy": 0.013221599161624908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07239320129156113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027363015338778496,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13300378620624542,
      "backward_entropy": 0.008077995053359441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05953501909971237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02737148478627205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13296586275100708,
      "backward_entropy": 0.008037688476698739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06754173338413239,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027379609644412994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1329285204410553,
      "backward_entropy": 0.013118912066732134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05898561701178551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027387674897909164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13289134204387665,
      "backward_entropy": 0.00796067395380565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07221204787492752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027395080775022507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13285398483276367,
      "backward_entropy": 0.007925014410700117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05682159215211868,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027402319014072418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328158974647522,
      "backward_entropy": 0.013104693165847234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03967618569731712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027409305796027184,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1327781081199646,
      "backward_entropy": 0.013003083212035043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06620657444000244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02741587720811367,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13274168968200684,
      "backward_entropy": 0.012978923107896532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06265848875045776,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027422310784459114,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1327044814825058,
      "backward_entropy": 0.012984695179121835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04849143698811531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027428820729255676,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1326669305562973,
      "backward_entropy": 0.012931272387504578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053290367126464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027435000985860825,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13262973725795746,
      "backward_entropy": 0.01290890680892127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054433561861515045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027441121637821198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325925886631012,
      "backward_entropy": 0.007700120764119285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05708391219377518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027447087690234184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13255515694618225,
      "backward_entropy": 0.0076706090143748695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0530363954603672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027452770620584488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325169950723648,
      "backward_entropy": 0.007642100432089397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05891568213701248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027458392083644867,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13247856497764587,
      "backward_entropy": 0.007613818560327802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0627250149846077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02746410295367241,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13243934512138367,
      "backward_entropy": 0.007585075816937855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0472729317843914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027469953522086143,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13239893317222595,
      "backward_entropy": 0.012783992503370558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037418998777866364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02747535891830921,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1323584020137787,
      "backward_entropy": 0.012667374951498849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04137900471687317,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0274805948138237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13231875002384186,
      "backward_entropy": 0.012636054839406694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05038364604115486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027485741302371025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13227945566177368,
      "backward_entropy": 0.007474792322942189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.047613535076379776,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027490820735692978,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.132239431142807,
      "backward_entropy": 0.012712485023907252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03761809319257736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027495555579662323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13219884037971497,
      "backward_entropy": 0.0074237436056137085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042311891913414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027500208467245102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13215871155261993,
      "backward_entropy": 0.007399334971393857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029805220663547516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02750442549586296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13211828470230103,
      "backward_entropy": 0.007376583559172494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03865119814872742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027508366852998734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1320788860321045,
      "backward_entropy": 0.01246855833700725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035647258162498474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02751214988529682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13203942775726318,
      "backward_entropy": 0.007334315351077488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041806407272815704,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027515746653079987,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13200007379055023,
      "backward_entropy": 0.012422752167497362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03155244514346123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027519484981894493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13196012377738953,
      "backward_entropy": 0.007293582494769778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031132198870182037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027522917836904526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13192060589790344,
      "backward_entropy": 0.012378331805978502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036748968064785004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027526138350367546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318815052509308,
      "backward_entropy": 0.007255745785576957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031469136476516724,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027528835460543633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1318419873714447,
      "backward_entropy": 0.01234033384493419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027659812942147255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02753148041665554,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13180266320705414,
      "backward_entropy": 0.012322955897876195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023637225851416588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02753407694399357,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13176389038562775,
      "backward_entropy": 0.012607257281030928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030191289260983467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027536490932106972,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13172608613967896,
      "backward_entropy": 0.012289873191288539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03390328958630562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027538757771253586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1316882073879242,
      "backward_entropy": 0.012274608016014099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027605511248111725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754104509949684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1316496729850769,
      "backward_entropy": 0.0071628886674131665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024137768894433975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02754335291683674,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13161131739616394,
      "backward_entropy": 0.01224392546074731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031315892934799194,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027545612305402756,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13157348334789276,
      "backward_entropy": 0.012597394841057914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02157764323055744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02754799835383892,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13153503835201263,
      "backward_entropy": 0.012213297188282013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025889791548252106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027550287544727325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1314973384141922,
      "backward_entropy": 0.007104534123625074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019329916685819626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0275524090975523,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13145966827869415,
      "backward_entropy": 0.012184096234185355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025576652958989143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02755429595708847,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1314229667186737,
      "backward_entropy": 0.007078126072883606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019520120695233345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02755625732243061,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13138599693775177,
      "backward_entropy": 0.012157886156014033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025690168142318726,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027558019384741783,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13134975731372833,
      "backward_entropy": 0.012588042233671461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01744508557021618,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027559584006667137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13131314516067505,
      "backward_entropy": 0.012134373188018799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022338252514600754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027561014518141747,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1312774121761322,
      "backward_entropy": 0.0070309995540550774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02153620682656765,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027562281116843224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13124166429042816,
      "backward_entropy": 0.007020927433456693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01897376962006092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027563512325286865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13120588660240173,
      "backward_entropy": 0.0070109862302030835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01862054318189621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756471373140812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13117043673992157,
      "backward_entropy": 0.007001224905252457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021224245429039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02756582945585251,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13113532960414886,
      "backward_entropy": 0.012603646942547389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02139347232878208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756677195429802,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13110004365444183,
      "backward_entropy": 0.006983140749590737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018346598371863365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02756763994693756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13106444478034973,
      "backward_entropy": 0.006974672100373677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022249558940529823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027568364515900612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13102906942367554,
      "backward_entropy": 0.0069667814033372065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018958767876029015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02756926789879799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13099297881126404,
      "backward_entropy": 0.012056181473391396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015865562483668327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027570072561502457,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13095688819885254,
      "backward_entropy": 0.006949853152036667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016748230904340744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027570821344852448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13092130422592163,
      "backward_entropy": 0.012041975344930376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0169932022690773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757161669433117,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13088588416576385,
      "backward_entropy": 0.01203484833240509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014816449955105782,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572475373744965,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13085046410560608,
      "backward_entropy": 0.012027442455291748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013878765515983105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027573443949222565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13081541657447815,
      "backward_entropy": 0.006916858788047518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013961972668766975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027574436739087105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1307808756828308,
      "backward_entropy": 0.01201166638306209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01299304235726595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757551707327366,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13074655830860138,
      "backward_entropy": 0.012003383466175624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013503016903996468,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757643535733223,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13071240484714508,
      "backward_entropy": 0.01199592649936676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013931519351899624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027577344328165054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13067829608917236,
      "backward_entropy": 0.0068831901465143475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012187532149255276,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027578379958868027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1306440830230713,
      "backward_entropy": 0.011980601719447545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012010861188173294,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02757936902344227,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13061022758483887,
      "backward_entropy": 0.011972901012216295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015597783960402012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02758042700588703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13057665526866913,
      "backward_entropy": 0.011964949113982064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010669131763279438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027581321075558662,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13054248690605164,
      "backward_entropy": 0.011957755046231406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010655608959496021,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027582155540585518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1305088996887207,
      "backward_entropy": 0.006842260914189475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009946717880666256,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02758299931883812,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1304757297039032,
      "backward_entropy": 0.012672762785639082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00973673164844513,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027583936229348183,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1304430216550827,
      "backward_entropy": 0.012674595628465925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011427889578044415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02758469618856907,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13041093945503235,
      "backward_entropy": 0.012677493904318129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00735370721668005,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027585327625274658,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1303788721561432,
      "backward_entropy": 0.012681217065879278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010610920377075672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027585886418819427,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13034790754318237,
      "backward_entropy": 0.01268518396786281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010512810200452805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027586378157138824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13031692802906036,
      "backward_entropy": 0.006801389157772064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007708812598139048,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027586767449975014,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13028596341609955,
      "backward_entropy": 0.012694613209792547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009729627519845963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027587300166487694,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13025566935539246,
      "backward_entropy": 0.0119049038205828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00782140251249075,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02758786641061306,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1302253007888794,
      "backward_entropy": 0.012701990348952157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009206246584653854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027588430792093277,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13019545376300812,
      "backward_entropy": 0.011894496423857552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008233732543885708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027588924393057823,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13016563653945923,
      "backward_entropy": 0.012709201446601323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008505415171384811,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02758941613137722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13013602793216705,
      "backward_entropy": 0.006766916385718754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009509047493338585,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027589881792664528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13010656833648682,
      "backward_entropy": 0.01188020408153534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00813186913728714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02759038656949997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13007675111293793,
      "backward_entropy": 0.006755761802196503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007336566690355539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027590913698077202,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1300469934940338,
      "backward_entropy": 0.012723782232829503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007359236478805542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02759157121181488,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13001739978790283,
      "backward_entropy": 0.011864902717726571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0066899401135742664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027592217549681664,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12998802959918976,
      "backward_entropy": 0.012728450553757804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006992849987000227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02759273536503315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12995918095111847,
      "backward_entropy": 0.006732316421610969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007310381159186363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027593301609158516,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12993046641349792,
      "backward_entropy": 0.011849648186138697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005594564601778984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02759380266070366,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12990179657936096,
      "backward_entropy": 0.012737345482621874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007462652865797281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027594292536377907,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12987375259399414,
      "backward_entropy": 0.012740338487284524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006715260911732912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0275946706533432,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12984558939933777,
      "backward_entropy": 0.012744152120181493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006675181910395622,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027595046907663345,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12981745600700378,
      "backward_entropy": 0.012747918920857566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004719317425042391,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027595387771725655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1297893226146698,
      "backward_entropy": 0.00670156574675015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006130876485258341,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02759571559727192,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12976202368736267,
      "backward_entropy": 0.011824625943388258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0054925959557294846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027596089988946915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12973469495773315,
      "backward_entropy": 0.011820657977036067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00518456706777215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02759638801217079,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12970778346061707,
      "backward_entropy": 0.012763283082417079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005195845849812031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027596693485975266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12968119978904724,
      "backward_entropy": 0.011813475617340632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004996879957616329,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02759701758623123,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12965479493141174,
      "backward_entropy": 0.011809820575373513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0050164819695055485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027597270905971527,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1296287178993225,
      "backward_entropy": 0.006674934710775103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004528867546468973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027597514912486076,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12960284948349,
      "backward_entropy": 0.012778805834906442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004406079649925232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027597686275839806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1295773983001709,
      "backward_entropy": 0.011800409427710943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004532669670879841,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027597913518548012,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1295521855354309,
      "backward_entropy": 0.011797304664339339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004391343332827091,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02759801223874092,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12952734529972076,
      "backward_entropy": 0.012792051902839116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004256902728229761,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02759803831577301,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12950283288955688,
      "backward_entropy": 0.012797318398952484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003590932348743081,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02759811282157898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12947843968868256,
      "backward_entropy": 0.011790367109434945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032155318185687065,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027598265558481216,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12945441901683807,
      "backward_entropy": 0.01280639214175088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004222089424729347,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027598464861512184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12943094968795776,
      "backward_entropy": 0.011784854744161879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028824196197092533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027598578482866287,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12940752506256104,
      "backward_entropy": 0.012814434511320931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003487762063741684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027598803862929344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12938466668128967,
      "backward_entropy": 0.006640117083277021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003605562262237072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02759900875389576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.129362091422081,
      "backward_entropy": 0.01177666655608586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003059412119910121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027599144726991653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12933969497680664,
      "backward_entropy": 0.0066335318343979975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037896621506661177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027599217370152473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1293177604675293,
      "backward_entropy": 0.006630693695374897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021192918065935373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027599237859249115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12929575145244598,
      "backward_entropy": 0.006628027984074184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025539377238601446,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027599375694990158,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1292744278907776,
      "backward_entropy": 0.012837844235556466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022878171876072884,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027599532157182693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1292535662651062,
      "backward_entropy": 0.006622004189661571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022801111917942762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02759968675673008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12923331558704376,
      "backward_entropy": 0.006619081433330264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022030670661479235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027599912136793137,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12921345233917236,
      "backward_entropy": 0.006615989974566868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016136245103552938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760019712150097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1291939914226532,
      "backward_entropy": 0.006612675530569894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002365151420235634,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027600549161434174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12917527556419373,
      "backward_entropy": 0.006609221122094563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001741076703183353,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027600975707173347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12915652990341187,
      "backward_entropy": 0.012852157865251814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023815748281776905,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027601443231105804,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1291383057832718,
      "backward_entropy": 0.012852760297911507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018894895911216736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027601832523941994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12912023067474365,
      "backward_entropy": 0.006598240030663354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021887323819100857,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027602292597293854,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12910234928131104,
      "backward_entropy": 0.0128544739314488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020873406901955605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027602728456258774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290845274925232,
      "backward_entropy": 0.011736035346984863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002448241226375103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027603108435869217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12906691431999207,
      "backward_entropy": 0.006587531417608261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015776025829836726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027603361755609512,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12904928624629974,
      "backward_entropy": 0.006584611322198596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017565555172041059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027603620663285255,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12903210520744324,
      "backward_entropy": 0.0065817322049822125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015624889638274908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760385163128376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290152370929718,
      "backward_entropy": 0.01172492333820888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018321669194847345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760406956076622,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1289987564086914,
      "backward_entropy": 0.011722507221358163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001916058361530304,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027604255825281143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12898236513137817,
      "backward_entropy": 0.011720224150589533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017996649257838726,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760443091392517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12896592915058136,
      "backward_entropy": 0.011718018778732844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014444635016843677,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027604559436440468,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1289495825767517,
      "backward_entropy": 0.012871077018124717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015707914717495441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604633942246437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12893372774124146,
      "backward_entropy": 0.006567048174994332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015149376122280955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604714035987854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12891799211502075,
      "backward_entropy": 0.006564977445772716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012032748199999332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760476991534233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12890248000621796,
      "backward_entropy": 0.006563023797103337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008697506855241954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604850009083748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1288873553276062,
      "backward_entropy": 0.006560994046075004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010183538543060422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760496363043785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12887287139892578,
      "backward_entropy": 0.0065589456685951775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015025661559775472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605077251791954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12885887920856476,
      "backward_entropy": 0.006556951041732516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00112305604852736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760516293346882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12884476780891418,
      "backward_entropy": 0.006555074027606419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006976316217333078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605224400758743,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12883101403713226,
      "backward_entropy": 0.011702577982630049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012362723937258124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760530821979046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12881793081760406,
      "backward_entropy": 0.011700996330806188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008913432830013335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605397626757622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1288047879934311,
      "backward_entropy": 0.00654978517975126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009918313007801771,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605518698692322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128791943192482,
      "backward_entropy": 0.011697678693703242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00104210851714015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605611830949783,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1287793517112732,
      "backward_entropy": 0.011696111943040575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009325235732831061,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760569378733635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12876689434051514,
      "backward_entropy": 0.006544527730771473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009287325665354729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605753391981125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12875469028949738,
      "backward_entropy": 0.006542975349085671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012025564210489392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605796232819557,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12874269485473633,
      "backward_entropy": 0.012907277260507857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012815649388357997,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605827897787094,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1287304162979126,
      "backward_entropy": 0.01290971998657499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005736960447393358,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605799958109856,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12871792912483215,
      "backward_entropy": 0.006538759384836469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006401050486601889,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760578691959381,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12870606780052185,
      "backward_entropy": 0.01291531856570925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007190785836428404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605801820755005,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1286945790052414,
      "backward_entropy": 0.00653618893453053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008811464067548513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760581485927105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12868337333202362,
      "backward_entropy": 0.006534951605967113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008720717160031199,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605794370174408,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128672257065773,
      "backward_entropy": 0.01168545229094369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006252778111957014,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605747804045677,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12866120040416718,
      "backward_entropy": 0.012925525861127036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007373965927399695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605721727013588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12865044176578522,
      "backward_entropy": 0.006531712732144764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000739137118216604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760571986436844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12863969802856445,
      "backward_entropy": 0.006530513720852988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006565918447449803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605682611465454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1286291480064392,
      "backward_entropy": 0.011681916458266122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004127658612560481,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605662122368813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12861868739128113,
      "backward_entropy": 0.011681028774806432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005216375575400889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605652809143066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1286087930202484,
      "backward_entropy": 0.006527382880449295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005362764350138605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605678886175156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12859904766082764,
      "backward_entropy": 0.011679051177842277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005250706453807652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605703100562096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12858954071998596,
      "backward_entropy": 0.006525115243026188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000629191636107862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605745941400528,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12858018279075623,
      "backward_entropy": 0.006523934326001576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007877126918174326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605775743722916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1285707950592041,
      "backward_entropy": 0.006522822060755321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006313456688076258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605757117271423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12856118381023407,
      "backward_entropy": 0.0065218572105680194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039040131377987564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605703100562096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1285516619682312,
      "backward_entropy": 0.0065210312604904175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003775062505155802,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605677023530006,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1285424530506134,
      "backward_entropy": 0.012952721544674464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004293589445296675,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605675160884857,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12853354215621948,
      "backward_entropy": 0.011672701154436384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041517603676766157,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760569378733635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1285247653722763,
      "backward_entropy": 0.01167174322264535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030451302882283926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605731040239334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12851615250110626,
      "backward_entropy": 0.011670723557472229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004530517035163939,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276058129966259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1285077929496765,
      "backward_entropy": 0.0065159233553068975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004390446993056685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605868875980377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284995675086975,
      "backward_entropy": 0.0065148334418024334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002730758860707283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605904266238213,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12849144637584686,
      "backward_entropy": 0.012962736189365387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036858138628304005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605963870882988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284836381673813,
      "backward_entropy": 0.006512793047087533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004669218324124813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760600484907627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12847600877285004,
      "backward_entropy": 0.006511831390006202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003212677256669849,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606045827269554,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12846818566322327,
      "backward_entropy": 0.012967129903180259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00037396984407678246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760607935488224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1284606158733368,
      "backward_entropy": 0.006509935217244285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004556274798233062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606111019849777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1284530758857727,
      "backward_entropy": 0.011662575815405165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026132751372642815,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760610356926918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12844546139240265,
      "backward_entropy": 0.011661837143557412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003257655771449208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760610170662403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12843815982341766,
      "backward_entropy": 0.006507497813020434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030563276959583163,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760608121752739,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12843100726604462,
      "backward_entropy": 0.012975538415568215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003651695151347667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606070041656494,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12842392921447754,
      "backward_entropy": 0.011659754174096244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026082375552505255,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760603092610836,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12841689586639404,
      "backward_entropy": 0.012979225388595037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017668203508947045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605997398495674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12841004133224487,
      "backward_entropy": 0.006504871483360018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003283898113295436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760598622262478,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12840352952480316,
      "backward_entropy": 0.012982742062636785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023995741503313184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760596200823784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1283969283103943,
      "backward_entropy": 0.006503607545580182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023189542116597295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760595642030239,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12839041650295258,
      "backward_entropy": 0.011656714337212699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002781898947432637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605967596173286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12838396430015564,
      "backward_entropy": 0.006502214287008558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022469052055384964,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760598622262478,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12837745249271393,
      "backward_entropy": 0.01298888134104865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024720365763641894,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605995535850525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12837113440036774,
      "backward_entropy": 0.011654517480305262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002099721459671855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605991810560226,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12836487591266632,
      "backward_entropy": 0.012991811547960554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002926807210315019,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760598063468933,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12835881114006042,
      "backward_entropy": 0.012993328273296356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001981907698791474,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605945244431496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12835262715816498,
      "backward_entropy": 0.011652772980076926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002683730563148856,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605919167399406,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12834656238555908,
      "backward_entropy": 0.0116522450532232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001711355580482632,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605870738625526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1283404529094696,
      "backward_entropy": 0.011651829949447088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023643250460736454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760584093630314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12833449244499207,
      "backward_entropy": 0.01165134459733963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021181876945775002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605796232819557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12832851707935333,
      "backward_entropy": 0.006496998880590711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020540655532386154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760574407875538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12832258641719818,
      "backward_entropy": 0.006496574197496686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023324751236941665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605673298239708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1283167451620102,
      "backward_entropy": 0.011650265327521734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002098765253322199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605580165982246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12831087410449982,
      "backward_entropy": 0.006495922803878784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000140981690492481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760547399520874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12830501794815063,
      "backward_entropy": 0.006495685981852668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020866136765107512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605382725596428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12829935550689697,
      "backward_entropy": 0.0064954060528959546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001963821123354137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605274692177773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12829364836215973,
      "backward_entropy": 0.006495197968823569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012482653255574405,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760516293346882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1282878965139389,
      "backward_entropy": 0.01164962351322174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001665511808823794,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605077251791954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12828229367733002,
      "backward_entropy": 0.011649437248706818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010767126514110714,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760498970746994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12827670574188232,
      "backward_entropy": 0.011649278657776969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010354266851209104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604922652244568,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12827135622501373,
      "backward_entropy": 0.006494135196719851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010199696407653391,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604874223470688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12826620042324066,
      "backward_entropy": 0.006493769586086273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012294935004319996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760484255850315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1282612383365631,
      "backward_entropy": 0.006493359271969114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.411327194655314e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027604812756180763,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12825633585453033,
      "backward_entropy": 0.013025728719575065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.499476436758414e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027604809030890465,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12825173139572144,
      "backward_entropy": 0.013026893138885498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010148333240067586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604812756180763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12824727594852448,
      "backward_entropy": 0.006492016038724354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.800951763987541e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760482020676136,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1282428801059723,
      "backward_entropy": 0.013029033584254128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.827990728197619e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027604825794696808,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12823869287967682,
      "backward_entropy": 0.011645770498684474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010303009185008705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276048444211483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12823469936847687,
      "backward_entropy": 0.006490599364042282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.226159843616188e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0276048481464386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1282307654619217,
      "backward_entropy": 0.01164468697139195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012022915325360373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604859322309494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1282268762588501,
      "backward_entropy": 0.006489749997854233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.536339060403407e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604850009083748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12822291254997253,
      "backward_entropy": 0.006489374275718417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.851764141581953e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760486491024494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12821902334690094,
      "backward_entropy": 0.006488925644329616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.919838779140264e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604874223470688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12821517884731293,
      "backward_entropy": 0.0064884887209960395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.195523696485907e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760489657521248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1282113939523697,
      "backward_entropy": 0.006488011351653508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.611005275975913e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760491333901882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12820762395858765,
      "backward_entropy": 0.006487570703029633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.189316966105253e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027604930102825165,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12820389866828918,
      "backward_entropy": 0.006487135908433369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.796576806460507e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760494500398636,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1282002031803131,
      "backward_entropy": 0.013039189789976393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8064961194759235e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760496363043785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12819664180278778,
      "backward_entropy": 0.006486257804291589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.279665103647858e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760498784482479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12819315493106842,
      "backward_entropy": 0.006485813430377415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6825560022844e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760501019656658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12818972766399384,
      "backward_entropy": 0.006485387150730405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6097040467429906e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760503999888897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12818634510040283,
      "backward_entropy": 0.006484941712447575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.49317519471515e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605080977082253,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1281830221414566,
      "backward_entropy": 0.013042639408792769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.766575148096308e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605116367340088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12817978858947754,
      "backward_entropy": 0.006483989102499825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.791655010194518e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605155482888222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12817662954330444,
      "backward_entropy": 0.006483522376843861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.609685856848955e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605192735791206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12817353010177612,
      "backward_entropy": 0.01163617947271892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.203827484161593e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605228126049042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12817053496837616,
      "backward_entropy": 0.006482669285365513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756348062073812e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760525979101658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12816764414310455,
      "backward_entropy": 0.011635127876486098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0354032535105944e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605289593338966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12816476821899414,
      "backward_entropy": 0.006481858236449105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4285371182486415e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605317533016205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1281619817018509,
      "backward_entropy": 0.006481462291308812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6221681511960924e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605358511209488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12815934419631958,
      "backward_entropy": 0.0064810461231640405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4150489480234683e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760540135204792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12815678119659424,
      "backward_entropy": 0.00648064272744315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.529114110278897e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0276054497808218,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12815435230731964,
      "backward_entropy": 0.013047693031174796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.738138522952795e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760550007224083,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12815190851688385,
      "backward_entropy": 0.01304801447050912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.21233383147046e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605539187788963,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281493902206421,
      "backward_entropy": 0.011631412165505546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.25101864291355e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605580165982246,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12814688682556152,
      "backward_entropy": 0.006479000406605857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.496040517347865e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760561928153038,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12814442813396454,
      "backward_entropy": 0.011630405272756304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.294913040008396e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605649083852768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12814199924468994,
      "backward_entropy": 0.006478261202573776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5686760131502524e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605675160884857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12813957035541534,
      "backward_entropy": 0.006477910493101392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2829524823464453e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605680748820305,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12813706696033478,
      "backward_entropy": 0.013050692422049386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.270478919148445e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276056919246912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12813468277454376,
      "backward_entropy": 0.006477351699556623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0351983039290644e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276056919246912,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12813232839107513,
      "backward_entropy": 0.006477137761456626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8484251743066125e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605701237916946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12813004851341248,
      "backward_entropy": 0.011628246733120509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2877584342495538e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605706825852394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12812776863574982,
      "backward_entropy": 0.011627931679998125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5316980099887587e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605712413787842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12812554836273193,
      "backward_entropy": 0.006476365561996188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6081063222372904e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605712413787842,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12812340259552002,
      "backward_entropy": 0.011627355856554849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6243895515799522e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760571986436844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12812131643295288,
      "backward_entropy": 0.011627046125275748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.104847771988716e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605734765529633,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1281193196773529,
      "backward_entropy": 0.006475656160286495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.782903382263612e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605747804045677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12811735272407532,
      "backward_entropy": 0.0064754219991820195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7794434825191274e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760576270520687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1281154304742813,
      "backward_entropy": 0.006475154310464859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5412437278428115e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027605779469013214,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1281135082244873,
      "backward_entropy": 0.006474902587277549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0212678716925438e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605799958109856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12811163067817688,
      "backward_entropy": 0.011625409126281738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.515430813014973e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605829760432243,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1281098574399948,
      "backward_entropy": 0.013056949845382146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1197052117495332e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760585956275463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12810811400413513,
      "backward_entropy": 0.01162467577627727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.122618394030724e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027605894953012466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12810643017292023,
      "backward_entropy": 0.01162429473229817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4239986739994492e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760593593120575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281048208475113,
      "backward_entropy": 0.011623891336577279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5206893294816837e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027605973184108734,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12810325622558594,
      "backward_entropy": 0.01305774918624333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3493116966856178e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760600484907627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1281016767024994,
      "backward_entropy": 0.011623135634831019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.647836143092718e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760603465139866,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12810012698173523,
      "backward_entropy": 0.013058160032544817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0440278856549412e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760605700314045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12809856235980988,
      "backward_entropy": 0.01162247998373849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0026428753917571e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760607935488224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280970275402069,
      "backward_entropy": 0.006472175674779075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.24808957480127e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760610356926918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12809555232524872,
      "backward_entropy": 0.006471939917121615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3883645806345157e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606124058365822,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12809407711029053,
      "backward_entropy": 0.013059188212667192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4046294381842017e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606137096881866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12809261679649353,
      "backward_entropy": 0.00647152800645147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.029583452502266e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606140822172165,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12809114158153534,
      "backward_entropy": 0.011621121849332536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.933321962307673e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606144547462463,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280897557735443,
      "backward_entropy": 0.013060222779001509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.030210933095077e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606148272752762,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12808838486671448,
      "backward_entropy": 0.011620715260505676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.992913768044673e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760615013539791,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12808699905872345,
      "backward_entropy": 0.006470908543893269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.882863428676501e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760615572333336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280856728553772,
      "backward_entropy": 0.006470749420779092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.489661013300065e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606161311268806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12808439135551453,
      "backward_entropy": 0.006470611585038049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7136124926037155e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606166899204254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12808310985565186,
      "backward_entropy": 0.006470458315951484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.214238161803223e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760617434978485,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12808185815811157,
      "backward_entropy": 0.013062176959855216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.529643087560544e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760617807507515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280806064605713,
      "backward_entropy": 0.0064701709364141735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.849299213878112e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606181800365448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12807942926883698,
      "backward_entropy": 0.011619369898523604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5036339290381875e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606187388300896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12807828187942505,
      "backward_entropy": 0.00646991069827761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.918480383115821e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606192976236343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1280771940946579,
      "backward_entropy": 0.011619010141917638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.902928362251259e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760619856417179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12807613611221313,
      "backward_entropy": 0.006469654717615673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3003971111611463e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760620228946209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12807509303092957,
      "backward_entropy": 0.00646952326808657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.425711373798549e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606211602687836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12807412445545197,
      "backward_entropy": 0.006469407784087318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.174218702246435e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606215327978134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12807312607765198,
      "backward_entropy": 0.006469281656401498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5134225981892087e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606220915913582,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12807217240333557,
      "backward_entropy": 0.013064627136502947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.895717782143038e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606230229139328,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12807124853134155,
      "backward_entropy": 0.011617979833057948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.565705239656381e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606241405010223,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12807033956050873,
      "backward_entropy": 0.011617783989225115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.966913027397823e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760625258088112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280694603919983,
      "backward_entropy": 0.006468781935317176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6686091081937775e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606263756752014,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12806859612464905,
      "backward_entropy": 0.013065389224461146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5387243921577465e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760627306997776,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280677616596222,
      "backward_entropy": 0.006468539791447776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1547685921395896e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760627493262291,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12806688249111176,
      "backward_entropy": 0.006468448255743299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.555725354293827e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606278657913208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280660480260849,
      "backward_entropy": 0.006468355123485837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.735209131467855e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606280520558357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12806519865989685,
      "backward_entropy": 0.006468264652150018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1665554161008913e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606278657913208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12806436419487,
      "backward_entropy": 0.011616756873471397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.002880703206756e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606278657913208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12806354463100433,
      "backward_entropy": 0.011616636599813188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8858889891125727e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606278657913208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12806275486946106,
      "backward_entropy": 0.011616533356053489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.059707407577662e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606280520558357,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12806200981140137,
      "backward_entropy": 0.013067180556910378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.685165782168042e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606278657913208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280612349510193,
      "backward_entropy": 0.006467866046088082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.041706688440172e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606278657913208,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280605047941208,
      "backward_entropy": 0.006467788879360471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0450871690845815e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760627493262291,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1280597597360611,
      "backward_entropy": 0.011616119316646032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.380275191171677e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760627120733261,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280590295791626,
      "backward_entropy": 0.0130681289093835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7474451396992663e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606267482042313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280583143234253,
      "backward_entropy": 0.006467622305665698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4545846574474126e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606267482042313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12805764377117157,
      "backward_entropy": 0.006467549928597042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.582301476650173e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606263756752014,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12805694341659546,
      "backward_entropy": 0.011615775525569916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7826148450694745e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606260031461716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12805628776550293,
      "backward_entropy": 0.011615682925496782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.160975100196083e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606258168816566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280556470155716,
      "backward_entropy": 0.006467387080192566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2934473236091435e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606256306171417,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12805502116680145,
      "backward_entropy": 0.013069404023034232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7878143125926726e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606254443526268,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280544102191925,
      "backward_entropy": 0.0064672838364328656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.316882955710753e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760625258088112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12805381417274475,
      "backward_entropy": 0.006467226360525403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6503282722624135e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760624885559082,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.128053218126297,
      "backward_entropy": 0.013070010713168554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.877084170904709e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760624699294567,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12805265188217163,
      "backward_entropy": 0.01161521247455052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3405592653725762e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606241405010223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12805207073688507,
      "backward_entropy": 0.013070417301995414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.477812586221262e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606237679719925,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1280515193939209,
      "backward_entropy": 0.011615110295159476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0759343922472908e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606230229139328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12805092334747314,
      "backward_entropy": 0.006467010825872421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6682751038388233e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760622464120388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12805038690567017,
      "backward_entropy": 0.006466986877577645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7471261344326194e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606219053268433,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12804986536502838,
      "backward_entropy": 0.011614933609962463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2403093023749534e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606213465332985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280493587255478,
      "backward_entropy": 0.006466917161430631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4630271607529721e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606209740042686,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280488669872284,
      "backward_entropy": 0.013071600879941667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1371840855645132e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760620415210724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280483901500702,
      "backward_entropy": 0.006466849574020931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.644336387282237e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760620042681694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.128047913312912,
      "backward_entropy": 0.006466823496988842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0437023547638091e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760619856417179,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804746627807617,
      "backward_entropy": 0.006466788905007499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1265872217336437e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606196701526642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12804701924324036,
      "backward_entropy": 0.011614588754517692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.082607695934712e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606194838881493,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804660201072693,
      "backward_entropy": 0.006466713334832873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4789832221140387e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606192976236343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1280461847782135,
      "backward_entropy": 0.011614482317652022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2076623079337878e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606189250946045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804575264453888,
      "backward_entropy": 0.006466644683054515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.513129046150425e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606185525655746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12804533541202545,
      "backward_entropy": 0.011614371623311723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.270226885542797e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606181800365448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804493308067322,
      "backward_entropy": 0.006466583481856755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.995705123496009e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0276061799377203,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12804454565048218,
      "backward_entropy": 0.013073178274290902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.112243921852496e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276061799377203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804417312145233,
      "backward_entropy": 0.0064665137657097405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.413102369151602e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02760617807507515,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12804380059242249,
      "backward_entropy": 0.01307343372276851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.020144832698861e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760617621243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804342806339264,
      "backward_entropy": 0.006466463208198547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.398826594202546e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760617621243,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804308533668518,
      "backward_entropy": 0.0064664243587425774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.271375466189056e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760617434978485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804274260997772,
      "backward_entropy": 0.0064663998782634735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.617945243509894e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606172487139702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804241478443146,
      "backward_entropy": 0.006466359432254519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.818211204517866e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606170624494553,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280421018600464,
      "backward_entropy": 0.01307404147727149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.479863827735244e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606168761849403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804177403450012,
      "backward_entropy": 0.006466318986245564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.028456027706852e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606166899204254,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12804147601127625,
      "backward_entropy": 0.013074279895850591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.018783551553497e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606165036559105,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12804117798805237,
      "backward_entropy": 0.01161375961133412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.223560831131181e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606163173913956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1280408799648285,
      "backward_entropy": 0.011613705328532628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.178180065788183e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606161311268806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128040611743927,
      "backward_entropy": 0.011613674461841583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.759278624533181e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606161311268806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280403435230255,
      "backward_entropy": 0.006466183811426163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.594295657829207e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606161311268806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12804006040096283,
      "backward_entropy": 0.006466163588421685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.459193405637052e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606161311268806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12803980708122253,
      "backward_entropy": 0.011613508420331138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.704868613065628e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606161311268806,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12803956866264343,
      "backward_entropy": 0.013074989829744612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.884500637876044e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606161311268806,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12803933024406433,
      "backward_entropy": 0.011613416884626662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3190027554373955e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606159448623657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12803907692432404,
      "backward_entropy": 0.011613390275410243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6698627897967526e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606157585978508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803882360458374,
      "backward_entropy": 0.006466058215924672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.780080757882388e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760615572333336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803858518600464,
      "backward_entropy": 0.006466027349233627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.971441853740544e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02760615386068821,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803834676742554,
      "backward_entropy": 0.006466019366468702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.464102119072777e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760615013539791,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12803809344768524,
      "backward_entropy": 0.011613241263798304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.77201138487726e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606146410107613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803786993026733,
      "backward_entropy": 0.006465997014726911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.947880375359091e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606144547462463,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803764641284943,
      "backward_entropy": 0.006465989031961986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.90526565752225e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606142684817314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12803742289543152,
      "backward_entropy": 0.011613158243043082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.461266828708176e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606140822172165,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280371993780136,
      "backward_entropy": 0.013075992465019226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3314603936341882e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027606138959527016,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1280369907617569,
      "backward_entropy": 0.01307609783751624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.997488254801283e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606137096881866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803679704666138,
      "backward_entropy": 0.006465931556054524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1240091996332922e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027606137096881866,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803660333156586,
      "backward_entropy": 0.006465919315814972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.61989328009804e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606137096881866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12803640961647034,
      "backward_entropy": 0.011613011360168457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5965545091821696e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027606137096881866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128036230802536,
      "backward_entropy": 0.01161298475095204,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.5910150378981597e-06,
    "avg_log_Z": 0.02760618770495057,
    "success_rate": 1.0,
    "avg_reward": 42.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.2,
      "1": 0.31,
      "2": 0.49
    },
    "avg_forward_entropy": 0.12805907890200616,
    "avg_backward_entropy": 0.009383973335581167,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}