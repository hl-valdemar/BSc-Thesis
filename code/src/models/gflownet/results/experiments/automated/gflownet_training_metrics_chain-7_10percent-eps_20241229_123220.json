{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09902071952819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09898713656834193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.210162162780762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700124621391296,
      "backward_entropy": 0.09896792684282575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.48215103149414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699787855148315,
      "backward_entropy": 0.0989842414855957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.899433135986328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00020003420650027692,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699547946453094,
      "backward_entropy": 0.09898129531315394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.47567367553711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003001548466272652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369924545288086,
      "backward_entropy": 0.09897821290152413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.019152641296387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004002253117505461,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369897723197937,
      "backward_entropy": 0.09897502831050328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.924975395202637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005003823316656053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369875967502594,
      "backward_entropy": 0.09897176708493914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.811123847961426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006008021882735193,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369849145412445,
      "backward_entropy": 0.09901514223643712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.8221435546875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007011336274445057,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13698214292526245,
      "backward_entropy": 0.09896481888634819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.658214569091797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008016317733563483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697978854179382,
      "backward_entropy": 0.09901172774178642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.799938201904297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009019559947773814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13697753846645355,
      "backward_entropy": 0.09892305306025914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.723706245422363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001002199249342084,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13697503507137299,
      "backward_entropy": 0.09900733402797154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.26004409790039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011023500701412559,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13697248697280884,
      "backward_entropy": 0.09891123431069511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.322617530822754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001202575396746397,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13697008788585663,
      "backward_entropy": 0.09894517489842006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.030024528503418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013026086380705237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13696691393852234,
      "backward_entropy": 0.09894073009490967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513379096984863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014023635303601623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13696399331092834,
      "backward_entropy": 0.0989361149924142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.90195083618164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015020632417872548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13696074485778809,
      "backward_entropy": 0.09888504232679095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827211380004883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016018199967220426,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695776462554932,
      "backward_entropy": 0.09887795788901192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.96658706665039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017012882744893432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13695496320724487,
      "backward_entropy": 0.09892115422657557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.695921897888184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001800886238925159,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695216178894043,
      "backward_entropy": 0.09886284385408674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.498284339904785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019005099311470985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13694937527179718,
      "backward_entropy": 0.09885474613734654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.027259826660156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020001018419861794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694623112678528,
      "backward_entropy": 0.09890408175332206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.685603141784668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002099839970469475,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13694298267364502,
      "backward_entropy": 0.09889783178056989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.019319534301758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002199583686888218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693971931934357,
      "backward_entropy": 0.09889132635934013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.554882049560547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002299452666193247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13693633675575256,
      "backward_entropy": 0.09888456548963274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.21843147277832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002399953082203865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13693270087242126,
      "backward_entropy": 0.0989441190447126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26340103149414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002500194823369384,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13692863285541534,
      "backward_entropy": 0.09893722193581718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.074753761291504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026001997757703066,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692496716976166,
      "backward_entropy": 0.09878965786525182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.214412689208984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027003188151866198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369209736585617,
      "backward_entropy": 0.09885474613734654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.113320350646973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028006036300212145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691630959510803,
      "backward_entropy": 0.09891396760940552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.44271469116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002900950377807021,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691210746765137,
      "backward_entropy": 0.0989053760256086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.986296653747559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003001475939527154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136908158659935,
      "backward_entropy": 0.09874464784349714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.792725563049316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031020042952150106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369040608406067,
      "backward_entropy": 0.09873250552586146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.903325080871582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003202474443241954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13689957559108734,
      "backward_entropy": 0.09871986934116908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860977172851562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033033008221536875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368948370218277,
      "backward_entropy": 0.0987068670136588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.04669189453125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003403662471100688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688990473747253,
      "backward_entropy": 0.09878993034362793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.589550971984863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0035036751069128513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368851363658905,
      "backward_entropy": 0.0986793041229248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.702107429504395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036036253441125154,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13687971234321594,
      "backward_entropy": 0.09883408887045723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.028429985046387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037035439163446426,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368742138147354,
      "backward_entropy": 0.0988220487322126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.518867492675781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003803568659350276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13686849176883698,
      "backward_entropy": 0.09880948066711426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.420442581176758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003903075819835067,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368628293275833,
      "backward_entropy": 0.0987963250705174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.701044082641602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004002912435680628,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13685666024684906,
      "backward_entropy": 0.09878269263676234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.727616310119629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004102312494069338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685090839862823,
      "backward_entropy": 0.09870728424617223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.209890365600586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004201732110232115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684579730033875,
      "backward_entropy": 0.09869341339383807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.67593002319336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004300966858863831,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13684126734733582,
      "backward_entropy": 0.09855360644204277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.293149948120117,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004400255158543587,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683660328388214,
      "backward_entropy": 0.0987218873841422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.250941276550293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004498984664678574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683263957500458,
      "backward_entropy": 0.09864888872419085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.012161254882812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0045980727300047874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13682833313941956,
      "backward_entropy": 0.09863300834383283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.519225120544434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004696949850767851,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13682407140731812,
      "backward_entropy": 0.0986166170665196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.166380882263184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004795848857611418,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13682003319263458,
      "backward_entropy": 0.09845781326293945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.582221031188965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004895051941275597,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13681581616401672,
      "backward_entropy": 0.09843686648777553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.790694236755371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004994278308004141,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368115246295929,
      "backward_entropy": 0.09856386695589338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.334440231323242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0050936429761350155,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13680651783943176,
      "backward_entropy": 0.09839374678475517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.075798988342285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00519332243129611,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13680164515972137,
      "backward_entropy": 0.09852559225899833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.312760353088379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005293175578117371,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13679683208465576,
      "backward_entropy": 0.09834827695574079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.52977466583252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005392867606133223,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367918848991394,
      "backward_entropy": 0.09832448618752616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.414562225341797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005492952652275562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678638637065887,
      "backward_entropy": 0.09846324580056327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.480765342712402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005592870991677046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13678130507469177,
      "backward_entropy": 0.09827489512307304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.26111125946045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005692680366337299,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13677635788917542,
      "backward_entropy": 0.09844568797520228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.826017379760742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005792762618511915,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13677074015140533,
      "backward_entropy": 0.0982224600655692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.999897003173828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005892915651202202,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136764258146286,
      "backward_entropy": 0.09839161804744176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.745180130004883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005993194412440062,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13675722479820251,
      "backward_entropy": 0.09816651684897286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20797348022461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00609347689896822,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1367502212524414,
      "backward_entropy": 0.09833436352866036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.203612327575684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006193491630256176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674359023571014,
      "backward_entropy": 0.09829277651650566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.021954536437988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006293267011642456,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13673725724220276,
      "backward_entropy": 0.0982731751033238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.796133995056152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0063927629962563515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673090934753418,
      "backward_entropy": 0.09823693547930036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.190314292907715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006492387969046831,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136723592877388,
      "backward_entropy": 0.09820818901062012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.691987991333008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006591813173145056,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13671649992465973,
      "backward_entropy": 0.09817419733319964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.195131301879883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006690844893455505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670960068702698,
      "backward_entropy": 0.09814738375799996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.12678337097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0067893099039793015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13670293986797333,
      "backward_entropy": 0.09811627864837646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.558768272399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006888150237500668,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669587671756744,
      "backward_entropy": 0.09808383669172015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167374610900879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006987067870795727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13668867945671082,
      "backward_entropy": 0.09805020264216832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.108776092529297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007085862103849649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366817057132721,
      "backward_entropy": 0.09801555531365531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80838394165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00718499394133687,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13667388260364532,
      "backward_entropy": 0.09794731651033674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.15234661102295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00728384405374527,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13666526973247528,
      "backward_entropy": 0.0979055677141462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.0770902633667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007382575888186693,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366567611694336,
      "backward_entropy": 0.0978621414729527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.595191955566406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00748116010800004,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13664859533309937,
      "backward_entropy": 0.09781623738152641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.345907211303711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007579888682812452,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13663984835147858,
      "backward_entropy": 0.09782467569623675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.303506851196289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0076786368153989315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13663053512573242,
      "backward_entropy": 0.09754857846668788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.888419151306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007777341641485691,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366216391324997,
      "backward_entropy": 0.0976701123373849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.672268867492676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007876325398683548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366119682788849,
      "backward_entropy": 0.09745700018746513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.14788818359375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00797542929649353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13660220801830292,
      "backward_entropy": 0.09764834812709264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.176112174987793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00807485543191433,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13659235835075378,
      "backward_entropy": 0.09751006535121373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.47957992553711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00817413255572319,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13658250868320465,
      "backward_entropy": 0.09731129237583705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09363842010498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008273426443338394,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13657236099243164,
      "backward_entropy": 0.09750129495348249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.352912902832031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008372539654374123,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13656243681907654,
      "backward_entropy": 0.0973344360079084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.098557472229004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008472072891891003,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13655224442481995,
      "backward_entropy": 0.09727025032043457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.241354942321777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008572358638048172,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13654100894927979,
      "backward_entropy": 0.0971005814416068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.084704399108887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008672411553561687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13653025031089783,
      "backward_entropy": 0.09704480852399554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.208386421203613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008772661909461021,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13651934266090393,
      "backward_entropy": 0.09698773281914848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29928970336914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00887220073491335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13650938868522644,
      "backward_entropy": 0.09692915848323277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.641590118408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008971123956143856,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13650080561637878,
      "backward_entropy": 0.09691836152757917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.060483932495117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009069712832570076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13649217784404755,
      "backward_entropy": 0.09680754797799247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.097402572631836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009168154560029507,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13648377358913422,
      "backward_entropy": 0.09674472468239921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.874427795410156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009266527369618416,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364743858575821,
      "backward_entropy": 0.09689113071986608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.011629104614258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009364228695631027,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13646650314331055,
      "backward_entropy": 0.09661427565983363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.21432113647461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009461894631385803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645827770233154,
      "backward_entropy": 0.09654664993286133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.9039306640625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009559659287333488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13644897937774658,
      "backward_entropy": 0.09667740549360003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.969791889190674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009657359682023525,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13643914461135864,
      "backward_entropy": 0.09633784634726388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.44650936126709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00975456740707159,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364295780658722,
      "backward_entropy": 0.09633268628801618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.265356063842773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009851527400314808,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13642047345638275,
      "backward_entropy": 0.09625773770468575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.332889556884766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009949153289198875,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364099681377411,
      "backward_entropy": 0.0960594926561628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.423574447631836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010046940296888351,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13639873266220093,
      "backward_entropy": 0.09610245909009661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.804287910461426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010144412517547607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363881528377533,
      "backward_entropy": 0.09620399134499687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.374431610107422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010241773910820484,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13637804985046387,
      "backward_entropy": 0.09594011306762695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.170707702636719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010339363478124142,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13636690378189087,
      "backward_entropy": 0.0956559521811349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.268823623657227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010436546057462692,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13635660707950592,
      "backward_entropy": 0.09554916620254517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.167535781860352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010532901622354984,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136348694562912,
      "backward_entropy": 0.09568236555371966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.443347930908203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01063000038266182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363385021686554,
      "backward_entropy": 0.09575520242963519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.544496536254883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010726891458034515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13632862269878387,
      "backward_entropy": 0.09565889835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.976299285888672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010823135264217854,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13632021844387054,
      "backward_entropy": 0.0950979334967477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.61488151550293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010920066386461258,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363091766834259,
      "backward_entropy": 0.09497918401445661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19693374633789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01101635955274105,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13630039989948273,
      "backward_entropy": 0.09485663686479841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.715890884399414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011112389154732227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13629262149333954,
      "backward_entropy": 0.09525150060653687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.92116641998291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011209015734493732,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13628247380256653,
      "backward_entropy": 0.09500388588224139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.445980072021484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01130570750683546,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13627249002456665,
      "backward_entropy": 0.09447177818843297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.519883155822754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011402265168726444,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13626305758953094,
      "backward_entropy": 0.09478429385593959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.318266868591309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011498718522489071,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13625404238700867,
      "backward_entropy": 0.09480002948216029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.187715530395508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011595489457249641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13624358177185059,
      "backward_entropy": 0.09467969621930804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.166375160217285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011691421270370483,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13623666763305664,
      "backward_entropy": 0.09391611814498901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.321576118469238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011787602677941322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13622954487800598,
      "backward_entropy": 0.09431375776018415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.575887203216553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011883644387125969,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13622237741947174,
      "backward_entropy": 0.09418955871037074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.088218688964844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011979187838733196,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136216402053833,
      "backward_entropy": 0.09346413612365723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.576824188232422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012074516154825687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13621126115322113,
      "backward_entropy": 0.09393095970153809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.854386329650879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012169941328465939,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13620525598526,
      "backward_entropy": 0.0937966023172651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621286392211914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012265603058040142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13619786500930786,
      "backward_entropy": 0.0937677196093968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.248424530029297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01236136443912983,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361895203590393,
      "backward_entropy": 0.09362551995686122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50881290435791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012457011267542839,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13618120551109314,
      "backward_entropy": 0.09337274517331805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.454806327819824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012552181258797646,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1361744999885559,
      "backward_entropy": 0.09248756510870797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.722911834716797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012647923082113266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13616546988487244,
      "backward_entropy": 0.09319204092025757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49300479888916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012743772007524967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361563503742218,
      "backward_entropy": 0.09292059285300118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.614862442016602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012840157374739647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13614484667778015,
      "backward_entropy": 0.09288500888007027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.032442092895508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012936555780470371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13613305985927582,
      "backward_entropy": 0.09272577081407819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.869236946105957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013033175840973854,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13612039387226105,
      "backward_entropy": 0.0925623859677996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.636943817138672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013129926286637783,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13610687851905823,
      "backward_entropy": 0.09140098946435112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.475502014160156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01322668045759201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13609285652637482,
      "backward_entropy": 0.09222878728594099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.389293670654297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013323371298611164,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13607841730117798,
      "backward_entropy": 0.09100963388170515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.015077590942383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013419952243566513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13606388866901398,
      "backward_entropy": 0.09188397441591535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.782121658325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013516261242330074,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13604971766471863,
      "backward_entropy": 0.09156691176550728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.412138938903809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013612702488899231,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13603475689888,
      "backward_entropy": 0.09039514405386788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.88401985168457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013709054328501225,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13602006435394287,
      "backward_entropy": 0.09018196378435407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.23363971710205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013805612921714783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360040307044983,
      "backward_entropy": 0.09115362167358398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.710169792175293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013901995494961739,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13598836958408356,
      "backward_entropy": 0.09079955305371966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.407245635986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013998440466821194,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13597261905670166,
      "backward_entropy": 0.08951818091528756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.69179630279541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014094813726842403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.135956808924675,
      "backward_entropy": 0.09056122813905988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7403740882873535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014190712943673134,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13594305515289307,
      "backward_entropy": 0.09018729414258685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9996466636657715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014286261983215809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13593021035194397,
      "backward_entropy": 0.09014804022652763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.604365348815918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014381643384695053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13591749966144562,
      "backward_entropy": 0.08993664809635707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.822709083557129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01447718683630228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13590368628501892,
      "backward_entropy": 0.08972017254148211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.940506935119629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014572453685104847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13589075207710266,
      "backward_entropy": 0.08931262152535575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74548625946045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01466755848377943,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13587793707847595,
      "backward_entropy": 0.08908278601510185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.761672019958496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014762935228645802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13586358726024628,
      "backward_entropy": 0.08884877817971366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.262207984924316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014858026057481766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585013151168823,
      "backward_entropy": 0.08861052138464791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.994112491607666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014952627941966057,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13583824038505554,
      "backward_entropy": 0.08702173403331212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.10678482055664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015047233551740646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13582539558410645,
      "backward_entropy": 0.08834255593163627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35569953918457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015141855925321579,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13581296801567078,
      "backward_entropy": 0.08810014384133476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.381073951721191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015236636623740196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357995569705963,
      "backward_entropy": 0.0878525802067348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.155838966369629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015331028960645199,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357877105474472,
      "backward_entropy": 0.0873408487864903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.349328994750977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015424920246005058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13577821850776672,
      "backward_entropy": 0.08735064097813197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.87763786315918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015519063919782639,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13576650619506836,
      "backward_entropy": 0.08680031129292079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.964173316955566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01561425905674696,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13574890792369843,
      "backward_entropy": 0.08652291979108538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.935497760772705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01570931077003479,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13573160767555237,
      "backward_entropy": 0.08654989515032087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.447330474853516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01580425724387169,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13571415841579437,
      "backward_entropy": 0.08595596040998187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.41465425491333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01589937135577202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13569536805152893,
      "backward_entropy": 0.08566590717860631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.588992595672607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015994088724255562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13567793369293213,
      "backward_entropy": 0.08569533484322685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.161571502685547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016088545322418213,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13566116988658905,
      "backward_entropy": 0.08540195226669312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.327340126037598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016183076426386833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13564345240592957,
      "backward_entropy": 0.08510230268750872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.096480369567871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016277799382805824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13562394678592682,
      "backward_entropy": 0.08445616279329572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.527853965759277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016373073682188988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13560132682323456,
      "backward_entropy": 0.08448183536529541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.371241569519043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016468586400151253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13557662069797516,
      "backward_entropy": 0.08416094950267247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835178375244141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016564173623919487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13555097579956055,
      "backward_entropy": 0.08383349009922572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.623319625854492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016658974811434746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355288177728653,
      "backward_entropy": 0.08318414006914411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.622365474700928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01675412431359291,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13550393283367157,
      "backward_entropy": 0.08114901610783168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.97834587097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01684897392988205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13547992706298828,
      "backward_entropy": 0.08282809598105294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.35213851928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016943752765655518,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1354556530714035,
      "backward_entropy": 0.08041888475418091,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.458390235900879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01703929901123047,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13542704284191132,
      "backward_entropy": 0.08004614285060338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.406411170959473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017134442925453186,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13539975881576538,
      "backward_entropy": 0.0817713737487793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519731521606445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017228636890649796,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13537661731243134,
      "backward_entropy": 0.0814154999596732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.800176620483398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017322594299912453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353539079427719,
      "backward_entropy": 0.08105476413454328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.077701568603516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017416521906852722,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13533037900924683,
      "backward_entropy": 0.0804355229650225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.287409782409668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01751060225069523,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1353049874305725,
      "backward_entropy": 0.07811442443302699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.817908763885498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01760377548635006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352837085723877,
      "backward_entropy": 0.07969835826328822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.523360252380371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017696434631943703,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13526438176631927,
      "backward_entropy": 0.07956443514142718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9243011474609375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01778963766992092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13524116575717926,
      "backward_entropy": 0.07917678356170654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9760637283325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017882995307445526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13521601259708405,
      "backward_entropy": 0.07855480057852608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.171106338500977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01797530986368656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351960003376007,
      "backward_entropy": 0.07838846955980573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.49747896194458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018067391589283943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13517645001411438,
      "backward_entropy": 0.0779892887387957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.764159202575684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018159523606300354,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13515542447566986,
      "backward_entropy": 0.07522877625056676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.478336811065674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018251808360219002,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13513249158859253,
      "backward_entropy": 0.07696575777871269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7119927406311035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0183440949767828,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13510791957378387,
      "backward_entropy": 0.07655564376286098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.574830055236816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018435943871736526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13508456945419312,
      "backward_entropy": 0.07613982473100935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.232795715332031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01852789893746376,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1350591778755188,
      "backward_entropy": 0.07346659047263009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.30681848526001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018619732931256294,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13503322005271912,
      "backward_entropy": 0.07301362923213414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.969839096069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01871156133711338,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13500598073005676,
      "backward_entropy": 0.07255861588886806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220311641693115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018803097307682037,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1349792778491974,
      "backward_entropy": 0.07209627968924386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.407668113708496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018894542008638382,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13495175540447235,
      "backward_entropy": 0.07397183350154332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.603169918060303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018986066803336143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13492220640182495,
      "backward_entropy": 0.07364904880523682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.443014144897461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01907714456319809,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13489405810832977,
      "backward_entropy": 0.07067810211862836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.51494836807251,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019167738035321236,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13486754894256592,
      "backward_entropy": 0.07271920783179146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.756889820098877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019257931038737297,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1348421424627304,
      "backward_entropy": 0.06971217904772077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.652944564819336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019347935914993286,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13481637835502625,
      "backward_entropy": 0.06922313570976257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.868478775024414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01943773590028286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13479042053222656,
      "backward_entropy": 0.07120437281472343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.429503440856934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01952679455280304,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13476799428462982,
      "backward_entropy": 0.07072910240718297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.298844337463379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01961490698158741,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13475069403648376,
      "backward_entropy": 0.07033996071134295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.463253498077393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019703399389982224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13472917675971985,
      "backward_entropy": 0.06984783070428031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.468011856079102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019791699945926666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347072720527649,
      "backward_entropy": 0.0693503703389849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.867147922515869,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019879154860973358,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13468970358371735,
      "backward_entropy": 0.06879889965057373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.370718002319336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019966160878539085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13467369973659515,
      "backward_entropy": 0.06835389137268066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9351091384887695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020053090527653694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13465644419193268,
      "backward_entropy": 0.06784863557134356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.016073703765869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020139632746577263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13464009761810303,
      "backward_entropy": 0.06733875615256173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.183832168579102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020225273445248604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13462868332862854,
      "backward_entropy": 0.06683284044265747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.353091239929199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020310144871473312,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13462096452713013,
      "backward_entropy": 0.06347013797078814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.920293807983398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020394446328282356,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13461542129516602,
      "backward_entropy": 0.06291129333632332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.629587173461914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020479315891861916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13460369408130646,
      "backward_entropy": 0.06529659884316581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.286748886108398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02056380733847618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13459257781505585,
      "backward_entropy": 0.0647718438080379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2707953453063965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020649133250117302,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13457347452640533,
      "backward_entropy": 0.06423361386571612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.688259124755859,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020734518766403198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345517337322235,
      "backward_entropy": 0.06368935533932277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.466803550720215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020819567143917084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13453012704849243,
      "backward_entropy": 0.06314335976328168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.887727737426758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020904839038848877,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13450457155704498,
      "backward_entropy": 0.0594710111618042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.937756538391113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0209899190813303,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134477898478508,
      "backward_entropy": 0.06215660912649972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.780759811401367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021074892953038216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13444960117340088,
      "backward_entropy": 0.061619315828595846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.658346176147461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021159682422876358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1344207376241684,
      "backward_entropy": 0.0609094500541687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.208500385284424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021244172006845474,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13439124822616577,
      "backward_entropy": 0.05713761278561184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.387223243713379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02132880873978138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13435789942741394,
      "backward_entropy": 0.05977336849485125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2909040451049805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021413689479231834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1343197524547577,
      "backward_entropy": 0.05919456481933594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.065679550170898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021498044952750206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13428279757499695,
      "backward_entropy": 0.05861748116356986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1588287353515625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02158249542117119,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1342422515153885,
      "backward_entropy": 0.05478133474077497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.346389293670654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021666333079338074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13420173525810242,
      "backward_entropy": 0.05745471375329154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8968682289123535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02174978144466877,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13416051864624023,
      "backward_entropy": 0.05721841539655413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.941742420196533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021832536906003952,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134121373295784,
      "backward_entropy": 0.056655011006764004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.054929733276367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021914733573794365,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1340835690498352,
      "backward_entropy": 0.05609015056065151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.250383377075195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021996479481458664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13404567539691925,
      "backward_entropy": 0.05552566051483154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7935614585876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02207804098725319,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13400618731975555,
      "backward_entropy": 0.05123049446514675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.462991714477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0221590306609869,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13396760821342468,
      "backward_entropy": 0.050636346851076396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.689576625823975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022239267826080322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13393184542655945,
      "backward_entropy": 0.05382426295961652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4697370529174805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022319041192531586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1338968127965927,
      "backward_entropy": 0.05279441816466195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0882039070129395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022398993372917175,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13385629653930664,
      "backward_entropy": 0.05268727881567819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.383439540863037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02247881330549717,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13381290435791016,
      "backward_entropy": 0.05211750950132098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.95244026184082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022557906806468964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13377119600772858,
      "backward_entropy": 0.05154767632484436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.20375919342041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022636860609054565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13372661173343658,
      "backward_entropy": 0.050446544374738424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4415411949157715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02271510474383831,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13368481397628784,
      "backward_entropy": 0.05039996760232108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.107746601104736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022792909294366837,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13364320993423462,
      "backward_entropy": 0.04928295952933175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9240503311157227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022870013490319252,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1336035579442978,
      "backward_entropy": 0.04532847234180996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.58774471282959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022946340963244438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13356678187847137,
      "backward_entropy": 0.048132240772247314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.377251625061035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02302258275449276,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13352708518505096,
      "backward_entropy": 0.0481075644493103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.381706237792969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023098530247807503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1334853321313858,
      "backward_entropy": 0.047536266701562066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.214742660522461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023174289613962173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1334419846534729,
      "backward_entropy": 0.046406064714704244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.109148025512695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023248828947544098,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13340654969215393,
      "backward_entropy": 0.04584247725350516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8149452209472656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02332305535674095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1333695352077484,
      "backward_entropy": 0.045279272965022495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.614929676055908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02339675836265087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13333335518836975,
      "backward_entropy": 0.0452603144305093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9810752868652344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02347073145210743,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13329046964645386,
      "backward_entropy": 0.04469302722385952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.82625150680542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023544330149888992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13324563205242157,
      "backward_entropy": 0.044129175799233575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6732091903686523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023617517203092575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1332007646560669,
      "backward_entropy": 0.043030355657849996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.064863204956055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02369016967713833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1331561803817749,
      "backward_entropy": 0.042473678077970235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.081270694732666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023762736469507217,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13310794532299042,
      "backward_entropy": 0.04191636613437107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.332923412322998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0238351933658123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13305450975894928,
      "backward_entropy": 0.04135859864098685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6890575885772705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023906871676445007,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133003368973732,
      "backward_entropy": 0.04134214350155422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7049195766448975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02397826500236988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1329512894153595,
      "backward_entropy": 0.040259480476379395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3725497722625732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024049362167716026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13289634883403778,
      "backward_entropy": 0.04024594170706613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8855907917022705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024119816720485687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13284052908420563,
      "backward_entropy": 0.03916969895362854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.343621253967285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024189282208681107,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13278962671756744,
      "backward_entropy": 0.0353747478553227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4162561893463135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024258343502879143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1327378898859024,
      "backward_entropy": 0.03810714398111616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2348732948303223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02432713285088539,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326841115951538,
      "backward_entropy": 0.03757743324552264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.112717866897583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024395447224378586,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13262885808944702,
      "backward_entropy": 0.037048169544764926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.106323719024658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024463240057229996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13257332146167755,
      "backward_entropy": 0.03652314628873553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3576221466064453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02453053928911686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13251636922359467,
      "backward_entropy": 0.03600160564695086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0147621631622314,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024597667157649994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13245441019535065,
      "backward_entropy": 0.03604001232555935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9343748092651367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024664301425218582,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13239139318466187,
      "backward_entropy": 0.03187809033053262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.02950382232666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02473035454750061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13232648372650146,
      "backward_entropy": 0.03445018402167729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.599256753921509,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024796023964881897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1322583556175232,
      "backward_entropy": 0.03394011514527457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6421403884887695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024860844016075134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13219113647937775,
      "backward_entropy": 0.03343755219663892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3979499340057373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024925006553530693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13212448358535767,
      "backward_entropy": 0.032941537243979316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.473783254623413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02498825266957283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13205978274345398,
      "backward_entropy": 0.03245397550719125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7095956802368164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02505084127187729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1319979429244995,
      "backward_entropy": 0.03197239977972848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5994763374328613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025113077834248543,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1319323629140854,
      "backward_entropy": 0.0286264568567276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.72721266746521,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025174899026751518,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13186439871788025,
      "backward_entropy": 0.028185103620801653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.493489980697632,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025236519053578377,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1317916065454483,
      "backward_entropy": 0.031246811151504517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2668943405151367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025297630578279495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13171574473381042,
      "backward_entropy": 0.030076918857438222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6606183052062988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02535806968808174,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1316409707069397,
      "backward_entropy": 0.030352590339524404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.951599359512329,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02541705220937729,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13157427310943604,
      "backward_entropy": 0.026477536984852383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1448938846588135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0254751555621624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1315106749534607,
      "backward_entropy": 0.029490413410323008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.091061592102051,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02553272433578968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1314457207918167,
      "backward_entropy": 0.028298424822943553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.10677170753479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025589745491743088,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13137948513031006,
      "backward_entropy": 0.025273095284189497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7422250509262085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02564629539847374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13131065666675568,
      "backward_entropy": 0.027448045355933055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2129321098327637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025701986625790596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13124650716781616,
      "backward_entropy": 0.027832644326346263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7128287553787231,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025757556781172752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13117696344852448,
      "backward_entropy": 0.0266226019178118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6278420686721802,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025812197476625443,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1311076581478119,
      "backward_entropy": 0.0237535046679633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6206707954406738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025865910574793816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13103991746902466,
      "backward_entropy": 0.025823271700314114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.624622106552124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025918876752257347,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13097524642944336,
      "backward_entropy": 0.02626845027719225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.832288146018982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025971096009016037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13091033697128296,
      "backward_entropy": 0.025055316942078725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4881447553634644,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026023007929325104,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13084115087985992,
      "backward_entropy": 0.02233799866267613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7226853370666504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026074029505252838,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13077186048030853,
      "backward_entropy": 0.0243074574640819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3241100311279297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026124633848667145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13069705665111542,
      "backward_entropy": 0.02480990333216531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.439446210861206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026174340397119522,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13062706589698792,
      "backward_entropy": 0.02358286508492061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3545458316802979,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02622346021234989,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1305588185787201,
      "backward_entropy": 0.024116330913134983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3354166746139526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026271864771842957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13049191236495972,
      "backward_entropy": 0.022887191602161953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2660962343215942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631962299346924,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1304263323545456,
      "backward_entropy": 0.02254904167992728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.21708345413208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026366576552391052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13036000728607178,
      "backward_entropy": 0.022217567477907454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4876595735549927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026412779465317726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13029460608959198,
      "backward_entropy": 0.02189292013645172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3277512788772583,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026458825916051865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13022351264953613,
      "backward_entropy": 0.019514567085674832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0306562185287476,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02650444582104683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1301502287387848,
      "backward_entropy": 0.021250505532537187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0907801389694214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02654915861785412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13008202612400055,
      "backward_entropy": 0.020940129246030535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.302085518836975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026593150570988655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13001494109630585,
      "backward_entropy": 0.020636409521102905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0670371055603027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026636885479092598,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1299421489238739,
      "backward_entropy": 0.02033479298864092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1849703788757324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02667994797229767,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12986937165260315,
      "backward_entropy": 0.020039279546056474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1699256896972656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0267227403819561,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.129794642329216,
      "backward_entropy": 0.017891590084348406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.023003101348877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026765139773488045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12971466779708862,
      "backward_entropy": 0.01945774257183075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0005459785461426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026806946843862534,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1296340972185135,
      "backward_entropy": 0.017389563577515737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6873699426651001,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026848113164305687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12955115735530853,
      "backward_entropy": 0.019858349646840776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7564319372177124,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02688799798488617,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1294735223054886,
      "backward_entropy": 0.016911918563502177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1472108364105225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026926986873149872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12940016388893127,
      "backward_entropy": 0.018368218626294817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8499656319618225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026966046541929245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12931816279888153,
      "backward_entropy": 0.01810800177710397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7855515480041504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027004366740584373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12923336029052734,
      "backward_entropy": 0.0162357719881194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7942466139793396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027041884139180183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1291472315788269,
      "backward_entropy": 0.018600934318133762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7896804809570312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027078798040747643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1290605664253235,
      "backward_entropy": 0.01736136738743101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7952372431755066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02711522951722145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12897393107414246,
      "backward_entropy": 0.018134862184524536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7247752547264099,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027151238173246384,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12888602912425995,
      "backward_entropy": 0.015399390033313207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5850299000740051,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027186671271920204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12879793345928192,
      "backward_entropy": 0.016657233238220215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.693658173084259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027221189811825752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12871292233467102,
      "backward_entropy": 0.016434569443975176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6114534139633179,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027255283668637276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12862804532051086,
      "backward_entropy": 0.014822292540754591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5718125700950623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027288682758808136,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12854361534118652,
      "backward_entropy": 0.014639756509235926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7252157330513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027321280911564827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12845894694328308,
      "backward_entropy": 0.01579534581729344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7428038716316223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027353692799806595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12836909294128418,
      "backward_entropy": 0.015589453279972076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6288206577301025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02738606557250023,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12827399373054504,
      "backward_entropy": 0.01411488332918712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5209572315216064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027418075129389763,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1281774342060089,
      "backward_entropy": 0.015182069369724818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33540573716163635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027449430897831917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12808279693126678,
      "backward_entropy": 0.014985314437321253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45601144433021545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027479441836476326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12799391150474548,
      "backward_entropy": 0.014798492193222046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35740381479263306,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027508648112416267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12790483236312866,
      "backward_entropy": 0.015688796128545488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4061840772628784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027536923065781593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12782104313373566,
      "backward_entropy": 0.014443333659853255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36365702748298645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027564451098442078,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12773805856704712,
      "backward_entropy": 0.014274595039231437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46833786368370056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027591129764914513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12765653431415558,
      "backward_entropy": 0.014111784952027457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4353623390197754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0276174433529377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12757131457328796,
      "backward_entropy": 0.013951241970062256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46889081597328186,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027643369510769844,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12748420238494873,
      "backward_entropy": 0.012786727930818285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3125654458999634,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027669142931699753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12739387154579163,
      "backward_entropy": 0.01363662098135267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3238476514816284,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02769404463469982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12730535864830017,
      "backward_entropy": 0.014556745333330972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3491358160972595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027718236669898033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12721769511699677,
      "backward_entropy": 0.013339960149356298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40020719170570374,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027741873636841774,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12712860107421875,
      "backward_entropy": 0.012301903750215257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.359194278717041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02776532620191574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1270361691713333,
      "backward_entropy": 0.013056516647338867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3591991662979126,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027788329869508743,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12694057822227478,
      "backward_entropy": 0.012078189424106054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30049729347229004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027811164036393166,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1268441379070282,
      "backward_entropy": 0.013860603528363364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24908041954040527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02783339098095894,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12674693763256073,
      "backward_entropy": 0.011863888374396734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2865818738937378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0278546754270792,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12664934992790222,
      "backward_entropy": 0.013606601527759008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2668802738189697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027875255793333054,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1265484094619751,
      "backward_entropy": 0.012397951313427516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2199501395225525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027895266190171242,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12644663453102112,
      "backward_entropy": 0.013372690549918584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2659030258655548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027914758771657944,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12634870409965515,
      "backward_entropy": 0.012162651334490095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25500714778900146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027933932840824127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1262499988079071,
      "backward_entropy": 0.0120490129504885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.287309855222702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02795272320508957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12615010142326355,
      "backward_entropy": 0.011937743851116725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22259074449539185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02797146886587143,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12604765594005585,
      "backward_entropy": 0.012936355812208993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22872008383274078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027989625930786133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12594443559646606,
      "backward_entropy": 0.01171952166727611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25474271178245544,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028007488697767258,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12584131956100464,
      "backward_entropy": 0.012732853846890586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17659275233745575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02802516706287861,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12573523819446564,
      "backward_entropy": 0.011509973023618971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21407046914100647,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028042081743478775,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1256299614906311,
      "backward_entropy": 0.010923343045370919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2373066544532776,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028058817610144615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.125524640083313,
      "backward_entropy": 0.011312129242079598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.167871356010437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02807546779513359,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1254163235425949,
      "backward_entropy": 0.012353859841823578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1611166000366211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028091566637158394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12530943751335144,
      "backward_entropy": 0.012264886072703771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15606600046157837,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028107184916734695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12520432472229004,
      "backward_entropy": 0.012178384831973485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1497814804315567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028122231364250183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12509992718696594,
      "backward_entropy": 0.01094114248241697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1443273425102234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028136782348155975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1249965950846672,
      "backward_entropy": 0.010856445346559798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14932994544506073,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028150856494903564,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12489424645900726,
      "backward_entropy": 0.010463562394891466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12706615030765533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028164418414235115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12479104101657867,
      "backward_entropy": 0.010695724615028926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1708603948354721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02817743644118309,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12468908727169037,
      "backward_entropy": 0.010620018201214927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1687357872724533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028190597891807556,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12458586692810059,
      "backward_entropy": 0.010543605046612876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14664602279663086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028203653171658516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12447961419820786,
      "backward_entropy": 0.010467659149851118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0739741325378418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02821652963757515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12437262386083603,
      "backward_entropy": 0.010392807424068451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12520787119865417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02822832390666008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12426954507827759,
      "backward_entropy": 0.010324258889470781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0950506180524826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02823980711400509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12416602671146393,
      "backward_entropy": 0.010257439953940255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08252127468585968,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028250789269804955,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12406490743160248,
      "backward_entropy": 0.010193628924233573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09484222531318665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028261104598641396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12396635860204697,
      "backward_entropy": 0.011328068162713732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10410206764936447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028271036222577095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12386906147003174,
      "backward_entropy": 0.010075919330120087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09775549173355103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028280457481741905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12377028167247772,
      "backward_entropy": 0.01122097032410758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10386690497398376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028289493173360825,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12367115914821625,
      "backward_entropy": 0.009967720934322901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11445297300815582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028298301622271538,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12357093393802643,
      "backward_entropy": 0.011122647140707289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08884333074092865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028307069092988968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12346833944320679,
      "backward_entropy": 0.011074768645422799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08409367501735687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02831564098596573,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12336654961109161,
      "backward_entropy": 0.009846603231770652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09406925737857819,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028324062004685402,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12326601147651672,
      "backward_entropy": 0.00981873380286353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08378136157989502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02833232656121254,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12316443771123886,
      "backward_entropy": 0.009791624333177294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08611852675676346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340298682451248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12306272238492966,
      "backward_entropy": 0.009667410382202693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10160309821367264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0283481627702713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12296070158481598,
      "backward_entropy": 0.01085171742098672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0639670193195343,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02835603803396225,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12285564839839935,
      "backward_entropy": 0.009715593286922999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07349152117967606,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028363479301333427,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1227526068687439,
      "backward_entropy": 0.009692537997450148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07302239537239075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02837064117193222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12264969944953918,
      "backward_entropy": 0.00948635914496013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07205274701118469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02837774157524109,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12254732847213745,
      "backward_entropy": 0.00944382165159498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04774543270468712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028384976089000702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12244587391614914,
      "backward_entropy": 0.009400749845164163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0619024820625782,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028391743078827858,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12234769761562347,
      "backward_entropy": 0.010619008115359716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06826511770486832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02839851751923561,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12225078046321869,
      "backward_entropy": 0.009584389626979828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05868005007505417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028405195102095604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12215305864810944,
      "backward_entropy": 0.009280328239713396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.054637178778648376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028411613777279854,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12205573916435242,
      "backward_entropy": 0.010513766535690852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05763518810272217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02841762825846672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12195882946252823,
      "backward_entropy": 0.010481963200228555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05494365096092224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028423264622688293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12186136841773987,
      "backward_entropy": 0.00917140713759831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05204422399401665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028428854420781136,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1217644214630127,
      "backward_entropy": 0.009496648396764482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05794636532664299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028434501960873604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12166853249073029,
      "backward_entropy": 0.01039304371391024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041696980595588684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02844010666012764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12157174944877625,
      "backward_entropy": 0.009069235197135381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03983675315976143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028445445001125336,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12147693336009979,
      "backward_entropy": 0.009450303656714303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04738389700651169,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028450461104512215,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1213839054107666,
      "backward_entropy": 0.010309606790542603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04759214445948601,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028455311432480812,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12129080295562744,
      "backward_entropy": 0.008976275367396218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041743867099285126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02845996432006359,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12119722366333008,
      "backward_entropy": 0.008947428848062242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04297881945967674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028464293107390404,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12110406160354614,
      "backward_entropy": 0.0089202666921275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036859605461359024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02846849337220192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12101104855537415,
      "backward_entropy": 0.00889377189534051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03473174199461937,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028472743928432465,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12091970443725586,
      "backward_entropy": 0.01019334580217089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03382844850420952,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028476689010858536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12082955241203308,
      "backward_entropy": 0.010172786457198007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03802113234996796,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028480421751737595,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12074064463376999,
      "backward_entropy": 0.008818384792123522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03506927192211151,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028484243899583817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12065199762582779,
      "backward_entropy": 0.00879417040518352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030825568363070488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02848803997039795,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12056395411491394,
      "backward_entropy": 0.00877014547586441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03436980023980141,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028491614386439323,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.120477095246315,
      "backward_entropy": 0.009348302015236445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036173950880765915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02849494479596615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12039005756378174,
      "backward_entropy": 0.010078103414603643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034966979175806046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028498107567429543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12030227482318878,
      "backward_entropy": 0.008704871471439089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030126038938760757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028501175343990326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12021395564079285,
      "backward_entropy": 0.008684505309377397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026568613946437836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028503945097327232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12012609839439392,
      "backward_entropy": 0.008665642035858971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02401699498295784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850644662976265,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12003949284553528,
      "backward_entropy": 0.008648184261151723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027045797556638718,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02850891463458538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11995482444763184,
      "backward_entropy": 0.008631031960248947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026187706738710403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02851130999624729,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11987081170082092,
      "backward_entropy": 0.008614289441279002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026601776480674744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02851363644003868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11978744715452194,
      "backward_entropy": 0.008597928498472487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02316528558731079,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02851586602628231,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11970432847738266,
      "backward_entropy": 0.009327807596751623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02324584499001503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02851812168955803,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11962247639894485,
      "backward_entropy": 0.008566208183765411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02415359951555729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028520120307803154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11954130977392197,
      "backward_entropy": 0.008552006312779017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018143609166145325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02852204442024231,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11946047842502594,
      "backward_entropy": 0.008538153554712023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02248348481953144,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028523938730359077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1193818598985672,
      "backward_entropy": 0.009329313678400857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021938271820545197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028525816276669502,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11930360645055771,
      "backward_entropy": 0.009329941655908312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018677663058042526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028527624905109406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192256435751915,
      "backward_entropy": 0.008497828883784158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019567474722862244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02852957881987095,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11914920061826706,
      "backward_entropy": 0.009330489805766515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02105551026761532,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028531476855278015,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11907345056533813,
      "backward_entropy": 0.009330303541251592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018675796687602997,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028533218428492546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11899745464324951,
      "backward_entropy": 0.008457644709518977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021380893886089325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028534822165966034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11892202496528625,
      "backward_entropy": 0.008445548691919871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015371140092611313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028536289930343628,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11884582042694092,
      "backward_entropy": 0.008434070540325982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016219334676861763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028537793084979057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11877140402793884,
      "backward_entropy": 0.00985341944864818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015524487011134624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028539158403873444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11869789659976959,
      "backward_entropy": 0.008411647485835212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018719466403126717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02854044735431671,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11862541735172272,
      "backward_entropy": 0.009839012154511042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017148161306977272,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02854183316230774,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11855252087116241,
      "backward_entropy": 0.009831551994596208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017014293000102043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028543172404170036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847959458827972,
      "backward_entropy": 0.008379606796162469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010929446667432785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028544532135128975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11840660870075226,
      "backward_entropy": 0.008368784827845437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013906609266996384,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028545822948217392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11833617091178894,
      "backward_entropy": 0.008358471095561981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010462728329002857,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028547164052724838,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11826662719249725,
      "backward_entropy": 0.009802761886801039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012970012612640858,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02854854054749012,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1181994378566742,
      "backward_entropy": 0.008337415754795074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01456285547465086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028549952432513237,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11813297122716904,
      "backward_entropy": 0.009787773447377341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010644453577697277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028551284223794937,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11806605756282806,
      "backward_entropy": 0.00935226253100804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012393185868859291,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028552597388625145,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11800072342157364,
      "backward_entropy": 0.009773491748741694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010942001827061176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028553882613778114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11793573945760727,
      "backward_entropy": 0.009354181587696075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010736598633229733,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028555145487189293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11787170171737671,
      "backward_entropy": 0.00975964856999261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0108577786013484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028556479141116142,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11780861765146255,
      "backward_entropy": 0.009752475789615087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00866673979908228,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02855772152543068,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1177460104227066,
      "backward_entropy": 0.009356391217027391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010501962155103683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028559019789099693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11768516153097153,
      "backward_entropy": 0.008257088384457998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01013671513646841,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028560245409607887,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11762452125549316,
      "backward_entropy": 0.00935730870280947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009888414293527603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02856152504682541,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11756426841020584,
      "backward_entropy": 0.008238061198166438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008947856724262238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028562815859913826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11750432848930359,
      "backward_entropy": 0.008228395666394914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00719240540638566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028564168140292168,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1174452006816864,
      "backward_entropy": 0.008218474686145782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009084808640182018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028565550222992897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11738783121109009,
      "backward_entropy": 0.008208545723131724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008110088296234608,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028566855937242508,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11733053624629974,
      "backward_entropy": 0.009355760046413966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007749099750071764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028567984700202942,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11727377027273178,
      "backward_entropy": 0.008190323199544634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007702236529439688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028569065034389496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11721768230199814,
      "backward_entropy": 0.0096856313092368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005680108442902565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028570035472512245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1171620786190033,
      "backward_entropy": 0.008174123508589608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0069589754566550255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02857104502618313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11710843443870544,
      "backward_entropy": 0.00816621950694493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0073831453919410706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028572088107466698,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11705543100833893,
      "backward_entropy": 0.008158203746591295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007003217935562134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02857305109500885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1170024648308754,
      "backward_entropy": 0.009663553110190801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006203672382980585,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02857396937906742,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11694970726966858,
      "backward_entropy": 0.009658409016472953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005099361762404442,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028574923053383827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11689773201942444,
      "backward_entropy": 0.00813570192881993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005017787683755159,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028575792908668518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11684726178646088,
      "backward_entropy": 0.008128713816404343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005622580647468567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028576625511050224,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11679811775684357,
      "backward_entropy": 0.008121950285775321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004091521259397268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028577467426657677,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11674953997135162,
      "backward_entropy": 0.008115201124123164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004937353078275919,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028578372672200203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1167028397321701,
      "backward_entropy": 0.009633298431124006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005019251722842455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02857922948896885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1166568398475647,
      "backward_entropy": 0.00810155804668154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004067395813763142,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02858002670109272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11661127209663391,
      "backward_entropy": 0.008095209087644304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004656463861465454,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02858087792992592,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11656700074672699,
      "backward_entropy": 0.009370348283222743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034669339656829834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028581667691469193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1165231317281723,
      "backward_entropy": 0.008082435599395208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003397543216124177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028582431375980377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11648081243038177,
      "backward_entropy": 0.00807642936706543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003930221777409315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028583260253071785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11643993109464645,
      "backward_entropy": 0.008070204939161028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004985829349607229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028584102168679237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11639958620071411,
      "backward_entropy": 0.008063935807773046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029473542235791683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028584886342287064,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11635836213827133,
      "backward_entropy": 0.008057898708752223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035995347425341606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028585750609636307,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1163187026977539,
      "backward_entropy": 0.008051580616406031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026714098639786243,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02858654037117958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11627952009439468,
      "backward_entropy": 0.009585508278438024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036139218136668205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028587372973561287,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11624184250831604,
      "backward_entropy": 0.00803958305290767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032214540988206863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028588179498910904,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11620422452688217,
      "backward_entropy": 0.009373463690280914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028587214183062315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02858891524374485,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11616704612970352,
      "backward_entropy": 0.008028100643839155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025799714494496584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02858962118625641,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11613065004348755,
      "backward_entropy": 0.008022738354546683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027453938964754343,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02859039232134819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11609525978565216,
      "backward_entropy": 0.008017127002988542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002719302661716938,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028591135516762733,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11606043577194214,
      "backward_entropy": 0.009374373725482396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002936390694230795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028591936454176903,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11602602899074554,
      "backward_entropy": 0.009553721972874232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026593049988150597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028592785820364952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11599156260490417,
      "backward_entropy": 0.008000026323965617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002489366801455617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02859356254339218,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11595742404460907,
      "backward_entropy": 0.00954438213791166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018951831152662635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02859441563487053,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11592362821102142,
      "backward_entropy": 0.007988539125238146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002245330950245261,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028595218434929848,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11589109897613525,
      "backward_entropy": 0.007982937885182244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021583191119134426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02859598770737648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1158590167760849,
      "backward_entropy": 0.009530522993632726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020148088224232197,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028596725314855576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11582739651203156,
      "backward_entropy": 0.009526235716683524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001685642171651125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028597498312592506,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1157962828874588,
      "backward_entropy": 0.009521805814334325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016252988716587424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028598228469491005,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11576618254184723,
      "backward_entropy": 0.009369068912097387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019545387476682663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02859889715909958,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11573707312345505,
      "backward_entropy": 0.007957059890031815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014254339039325714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02859954908490181,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11570809781551361,
      "backward_entropy": 0.007952380925416946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019845229107886553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02860022708773613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11568008363246918,
      "backward_entropy": 0.009505675307341985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015910167712718248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860083431005478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1156519278883934,
      "backward_entropy": 0.007943228951522283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010476962197571993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860140986740589,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11562425643205643,
      "backward_entropy": 0.007938998086111886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013013528659939766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028602035716176033,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11559794843196869,
      "backward_entropy": 0.009367800184658595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012791813351213932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860267087817192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11557230353355408,
      "backward_entropy": 0.007930209594113486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012533399276435375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860327437520027,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.115547314286232,
      "backward_entropy": 0.007926005337919508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001387964584864676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028603872284293175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1155228465795517,
      "backward_entropy": 0.007921854300158364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001172321499325335,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02860444039106369,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11549851298332214,
      "backward_entropy": 0.009480853165899004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012512097600847483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860502526164055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11547461152076721,
      "backward_entropy": 0.007913785853556224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010451903799548745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02860557660460472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11545096337795258,
      "backward_entropy": 0.009474207248006548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015314280753955245,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860613912343979,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11542783677577972,
      "backward_entropy": 0.007906001593385423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011187312193214893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028606591746211052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11540424823760986,
      "backward_entropy": 0.00946816269840513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011960586998611689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028607042506337166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1153809130191803,
      "backward_entropy": 0.007899218371936254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008327667601406574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286074448376894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1153576672077179,
      "backward_entropy": 0.007896074226924352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010571773163974285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860787883400917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1153351292014122,
      "backward_entropy": 0.007892819387572152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008320692577399313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028608258813619614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.115312859416008,
      "backward_entropy": 0.009457884090287345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007316395058296621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028608640655875206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11529120057821274,
      "backward_entropy": 0.007886889257601329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000745490484405309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028609029948711395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11527027189731598,
      "backward_entropy": 0.007883919136864799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006108576199039817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028609415516257286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11524999141693115,
      "backward_entropy": 0.007881022989749908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006692123133689165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860981598496437,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11523053050041199,
      "backward_entropy": 0.007878095443759645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007018808973953128,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861020527780056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11521168798208237,
      "backward_entropy": 0.009445639593260629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008617376442998648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028610575944185257,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11519326269626617,
      "backward_entropy": 0.007872519216367177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008604120812378824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861090563237667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11517472565174103,
      "backward_entropy": 0.007869978568383626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005395739572122693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028611203655600548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11515597999095917,
      "backward_entropy": 0.009438961744308472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007063522352837026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028611527755856514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11513780802488327,
      "backward_entropy": 0.007865100566829954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006378352991305292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028611838817596436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11511968076229095,
      "backward_entropy": 0.007862678595951625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006376546225510538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028612129390239716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11510185897350311,
      "backward_entropy": 0.00786034603204046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006912280223332345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861240692436695,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11508417129516602,
      "backward_entropy": 0.00785810500383377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046437507262453437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02861265279352665,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11506643891334534,
      "backward_entropy": 0.009372952793325697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043472700053825974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286128968000412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11504939198493958,
      "backward_entropy": 0.00785396620631218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005392086459323764,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286131352186203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11503305286169052,
      "backward_entropy": 0.009425106857504164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004482670337893069,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028613364323973656,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11501684784889221,
      "backward_entropy": 0.007850047200918198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004687948676291853,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861359901726246,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11500099301338196,
      "backward_entropy": 0.009421497583389282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035157433012500405,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861381694674492,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11498548090457916,
      "backward_entropy": 0.009419748825686318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048574546235613525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028614025563001633,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11497071385383606,
      "backward_entropy": 0.009377412497997284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044536113273352385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02861420251429081,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1149560809135437,
      "backward_entropy": 0.00937833424125399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003623423690441996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02861437387764454,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11494150757789612,
      "backward_entropy": 0.009379280464989799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003231206501368433,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028614554554224014,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1149272620677948,
      "backward_entropy": 0.009413306202207292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040241022361442447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028614750131964684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11491340398788452,
      "backward_entropy": 0.007838076778820582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003101328038610518,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861492708325386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1148996502161026,
      "backward_entropy": 0.009410182280199868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041340728057548404,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028615092858672142,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11488640308380127,
      "backward_entropy": 0.009382404386997223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000281255372101441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028615226969122887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11487314105033875,
      "backward_entropy": 0.0078337128673281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002442732220515609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861536666750908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11486029624938965,
      "backward_entropy": 0.007832390921456473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030108820647001266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028615517541766167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11484795063734055,
      "backward_entropy": 0.009404611374650682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028030676185153425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028615647926926613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1148359552025795,
      "backward_entropy": 0.007829792265381132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002594218240119517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028615780174732208,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11482410132884979,
      "backward_entropy": 0.009401980255331312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002530888596083969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861589938402176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11481262743473053,
      "backward_entropy": 0.009400691304888045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024655094603076577,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861602045595646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1148013323545456,
      "backward_entropy": 0.009399447057928358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023235274420585483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861614339053631,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11479020118713379,
      "backward_entropy": 0.007825090416840144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021532655227929354,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028616268187761307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1147792637348175,
      "backward_entropy": 0.009397001138755254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002603363827802241,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028616389259696007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11476859450340271,
      "backward_entropy": 0.007822813732283456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023527158191427588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028616493567824364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11475792527198792,
      "backward_entropy": 0.007821757878576006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021474402456078678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028616588562726974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1147473156452179,
      "backward_entropy": 0.007820758436407362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002465768775437027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028616681694984436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11473679542541504,
      "backward_entropy": 0.007819782942533493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020550194312818348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028616756200790405,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11472618579864502,
      "backward_entropy": 0.009391544120652335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001819838216761127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028616825118660927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11471569538116455,
      "backward_entropy": 0.007818007043429784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012714622425846756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861689403653145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11470542103052139,
      "backward_entropy": 0.007817167256559645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010180663230130449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028616981580853462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11469560861587524,
      "backward_entropy": 0.007816212517874581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001652951177675277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028617089614272118,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11468642950057983,
      "backward_entropy": 0.007815243942396981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014421407831832767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028617195785045624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11467727273702621,
      "backward_entropy": 0.007814260465758187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001246552710654214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861730195581913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11466830968856812,
      "backward_entropy": 0.00781330359833581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001319740986218676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028617404401302338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11465977132320404,
      "backward_entropy": 0.007812372807945524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.326341048814356e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861749939620495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11465152353048325,
      "backward_entropy": 0.009383451725755419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013261736603453755,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028617611154913902,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11464376747608185,
      "backward_entropy": 0.007810559123754501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012646584946196526,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02861771173775196,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1146361231803894,
      "backward_entropy": 0.009401859981673104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010003006900660694,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02861780859529972,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11462847888469696,
      "backward_entropy": 0.00940241026026862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012658828927669674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861790917813778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11462107300758362,
      "backward_entropy": 0.007807997188397816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010693412332329899,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028617994859814644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11461367458105087,
      "backward_entropy": 0.009378322533198766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012830874766223133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861807681620121,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11460639536380768,
      "backward_entropy": 0.007806454918214253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013006888912059367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028618136420845985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11459912359714508,
      "backward_entropy": 0.00937660038471222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.085623267106712e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861817367374897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1145917996764183,
      "backward_entropy": 0.007805241537945611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010632882360369e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028618212789297104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11458484828472137,
      "backward_entropy": 0.007804694452456066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5185923227109015e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028618255630135536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11457818001508713,
      "backward_entropy": 0.007804151092256818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6424742069793865e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861831896007061,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11457204818725586,
      "backward_entropy": 0.007803546530859811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.313360063359141e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861839346587658,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11456625163555145,
      "backward_entropy": 0.009372679250580924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.549607496708632e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028618477284908295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11456058919429779,
      "backward_entropy": 0.0078022171344075885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.242629024200141e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861855737864971,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11455515772104263,
      "backward_entropy": 0.007801563612052372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.844881136203185e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028618641197681427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11454980820417404,
      "backward_entropy": 0.007800896785088948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0837690903572366e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028618715703487396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11454463005065918,
      "backward_entropy": 0.00936908062015261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1120110583724454e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861880138516426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1145397424697876,
      "backward_entropy": 0.007799631250756127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.711762085207738e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028618892654776573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11453492939472198,
      "backward_entropy": 0.0077989548444747925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0786835092585534e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028618987649679184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11453024297952652,
      "backward_entropy": 0.007798264069216592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.987256008666009e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861907333135605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11452557146549225,
      "backward_entropy": 0.009365440479346685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.149680848466232e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028619149699807167,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1145208403468132,
      "backward_entropy": 0.00936461559363774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.336478377808817e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861921675503254,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1145160123705864,
      "backward_entropy": 0.007796464221818107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.842513251584023e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861928567290306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11451131105422974,
      "backward_entropy": 0.009363118026937758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.514978016028181e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028619354590773582,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11450687050819397,
      "backward_entropy": 0.007795342377253941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.366449477151036e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028619425371289253,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11450262367725372,
      "backward_entropy": 0.007794789969921112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.229386831866577e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861948311328888,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1144983172416687,
      "backward_entropy": 0.007794300892523357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.173799268552102e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028619537129998207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11449405550956726,
      "backward_entropy": 0.009413243404456548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.462942913756706e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028619596734642982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11448990553617477,
      "backward_entropy": 0.007793331784861428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.702925459947437e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861965261399746,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11448591947555542,
      "backward_entropy": 0.00935893931559154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.682657759578433e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028619704768061638,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11448197066783905,
      "backward_entropy": 0.009414199207510267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.055195677210577e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028619760647416115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11447818577289581,
      "backward_entropy": 0.009357643978936332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1163450077874586e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028619805350899696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11447442322969437,
      "backward_entropy": 0.007791558014495032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8651029424509034e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028619835153222084,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11447065323591232,
      "backward_entropy": 0.009415300829069955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2801374143455178e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861986681818962,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11446695029735565,
      "backward_entropy": 0.007790899702480861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1771089450339787e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028619904071092606,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11446337401866913,
      "backward_entropy": 0.0077905356884002686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.435749593132641e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861994504928589,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11445992439985275,
      "backward_entropy": 0.007790162627186094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.537162981752772e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028619984164834023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11445657908916473,
      "backward_entropy": 0.007789811385529382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2605432604905218e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620021417737007,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11445330083370209,
      "backward_entropy": 0.007789467062268939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6374026017729193e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620058670639992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11445008218288422,
      "backward_entropy": 0.007789138704538345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.216341636085417e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620101511478424,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11444699764251709,
      "backward_entropy": 0.007788776287010738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1047881091362797e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620140627026558,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11444397270679474,
      "backward_entropy": 0.00778843994651522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.012044205912389e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620176017284393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11444102227687836,
      "backward_entropy": 0.007788125425577164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5774997993721627e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862020768225193,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11443813145160675,
      "backward_entropy": 0.007787821016141346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3886489796277601e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862023003399372,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11443515121936798,
      "backward_entropy": 0.007787572486060006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2037853593938053e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862025611102581,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11443234980106354,
      "backward_entropy": 0.007787302668605532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3951203982287552e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620287775993347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11442969739437103,
      "backward_entropy": 0.0077870312545980725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4986244423198514e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620319440960884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11442716419696808,
      "backward_entropy": 0.007786742278507778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1764717783080414e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862035110592842,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1144246906042099,
      "backward_entropy": 0.007786462349551064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8615799490362406e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620384633541107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11442231386899948,
      "backward_entropy": 0.007786194660833904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.122602255549282e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620410710573196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1144198551774025,
      "backward_entropy": 0.007785942405462265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1472518963273615e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028620444238185883,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11441759020090103,
      "backward_entropy": 0.00942067482641765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.966235666070133e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02862047776579857,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11441537737846375,
      "backward_entropy": 0.009420870670250483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.477660230710171e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028620513156056404,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11441323161125183,
      "backward_entropy": 0.009347143982137953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.014647053438239e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620552271604538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11441117525100708,
      "backward_entropy": 0.0077848248183727264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3106888218317181e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862059511244297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11440922319889069,
      "backward_entropy": 0.007784524134227208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7647266658023e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620630502700806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11440727114677429,
      "backward_entropy": 0.00778426176735333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.852077710092999e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862067148089409,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11440541595220566,
      "backward_entropy": 0.007783969065972737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.390786206291523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620710596442223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11440351605415344,
      "backward_entropy": 0.007783704570361546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.817028745193966e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028620747849345207,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.114401675760746,
      "backward_entropy": 0.009344637393951416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.733454706089105e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620783239603043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11439991742372513,
      "backward_entropy": 0.007783181965351105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.674790711258538e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862081676721573,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11439812183380127,
      "backward_entropy": 0.007782912680080959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.006075763143599e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620850294828415,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11439639329910278,
      "backward_entropy": 0.007782665746552604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.295530278701335e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028620878234505653,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11439462006092072,
      "backward_entropy": 0.009422142590795244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.901334356574807e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620902448892593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11439281702041626,
      "backward_entropy": 0.007782253303698131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.912157914484851e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620922937989235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143910363316536,
      "backward_entropy": 0.007782051073653358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2000902946456335e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620943427085876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11438927054405212,
      "backward_entropy": 0.00778187598500933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.547310360678239e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862096019089222,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11438753455877304,
      "backward_entropy": 0.007781708879130227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.428087661130121e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620973229408264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11438578367233276,
      "backward_entropy": 0.007781551352569035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.057479600305669e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028620988130569458,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11438408493995667,
      "backward_entropy": 0.0077814071306160516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5072869145078585e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286210048943758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11438246071338654,
      "backward_entropy": 0.0077812448143959045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.83877681492595e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621019795536995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1143808662891388,
      "backward_entropy": 0.009341162230287279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0707431000773795e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862103283405304,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11437924951314926,
      "backward_entropy": 0.007780949984277997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.891242158715613e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621045872569084,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11437766253948212,
      "backward_entropy": 0.007780803101403373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.571473255055025e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862105891108513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11437609046697617,
      "backward_entropy": 0.007780657282897404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.882147211697884e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621071949601173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11437459290027618,
      "backward_entropy": 0.007780514657497406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.792773668465088e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621084988117218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11437314748764038,
      "backward_entropy": 0.007780395448207855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.408051609061658e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621098026633263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11437173187732697,
      "backward_entropy": 0.009339962686811174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9089925444859546e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621109202504158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11437033116817474,
      "backward_entropy": 0.0077801453215735296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.395352789288154e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621124103665352,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11436902731657028,
      "backward_entropy": 0.009424833314759391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.498822479741648e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621135279536247,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11436772346496582,
      "backward_entropy": 0.00933940282889775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9677955808438128e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621146455407143,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11436641961336136,
      "backward_entropy": 0.007779762148857117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.832269612757955e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621157631278038,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11436519026756287,
      "backward_entropy": 0.009425264384065355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.586515387927648e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621165081858635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11436396837234497,
      "backward_entropy": 0.009338896189417158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.008981709877844e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621168807148933,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11436272412538528,
      "backward_entropy": 0.007779484880822045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7991607112198835e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862117439508438,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11436156183481216,
      "backward_entropy": 0.007779400795698166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1811869121156633e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862117998301983,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11436039954423904,
      "backward_entropy": 0.009338489600590296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5008712352937437e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621183708310127,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11435922980308533,
      "backward_entropy": 0.009426114814622062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.648118652359699e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621189296245575,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11435814946889877,
      "backward_entropy": 0.007779163441487721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1419093652875745e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621194884181023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11435709148645401,
      "backward_entropy": 0.007779087339128766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.195104343627463e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862120233476162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11435611546039581,
      "backward_entropy": 0.007779004318373544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0991806195524987e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621209785342216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143551766872406,
      "backward_entropy": 0.007778920233249664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8020377865468618e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621217235922813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.114354208111763,
      "backward_entropy": 0.009337649813720159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1114487935847137e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862122468650341,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11435330659151077,
      "backward_entropy": 0.00933751038142613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.014512347159325e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621230274438858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11435240507125854,
      "backward_entropy": 0.007778689797435488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3938778238298255e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621233999729156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11435149610042572,
      "backward_entropy": 0.009337267705372401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1617322570600663e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621239587664604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11435062438249588,
      "backward_entropy": 0.007778550897325788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9181672996637644e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286212470382452,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11434979736804962,
      "backward_entropy": 0.009337023964950017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2149790791227133e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862125262618065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434894800186157,
      "backward_entropy": 0.0077784088041101184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56638791901787e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621258214116096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143481507897377,
      "backward_entropy": 0.007778338023594448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1060102451665443e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621265664696693,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11434737592935562,
      "backward_entropy": 0.009336671658924647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3377798495639581e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862127311527729,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11434663087129593,
      "backward_entropy": 0.009336547127791814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.821093047117756e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621280565857887,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434590816497803,
      "backward_entropy": 0.007778134196996689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4798473557675607e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621288016438484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434520781040192,
      "backward_entropy": 0.007778060755559376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.808978696426493e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621293604373932,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143445074558258,
      "backward_entropy": 0.0077779947647026604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.497140816463798e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862130105495453,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11434384435415268,
      "backward_entropy": 0.009336090513638087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1854301646962995e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621310368180275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434323340654373,
      "backward_entropy": 0.0077778494783810204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2435494909368572e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621317818760872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.114342600107193,
      "backward_entropy": 0.007777780294418335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0966195986839011e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02862132340669632,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11434195935726166,
      "backward_entropy": 0.009428311671529497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.042917119775666e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621327131986618,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434131860733032,
      "backward_entropy": 0.007777678115027291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03900832124782e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621330857276917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11434069275856018,
      "backward_entropy": 0.007777625960963113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.759192956451443e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621334582567215,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11434008181095123,
      "backward_entropy": 0.00942856924874442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.806979691489687e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621338307857513,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433950066566467,
      "backward_entropy": 0.007777535489627293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.241036771825748e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862134389579296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143389344215393,
      "backward_entropy": 0.007777483867747443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.302622471641371e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862134948372841,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433841288089752,
      "backward_entropy": 0.009335225181920188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.428263645830157e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621355071663857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433792859315872,
      "backward_entropy": 0.007777381156172071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.811029263393721e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621360659599304,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11433742195367813,
      "backward_entropy": 0.009428874722548894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.645144700698438e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621366247534752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433693021535873,
      "backward_entropy": 0.007777267268725804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.972374085809861e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286213681101799,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433644592761993,
      "backward_entropy": 0.007777238530772073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.04513502366899e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286213718354702,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433596163988113,
      "backward_entropy": 0.0077772097928183416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8669355717502185e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02862137369811535,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11433547735214233,
      "backward_entropy": 0.009429157844611577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4061496851099946e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621377423405647,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433502286672592,
      "backward_entropy": 0.009334657873426164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.032621513440972e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433456838130951,
      "backward_entropy": 0.007777091647897448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.95958214894199e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621383011341095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433415114879608,
      "backward_entropy": 0.009334516312394823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.548492592628463e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621383011341095,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11433369666337967,
      "backward_entropy": 0.009429443095411574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2318354215021827e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433324217796326,
      "backward_entropy": 0.009334418390478407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.458288114823517e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433281004428864,
      "backward_entropy": 0.009334359850202287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.892451504976634e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621379286050797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433239281177521,
      "backward_entropy": 0.0077769894685064045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0234050051849408e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621379286050797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433199793100357,
      "backward_entropy": 0.00777695540870939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.000050802867918e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433165520429611,
      "backward_entropy": 0.007776934121336255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5650983793166233e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11433129012584686,
      "backward_entropy": 0.00777691975235939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1150543122748786e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433091759681702,
      "backward_entropy": 0.009334073535033635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.098654417499347e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11433057487010956,
      "backward_entropy": 0.009334034153393336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5394811586920696e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1143302470445633,
      "backward_entropy": 0.009333978806223189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3734650628503005e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11432991921901703,
      "backward_entropy": 0.00933392345905304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.365423401011867e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11432960629463196,
      "backward_entropy": 0.009430261594908578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.709552629516111e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621383011341095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11432931572198868,
      "backward_entropy": 0.009333822344030653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.068909168428945e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621383011341095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143290251493454,
      "backward_entropy": 0.007776796817779541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7446464539716544e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621383011341095,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11432874202728271,
      "backward_entropy": 0.00933373932327543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.676315205007995e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621384873986244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432848870754242,
      "backward_entropy": 0.007776772337300437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.003247002197895e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621384873986244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432821303606033,
      "backward_entropy": 0.007776757436139243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.90828870927362e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621384873986244,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11432793736457825,
      "backward_entropy": 0.009430611772196633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0212356705305865e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621384873986244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432766914367676,
      "backward_entropy": 0.0077767228441579005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2275490607626125e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621383011341095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432738602161407,
      "backward_entropy": 0.0077767132648399896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0416190576734152e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432710289955139,
      "backward_entropy": 0.0077767132648399896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.999123355744814e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1143268495798111,
      "backward_entropy": 0.0077767036855220795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5104106410035456e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1143266037106514,
      "backward_entropy": 0.009333397660936629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9946841689488792e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621381148695946,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1143263429403305,
      "backward_entropy": 0.00943096514259066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8333565776629257e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621379286050797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432608962059021,
      "backward_entropy": 0.007776679737227303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.464075722878988e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621377423405647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432585120201111,
      "backward_entropy": 0.007776674947568348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.961394826201285e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621375560760498,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11432559788227081,
      "backward_entropy": 0.009431126926626478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.918340199670638e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621375560760498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432535946369171,
      "backward_entropy": 0.007776648870536259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0120093918430939e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621375560760498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432512104511261,
      "backward_entropy": 0.007776636630296707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.324652885159594e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621375560760498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432491987943649,
      "backward_entropy": 0.00777662917971611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6115765788526915e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621375560760498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432470381259918,
      "backward_entropy": 0.007776620132582528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3024776990278042e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621375560760498,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432449519634247,
      "backward_entropy": 0.007776615342923573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2256430181878386e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862137369811535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11432427167892456,
      "backward_entropy": 0.009333091122763497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1680850064976767e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0286213718354702,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11432404816150665,
      "backward_entropy": 0.009431463267121996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.128856959250697e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862136997282505,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11432383954524994,
      "backward_entropy": 0.009333038968699319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0755580603927228e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286213681101799,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11432362347841263,
      "backward_entropy": 0.009333021938800812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183435085129531e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621366247534752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432342231273651,
      "backward_entropy": 0.007776596184287753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.690067794716924e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432322859764099,
      "backward_entropy": 0.007776590862444469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.669044859743735e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432304978370667,
      "backward_entropy": 0.00777657117162432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.075080787899424e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11432286351919174,
      "backward_entropy": 0.009332929338727678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.753146746836137e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11432269215583801,
      "backward_entropy": 0.009431770869663783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.093238897302399e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432251334190369,
      "backward_entropy": 0.0077765583992004395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.38836388841446e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432234942913055,
      "backward_entropy": 0.0077765509486198425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.131028129630067e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432220041751862,
      "backward_entropy": 0.007776543498039246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4674972226866885e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11432203650474548,
      "backward_entropy": 0.00943191455943244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.740177838082673e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432188749313354,
      "backward_entropy": 0.007776532854352679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.844889645028161e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1143217384815216,
      "backward_entropy": 0.009332749460424696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9858622241363264e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028621364384889603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11432160437107086,
      "backward_entropy": 0.007776520081928798,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.053943456668094e-06,
    "avg_log_Z": 0.028621306885033847,
    "success_rate": 1.0,
    "avg_reward": 47.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.28,
      "2": 0.57
    },
    "avg_forward_entropy": 0.1143397817015648,
    "avg_backward_entropy": 0.00846161728458745,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}