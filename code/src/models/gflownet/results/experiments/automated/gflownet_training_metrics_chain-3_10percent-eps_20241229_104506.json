{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.2306816577911377,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.2306816577911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.2306816577911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.2306816577911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.2306816577911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.2306816577911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.2306816577911377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23091200987497965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.79014778137207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460604906082153,
      "backward_entropy": 0.23084092140197754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.147886276245117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460724115371704,
      "backward_entropy": 0.23082427183787027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.777144432067871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0002000447129830718,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460816502571106,
      "backward_entropy": 0.2308069864908854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.750372886657715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003000368014909327,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2746088206768036,
      "backward_entropy": 0.2307891050974528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.655167579650879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00040018666186369956,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460920810699463,
      "backward_entropy": 0.2305968999862671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.75871753692627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000500185473356396,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460917830467224,
      "backward_entropy": 0.23084795475006104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.609991073608398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006001223810017109,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274608850479126,
      "backward_entropy": 0.2308340867360433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.746655464172363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006999934557825327,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460840344429016,
      "backward_entropy": 0.23081966241200766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.100759506225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00079984066542238,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27460765838623047,
      "backward_entropy": 0.23050365845362344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.124345779418945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008997676777653396,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27460652589797974,
      "backward_entropy": 0.23067780335744223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.119363784790039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009994839783757925,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2746051847934723,
      "backward_entropy": 0.23077313105265299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.331283569335938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010990359587594867,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27460360527038574,
      "backward_entropy": 0.2307563622792562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.001264572143555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011985418386757374,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2746019661426544,
      "backward_entropy": 0.230400284131368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.569927215576172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012978835729882121,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459996938705444,
      "backward_entropy": 0.23072121540705362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.207574844360352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013972918968647718,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27459776401519775,
      "backward_entropy": 0.23034425576527914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.52337646484375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014966420130804181,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27459537982940674,
      "backward_entropy": 0.2305444876352946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.338136672973633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001595690380781889,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745925784111023,
      "backward_entropy": 0.23066377639770508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.043044090270996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016947744879871607,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274589478969574,
      "backward_entropy": 0.23049374421437582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.725778579711914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017941247206181288,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745859920978546,
      "backward_entropy": 0.23046700159708658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.075417518615723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001893264940008521,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745823264122009,
      "backward_entropy": 0.2305999994277954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.777425765991211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019923520740121603,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745784521102905,
      "backward_entropy": 0.23041160901387533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.065671920776367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00209164060652256,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27457427978515625,
      "backward_entropy": 0.23038305838902792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.904894828796387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021908541675657034,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27456986904144287,
      "backward_entropy": 0.23053308327992758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.865665435791016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022902849595993757,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27456510066986084,
      "backward_entropy": 0.23032192389170328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.944686889648438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023899185471236706,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27456003427505493,
      "backward_entropy": 0.2304848631223043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.906919479370117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002489376114681363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745547592639923,
      "backward_entropy": 0.2302556037902832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.46366024017334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002588698174804449,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745494544506073,
      "backward_entropy": 0.23043370246887207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.490885734558105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026881315279752016,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745441198348999,
      "backward_entropy": 0.2299130161603292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.543248176574707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00278764427639544,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274538516998291,
      "backward_entropy": 0.23015153408050537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.782354354858398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002886876929551363,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27453288435935974,
      "backward_entropy": 0.2298379143079122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.926392555236816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029859496280550957,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27452710270881653,
      "backward_entropy": 0.23032172520955405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.46780776977539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0030853357166051865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27452096343040466,
      "backward_entropy": 0.23003776868184408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.115052223205566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031848109792917967,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27451449632644653,
      "backward_entropy": 0.2302612066268921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.599069595336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003284228267148137,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745078206062317,
      "backward_entropy": 0.22967676321665445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.896628379821777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003384183393791318,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450060844421387,
      "backward_entropy": 0.22991238037745157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.098731994628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00348391174338758,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27449309825897217,
      "backward_entropy": 0.22959103186925253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.472707748413086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003583543701097369,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744855284690857,
      "backward_entropy": 0.2298217217127482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.2257080078125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036832124460488558,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27447718381881714,
      "backward_entropy": 0.2297746737798055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.04493236541748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037828253116458654,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27446871995925903,
      "backward_entropy": 0.22972591718037924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.214284896850586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0038827022071927786,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744596004486084,
      "backward_entropy": 0.2296755313873291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.941280364990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003982494119554758,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27445030212402344,
      "backward_entropy": 0.22935426235198975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.135127067565918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00408168975263834,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744411528110504,
      "backward_entropy": 0.229302446047465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.436124801635742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004180811811238527,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744317054748535,
      "backward_entropy": 0.22951390345891318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.907243728637695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004280029330402613,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744218707084656,
      "backward_entropy": 0.22985108693440756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.844901084899902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00437950948253274,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27441152930259705,
      "backward_entropy": 0.2293956478436788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.077317237854004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004478805232793093,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27440109848976135,
      "backward_entropy": 0.22933467229207358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.173331260681152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004578028805553913,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27439045906066895,
      "backward_entropy": 0.22902433077494302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.525076866149902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0046772425994277,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743796408176422,
      "backward_entropy": 0.2296688954035441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.215306282043457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004776243586093187,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743690609931946,
      "backward_entropy": 0.229620099067688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.594707489013672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004874890670180321,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743585705757141,
      "backward_entropy": 0.2295703093210856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.250853538513184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004973797593265772,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743474841117859,
      "backward_entropy": 0.2290111780166626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.479996681213379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0050727869383990765,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27433598041534424,
      "backward_entropy": 0.2294680674870809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.372259140014648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005171941593289375,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743239104747772,
      "backward_entropy": 0.22887031237284342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.466249465942383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005271186586469412,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743113934993744,
      "backward_entropy": 0.2293604016304016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.890100479125977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00537056615576148,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27429836988449097,
      "backward_entropy": 0.2287203073501587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.351713180541992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005469821393489838,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742852568626404,
      "backward_entropy": 0.2292469342549642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.911979675292969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005569152999669313,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27427223324775696,
      "backward_entropy": 0.22856279214223227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.072602272033691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0056687924079597,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742583751678467,
      "backward_entropy": 0.2283318837483724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.397958755493164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005767933093011379,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27424487471580505,
      "backward_entropy": 0.22906547784805298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.622941970825195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005867232568562031,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742308974266052,
      "backward_entropy": 0.22831088304519653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.747660636901855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005966764874756336,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742166519165039,
      "backward_entropy": 0.22822980086008707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.045286178588867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006066539790481329,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742011547088623,
      "backward_entropy": 0.22814899682998657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.128073692321777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006166245322674513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27418574690818787,
      "backward_entropy": 0.22806700070699057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.603057861328125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00626639137044549,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27416956424713135,
      "backward_entropy": 0.2287407120068868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.366538047790527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006366213783621788,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274153470993042,
      "backward_entropy": 0.2278976837793986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.477574348449707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006465651094913483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741376757621765,
      "backward_entropy": 0.22781085968017578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.240114212036133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006565237883478403,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741212844848633,
      "backward_entropy": 0.22853167851765951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.642240524291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006664860062301159,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274104505777359,
      "backward_entropy": 0.22755944728851318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.308797836303711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006764281075447798,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740878760814667,
      "backward_entropy": 0.22753791014353433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.217668533325195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006863369140774012,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27407151460647583,
      "backward_entropy": 0.2274448275566101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.2211275100708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006962544284760952,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27405470609664917,
      "backward_entropy": 0.22729972998301187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.5881986618042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007062231656163931,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27403712272644043,
      "backward_entropy": 0.22724926471710205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.45820426940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007161615416407585,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27401968836784363,
      "backward_entropy": 0.2271477778752645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.642217636108398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007261127699166536,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740020453929901,
      "backward_entropy": 0.2279815673828125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.047627449035645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007360862568020821,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27398329973220825,
      "backward_entropy": 0.22693212827046713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.135224342346191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007460559718310833,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739644944667816,
      "backward_entropy": 0.2268237272898356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.425752639770508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007560276426374912,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27394533157348633,
      "backward_entropy": 0.2267089287439982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.059934616088867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007660075090825558,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739257514476776,
      "backward_entropy": 0.2265926202138265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.05195426940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007759806700050831,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739059627056122,
      "backward_entropy": 0.22647400697072348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.007331848144531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007859475910663605,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738860249519348,
      "backward_entropy": 0.2263526717821757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.36054801940918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007959101349115372,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27386587858200073,
      "backward_entropy": 0.22732873757680258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.79587459564209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008058379404246807,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738460302352905,
      "backward_entropy": 0.22610392173131308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33566665649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008157983422279358,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738252878189087,
      "backward_entropy": 0.22606873512268066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.328763961791992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008256707340478897,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738061547279358,
      "backward_entropy": 0.2258432904879252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.872570991516113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008355621248483658,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27378660440444946,
      "backward_entropy": 0.22570755084355673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.980928421020508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00845450721681118,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27376654744148254,
      "backward_entropy": 0.22557040055592856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.747551918029785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008553850464522839,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27374520897865295,
      "backward_entropy": 0.22667109966278076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.107194900512695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00865350104868412,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737234830856323,
      "backward_entropy": 0.2252828280131022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.431879043579102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00875311903655529,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737014889717102,
      "backward_entropy": 0.22513333956400552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.494991302490234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008852412924170494,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736797630786896,
      "backward_entropy": 0.22516397635142008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41609001159668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008951913565397263,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27365726232528687,
      "backward_entropy": 0.2250234285990397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.40808391571045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009051097556948662,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736351490020752,
      "backward_entropy": 0.22606964906056723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.932369232177734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009149996563792229,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736132740974426,
      "backward_entropy": 0.22450900077819824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.574841499328613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009248889051377773,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2735910713672638,
      "backward_entropy": 0.22458465894063315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.133410453796387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009347633458673954,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27356886863708496,
      "backward_entropy": 0.22443397839864096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.19299030303955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009446481242775917,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27354609966278076,
      "backward_entropy": 0.2255350947380066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.641965866088867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009544960223138332,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27352407574653625,
      "backward_entropy": 0.225393017133077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.139883041381836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009643815457820892,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2735007405281067,
      "backward_entropy": 0.22524801890055338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.800725936889648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009742309339344501,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2734780013561249,
      "backward_entropy": 0.22379769881566366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.698397636413574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009841280058026314,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27345362305641174,
      "backward_entropy": 0.22494745254516602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.342962265014648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009940617717802525,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2734293043613434,
      "backward_entropy": 0.22479244073232016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.665220260620117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01004013977944851,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27340343594551086,
      "backward_entropy": 0.22463438908259073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.014219284057617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01013945322483778,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27337709069252014,
      "backward_entropy": 0.22447379430135092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.129094123840332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01023879460990429,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2733497619628906,
      "backward_entropy": 0.22430972258249918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.723812103271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010338199324905872,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733217179775238,
      "backward_entropy": 0.22279953956604004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.01655101776123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010437451303005219,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732945382595062,
      "backward_entropy": 0.22397180398305258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.14972972869873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01053620595484972,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732704281806946,
      "backward_entropy": 0.22189764181772867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.421980857849121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010634634643793106,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27324700355529785,
      "backward_entropy": 0.22226009766260782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.225370407104492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010733351111412048,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2732226252555847,
      "backward_entropy": 0.22207160790761313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731609344482422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01083128247410059,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27320045232772827,
      "backward_entropy": 0.2212472359339396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.438826560974121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010928761214017868,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27317941188812256,
      "backward_entropy": 0.2230552633603414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.784231185913086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011026686988770962,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2731562852859497,
      "backward_entropy": 0.22285902500152588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.616437911987305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01112413126975298,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2731342017650604,
      "backward_entropy": 0.2212804158528646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.346797943115234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011221112683415413,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731134593486786,
      "backward_entropy": 0.22032622496287027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.160249710083008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011318103410303593,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27309277653694153,
      "backward_entropy": 0.22008617719014487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.429361343383789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011415408924221992,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27307090163230896,
      "backward_entropy": 0.22203326225280762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.383530616760254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011512648314237595,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2730490267276764,
      "backward_entropy": 0.2218171755472819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.790740013122559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011609837412834167,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2730277180671692,
      "backward_entropy": 0.21932685375213623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.44813346862793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011707172729074955,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27300503849983215,
      "backward_entropy": 0.21996736526489258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.523645401000977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011804496869444847,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27298209071159363,
      "backward_entropy": 0.21879353125890097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.019916534423828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011901861988008022,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27295833826065063,
      "backward_entropy": 0.2195043166478475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.735966682434082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011999999172985554,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729305922985077,
      "backward_entropy": 0.22068381309509277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.279540061950684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012097671627998352,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2729049623012543,
      "backward_entropy": 0.21795900662740073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.681126594543457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012195239774882793,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728796601295471,
      "backward_entropy": 0.21767260630925497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.958932876586914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0122924093157053,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728554904460907,
      "backward_entropy": 0.21738308668136597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.242196083068848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012389863841235638,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728307843208313,
      "backward_entropy": 0.21708605686823526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.520501136779785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012487226165831089,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728060781955719,
      "backward_entropy": 0.21678423881530762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.485688209533691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012584652751684189,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27278074622154236,
      "backward_entropy": 0.21779298782348633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.25548267364502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0126820532605052,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27275514602661133,
      "backward_entropy": 0.21889897187550864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.017960548400879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012779822573065758,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727290987968445,
      "backward_entropy": 0.21724418799082437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630468368530273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01287734042853117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2727038264274597,
      "backward_entropy": 0.21550635496775308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.310750007629395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012974425218999386,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726795971393585,
      "backward_entropy": 0.21517252922058105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775469779968262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013071460649371147,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27265435457229614,
      "backward_entropy": 0.21637161572774252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.568013191223145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013168212957680225,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27262988686561584,
      "backward_entropy": 0.21606914202372232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.008448600769043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013265091925859451,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27260369062423706,
      "backward_entropy": 0.2141359249750773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.30521297454834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013362336903810501,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725754976272583,
      "backward_entropy": 0.2137721379597982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.666584014892578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013459563255310059,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27254724502563477,
      "backward_entropy": 0.2165804902712504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.219196319580078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013555921614170074,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27252307534217834,
      "backward_entropy": 0.21626671155293783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.636604309082031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013652278110384941,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724994719028473,
      "backward_entropy": 0.21594866116841635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.487072944641113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013748329132795334,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724760174751282,
      "backward_entropy": 0.21562564373016357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.932207107543945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013845104724168777,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2724479138851166,
      "backward_entropy": 0.21186151107152304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49024772644043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013942211866378784,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27241724729537964,
      "backward_entropy": 0.21497484048207602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.472329139709473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014039432629942894,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2723868787288666,
      "backward_entropy": 0.2130898634592692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.677728652954102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014136748388409615,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27235573530197144,
      "backward_entropy": 0.21061313152313232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.379011154174805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014234223403036594,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2723231613636017,
      "backward_entropy": 0.2123485803604126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.081511497497559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01433168537914753,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27228957414627075,
      "backward_entropy": 0.20973543326059976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.423691749572754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014428979717195034,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27225643396377563,
      "backward_entropy": 0.21324018637339273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.260025978088379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014526319690048695,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27222272753715515,
      "backward_entropy": 0.212872048219045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.383523941040039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014624121598899364,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2721872925758362,
      "backward_entropy": 0.21249711513519287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.979496955871582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014721899293363094,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27215442061424255,
      "backward_entropy": 0.20790561040242514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.470138549804688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014819460920989513,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2721198797225952,
      "backward_entropy": 0.21172726154327393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775110244750977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014916595071554184,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27208608388900757,
      "backward_entropy": 0.2113312085469564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.590441703796387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015013458207249641,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27205345034599304,
      "backward_entropy": 0.20650253693262735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.98429012298584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015109962783753872,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27202141284942627,
      "backward_entropy": 0.20865513881047568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.714779853820801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015206408686935902,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2719876170158386,
      "backward_entropy": 0.20553956429163614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.696969985961914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015302097424864769,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27195820212364197,
      "backward_entropy": 0.20968780914942423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.239274024963379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015397637151181698,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27192777395248413,
      "backward_entropy": 0.20925660928090414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.610795974731445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015493313781917095,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271894633769989,
      "backward_entropy": 0.20405209064483643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.799032211303711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015588858164846897,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2718612849712372,
      "backward_entropy": 0.20354382197062174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10420036315918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015684355050325394,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2718280851840973,
      "backward_entropy": 0.20584100484848022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.118724822998047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015780014917254448,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27179402112960815,
      "backward_entropy": 0.20740310351053873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.548596382141113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01587526686489582,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27176088094711304,
      "backward_entropy": 0.20484844843546549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.81368637084961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0159703828394413,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27172499895095825,
      "backward_entropy": 0.2064164082209269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.790337562561035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016065500676631927,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.271688848733902,
      "backward_entropy": 0.2059105634689331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.137357711791992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01616060920059681,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27165108919143677,
      "backward_entropy": 0.20329097906748453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.449609756469727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016255371272563934,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27161461114883423,
      "backward_entropy": 0.1997655232747396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.047426223754883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016350528225302696,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27157366275787354,
      "backward_entropy": 0.2022033929824829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.510936737060547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01644635573029518,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2715262770652771,
      "backward_entropy": 0.19859311978022257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.106009483337402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016541970893740654,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27148160338401794,
      "backward_entropy": 0.20325730244318643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763394832611084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016637712717056274,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27143460512161255,
      "backward_entropy": 0.20269954204559326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.818894863128662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016732849180698395,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27139151096343994,
      "backward_entropy": 0.1999160647392273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.773931980133057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01682748645544052,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713516354560852,
      "backward_entropy": 0.19613850116729736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.05040454864502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01692168228328228,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27131444215774536,
      "backward_entropy": 0.19551249345143637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.391664981842041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017016177996993065,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2712725102901459,
      "backward_entropy": 0.20030003786087036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.897412300109863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017110027372837067,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27124181389808655,
      "backward_entropy": 0.19423476854960123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.653602600097656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0172035600990057,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27121084928512573,
      "backward_entropy": 0.19901074965794882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9983015060424805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01729721762239933,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27117419242858887,
      "backward_entropy": 0.19290719429651895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718653678894043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01739066280424595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2711380422115326,
      "backward_entropy": 0.19221307833989462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.465712547302246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01748376153409481,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27110445499420166,
      "backward_entropy": 0.1970010201136271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.011238098144531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017576955258846283,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2710675001144409,
      "backward_entropy": 0.19079303741455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.906284332275391,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017669986933469772,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27103137969970703,
      "backward_entropy": 0.19006550312042236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876517295837402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017762809991836548,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2709953486919403,
      "backward_entropy": 0.1928807497024536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.650463104248047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017855431884527206,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27095919847488403,
      "backward_entropy": 0.19218007723490396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30766773223877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017947783693671227,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27092254161834717,
      "backward_entropy": 0.1878259778022766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.053251266479492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018040243536233902,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2708810567855835,
      "backward_entropy": 0.19261793295542398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.825854301452637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018132630735635757,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27083662152290344,
      "backward_entropy": 0.19002006451288858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.356247901916504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018224861472845078,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27079150080680847,
      "backward_entropy": 0.1854877471923828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.849027633666992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018316715955734253,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27075037360191345,
      "backward_entropy": 0.19026692708333334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.967259407043457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018409034237265587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.270700067281723,
      "backward_entropy": 0.18387927611668906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.499800205230713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01850130222737789,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27064794301986694,
      "backward_entropy": 0.18864589929580688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.490244388580322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018593287095427513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2705983817577362,
      "backward_entropy": 0.18222610155741373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.859879970550537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01868499256670475,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2705506682395935,
      "backward_entropy": 0.18697075049082437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.823044776916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01877666264772415,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2705012857913971,
      "backward_entropy": 0.1845992604891459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715709686279297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018868284299969673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2704504430294037,
      "backward_entropy": 0.17967895666758218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.311138153076172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01895979605615139,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2703985273838043,
      "backward_entropy": 0.18436972300211588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4070940017700195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01905156299471855,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2703417241573334,
      "backward_entropy": 0.1834807594617208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.43829870223999,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019143030047416687,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27028772234916687,
      "backward_entropy": 0.18258174260457358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.212043762207031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01923425868153572,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2702353298664093,
      "backward_entropy": 0.18032081921895346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.330382347106934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019325707107782364,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27017712593078613,
      "backward_entropy": 0.17519478003184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.641836643218994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019417421892285347,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.270112544298172,
      "backward_entropy": 0.17982816696166992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.212612152099609,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019508996978402138,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27004721760749817,
      "backward_entropy": 0.17889157931009927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.299038887023926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019600197672843933,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26998525857925415,
      "backward_entropy": 0.17668493588765463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.154534339904785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01969173736870289,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26991578936576843,
      "backward_entropy": 0.17124521732330322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.708578586578369,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019782856106758118,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26984935998916626,
      "backward_entropy": 0.17022939523061117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.219378471374512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0198733601719141,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2697898745536804,
      "backward_entropy": 0.16920985778172812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.253106594085693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01996367797255516,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26973143219947815,
      "backward_entropy": 0.168183704217275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.060391426086426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02005319483578205,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26968371868133545,
      "backward_entropy": 0.17302878697713217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9817795753479,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020141884684562683,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26964765787124634,
      "backward_entropy": 0.1661312977472941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.219062805175781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020230401307344437,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2696111500263214,
      "backward_entropy": 0.17098385095596313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.780016899108887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020318927243351936,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26957130432128906,
      "backward_entropy": 0.16891729831695557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.872171878814697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020407792180776596,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2695223391056061,
      "backward_entropy": 0.167902410030365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528969764709473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020496387034654617,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26947396993637085,
      "backward_entropy": 0.16190660993258157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.394853115081787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020585177466273308,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2694185674190521,
      "backward_entropy": 0.1608162224292755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.130309104919434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020673444494605064,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2693687975406647,
      "backward_entropy": 0.15971972544987997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.599586486816406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02076171711087227,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26931527256965637,
      "backward_entropy": 0.1586047907670339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.258831024169922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020849647000432014,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26926374435424805,
      "backward_entropy": 0.16350831588109335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.710755825042725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02093706838786602,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2692176401615143,
      "backward_entropy": 0.1563563048839569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.903391361236572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021024320274591446,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2691704034805298,
      "backward_entropy": 0.15522042910257974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.586451053619385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021111587062478065,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26911962032318115,
      "backward_entropy": 0.16015559434890747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.47699499130249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021198656409978867,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26906833052635193,
      "backward_entropy": 0.15835126241048178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.819409370422363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02128608152270317,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2690054178237915,
      "backward_entropy": 0.1516759991645813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.912596702575684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021372783929109573,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2689513862133026,
      "backward_entropy": 0.15047581990559897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.260239601135254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02145889587700367,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.268903911113739,
      "backward_entropy": 0.15554199616114298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.150063514709473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021544720977544785,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26885703206062317,
      "backward_entropy": 0.15436768531799316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.12152099609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021630210801959038,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2688114047050476,
      "backward_entropy": 0.15274205803871155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.352947235107422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021715359762310982,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2687664330005646,
      "backward_entropy": 0.15159332752227783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.127880573272705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021800413727760315,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2687186598777771,
      "backward_entropy": 0.15043646097183228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.185029029846191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021885208785533905,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26867032051086426,
      "backward_entropy": 0.1431520382563273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.430052757263184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021969834342598915,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2686200737953186,
      "backward_entropy": 0.1480970780054728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.450640678405762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022054506465792656,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2685644328594208,
      "backward_entropy": 0.14717783530553183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.225150108337402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022138509899377823,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26851603388786316,
      "backward_entropy": 0.13939220706621805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.065377235412598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022222453728318214,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26846274733543396,
      "backward_entropy": 0.1445487638314565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.182969093322754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022306280210614204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26840680837631226,
      "backward_entropy": 0.13685651620229086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.89324951171875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022390035912394524,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2683459222316742,
      "backward_entropy": 0.142249862353007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.927896022796631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02247357927262783,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2682836949825287,
      "backward_entropy": 0.1342895726362864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3883748054504395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022556236013770103,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26823344826698303,
      "backward_entropy": 0.13302071889241537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.788340091705322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022639155387878418,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2681729197502136,
      "backward_entropy": 0.13853649298350015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.205264091491699,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022721879184246063,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26810991764068604,
      "backward_entropy": 0.13043439388275146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.489981174468994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022804738953709602,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2680381238460541,
      "backward_entropy": 0.12912724415461221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.088470935821533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022887205705046654,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2679672837257385,
      "backward_entropy": 0.13470149040222168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.395350456237793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022969083860516548,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2679033875465393,
      "backward_entropy": 0.13341540098190308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.057801246643066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023050649091601372,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26783981919288635,
      "backward_entropy": 0.12519062558809915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.557746410369873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02313239499926567,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26776546239852905,
      "backward_entropy": 0.1312356690565745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.277046203613281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023213975131511688,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2676880359649658,
      "backward_entropy": 0.1295180320739746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.517792701721191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023295190185308456,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2676108479499817,
      "backward_entropy": 0.12119020024935405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0081024169921875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023376241326332092,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26752883195877075,
      "backward_entropy": 0.12690279881159464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.220957279205322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023456765338778496,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2674493193626404,
      "backward_entropy": 0.118496835231781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.858162879943848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023536983877420425,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2673680782318115,
      "backward_entropy": 0.12429888049761455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.70497465133667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02361668273806572,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.267289936542511,
      "backward_entropy": 0.12299720446268718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.220935821533203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02369578182697296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2672159671783447,
      "backward_entropy": 0.11446989576021831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.777243614196777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0237747635692358,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2671360969543457,
      "backward_entropy": 0.11312965552012126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.385073661804199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023853303864598274,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26705771684646606,
      "backward_entropy": 0.12006922562917073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.539161205291748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02393115684390068,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2669863700866699,
      "backward_entropy": 0.11780308683713277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.772748947143555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024008512496948242,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2669191360473633,
      "backward_entropy": 0.10914934674898784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.51690149307251,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024085627868771553,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2668497562408447,
      "backward_entropy": 0.11520918210347493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.492647171020508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024162311106920242,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26678335666656494,
      "backward_entropy": 0.10652048389116923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.530226230621338,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024238605052232742,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26671475172042847,
      "backward_entropy": 0.1138373613357544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2588276863098145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024314582347869873,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26664185523986816,
      "backward_entropy": 0.10391074419021606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.217206954956055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024390066042542458,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2665696442127228,
      "backward_entropy": 0.10261618097623189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.406394958496094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024465056136250496,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2664978504180908,
      "backward_entropy": 0.11013833681742351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.422600269317627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024539802223443985,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26642078161239624,
      "backward_entropy": 0.1000445286432902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.023545265197754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02461431734263897,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2663339078426361,
      "backward_entropy": 0.09876284996668498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8989596366882324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024688290432095528,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26624423265457153,
      "backward_entropy": 0.09748725096384685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2759857177734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024761691689491272,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2661586403846741,
      "backward_entropy": 0.10526068011919658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.053717136383057,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024834884330630302,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2660650610923767,
      "backward_entropy": 0.1040475865205129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.113818168640137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02490772306919098,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26596799492836,
      "backward_entropy": 0.10283859570821126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6671059131622314,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02498031221330166,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26586490869522095,
      "backward_entropy": 0.1016341249148051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.524162769317627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02505226619541645,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2657662630081177,
      "backward_entropy": 0.09875784317652385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2839291095733643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025123560801148415,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2656729519367218,
      "backward_entropy": 0.09924615422884624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.719207286834717,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02519405633211136,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26558876037597656,
      "backward_entropy": 0.08877140283584595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.374985456466675,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025264210999011993,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26549968123435974,
      "backward_entropy": 0.09512168169021606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.502859115600586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025333689525723457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2654152810573578,
      "backward_entropy": 0.08637940883636475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.607715606689453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025402747094631195,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26532822847366333,
      "backward_entropy": 0.0851974884668986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3669464588165283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025471527129411697,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.265237033367157,
      "backward_entropy": 0.0840202768643697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2002487182617188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025539807975292206,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.265145480632782,
      "backward_entropy": 0.09043428301811218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1306936740875244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025607513263821602,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.265054851770401,
      "backward_entropy": 0.0892884333928426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2162082195281982,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02567460387945175,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2649664282798767,
      "backward_entropy": 0.08998535076777141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.841750144958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02574128471314907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2648741602897644,
      "backward_entropy": 0.0794217586517334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7763800621032715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02580724097788334,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2647884786128998,
      "backward_entropy": 0.07830796142419179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3416969776153564,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025872448459267616,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26470980048179626,
      "backward_entropy": 0.08479435245196025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8128864765167236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02593761309981346,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2646167576313019,
      "backward_entropy": 0.07611608008543651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.801302909851074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026002150028944016,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2645263373851776,
      "backward_entropy": 0.07503466308116913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4277336597442627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02606610395014286,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26443687081336975,
      "backward_entropy": 0.08341387907663982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5054843425750732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026129139587283134,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26436030864715576,
      "backward_entropy": 0.07291665176550548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5147347450256348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026191487908363342,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2642892301082611,
      "backward_entropy": 0.07188556591669719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7681095600128174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026253195479512215,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2642223536968231,
      "backward_entropy": 0.08026279509067535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5918965339660645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026314646005630493,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26414763927459717,
      "backward_entropy": 0.07727174460887909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2676875591278076,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026375658810138702,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.264068603515625,
      "backward_entropy": 0.07623891532421112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.677525520324707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02643592655658722,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2639961242675781,
      "backward_entropy": 0.07521669069925944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.507479190826416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026495981961488724,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26391175389289856,
      "backward_entropy": 0.07621318101882935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.200573205947876,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026555636897683144,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26382124423980713,
      "backward_entropy": 0.07522358000278473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9787286520004272,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02661462500691414,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2637346386909485,
      "backward_entropy": 0.07222201426823933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0543782711029053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026672735810279846,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26365897059440613,
      "backward_entropy": 0.07328981161117554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2947864532470703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026730144396424294,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26358795166015625,
      "backward_entropy": 0.07028624415397644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7141954898834229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02678726613521576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26350873708724976,
      "backward_entropy": 0.06223138173421224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9678716659545898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026843342930078506,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26344555616378784,
      "backward_entropy": 0.06839319070180257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1142687797546387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02689882181584835,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2633832097053528,
      "backward_entropy": 0.06047665079434713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0441367626190186,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026953957974910736,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26331308484077454,
      "backward_entropy": 0.06868711113929749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.202157974243164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02700868993997574,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26323679089546204,
      "backward_entropy": 0.05875760316848755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.630662202835083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02706332691013813,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26314598321914673,
      "backward_entropy": 0.057905723651250206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7330663204193115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02711702696979046,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2630656659603119,
      "backward_entropy": 0.05707366267840067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6706546545028687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02717004157602787,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2629883885383606,
      "backward_entropy": 0.06303336222966512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6269505023956299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027222419157624245,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26291364431381226,
      "backward_entropy": 0.06435581048329671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5840704441070557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027274128049612045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26284128427505493,
      "backward_entropy": 0.054660687843958534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4581180810928345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027325177565217018,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26277101039886475,
      "backward_entropy": 0.060536776979764305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4672752618789673,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027375435456633568,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2627066969871521,
      "backward_entropy": 0.05312619606653849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6559066772460938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027425028383731842,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2626451253890991,
      "backward_entropy": 0.05894449849923452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6434425115585327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027474282309412956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2625746726989746,
      "backward_entropy": 0.05164299408594767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4583966732025146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02752324379980564,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26249468326568604,
      "backward_entropy": 0.05091272294521332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3569004535675049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027571672573685646,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26241374015808105,
      "backward_entropy": 0.05664293964703878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3619152307510376,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027619460597634315,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26233434677124023,
      "backward_entropy": 0.05589852730433146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5452603101730347,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027666717767715454,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2622542381286621,
      "backward_entropy": 0.05516270796457926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4290019273757935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771378681063652,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2621619701385498,
      "backward_entropy": 0.04809951285521189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.134605050086975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027760522440075874,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.262062668800354,
      "backward_entropy": 0.047417680422465004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.376891851425171,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780645340681076,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2619704008102417,
      "backward_entropy": 0.046752914786338806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.217212200164795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027852078899741173,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26186951994895935,
      "backward_entropy": 0.054497589667638145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0883477926254272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02789713442325592,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2617671489715576,
      "backward_entropy": 0.04544784128665924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0667335987091064,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027941446751356125,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2616683840751648,
      "backward_entropy": 0.05315041045347849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1721419095993042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027985068038105965,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26157230138778687,
      "backward_entropy": 0.04419652124245962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0124709606170654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028028277680277824,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2614707946777344,
      "backward_entropy": 0.049650500218073525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.958819568157196,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028070824220776558,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2613714933395386,
      "backward_entropy": 0.049014667669932045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.125093698501587,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02811264991760254,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26127520203590393,
      "backward_entropy": 0.04839251438776652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7776759266853333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028154203668236732,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26117047667503357,
      "backward_entropy": 0.04998055100440979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8545411825180054,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028194822371006012,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2610769271850586,
      "backward_entropy": 0.047175854444503784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7883683443069458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02823474258184433,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26098689436912537,
      "backward_entropy": 0.04658573865890503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8561784625053406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028273850679397583,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26090171933174133,
      "backward_entropy": 0.04601094126701355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8698118329048157,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028312399983406067,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26081526279449463,
      "backward_entropy": 0.0396640400091807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8358631134033203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02835048921406269,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2607250213623047,
      "backward_entropy": 0.03914926697810491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8308656811714172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028388136997818947,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26063230633735657,
      "backward_entropy": 0.046562363704045616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7490347623825073,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028425367549061775,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2605360746383667,
      "backward_entropy": 0.046028261383374534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7534087896347046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028462007641792297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2604392468929291,
      "backward_entropy": 0.03765606383482615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8372218012809753,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028498126193881035,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26033976674079895,
      "backward_entropy": 0.04498946666717529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6538339853286743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02853400819003582,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26023098826408386,
      "backward_entropy": 0.03670086214939753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5755768418312073,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028569238260388374,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2601242959499359,
      "backward_entropy": 0.043985515832901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49455103278160095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860364131629467,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26002252101898193,
      "backward_entropy": 0.03578595817089081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5999850630760193,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02863708883523941,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2599292993545532,
      "backward_entropy": 0.04081438978513082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.650624692440033,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02867002785205841,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25983595848083496,
      "backward_entropy": 0.04035457720359167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5903581380844116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02870256081223488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2597360908985138,
      "backward_entropy": 0.0421131948630015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4476087987422943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028734611347317696,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25963348150253296,
      "backward_entropy": 0.0340908815463384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4600013196468353,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028765859082341194,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25953781604766846,
      "backward_entropy": 0.03903539230426153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5411468744277954,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028796426951885223,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25944626331329346,
      "backward_entropy": 0.03861571351687113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5346041917800903,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02882661297917366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2593507170677185,
      "backward_entropy": 0.03292015194892883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4763987958431244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028856411576271057,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25925013422966003,
      "backward_entropy": 0.03254338105519613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47593969106674194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02888571470975876,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2591482996940613,
      "backward_entropy": 0.03217428922653198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5006639361381531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02891455590724945,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2590435743331909,
      "backward_entropy": 0.031812138855457306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42567935585975647,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028943056240677834,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2589336037635803,
      "backward_entropy": 0.03663625319798788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38175660371780396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028971044346690178,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25882309675216675,
      "backward_entropy": 0.031105463703473408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34796881675720215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02899840660393238,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25871387124061584,
      "backward_entropy": 0.03808033466339111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4397470951080322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02902509830892086,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.258607417345047,
      "backward_entropy": 0.03555095692475637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30673733353614807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02905152551829815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258495032787323,
      "backward_entropy": 0.030105655392011006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4468602240085602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029077252373099327,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25838708877563477,
      "backward_entropy": 0.029786897202332813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37210458517074585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029102863743901253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258270263671875,
      "backward_entropy": 0.029469328622023266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.377594530582428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029128091409802437,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581501603126526,
      "backward_entropy": 0.029157007733980816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.346717894077301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029153011739253998,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.258025586605072,
      "backward_entropy": 0.03388585150241852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2960435748100281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029177552089095116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2578985393047333,
      "backward_entropy": 0.028546387950579327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3019689619541168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029201533645391464,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25777217745780945,
      "backward_entropy": 0.035424028833707176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.272612601518631,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029225053265690804,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2576449513435364,
      "backward_entropy": 0.03296439349651337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33040285110473633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029248028993606567,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2575187385082245,
      "backward_entropy": 0.02768293519814809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2668059468269348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029270829632878304,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2573877274990082,
      "backward_entropy": 0.03238416959842046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2538089454174042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029293153434991837,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2572576403617859,
      "backward_entropy": 0.032102763652801514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23422285914421082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029314981773495674,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2571278512477875,
      "backward_entropy": 0.02686923493941625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2351919412612915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029336314648389816,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2569994330406189,
      "backward_entropy": 0.0266116460164388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14418549835681915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029357191175222397,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25687071681022644,
      "backward_entropy": 0.026360221207141876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16617557406425476,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029377160593867302,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2567490339279175,
      "backward_entropy": 0.031052003304163616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20067918300628662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029396461322903633,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25663143396377563,
      "backward_entropy": 0.03296645979086558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17733457684516907,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02941540814936161,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2565144896507263,
      "backward_entropy": 0.03273003796736399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18324466049671173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029433870688080788,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2563987970352173,
      "backward_entropy": 0.02544646958510081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24810078740119934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029451962560415268,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25628334283828735,
      "backward_entropy": 0.03012171636025111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13412192463874817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029470058158040047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2561596632003784,
      "backward_entropy": 0.025017914672692616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1690465360879898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0294874906539917,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.256039559841156,
      "backward_entropy": 0.024812040229638416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18259626626968384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029504550620913506,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2559184432029724,
      "backward_entropy": 0.02947595218817393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20454230904579163,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029521392658352852,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2557946443557739,
      "backward_entropy": 0.029270564516385395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15175843238830566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029538225382566452,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2556670010089874,
      "backward_entropy": 0.02906632423400879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09877902269363403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029554734006524086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25554072856903076,
      "backward_entropy": 0.024020202457904816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09568573534488678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029570497572422028,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2554195523262024,
      "backward_entropy": 0.03084021310011546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13903550803661346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02958560548722744,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2553028464317322,
      "backward_entropy": 0.02849270651737849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11876243352890015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029600417241454124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2551836371421814,
      "backward_entropy": 0.023487245043118794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10622037947177887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029614852741360664,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25506505370140076,
      "backward_entropy": 0.02331879734992981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08752772212028503,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029628844931721687,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2549472153186798,
      "backward_entropy": 0.03015956034262975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09803550690412521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029642289504408836,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25483185052871704,
      "backward_entropy": 0.02300046632687251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09356015175580978,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029655354097485542,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2547173798084259,
      "backward_entropy": 0.02765601873397827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08971695601940155,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029667984694242477,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2546028196811676,
      "backward_entropy": 0.027505286037921906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08044910430908203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029680155217647552,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25448837876319885,
      "backward_entropy": 0.029578936596711475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07149046659469604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691878706216812,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2543748915195465,
      "backward_entropy": 0.027221612632274628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11455576121807098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029703108593821526,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.254262775182724,
      "backward_entropy": 0.022296654681364696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10468331724405289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02971428819000721,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25414589047431946,
      "backward_entropy": 0.026956990361213684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07920409739017487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029725411906838417,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2540263533592224,
      "backward_entropy": 0.022037364542484283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06635155528783798,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029736313968896866,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25390857458114624,
      "backward_entropy": 0.02191089590390523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07836519181728363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029746798798441887,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2537923753261566,
      "backward_entropy": 0.021789342164993286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.066219761967659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0297570638358593,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2536759078502655,
      "backward_entropy": 0.026456758379936218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06772065907716751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029766976833343506,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25356006622314453,
      "backward_entropy": 0.021555185317993164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06537311524152756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02977665327489376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2534458339214325,
      "backward_entropy": 0.02144286533196767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07597675174474716,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02978607639670372,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2533327639102936,
      "backward_entropy": 0.02611972639958064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052054740488529205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029795363545417786,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25321727991104126,
      "backward_entropy": 0.021225526928901672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07047823816537857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029804322868585587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25310438871383667,
      "backward_entropy": 0.021121226251125336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.046070195734500885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029813149943947792,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2529892325401306,
      "backward_entropy": 0.028139616052309673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05846012756228447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029821520671248436,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2528749704360962,
      "backward_entropy": 0.020920713742574055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05084431916475296,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02982967160642147,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25275981426239014,
      "backward_entropy": 0.025619186460971832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050254035741090775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02983744814991951,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2526441216468811,
      "backward_entropy": 0.020734111467997234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04968483746051788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029845019802451134,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2525292634963989,
      "backward_entropy": 0.025444768369197845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04991089552640915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029852336272597313,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2524140179157257,
      "backward_entropy": 0.020558847735325497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06027378514409065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029859500005841255,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2522989809513092,
      "backward_entropy": 0.02047426129380862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035192232578992844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029866673052310944,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.252181738615036,
      "backward_entropy": 0.027588946123917896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03726597875356674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029873494058847427,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.252066969871521,
      "backward_entropy": 0.020308534304300945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040993548929691315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029880007728934288,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25195348262786865,
      "backward_entropy": 0.020231202244758606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04268384724855423,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02988632582128048,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25184082984924316,
      "backward_entropy": 0.024980448186397552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024387875571846962,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02989247441291809,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2517276406288147,
      "backward_entropy": 0.02491206427415212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037543199956417084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02989828959107399,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2516186833381653,
      "backward_entropy": 0.020012789716323216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03356163203716278,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029903918504714966,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.251509428024292,
      "backward_entropy": 0.019945176939169567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035521142184734344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029909346252679825,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2514008581638336,
      "backward_entropy": 0.024725618461767834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035794828087091446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029914703220129013,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2512931227684021,
      "backward_entropy": 0.019815221428871155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03671753779053688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029919935390353203,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2511846721172333,
      "backward_entropy": 0.019751958549022675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03353293240070343,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02992508001625538,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2510755658149719,
      "backward_entropy": 0.024553770820299785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025360602885484695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029930096119642258,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25096628069877625,
      "backward_entropy": 0.024499374131361645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02775462530553341,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029934726655483246,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2508575916290283,
      "backward_entropy": 0.026932602127393086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025636855512857437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029939183965325356,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2507495880126953,
      "backward_entropy": 0.024401438732941944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032705239951610565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029943425208330154,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25064218044281006,
      "backward_entropy": 0.019464105367660522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027466464787721634,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02994774840772152,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2505350112915039,
      "backward_entropy": 0.024310114483038586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028833424672484398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029951920732855797,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.250427782535553,
      "backward_entropy": 0.019358783960342407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0248689204454422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029956044629216194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25032055377960205,
      "backward_entropy": 0.019307648142178852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024581274017691612,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02996004745364189,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2502143979072571,
      "backward_entropy": 0.01925756906469663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02851147949695587,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029963916167616844,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2501087188720703,
      "backward_entropy": 0.02667652815580368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020793799310922623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029967818409204483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25000256299972534,
      "backward_entropy": 0.019160060832897823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01980215311050415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029971571639180183,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24989810585975647,
      "backward_entropy": 0.019112889965375263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022373342886567116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029975123703479767,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24979451298713684,
      "backward_entropy": 0.026579760015010834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02062644250690937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029978465288877487,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24969102442264557,
      "backward_entropy": 0.0190251221259435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023720450699329376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0299817081540823,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24958918988704681,
      "backward_entropy": 0.018983419984579086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01986793428659439,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029985008761286736,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2494875192642212,
      "backward_entropy": 0.023922890424728394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023106997832655907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029988186433911324,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24938659369945526,
      "backward_entropy": 0.018900160988171894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01915430650115013,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029991384595632553,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2492852509021759,
      "backward_entropy": 0.026447854936122894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0158188845962286,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02999444305896759,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24918414652347565,
      "backward_entropy": 0.018819211671749752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015210220590233803,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029997387900948524,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24908500909805298,
      "backward_entropy": 0.026400176187356312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018493803218007088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03000011295080185,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24898706376552582,
      "backward_entropy": 0.01874491199851036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018809039145708084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030002810060977936,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24888944625854492,
      "backward_entropy": 0.02635914832353592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01441497914493084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030005503445863724,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24879160523414612,
      "backward_entropy": 0.023718816538651783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012806395068764687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030008135363459587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2486957311630249,
      "backward_entropy": 0.01863863815863927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013180824927985668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030010582879185677,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2486015260219574,
      "backward_entropy": 0.018605828285217285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015872003510594368,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030012940987944603,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24850893020629883,
      "backward_entropy": 0.0236479714512825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01468184869736433,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03001527301967144,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24841642379760742,
      "backward_entropy": 0.023626071711381275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01327283401042223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03001754730939865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24832427501678467,
      "backward_entropy": 0.018511783331632614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01290730107575655,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030019696801900864,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.248232901096344,
      "backward_entropy": 0.026232828696568806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013736126944422722,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030021730810403824,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24814213812351227,
      "backward_entropy": 0.023566457132498424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012742015533149242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030023621395230293,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2480509877204895,
      "backward_entropy": 0.023549338181813557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011066562496125698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030025575309991837,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2479613721370697,
      "backward_entropy": 0.018399698038895924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012500467710196972,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03002735786139965,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24787235260009766,
      "backward_entropy": 0.02618389328320821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011234509758651257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0300290584564209,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24778343737125397,
      "backward_entropy": 0.02350110560655594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010928488336503506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030030667781829834,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2476952075958252,
      "backward_entropy": 0.026165862878163654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010474564507603645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030032193288207054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24760779738426208,
      "backward_entropy": 0.01830294479926427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010839665308594704,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030033603310585022,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24752092361450195,
      "backward_entropy": 0.026152439415454865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009925393387675285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03003496676683426,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24743451178073883,
      "backward_entropy": 0.018260286500056584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012617168948054314,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03003622591495514,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24734866619110107,
      "backward_entropy": 0.02344135691722234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009299172088503838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030037682503461838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24726292490959167,
      "backward_entropy": 0.018218442797660828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009463121183216572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030039099976420403,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2471783459186554,
      "backward_entropy": 0.018197055906057358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009697850793600082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030040504410862923,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2470947802066803,
      "backward_entropy": 0.023405517141024273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008284321054816246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030041947960853577,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24701198935508728,
      "backward_entropy": 0.0181543231010437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00880220253020525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03004338964819908,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24693068861961365,
      "backward_entropy": 0.018133024374643963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0075913057662546635,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03004486858844757,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2468506246805191,
      "backward_entropy": 0.023369123538335163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008863698691129684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030046235769987106,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24677154421806335,
      "backward_entropy": 0.018090970814228058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0073874047957360744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030047619715332985,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24669285118579865,
      "backward_entropy": 0.02334676186243693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00661351066082716,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030048824846744537,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24661454558372498,
      "backward_entropy": 0.023337431252002716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007717222906649113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0300498865544796,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24653726816177368,
      "backward_entropy": 0.02332978943983714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006989586167037487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03005090169608593,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24646037817001343,
      "backward_entropy": 0.01801810786128044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007058544550091028,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030051952227950096,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24638471007347107,
      "backward_entropy": 0.018001293142636616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007709920406341553,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030053025111556053,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24630996584892273,
      "backward_entropy": 0.023307107388973236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008265036158263683,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03005417250096798,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24623560905456543,
      "backward_entropy": 0.023298360407352448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006698074284940958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030055297538638115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24616053700447083,
      "backward_entropy": 0.017949014902114868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006507988087832928,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0300562996417284,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24608564376831055,
      "backward_entropy": 0.023282065987586975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005835701711475849,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03005724772810936,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2460113763809204,
      "backward_entropy": 0.017917122691869736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0063796089962124825,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030058080330491066,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2459377646446228,
      "backward_entropy": 0.023269452154636383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0066419728100299835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03005889058113098,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24586457014083862,
      "backward_entropy": 0.017888550957043965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0053814672864973545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03005974553525448,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2457917332649231,
      "backward_entropy": 0.017873965203762054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005604571662843227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030060462653636932,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24571946263313293,
      "backward_entropy": 0.017860807478427887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00562597019597888,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03006117418408394,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24564793705940247,
      "backward_entropy": 0.023248630265394848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00552488025277853,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03006192296743393,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24557717144489288,
      "backward_entropy": 0.01783452307184537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005195167381316423,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03006262332201004,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24550685286521912,
      "backward_entropy": 0.017821659644444782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005794748198240995,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030063237994909286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2454368770122528,
      "backward_entropy": 0.017809787144263584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005361469462513924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030063841491937637,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24536676704883575,
      "backward_entropy": 0.017798027644554775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005195654928684235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03006449155509472,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24529719352722168,
      "backward_entropy": 0.017785869538784027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005426852498203516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030065182596445084,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24522823095321655,
      "backward_entropy": 0.02322241912285487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004768979735672474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03006589226424694,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2451592981815338,
      "backward_entropy": 0.017760617037614185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004870961420238018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03006656840443611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24509084224700928,
      "backward_entropy": 0.017748297502597172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004958735313266516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030067291110754013,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2450229525566101,
      "backward_entropy": 0.01773557687799136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037661069072782993,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03006799891591072,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24495509266853333,
      "backward_entropy": 0.023201192418734234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00391822773963213,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030068716034293175,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24488884210586548,
      "backward_entropy": 0.023195671538511913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003120439127087593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030069470405578613,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24482381343841553,
      "backward_entropy": 0.017697749038537342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030205044895410538,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03007018007338047,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2447604537010193,
      "backward_entropy": 0.023184478282928467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004023961257189512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030070848762989044,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24469861388206482,
      "backward_entropy": 0.0260420764485995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003777157049626112,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030071528628468513,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24463701248168945,
      "backward_entropy": 0.026041125257809956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003287640865892172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030072201043367386,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24457582831382751,
      "backward_entropy": 0.017650477588176727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034730820916593075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030072767287492752,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2445150464773178,
      "backward_entropy": 0.017639947434266407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002880608197301626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030073300004005432,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24445471167564392,
      "backward_entropy": 0.026042059063911438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026124382857233286,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030073843896389008,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24439573287963867,
      "backward_entropy": 0.017619655778010685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003395885694772005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03007429465651512,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2443377822637558,
      "backward_entropy": 0.017610506465037663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024550645612180233,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030074726790189743,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2442798614501953,
      "backward_entropy": 0.017601607988278072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028672590851783752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0300750769674778,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24422302842140198,
      "backward_entropy": 0.026049472391605377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002912885043770075,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030075347051024437,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24416647851467133,
      "backward_entropy": 0.026053669552008312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001993906684219837,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030075587332248688,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24411022663116455,
      "backward_entropy": 0.0231517752011617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026954319328069687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030075883492827415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.244055837392807,
      "backward_entropy": 0.01757209872206052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024982173927128315,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0300761666148901,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24400177597999573,
      "backward_entropy": 0.026065198083718617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002455154899507761,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030076496303081512,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24394848942756653,
      "backward_entropy": 0.02314876765012741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002340108621865511,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030076846480369568,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2438957840204239,
      "backward_entropy": 0.026070234676202137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002009154763072729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03007723204791546,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24384388327598572,
      "backward_entropy": 0.026071928441524506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021957429125905037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030077679082751274,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2437932789325714,
      "backward_entropy": 0.01753330851594607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019881778862327337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030078057199716568,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24374297261238098,
      "backward_entropy": 0.017525571087996166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019041344057768583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030078396201133728,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2436932921409607,
      "backward_entropy": 0.02313857525587082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018994559068232775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030078627169132233,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24364405870437622,
      "backward_entropy": 0.0175120048224926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020486253779381514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030078817158937454,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24359539151191711,
      "backward_entropy": 0.017506300161282223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016284832963719964,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030079029500484467,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24354711174964905,
      "backward_entropy": 0.023137780527273815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018376491498202085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030079199001193047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24349965155124664,
      "backward_entropy": 0.017494951685269673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018038807902485132,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030079355463385582,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24345263838768005,
      "backward_entropy": 0.02313823252916336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001439346233382821,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030079524964094162,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2434062361717224,
      "backward_entropy": 0.02313823749621709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001661111949943006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030079714953899384,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24336093664169312,
      "backward_entropy": 0.026102915406227112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015621018828824162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030079931020736694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24331623315811157,
      "backward_entropy": 0.02313755452632904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017150240018963814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030080119147896767,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24327194690704346,
      "backward_entropy": 0.0174677607913812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015316193457692862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008028119802475,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24322770535945892,
      "backward_entropy": 0.01746266211072604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014301943592727184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030080454424023628,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2431839406490326,
      "backward_entropy": 0.023136943578720093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001337610767222941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008066862821579,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24314090609550476,
      "backward_entropy": 0.01745199163754781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013171978062018752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03008090704679489,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.243098646402359,
      "backward_entropy": 0.026122433443864185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013575315242633224,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03008115477859974,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2430570274591446,
      "backward_entropy": 0.026124678552150726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001230383524671197,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030081426724791527,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24301597476005554,
      "backward_entropy": 0.02313251296679179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013523413799703121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030081702396273613,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24297553300857544,
      "backward_entropy": 0.026128289600213368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010570548474788666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0300819780677557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24293527007102966,
      "backward_entropy": 0.017422908296187718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011152608785778284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008221834897995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2428957223892212,
      "backward_entropy": 0.017417451987663906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009207380935549736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030082430690526962,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24285660684108734,
      "backward_entropy": 0.01741232102115949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010655358200892806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008265234529972,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24281847476959229,
      "backward_entropy": 0.017407188812891643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009222743101418018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030082888901233673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.242780864238739,
      "backward_entropy": 0.01740192621946335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009765697177499533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030083145946264267,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2427440583705902,
      "backward_entropy": 0.017396599054336548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009268095600418746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030083341524004936,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24270755052566528,
      "backward_entropy": 0.01739187290271123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007980939699336886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030083544552326202,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24267160892486572,
      "backward_entropy": 0.0173871045311292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008025996503420174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030083762481808662,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24263659119606018,
      "backward_entropy": 0.02312278002500534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008839165093377233,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030083922669291496,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24260202050209045,
      "backward_entropy": 0.01737787698705991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007923553930595517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008405864238739,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24256767332553864,
      "backward_entropy": 0.017373929421106975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000861817505210638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030084187164902687,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2425338178873062,
      "backward_entropy": 0.017370015382766724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007558941724710166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030084365978837013,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24250036478042603,
      "backward_entropy": 0.0231229563554128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006265377160161734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008457086980343,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2424675077199936,
      "backward_entropy": 0.017361170301834743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007786591304466128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030084799975156784,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2424355447292328,
      "backward_entropy": 0.017356460293134052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004413688147906214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030084967613220215,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2424035370349884,
      "backward_entropy": 0.01735236868262291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006653383024968207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008515015244484,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24237287044525146,
      "backward_entropy": 0.01734825223684311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006202773656696081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008534386754036,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24234262108802795,
      "backward_entropy": 0.017343984295924503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005977317341603339,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030085543170571327,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24231287837028503,
      "backward_entropy": 0.02311950922012329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005884792772121727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030085744336247444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24228352308273315,
      "backward_entropy": 0.017335725327332813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005590608343482018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030085939913988113,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24225462973117828,
      "backward_entropy": 0.02311806132396062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006514742854051292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030086178332567215,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24222645163536072,
      "backward_entropy": 0.023116618394851685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005471303011290729,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030086424201726913,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24219836294651031,
      "backward_entropy": 0.026203225056330364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005947811878286302,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030086662620306015,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24217064678668976,
      "backward_entropy": 0.023113220930099487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004274289240129292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030086878687143326,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24214297533035278,
      "backward_entropy": 0.017316068212191265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000459347473224625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030087100341916084,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24211609363555908,
      "backward_entropy": 0.017311981568733852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004112785100005567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0300873052328825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2420896738767624,
      "backward_entropy": 0.0173079917828242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004452230059541762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03008752129971981,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24206393957138062,
      "backward_entropy": 0.026210777461528778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046995157026685774,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03008774109184742,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24203860759735107,
      "backward_entropy": 0.026211760938167572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003677048662211746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030087927356362343,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2420133799314499,
      "backward_entropy": 0.017295870929956436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003278902149759233,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008807823061943,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24198856949806213,
      "backward_entropy": 0.017292434970537823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036171343526802957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030088232830166817,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24196448922157288,
      "backward_entropy": 0.026217040916283924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003418196283746511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008839674293995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24194088578224182,
      "backward_entropy": 0.017285382996002834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032448244746774435,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030088530853390694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2419176995754242,
      "backward_entropy": 0.02309868484735489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030018441611900926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030088672414422035,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24189499020576477,
      "backward_entropy": 0.026221876343091328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003307455044705421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030088800936937332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24187275767326355,
      "backward_entropy": 0.01727563391129176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028291152557358146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030088936910033226,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24185088276863098,
      "backward_entropy": 0.026224960883458454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003050696395803243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03008909709751606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24182960391044617,
      "backward_entropy": 0.017268836498260498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003299808013252914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030089236795902252,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24180856347084045,
      "backward_entropy": 0.017265538374582928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021607668895740062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0300893634557724,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24178758263587952,
      "backward_entropy": 0.023091802994410198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027440045960247517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0300894845277071,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24176724255084991,
      "backward_entropy": 0.023090777297814686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002880946849472821,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030089611187577248,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2417472004890442,
      "backward_entropy": 0.023089677095413208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002468673337716609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030089732259511948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24172726273536682,
      "backward_entropy": 0.01725323994954427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020052232139278203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030089832842350006,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24170759320259094,
      "backward_entropy": 0.01725071668624878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022890085529070348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03008994646370411,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24168846011161804,
      "backward_entropy": 0.02308689057826996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019343574240338057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030090080574154854,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2416696697473526,
      "backward_entropy": 0.017245300114154816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019901522318832576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009020909667015,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24165131151676178,
      "backward_entropy": 0.02308473487695058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019921032071579248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030090348795056343,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2416333258152008,
      "backward_entropy": 0.017239893476168316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001345400232821703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009048104286194,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2416156381368637,
      "backward_entropy": 0.02308269590139389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001814740535337478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030090615153312683,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24159854650497437,
      "backward_entropy": 0.017234596113363903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020633498206734657,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009072132408619,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24158167839050293,
      "backward_entropy": 0.017232249180475872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014975052908994257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009083867073059,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24156489968299866,
      "backward_entropy": 0.017229847609996796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017230259254574776,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030090946704149246,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24154847860336304,
      "backward_entropy": 0.026244156062602997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016379942826461047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030091045424342155,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24153222143650055,
      "backward_entropy": 0.017225421965122223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020923931151628494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030091114342212677,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2415161430835724,
      "backward_entropy": 0.017223762969175976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014305404329206795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030091160908341408,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2414998710155487,
      "backward_entropy": 0.02624984582265218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013891949492972344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030091214925050735,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24148401618003845,
      "backward_entropy": 0.023079293469587963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001285848702536896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030091265216469765,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24146847426891327,
      "backward_entropy": 0.01721921314795812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011881454702233896,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030091319233179092,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2414533495903015,
      "backward_entropy": 0.026255890727043152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001136016653617844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030091382563114166,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.241438627243042,
      "backward_entropy": 0.026257437964280445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012290736776776612,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030091458931565285,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24142438173294067,
      "backward_entropy": 0.026258692145347595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015317641373258084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030091542750597,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24141035974025726,
      "backward_entropy": 0.026259757578372955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012677389895543456,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009161353111267,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24139629304409027,
      "backward_entropy": 0.02626107136408488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013691930507775396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009168431162834,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24138236045837402,
      "backward_entropy": 0.017208381245533626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.785858128452674e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030091755092144012,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24136848747730255,
      "backward_entropy": 0.023076226313908894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010672729695215821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009183332324028,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24135500192642212,
      "backward_entropy": 0.01720457896590233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.536061795894057e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009190410375595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2413417100906372,
      "backward_entropy": 0.017202727496623993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011683943739626557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030091971158981323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24132874608039856,
      "backward_entropy": 0.017200930664936703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010753240349004045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0300920233130455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2413158118724823,
      "backward_entropy": 0.017199385911226273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.674613491166383e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009207174181938,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2413029819726944,
      "backward_entropy": 0.01719777410229047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.9523676908575e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009212762117386,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24129045009613037,
      "backward_entropy": 0.023073191444079082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519523933297023e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092179775238037,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2412780225276947,
      "backward_entropy": 0.01719470073779424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.572519825771451e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092233791947365,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24126586318016052,
      "backward_entropy": 0.017193255325158436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876680319895968e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030092284083366394,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24125394225120544,
      "backward_entropy": 0.023072071373462677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.125383126549423e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009234368801117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24124222993850708,
      "backward_entropy": 0.017190419137477875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4751337302150205e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092407017946243,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2412307858467102,
      "backward_entropy": 0.017188931504885357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.595204806420952e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092468485236168,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24121972918510437,
      "backward_entropy": 0.01718750347693761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.917773862369359e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030092529952526093,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2412087768316269,
      "backward_entropy": 0.023070484399795532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.166266343323514e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009258583188057,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24119800329208374,
      "backward_entropy": 0.026280822853247326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.762599903391674e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030092628672719002,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2411872148513794,
      "backward_entropy": 0.023069826265176136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.676539487671107e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092667788267136,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24117669463157654,
      "backward_entropy": 0.01718240479628245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.994697494315915e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092699453234673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24116621911525726,
      "backward_entropy": 0.017181324462095898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7914440074237064e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092723667621613,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24115589261054993,
      "backward_entropy": 0.01718033477663994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.017060852376744e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009275533258915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24114593863487244,
      "backward_entropy": 0.01717926561832428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.612943641608581e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092790722846985,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24113592505455017,
      "backward_entropy": 0.01717812940478325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.171469456399791e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009282425045967,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24112604558467865,
      "backward_entropy": 0.017177019268274307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.068121729185805e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092857778072357,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24111634492874146,
      "backward_entropy": 0.0171759066482385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.95418680657167e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092893168330193,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24110668897628784,
      "backward_entropy": 0.017174754291772842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8151057853829116e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009292483329773,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24109716713428497,
      "backward_entropy": 0.023067809641361237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4045340220909566e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030092960223555565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24108779430389404,
      "backward_entropy": 0.01717265446980794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.661401933641173e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030092991888523102,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24107840657234192,
      "backward_entropy": 0.02306722601254781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2242052586516365e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030093032866716385,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24106931686401367,
      "backward_entropy": 0.017170537263154984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0419901779387146e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009306639432907,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24106034636497498,
      "backward_entropy": 0.02306667963663737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3569693187018856e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009309247136116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24105152487754822,
      "backward_entropy": 0.017168706903855007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7152149161556736e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009311482310295,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24104292690753937,
      "backward_entropy": 0.0171679084499677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.815779225784354e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009314090013504,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24103450775146484,
      "backward_entropy": 0.026303336024284363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.195269528077915e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030093178153038025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.241026371717453,
      "backward_entropy": 0.017166034628947575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4468268748023547e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030093226581811905,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24101847410202026,
      "backward_entropy": 0.02306535094976425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5386718334630132e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009328618645668,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.241010844707489,
      "backward_entropy": 0.01716368521253268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.869826857931912e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030093345791101456,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24100342392921448,
      "backward_entropy": 0.023064124087492626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.489844337105751e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009340539574623,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2409961223602295,
      "backward_entropy": 0.017161371807257336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.603039683890529e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009345941245556,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24098896980285645,
      "backward_entropy": 0.017160323758920033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.269231845275499e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030093509703874588,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24098193645477295,
      "backward_entropy": 0.01715931420524915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7395775759941898e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030093561857938766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2409750521183014,
      "backward_entropy": 0.017158272365729015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1210309569141828e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030093608424067497,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24096821248531342,
      "backward_entropy": 0.017157309999068577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3692369722994044e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009365312755108,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24096153676509857,
      "backward_entropy": 0.017156412204106648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7336982637061737e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009369969367981,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24095496535301208,
      "backward_entropy": 0.026309942205746967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.057578785752412e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009374439716339,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24094858765602112,
      "backward_entropy": 0.017154689878225327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7336247765342705e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030093783512711525,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2409423291683197,
      "backward_entropy": 0.023060085872809093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.056066139426548e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009382076561451,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24093621969223022,
      "backward_entropy": 0.02305976301431656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8230351997772232e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030093858018517494,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.240930438041687,
      "backward_entropy": 0.017152196417252224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0538964488659985e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030093898996710777,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24092471599578857,
      "backward_entropy": 0.017151378095149994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5909023204585537e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030093945562839508,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24091923236846924,
      "backward_entropy": 0.02631300687789917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3666940503753722e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009398840367794,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24091383814811707,
      "backward_entropy": 0.017149603615204494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3060322089586407e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094027519226074,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24090859293937683,
      "backward_entropy": 0.023057719071706135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7443953765905462e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094066634774208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24090346693992615,
      "backward_entropy": 0.023057304322719574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3196685358707327e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094102025032043,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24089832603931427,
      "backward_entropy": 0.017147235572338104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2027368029521313e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009413368999958,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24089327454566956,
      "backward_entropy": 0.017146579921245575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3067738109384663e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009415976703167,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24088828265666962,
      "backward_entropy": 0.02305646240711212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1537011232576333e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009418398141861,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24088338017463684,
      "backward_entropy": 0.026316071550051372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.150193363893777e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009420819580555,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24087858200073242,
      "backward_entropy": 0.026316652695337932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0342168025090359e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009423427283764,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24087393283843994,
      "backward_entropy": 0.017144201944271725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.309187791775912e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009425848722458,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24086938798427582,
      "backward_entropy": 0.017143582304318745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.032797268242575e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009428083896637,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2408648133277893,
      "backward_entropy": 0.02631814032793045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0760687473521102e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009430505335331,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24086041748523712,
      "backward_entropy": 0.026318617165088654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0104170542035718e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009432554244995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24085606634616852,
      "backward_entropy": 0.017141891022523243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.775952665018849e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094344168901443,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2408517599105835,
      "backward_entropy": 0.023054875433444977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0752161870186683e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094362795352936,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24084752798080444,
      "backward_entropy": 0.02305471400419871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.745065886410885e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009437583386898,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2408432960510254,
      "backward_entropy": 0.026320867240428925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0040611414297018e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094383284449577,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2408391535282135,
      "backward_entropy": 0.017140095432599384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.549449376005214e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094388872385025,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.240835040807724,
      "backward_entropy": 0.026322347422440846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.246883913263446e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094388872385025,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24083098769187927,
      "backward_entropy": 0.02632319927215576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.992689122853335e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094390735030174,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2408270388841629,
      "backward_entropy": 0.023054614663124084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.056731530814432e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094392597675323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2408231794834137,
      "backward_entropy": 0.017138925691445667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9263430810242426e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094392597675323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24081934988498688,
      "backward_entropy": 0.017138632635275524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2458552747557405e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094394460320473,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2408156394958496,
      "backward_entropy": 0.01713835448026657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.131462330609793e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009439818561077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2408120185136795,
      "backward_entropy": 0.017138039072354633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.637293841369683e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009440377354622,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24080848693847656,
      "backward_entropy": 0.026327533026536305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.453942776512122e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094411224126816,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24080510437488556,
      "backward_entropy": 0.023054547607898712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7071851036453154e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094418674707413,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24080175161361694,
      "backward_entropy": 0.017137053112188976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.106948265165556e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009442798793316,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24079857766628265,
      "backward_entropy": 0.026329070329666138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.710874807438813e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094433575868607,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24079546332359314,
      "backward_entropy": 0.02632962167263031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7111888104846003e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094441026449203,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2407924234867096,
      "backward_entropy": 0.026330051322778065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.798162080987822e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009445033967495,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407895028591156,
      "backward_entropy": 0.017135702073574066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8076999569748295e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094457790255547,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.240786612033844,
      "backward_entropy": 0.02305405338605245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.932363142666873e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094467103481293,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24078381061553955,
      "backward_entropy": 0.026331317921479542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3046846965589793e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009447269141674,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24078106880187988,
      "backward_entropy": 0.023053934176762898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2122177344717784e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094480141997337,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2407783716917038,
      "backward_entropy": 0.026332249244054157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.19770083478943e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094487592577934,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24077574908733368,
      "backward_entropy": 0.017134358485539753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.149508529531886e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009449690580368,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24077317118644714,
      "backward_entropy": 0.01713411509990692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.976525138365105e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094504356384277,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24077066779136658,
      "backward_entropy": 0.017133835703134537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.817112090269802e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094513669610023,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.240768164396286,
      "backward_entropy": 0.01713359480102857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.232623839721782e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009452112019062,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407657653093338,
      "backward_entropy": 0.017133329063653946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9846127037890255e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094528570771217,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2407633662223816,
      "backward_entropy": 0.02305350701014201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9463557237031637e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094532296061516,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2407609075307846,
      "backward_entropy": 0.02633510281642278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3287436761165736e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094536021351814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24075859785079956,
      "backward_entropy": 0.017132694522539776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0783581931027584e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094541609287262,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407563179731369,
      "backward_entropy": 0.017132479697465897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5028342659206828e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009454719722271,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407541126012802,
      "backward_entropy": 0.0171322301030159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.28688440984115e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094552785158157,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24075201153755188,
      "backward_entropy": 0.017132011552651722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4807330899202498e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094558373093605,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24074992537498474,
      "backward_entropy": 0.017131780584653217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.099033508784487e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094565823674202,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24074795842170715,
      "backward_entropy": 0.023053079843521118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.718387693472323e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0300945732742548,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24074599146842957,
      "backward_entropy": 0.01713135465979576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6716282971174223e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094580724835396,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24074405431747437,
      "backward_entropy": 0.017131087680657704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7848626612249063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094588175415993,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24074220657348633,
      "backward_entropy": 0.02305275450150172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.765684828569647e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009459376335144,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2407403588294983,
      "backward_entropy": 0.023052687446276348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6772034996392904e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094599351286888,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24073855578899384,
      "backward_entropy": 0.017130454381306965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3800975011690753e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094604939222336,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24073678255081177,
      "backward_entropy": 0.01713026563326518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7180739178002113e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094610527157784,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407350391149521,
      "backward_entropy": 0.017130074401696522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7612006786293932e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009461611509323,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2407332956790924,
      "backward_entropy": 0.026339414219061535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7928163060787483e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009461984038353,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24073155224323273,
      "backward_entropy": 0.017129726707935333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0900942015723558e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009462170302868,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24072983860969543,
      "backward_entropy": 0.01712959259748459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0225764981441898e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094623565673828,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24072813987731934,
      "backward_entropy": 0.02305234471956889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.369557005811657e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094627290964127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407265305519104,
      "backward_entropy": 0.017129333068927128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.079698336070578e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094632878899574,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24072498083114624,
      "backward_entropy": 0.01712917909026146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.97486791270785e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030094638466835022,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24072344601154327,
      "backward_entropy": 0.02305216093858083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.364820930888527e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03009464591741562,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24072200059890747,
      "backward_entropy": 0.02634145071109136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0017874956247397e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094655230641365,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24072059988975525,
      "backward_entropy": 0.0263415922721227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981721180134628e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094662681221962,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24071921408176422,
      "backward_entropy": 0.02634180337190628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.168411002567154e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009466826915741,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24071785807609558,
      "backward_entropy": 0.017128283778826397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.449271268138546e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094673857092857,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2407165765762329,
      "backward_entropy": 0.0263421634833018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.206277589626552e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094679445028305,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24071532487869263,
      "backward_entropy": 0.01712794229388237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.159733629829134e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094686895608902,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24071410298347473,
      "backward_entropy": 0.017127777139345806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.156662261171732e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094696208834648,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407129406929016,
      "backward_entropy": 0.017127595841884613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.476178668890498e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094703659415245,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24071179330348969,
      "backward_entropy": 0.026342724760373432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.037905109224084e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094711109995842,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24071064591407776,
      "backward_entropy": 0.026342853903770447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.042352763164672e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009471856057644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24070954322814941,
      "backward_entropy": 0.01712713638941447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.320215556523181e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094726011157036,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24070842564105988,
      "backward_entropy": 0.02634313702583313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.014491648580588e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094731599092484,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24070733785629272,
      "backward_entropy": 0.026343298455079395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.341438046954863e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009473718702793,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24070626497268677,
      "backward_entropy": 0.02305090179045995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.634947228827514e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03009474091231823,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24070516228675842,
      "backward_entropy": 0.017126623541116714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.660012902808376e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094744637608528,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24070410430431366,
      "backward_entropy": 0.02634384234746297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7602119934708753e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094748362898827,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2407030463218689,
      "backward_entropy": 0.017126404990752537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.755402815386333e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094752088189125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24070203304290771,
      "backward_entropy": 0.017126283297936123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.084017402623431e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094757676124573,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24070104956626892,
      "backward_entropy": 0.017126139253377914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.861871616412827e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009476140141487,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24070009589195251,
      "backward_entropy": 0.023050551613171894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.066182779955852e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009476512670517,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24069912731647491,
      "backward_entropy": 0.023050511876742046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.527403234533267e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030094768851995468,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24069815874099731,
      "backward_entropy": 0.017125797768433888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.289526257001853e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030094770714640617,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2406972348690033,
      "backward_entropy": 0.026344964901606243,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 6.607357873349429e-06,
    "avg_log_Z": 0.0300943785533309,
    "success_rate": 1.0,
    "avg_reward": 43.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.27,
      "1": 0.21,
      "2": 0.52
    },
    "avg_forward_entropy": 0.24080281242728233,
    "avg_backward_entropy": 0.020862780672808487,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}