{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23099366823832193,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23099366823832193,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23099366823832193,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23099366823832193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23099366823832193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23099366823832193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104854424794516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.91903018951416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742025852203369,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.914412498474121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741861045360565,
      "backward_entropy": 0.23098758856455484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.025710105895996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00019999964570160955,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27416929602622986,
      "backward_entropy": 0.23104894161224365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.905221939086914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003000259748660028,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741527855396271,
      "backward_entropy": 0.23104560375213623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.0166015625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00040003281901590526,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741357982158661,
      "backward_entropy": 0.23096742232640585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447717666625977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005000622477382421,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741186022758484,
      "backward_entropy": 0.23095987240473428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.56036376953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005999614950269461,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741016745567322,
      "backward_entropy": 0.23095186551411948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878973960876465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006998125463724136,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27408507466316223,
      "backward_entropy": 0.23103487491607666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.215337753295898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007994238985702395,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740691304206848,
      "backward_entropy": 0.2309341828028361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99061107635498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008989656344056129,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740534245967865,
      "backward_entropy": 0.23092452685038248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.104294776916504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009983936324715614,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740384340286255,
      "backward_entropy": 0.23091423511505127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.207517623901367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001097781234420836,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27402424812316895,
      "backward_entropy": 0.23090330759684244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879008293151855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011971569620072842,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27400994300842285,
      "backward_entropy": 0.23100562890370688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.758825302124023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012964413035660982,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27399688959121704,
      "backward_entropy": 0.23103435834248862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.875185012817383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013959149364382029,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739827334880829,
      "backward_entropy": 0.2308668295542399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42784309387207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014952804194763303,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739696204662323,
      "backward_entropy": 0.23102599382400513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.093876838684082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015947424108162522,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27395665645599365,
      "backward_entropy": 0.23102092742919922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.088038444519043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016945140669122338,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739432454109192,
      "backward_entropy": 0.23095476627349854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.096633911132812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017941956175491214,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739301919937134,
      "backward_entropy": 0.23100900650024414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75007438659668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018941853195428848,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27391743659973145,
      "backward_entropy": 0.23100207249323526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.620671272277832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019939239136874676,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739054262638092,
      "backward_entropy": 0.2309944232304891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513697624206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002093735383823514,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27389177680015564,
      "backward_entropy": 0.2308944265047709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.179069519042969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021935892291367054,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738773226737976,
      "backward_entropy": 0.23087636629740396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95920467376709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002293354133144021,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27386245131492615,
      "backward_entropy": 0.2309675415356954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.163345336914062,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023929683957248926,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273847758769989,
      "backward_entropy": 0.23083635171254477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.057507514953613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002492495346814394,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27383166551589966,
      "backward_entropy": 0.2308143973350525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.168279647827148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025919261388480663,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738150358200073,
      "backward_entropy": 0.23079103231430054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16552734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002691329224035144,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737981081008911,
      "backward_entropy": 0.23076623678207397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69563102722168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002790709026157856,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273780882358551,
      "backward_entropy": 0.23090831438700357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.492388725280762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028902445919811726,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27376168966293335,
      "backward_entropy": 0.23071229457855225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.484681129455566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002989434637129307,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27374231815338135,
      "backward_entropy": 0.2308806578318278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.267288208007812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003088766010478139,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27372244000434875,
      "backward_entropy": 0.23086549838383993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.118776321411133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003188143018633127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737027108669281,
      "backward_entropy": 0.23084898789723715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.361391067504883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032878739293664694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27368104457855225,
      "backward_entropy": 0.23047939936319986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.583860397338867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033876209054142237,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736596167087555,
      "backward_entropy": 0.2304499944051107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.467288970947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003487496869638562,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736380696296692,
      "backward_entropy": 0.2305147647857666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.139001846313477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035874275490641594,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273616224527359,
      "backward_entropy": 0.23047608137130737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.784107208251953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003687266493216157,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27359431982040405,
      "backward_entropy": 0.2303534746170044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.823544979095459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037873031105846167,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2735717296600342,
      "backward_entropy": 0.23039336999257407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919022560119629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003886622376739979,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2735503315925598,
      "backward_entropy": 0.2302824854850769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.079227447509766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003985840827226639,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27352961897850037,
      "backward_entropy": 0.23030356566111246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.429680824279785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004085440654307604,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27350670099258423,
      "backward_entropy": 0.2306570609410604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.11978530883789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00418509216979146,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27348271012306213,
      "backward_entropy": 0.23016377290089926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.795181274414062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0042846836149692535,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273458868265152,
      "backward_entropy": 0.2306030591328939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.983628273010254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0043840776197612286,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2734357714653015,
      "backward_entropy": 0.23007738590240479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.901968955993652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004483341705054045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27341175079345703,
      "backward_entropy": 0.23054436842600504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.823057174682617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004582508467137814,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733886241912842,
      "backward_entropy": 0.22998696565628052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.741662979125977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0046819476410746574,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2733630836009979,
      "backward_entropy": 0.2299376130104065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.418203353881836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0047816443257033825,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27333688735961914,
      "backward_entropy": 0.22988788286844888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.73248291015625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004881422501057386,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27331051230430603,
      "backward_entropy": 0.23041228453318277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.250829696655273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004981417674571276,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27328240871429443,
      "backward_entropy": 0.2297523021697998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.248620986938477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005080927163362503,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27325642108917236,
      "backward_entropy": 0.2297274669011434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65538215637207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005180005915462971,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27323269844055176,
      "backward_entropy": 0.22962969541549683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.72348165512085,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005278875585645437,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27320945262908936,
      "backward_entropy": 0.22956514358520508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.393797874450684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00537714920938015,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2731907367706299,
      "backward_entropy": 0.2295522689819336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.239259719848633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005475672893226147,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2731703519821167,
      "backward_entropy": 0.2294903596242269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.385963439941406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005573879927396774,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27315187454223633,
      "backward_entropy": 0.22942652304967245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.675607681274414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005672348663210869,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27313196659088135,
      "backward_entropy": 0.2300869027773539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.468212127685547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005771157797425985,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2731093168258667,
      "backward_entropy": 0.22920437653859457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.351560592651367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005870182998478413,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27308475971221924,
      "backward_entropy": 0.22922412554423013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.167135238647461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0059693343937397,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27305835485458374,
      "backward_entropy": 0.22915363311767578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.760415077209473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006068554241210222,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27303212881088257,
      "backward_entropy": 0.22908061742782593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.556015014648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006167660932987928,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27300775051116943,
      "backward_entropy": 0.22888467709223428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.180282592773438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006266579497605562,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729860842227936,
      "backward_entropy": 0.22892606258392334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.707427024841309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00636606989428401,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2729611396789551,
      "backward_entropy": 0.22871071100234985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.478053092956543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006465914659202099,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729370892047882,
      "backward_entropy": 0.2287611166636149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.497091293334961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0065649100579321384,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2729169726371765,
      "backward_entropy": 0.2285273869832357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.649152755737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0066636367700994015,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27289679646492004,
      "backward_entropy": 0.2284314235051473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.622937202453613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006762279663234949,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27287915349006653,
      "backward_entropy": 0.22947430610656738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.083928108215332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006860803812742233,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2728625535964966,
      "backward_entropy": 0.22840472062428793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.526540756225586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006959377788007259,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27284276485443115,
      "backward_entropy": 0.22831042607625326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.323793411254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0070578185841441154,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27282536029815674,
      "backward_entropy": 0.22801995277404785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.135384559631348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007156051695346832,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27281102538108826,
      "backward_entropy": 0.22811088959376016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.808538913726807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007254499942064285,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27279675006866455,
      "backward_entropy": 0.22800469398498535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.213888168334961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007352493237704039,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2727871835231781,
      "backward_entropy": 0.2290507952372233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.593450546264648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007450751960277557,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727760672569275,
      "backward_entropy": 0.22756954034169516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.203401565551758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007548935245722532,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27276530861854553,
      "backward_entropy": 0.2288931409517924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9700798988342285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007647363003343344,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727530598640442,
      "backward_entropy": 0.22732814153035483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399016380310059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007745381910353899,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727431654930115,
      "backward_entropy": 0.22741458813349405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.637513637542725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007843302562832832,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2727356553077698,
      "backward_entropy": 0.22863741715749106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.263059616088867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007940668612718582,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2727300226688385,
      "backward_entropy": 0.22854681809743246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.580483436584473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008037900552153587,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27272534370422363,
      "backward_entropy": 0.22701950867970785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.14612865447998,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008135211654007435,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727223038673401,
      "backward_entropy": 0.22688029209772745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.340099334716797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008232328109443188,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727198600769043,
      "backward_entropy": 0.22673805554707846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.265844345092773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008329363539814949,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2727169394493103,
      "backward_entropy": 0.22816733519236246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13154411315918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008426842279732227,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2727116346359253,
      "backward_entropy": 0.228066086769104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.372503280639648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008524108678102493,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27270716428756714,
      "backward_entropy": 0.22607950369517008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.637273788452148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008621898479759693,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27270159125328064,
      "backward_entropy": 0.2261297106742859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.532907485961914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0087197320535779,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726958990097046,
      "backward_entropy": 0.22774503628412882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.537025451660156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008818038739264011,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27268582582473755,
      "backward_entropy": 0.22578948736190796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.706215858459473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008916803635656834,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27267301082611084,
      "backward_entropy": 0.2254270315170288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.497304916381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009015022777020931,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2726639211177826,
      "backward_entropy": 0.22525314490000406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.401232719421387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009113128297030926,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27265387773513794,
      "backward_entropy": 0.22524436314900717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485282897949219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009211607277393341,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27263975143432617,
      "backward_entropy": 0.2248909870783488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.693475723266602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009309940971434116,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2726251184940338,
      "backward_entropy": 0.22484850883483887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.18442440032959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009408311918377876,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2726111114025116,
      "backward_entropy": 0.22463774681091309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.268856048583984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009506460279226303,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27259987592697144,
      "backward_entropy": 0.22441955407460532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.265775680541992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009604907594621181,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27258461713790894,
      "backward_entropy": 0.22419720888137817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.268856048583984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009703148156404495,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2725711464881897,
      "backward_entropy": 0.2238986094792684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.55578327178955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009801273234188557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27256131172180176,
      "backward_entropy": 0.22629769643147787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.549805641174316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00989941693842411,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27255403995513916,
      "backward_entropy": 0.22614399592081705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.632499694824219,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009998115710914135,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2725452780723572,
      "backward_entropy": 0.2232280174891154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.525020599365234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010096759535372257,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725355327129364,
      "backward_entropy": 0.2258229653040568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115354537963867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010195320472121239,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725260257720947,
      "backward_entropy": 0.22565641005833945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.60684871673584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010294122621417046,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725144028663635,
      "backward_entropy": 0.22548512617746988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.495317459106445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010392849333584309,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27250197529792786,
      "backward_entropy": 0.22214742501576742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.794259071350098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010491504333913326,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724910378456116,
      "backward_entropy": 0.22185925642649332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.179403305053711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010589644312858582,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2724817097187042,
      "backward_entropy": 0.22178834676742554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.267693519592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010687576606869698,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27247366309165955,
      "backward_entropy": 0.2215223709742228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.254297256469727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010785384103655815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2724667489528656,
      "backward_entropy": 0.22459272543589273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35073471069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010883590206503868,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27245602011680603,
      "backward_entropy": 0.22095743815104166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.444928169250488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010981667786836624,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724454998970032,
      "backward_entropy": 0.2203585704167684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.710820198059082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011079661548137665,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724340558052063,
      "backward_entropy": 0.22004149357477823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12374210357666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011178307235240936,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27241796255111694,
      "backward_entropy": 0.2238084077835083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.410483360290527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011277155950665474,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2723977565765381,
      "backward_entropy": 0.21974345048268637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.298592567443848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011375333182513714,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27238357067108154,
      "backward_entropy": 0.21942214171091715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.488582611083984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011473363265395164,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.272369921207428,
      "backward_entropy": 0.21909314393997192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.390428066253662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011571355164051056,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723556160926819,
      "backward_entropy": 0.22295387585957846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438936233520508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011668725870549679,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27234581112861633,
      "backward_entropy": 0.22272845109303793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.677960395812988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011766171082854271,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723368704319,
      "backward_entropy": 0.22249660889307657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.14798641204834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011863181367516518,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27232950925827026,
      "backward_entropy": 0.2176994482676188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2531304359436035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011960084550082684,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27232199907302856,
      "backward_entropy": 0.21733103195826212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.603080749511719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012056400068104267,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27231842279434204,
      "backward_entropy": 0.21643640597661337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.019752502441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0121529595926404,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27231279015541077,
      "backward_entropy": 0.21656852960586548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.576467514038086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012249385006725788,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723069489002228,
      "backward_entropy": 0.22126869360605875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.601545333862305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01234603300690651,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27229923009872437,
      "backward_entropy": 0.21518786748250326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.255093574523926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012442830950021744,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27228766679763794,
      "backward_entropy": 0.21475656827290854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.947648048400879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012539639137685299,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2722760736942291,
      "backward_entropy": 0.21493099133173624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.035307884216309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01263628713786602,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27226585149765015,
      "backward_entropy": 0.21385757128397623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.164778709411621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012733355164527893,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722505033016205,
      "backward_entropy": 0.21982385714848837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.487686157226562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012830283492803574,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27223363518714905,
      "backward_entropy": 0.21950995922088623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673806190490723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012927345931529999,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722158432006836,
      "backward_entropy": 0.21918745835622153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.163640022277832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01302462350577116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.272195965051651,
      "backward_entropy": 0.2188559571901957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.044154167175293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013121820986270905,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27217674255371094,
      "backward_entropy": 0.2121023734410604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9524030685424805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013219407759606838,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2721531093120575,
      "backward_entropy": 0.21157375971476236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.515954971313477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0133167440071702,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27213019132614136,
      "backward_entropy": 0.21781190236409506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.191034317016602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013414175249636173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27210548520088196,
      "backward_entropy": 0.21744714180628458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.618759155273438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013512049801647663,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2720754146575928,
      "backward_entropy": 0.21707232793172201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52122688293457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013609969057142735,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27204227447509766,
      "backward_entropy": 0.21668946743011475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.776432991027832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013707972131669521,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27200794219970703,
      "backward_entropy": 0.21629281838734946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.8588228225708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013805576600134373,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271975040435791,
      "backward_entropy": 0.2158889373143514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.738516807556152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01390401367098093,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2719345688819885,
      "backward_entropy": 0.21547192335128784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.03742790222168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014001986011862755,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2718966603279114,
      "backward_entropy": 0.206860880057017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4987077713012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014100303873419762,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27185511589050293,
      "backward_entropy": 0.2062143087387085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849163055419922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014198045246303082,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.271817684173584,
      "backward_entropy": 0.20555192232131958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.397001266479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014295483939349651,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27178218960762024,
      "backward_entropy": 0.20487411816914877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890010833740234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014392966404557228,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27174532413482666,
      "backward_entropy": 0.20367499192555746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.57972526550293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014490210451185703,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27171018719673157,
      "backward_entropy": 0.21278182665506998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.843354225158691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014587584882974625,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2716712951660156,
      "backward_entropy": 0.21229954560597739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.30055046081543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0146847078576684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27163419127464294,
      "backward_entropy": 0.21179908514022827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.556808471679688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014781860634684563,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27159568667411804,
      "backward_entropy": 0.20078402757644653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28172779083252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014879190362989902,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2715543508529663,
      "backward_entropy": 0.20002120733261108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.295537948608398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01497648935765028,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.271511048078537,
      "backward_entropy": 0.19924680391947427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39220142364502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015074338763952255,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2714601755142212,
      "backward_entropy": 0.1984607974688212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.084566116333008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015172191895544529,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2714075446128845,
      "backward_entropy": 0.1976588567097982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.531630516052246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01526987086981535,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27135494351387024,
      "backward_entropy": 0.20847698052724203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.304422378540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015367645770311356,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27129924297332764,
      "backward_entropy": 0.19639472166697183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.890131950378418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015465387143194675,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27124208211898804,
      "backward_entropy": 0.20725440979003906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.046692848205566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01556226797401905,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27119266986846924,
      "backward_entropy": 0.19457654158274332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.015435218811035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015659073367714882,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2711428701877594,
      "backward_entropy": 0.20598973830540976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.825217247009277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01575579307973385,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2710922956466675,
      "backward_entropy": 0.1926844914754232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420134544372559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01585230603814125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27104151248931885,
      "backward_entropy": 0.20467166105906168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.761080265045166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015948999673128128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2709866762161255,
      "backward_entropy": 0.20398875077565512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.949310302734375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016045453026890755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2709319293498993,
      "backward_entropy": 0.2032944162686666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.38409948348999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016141176223754883,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27088218927383423,
      "backward_entropy": 0.20259199539820352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.009125709533691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016236571595072746,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2708350419998169,
      "backward_entropy": 0.20187715689341226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.775160312652588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016332030296325684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27078497409820557,
      "backward_entropy": 0.20114678144454956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.517082214355469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016426824033260345,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27074161171913147,
      "backward_entropy": 0.18583502372105917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.36214542388916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01652202568948269,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27069011330604553,
      "backward_entropy": 0.18440612157185873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.745981693267822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016616927459836006,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27063989639282227,
      "backward_entropy": 0.19887920220692953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4397125244140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016711818054318428,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2705881595611572,
      "backward_entropy": 0.19809353351593018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.717193603515625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01680651493370533,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2705380916595459,
      "backward_entropy": 0.1816420555114746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.820343017578125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016900572925806046,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.270494282245636,
      "backward_entropy": 0.18054771423339844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62005615234375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01699475198984146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27044451236724854,
      "backward_entropy": 0.19565985600153604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.339799404144287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01708950474858284,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27038463950157166,
      "backward_entropy": 0.19481398661931357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.476186275482178,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01718338020145893,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27033472061157227,
      "backward_entropy": 0.17717109123865762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.316996097564697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017277158796787262,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27028393745422363,
      "backward_entropy": 0.17602149645487467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.513574123382568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01737077720463276,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2702334523200989,
      "backward_entropy": 0.19221278031667074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0855913162231445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017463792115449905,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27018943428993225,
      "backward_entropy": 0.17368410031000772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.117613315582275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01755589433014393,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27015259861946106,
      "backward_entropy": 0.19042555491129556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.505502223968506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0176478810608387,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27011406421661377,
      "backward_entropy": 0.18951435883839926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.196280479431152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01773940958082676,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27007943391799927,
      "backward_entropy": 0.18859219551086426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.008460998535156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01783100888133049,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27004292607307434,
      "backward_entropy": 0.16731510559717813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.870455265045166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017922529950737953,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2700052857398987,
      "backward_entropy": 0.16597511370976767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.481565952301025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018013836815953255,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2699660658836365,
      "backward_entropy": 0.16462025046348572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.105831146240234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01810537278652191,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2699204087257385,
      "backward_entropy": 0.18474388122558594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0751752853393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018196864053606987,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26987290382385254,
      "backward_entropy": 0.1618898610273997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.40075159072876,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018288344144821167,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26982322335243225,
      "backward_entropy": 0.1624374488989512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.09289026260376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01838001050055027,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2697676718235016,
      "backward_entropy": 0.18161696195602417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.598458290100098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018471645191311836,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2697088122367859,
      "backward_entropy": 0.15975860754648843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5319318771362305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018562939018011093,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26965147256851196,
      "backward_entropy": 0.15627922614415488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.867485046386719,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01865321584045887,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2696058750152588,
      "backward_entropy": 0.15701975425084433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.375060558319092,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018743455410003662,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2695572078227997,
      "backward_entropy": 0.1556341548760732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.131003379821777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0188333448022604,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26950913667678833,
      "backward_entropy": 0.17598370711008707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.010096549987793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018923398107290268,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2694534659385681,
      "backward_entropy": 0.15043969949086508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.646409511566162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019013511016964912,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2693912386894226,
      "backward_entropy": 0.17359709739685059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.718564510345459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01910346932709217,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2693262994289398,
      "backward_entropy": 0.17237738768259683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.720078945159912,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01919262856245041,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2692667245864868,
      "backward_entropy": 0.1459273099899292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9811272621154785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01928183063864708,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2692030370235443,
      "backward_entropy": 0.1444052259127299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.413684844970703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01937052235007286,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2691410779953003,
      "backward_entropy": 0.14287331700325012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.379005432128906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019459063187241554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26907530426979065,
      "backward_entropy": 0.1673625906308492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.171597480773926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019546741619706154,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26901668310165405,
      "backward_entropy": 0.16607566674550375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.628591060638428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01963418535888195,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2689550518989563,
      "backward_entropy": 0.1382260819276174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.870345115661621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019721033051609993,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26889568567276,
      "backward_entropy": 0.13666059573491415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.690117835998535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019807588309049606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26883605122566223,
      "backward_entropy": 0.16213862101236978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.985621452331543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01989372819662094,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2687768340110779,
      "backward_entropy": 0.13352536161740622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4574737548828125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01997974142432213,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26871463656425476,
      "backward_entropy": 0.13538914918899536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.159222602844238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020065953955054283,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26864343881607056,
      "backward_entropy": 0.1580872138341268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.797316074371338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020152077078819275,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26856550574302673,
      "backward_entropy": 0.1567041277885437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.971088409423828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02023789845407009,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2684851288795471,
      "backward_entropy": 0.13088535269101462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.379654407501221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02032287046313286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2684118151664734,
      "backward_entropy": 0.15391562382380167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.777053356170654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020407337695360184,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26833826303482056,
      "backward_entropy": 0.15251382191975912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4813361167907715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02049165964126587,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2682591378688812,
      "backward_entropy": 0.12637992699941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9886250495910645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02057562954723835,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2681776285171509,
      "backward_entropy": 0.12086931864420573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.081912517547607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020659655332565308,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2680865526199341,
      "backward_entropy": 0.12338682015736897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.886678695678711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020743854343891144,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26798614859580994,
      "backward_entropy": 0.1467831532160441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.25911808013916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0208272747695446,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2678895592689514,
      "backward_entropy": 0.12039206425348918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.863091468811035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02091035433113575,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2677922248840332,
      "backward_entropy": 0.11888928214708964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.174285411834717,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020992785692214966,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2676975131034851,
      "backward_entropy": 0.1129487653573354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4603095054626465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021074935793876648,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26760151982307434,
      "backward_entropy": 0.1113806168238322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.549933433532715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021156197413802147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2675110995769501,
      "backward_entropy": 0.13948065042495728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.901171684265137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021236779168248177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.267424613237381,
      "backward_entropy": 0.13802013794581094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.794112205505371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02131778933107853,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26732203364372253,
      "backward_entropy": 0.13654003540674844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.837435722351074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02139834500849247,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26721811294555664,
      "backward_entropy": 0.10516445835431416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.283562183380127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021478503942489624,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26711156964302063,
      "backward_entropy": 0.10839052001635234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.328761100769043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0215578842908144,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26701024174690247,
      "backward_entropy": 0.10690364241600037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.356932640075684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02163657732307911,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2669110894203186,
      "backward_entropy": 0.130630761384964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.147778034210205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0217147134244442,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2668132185935974,
      "backward_entropy": 0.10394955674807231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6271562576293945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02179211936891079,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26671749353408813,
      "backward_entropy": 0.12770153085390726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.262476921081543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021869350224733353,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26661694049835205,
      "backward_entropy": 0.10102382302284241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3943607807159424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021946070715785027,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26651495695114136,
      "backward_entropy": 0.12477204203605652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9277279376983643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022021546959877014,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26642391085624695,
      "backward_entropy": 0.12332651019096375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7523369789123535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02209639362990856,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2663334012031555,
      "backward_entropy": 0.09168976545333862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.575137615203857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022170549258589745,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2662457823753357,
      "backward_entropy": 0.1204512615998586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.140195369720459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022244827821850777,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26614564657211304,
      "backward_entropy": 0.08882178862889607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6639461517333984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022318745031952858,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2660382390022278,
      "backward_entropy": 0.09248967965443929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.289107322692871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02239195629954338,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26593244075775146,
      "backward_entropy": 0.08599520723025005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.331850051879883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02246519923210144,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2658182680606842,
      "backward_entropy": 0.11468267440795898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6136088371276855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02253739722073078,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2657070755958557,
      "backward_entropy": 0.08837848901748657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.992631196975708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022609008476138115,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26559436321258545,
      "backward_entropy": 0.0818574329217275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7012343406677246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02268051728606224,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2654739320278168,
      "backward_entropy": 0.11038355032602946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.879199504852295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02275162935256958,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26534906029701233,
      "backward_entropy": 0.08438219626744588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6676344871520996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02282252162694931,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26521486043930054,
      "backward_entropy": 0.1075206200281779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3561758995056152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022893026471138,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26507461071014404,
      "backward_entropy": 0.07652316490809123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1161677837371826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022962916642427444,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2649339437484741,
      "backward_entropy": 0.07522640625635783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0836539268493652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02303200587630272,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2647957503795624,
      "backward_entropy": 0.07394830882549286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4127004146575928,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023100264370441437,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2646573483943939,
      "backward_entropy": 0.07798278828461964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.662285327911377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02316707745194435,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26453086733818054,
      "backward_entropy": 0.07676225403944652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8980584144592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023233968764543533,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26439085602760315,
      "backward_entropy": 0.07021903991699219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2937824726104736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023300055414438248,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2642502188682556,
      "backward_entropy": 0.09779940048853557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.581066131591797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02336585894227028,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2641001343727112,
      "backward_entropy": 0.0731836309035619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1588759422302246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023431776091456413,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2639356255531311,
      "backward_entropy": 0.06662489970525105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.312070369720459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02349739894270897,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26376599073410034,
      "backward_entropy": 0.0937490959962209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8113715648651123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023561643436551094,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26360395550727844,
      "backward_entropy": 0.09243044257164001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.02400541305542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023625321686267853,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2634391784667969,
      "backward_entropy": 0.09112360080083211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0310914516448975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02368874102830887,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2632659077644348,
      "backward_entropy": 0.06751251220703125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5662999153137207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02375066839158535,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2631027102470398,
      "backward_entropy": 0.06097904841105143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6586551666259766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02381204627454281,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2629390358924866,
      "backward_entropy": 0.0872953434785207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.394493579864502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023872945457696915,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2627694010734558,
      "backward_entropy": 0.058837672074635826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.391601324081421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02393314614892006,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26260244846343994,
      "backward_entropy": 0.08481677373250325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1233503818511963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023992767557501793,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26243528723716736,
      "backward_entropy": 0.06225779155890147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.073397636413574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024052709341049194,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2622496485710144,
      "backward_entropy": 0.0557465652624766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6094090938568115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02411148138344288,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26206594705581665,
      "backward_entropy": 0.0547490268945694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7464139461517334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024170011281967163,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26187121868133545,
      "backward_entropy": 0.07998001575469971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.593871831893921,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024227222427725792,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26168909668922424,
      "backward_entropy": 0.05280922849973043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7125320434570312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024283045902848244,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26152053475379944,
      "backward_entropy": 0.05738250414530436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.793561339378357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024337690323591232,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2613566517829895,
      "backward_entropy": 0.05647097031275431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6906770467758179,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02439139410853386,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26119378209114075,
      "backward_entropy": 0.05007959405581156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.582179307937622,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024444175884127617,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.261035293340683,
      "backward_entropy": 0.07441076636314392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6601638793945312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024495873600244522,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26087990403175354,
      "backward_entropy": 0.053849101066589355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3066508769989014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02454672008752823,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26072394847869873,
      "backward_entropy": 0.05301308135191599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8072773218154907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024596279487013817,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2605770528316498,
      "backward_entropy": 0.07133955756823222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9892610311508179,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024645449593663216,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2604221999645233,
      "backward_entropy": 0.07034920652707417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2922390699386597,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02469458617269993,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26025405526161194,
      "backward_entropy": 0.050596763690312706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3461551666259766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02474271133542061,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26009732484817505,
      "backward_entropy": 0.04980594416459402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.256500005722046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02478998899459839,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2599472403526306,
      "backward_entropy": 0.06745099524656932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.276913046836853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02483624964952469,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2598017752170563,
      "backward_entropy": 0.042948782444000244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7203527688980103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02488153614103794,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25965616106987,
      "backward_entropy": 0.06562968095143636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3723100423812866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024926895275712013,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25949999690055847,
      "backward_entropy": 0.04678881665070852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5740399360656738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024971675127744675,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25934261083602905,
      "backward_entropy": 0.06384193897247314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0342693328857422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02501619979739189,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2591738998889923,
      "backward_entropy": 0.04021507501602173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2218596935272217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025059638544917107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2590146064758301,
      "backward_entropy": 0.044655283292134605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8312374353408813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02510230429470539,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25885215401649475,
      "backward_entropy": 0.06126616398493449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0767757892608643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025145499035716057,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25866761803627014,
      "backward_entropy": 0.06041670342286428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0462234020233154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02518768236041069,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258484810590744,
      "backward_entropy": 0.037711188197135925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4983023405075073,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02522888593375683,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2583032548427582,
      "backward_entropy": 0.041997661193211876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1378016471862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02527005970478058,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25810515880584717,
      "backward_entropy": 0.05798115332921346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.032991886138916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025310490280389786,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25790345668792725,
      "backward_entropy": 0.040750538309415184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6039584875106812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02535005286335945,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.257700651884079,
      "backward_entropy": 0.04015228897333145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2431466579437256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025387868285179138,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2575100362300873,
      "backward_entropy": 0.05569462478160858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8635684847831726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02542535960674286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25730380415916443,
      "backward_entropy": 0.054969921708106995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2148633003234863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02546183578670025,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2570994794368744,
      "backward_entropy": 0.03848502536614736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7577939629554749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02549823746085167,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25688406825065613,
      "backward_entropy": 0.05356588462988535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.379168152809143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025533540174365044,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25667306780815125,
      "backward_entropy": 0.05288875102996826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8577316999435425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02556939795613289,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2564436197280884,
      "backward_entropy": 0.05220151940981547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7074881792068481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025604475289583206,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2562143802642822,
      "backward_entropy": 0.05153173704942068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7488468885421753,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025638526305556297,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2559911012649536,
      "backward_entropy": 0.03593816856543223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8545178174972534,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02567172609269619,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2557699680328369,
      "backward_entropy": 0.050256053606669106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7618066072463989,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02570442296564579,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2555452585220337,
      "backward_entropy": 0.030784524977207184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1179536581039429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025736359879374504,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25531861186027527,
      "backward_entropy": 0.04903672138849894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6723790764808655,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025768693536520004,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2550768554210663,
      "backward_entropy": 0.048428247372309365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8316192626953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025800175964832306,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.254838228225708,
      "backward_entropy": 0.04783820609251658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7466205954551697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025831401348114014,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2545957565307617,
      "backward_entropy": 0.04725479086240133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8351602554321289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025862092152237892,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2543509602546692,
      "backward_entropy": 0.02887122333049774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.642051100730896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02589256316423416,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2540990710258484,
      "backward_entropy": 0.046117266019185386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.673315703868866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025922102853655815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25384560227394104,
      "backward_entropy": 0.0455697625875473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7675002217292786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025950824841856956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2535869777202606,
      "backward_entropy": 0.04503828287124634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7341258525848389,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025979354977607727,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25332188606262207,
      "backward_entropy": 0.04451175034046173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.528654932975769,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026007264852523804,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25304579734802246,
      "backward_entropy": 0.02720779925584793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6105729341506958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0260341614484787,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2527710199356079,
      "backward_entropy": 0.030485014120737713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5479397177696228,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026060519739985466,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2524907886981964,
      "backward_entropy": 0.02662731210390727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6232520341873169,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02608616091310978,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2522093653678894,
      "backward_entropy": 0.02980973819891612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.778174877166748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026111528277397156,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2519245147705078,
      "backward_entropy": 0.04208712776501974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.88255774974823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026137107983231544,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2516266405582428,
      "backward_entropy": 0.04162047555049261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8162153959274292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026163261383771896,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25130993127822876,
      "backward_entropy": 0.04114425679047903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5940433144569397,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02618975006043911,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25097864866256714,
      "backward_entropy": 0.028501741588115692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4637176990509033,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026215752586722374,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2506444454193115,
      "backward_entropy": 0.028183095157146454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6726622581481934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026240626350045204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2503107786178589,
      "backward_entropy": 0.039743480583031975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.435494989156723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626539207994938,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24996638298034668,
      "backward_entropy": 0.039297359685103096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4963289201259613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026289217174053192,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.249625563621521,
      "backward_entropy": 0.038870165745417275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47283118963241577,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026312291622161865,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24928195774555206,
      "backward_entropy": 0.02403928091128667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4011702537536621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335006579756737,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2489415854215622,
      "backward_entropy": 0.0267606923977534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5131788849830627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026356801390647888,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24860350787639618,
      "backward_entropy": 0.02650569627682368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37781891226768494,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026378413662314415,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24826177954673767,
      "backward_entropy": 0.0262544850508372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.39615747332572937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02639918588101864,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2479226142168045,
      "backward_entropy": 0.03691103061040243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.289570152759552,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02641933038830757,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2475842535495758,
      "backward_entropy": 0.03655478854974111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4039493501186371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02643866464495659,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24725602567195892,
      "backward_entropy": 0.02285917103290558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43079081177711487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02645755559206009,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24692514538764954,
      "backward_entropy": 0.0358818049232165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5118699669837952,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026475930586457253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2465861439704895,
      "backward_entropy": 0.03555814176797867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31647175550460815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02649461105465889,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24623741209506989,
      "backward_entropy": 0.03522959599892298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1745258867740631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026512619107961655,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24589289724826813,
      "backward_entropy": 0.03491424769163132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35276857018470764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026528913527727127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2455577552318573,
      "backward_entropy": 0.03462891529003779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4113081991672516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026544887572526932,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24522075057029724,
      "backward_entropy": 0.034348972141742706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.31671565771102905,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02656097710132599,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24487784504890442,
      "backward_entropy": 0.03406685094038645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2513125538825989,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02657650038599968,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24453383684158325,
      "backward_entropy": 0.033794380724430084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35671520233154297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02659144252538681,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24419884383678436,
      "backward_entropy": 0.023885299762090046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3501242697238922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026606392115354538,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2438610941171646,
      "backward_entropy": 0.03327024231354395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32560819387435913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026621270924806595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24351897835731506,
      "backward_entropy": 0.03300933043162028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3026539385318756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026635857298970222,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2431730329990387,
      "backward_entropy": 0.03275329867998759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1726749837398529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026649951934814453,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24282370507717133,
      "backward_entropy": 0.021114570399125416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35307776927948,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026662971824407578,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24248304963111877,
      "backward_entropy": 0.023135259747505188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35326769948005676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026676207780838013,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24213430285453796,
      "backward_entropy": 0.03204525510470072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3128626048564911,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02668984793126583,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2417794167995453,
      "backward_entropy": 0.02286071578661601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20735807716846466,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026703521609306335,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24142079055309296,
      "backward_entropy": 0.022722139954566956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3219783306121826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026716439053416252,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24106675386428833,
      "backward_entropy": 0.022592554489771526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16692176461219788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026729382574558258,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.240704745054245,
      "backward_entropy": 0.031118124723434448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3047912120819092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026741351932287216,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24035035073757172,
      "backward_entropy": 0.030909334619839985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1624414473772049,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026753386482596397,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23998892307281494,
      "backward_entropy": 0.02222741146882375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23709189891815186,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0267647635191679,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23963694274425507,
      "backward_entropy": 0.020277173568805058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21001534163951874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026775993406772614,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23928454518318176,
      "backward_entropy": 0.02200766404469808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2388993501663208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0267870482057333,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2389352023601532,
      "backward_entropy": 0.020123136540253956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20781978964805603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02679804153740406,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23858371376991272,
      "backward_entropy": 0.029918010036150616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2097553312778473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02680872194468975,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23823264241218567,
      "backward_entropy": 0.019973471760749817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19702142477035522,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026819273829460144,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23788219690322876,
      "backward_entropy": 0.021592517693837483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18517187237739563,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026829516515135765,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2375321388244629,
      "backward_entropy": 0.019831568002700806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22091755270957947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02683928981423378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23718222975730896,
      "backward_entropy": 0.029193786283334095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16111060976982117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026849357411265373,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23683154582977295,
      "backward_entropy": 0.021309614181518555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15990948677062988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02685888297855854,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23648346960544586,
      "backward_entropy": 0.028849740823109944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22503872215747833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02686786837875843,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2361365556716919,
      "backward_entropy": 0.02869105835755666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1672505885362625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026877103373408318,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23578351736068726,
      "backward_entropy": 0.0285286083817482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19651955366134644,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026886286213994026,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23543334007263184,
      "backward_entropy": 0.019463057319323223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15425296127796173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026895636692643166,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23508088290691376,
      "backward_entropy": 0.028204336762428284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17668989300727844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026904495432972908,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23472929000854492,
      "backward_entropy": 0.028049225608507793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1502280831336975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026913195848464966,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23437559604644775,
      "backward_entropy": 0.02072847510377566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16815665364265442,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026921596378087997,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23402360081672668,
      "backward_entropy": 0.02065373460451762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12965679168701172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02693003974854946,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23367124795913696,
      "backward_entropy": 0.02760003258784612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1834454983472824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02693793922662735,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23332148790359497,
      "backward_entropy": 0.020509307583173115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1374165266752243,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026945963501930237,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2329665720462799,
      "backward_entropy": 0.020438456286986668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13248750567436218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026953846216201782,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23261204361915588,
      "backward_entropy": 0.02717854082584381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13974742591381073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026961224153637886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23225602507591248,
      "backward_entropy": 0.027046749989191692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13589835166931152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026968544349074364,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23189985752105713,
      "backward_entropy": 0.02691594511270523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09296028316020966,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026975972577929497,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23154544830322266,
      "backward_entropy": 0.018923956900835037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13954004645347595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026982592418789864,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2311951071023941,
      "backward_entropy": 0.0201214204231898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1308896690607071,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026989376172423363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2308432161808014,
      "backward_entropy": 0.026542939245700836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1422865241765976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026996182277798653,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2304905354976654,
      "backward_entropy": 0.026421604057153065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10413403809070587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02700311876833439,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2301349639892578,
      "backward_entropy": 0.026298341651757557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10167306661605835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027009805664420128,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22978320717811584,
      "backward_entropy": 0.019890754173199337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12753531336784363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0270159300416708,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22943221032619476,
      "backward_entropy": 0.026068322360515594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0954810231924057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027022235095500946,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2290799915790558,
      "backward_entropy": 0.025954872369766235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10367276519536972,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027028163895010948,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22873051464557648,
      "backward_entropy": 0.019737693170706432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08745354413986206,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027033889666199684,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22838179767131805,
      "backward_entropy": 0.018628381192684174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08909167349338531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027039464563131332,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22803828120231628,
      "backward_entropy": 0.018603168427944183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09406374394893646,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027044687420129776,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22769662737846375,
      "backward_entropy": 0.018582011262575786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07848642766475677,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027049904689192772,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22735729813575745,
      "backward_entropy": 0.02544796218474706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1066015362739563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02705487608909607,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22702236473560333,
      "backward_entropy": 0.02535556008418401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09865487366914749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027060266584157944,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22668755054473877,
      "backward_entropy": 0.02525724470615387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08517486602067947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027065953239798546,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22635406255722046,
      "backward_entropy": 0.025155094762643177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05182921886444092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027071380987763405,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22602054476737976,
      "backward_entropy": 0.025057060023148853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060596615076065063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027076395228505135,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22569629549980164,
      "backward_entropy": 0.02496566375096639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07384049147367477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027080995962023735,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22537675499916077,
      "backward_entropy": 0.024880655109882355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06395196914672852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02708561159670353,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2250601202249527,
      "backward_entropy": 0.024795932074387867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05530505254864693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027090106159448624,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22474800050258636,
      "backward_entropy": 0.01837259531021118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06574815511703491,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02709423005580902,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22444042563438416,
      "backward_entropy": 0.02463606745004654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05612831562757492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027098175138235092,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22413401305675507,
      "backward_entropy": 0.024561628699302673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05511412024497986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027101729065179825,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22382992506027222,
      "backward_entropy": 0.018333014100790024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06333301961421967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02710503712296486,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22352886199951172,
      "backward_entropy": 0.024427801370620728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055096179246902466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027108529582619667,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22323068976402283,
      "backward_entropy": 0.024360281725724537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06927768141031265,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027112064883112907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22293679416179657,
      "backward_entropy": 0.024292466541131336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052259661257267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027115795761346817,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22264204919338226,
      "backward_entropy": 0.024221844971179962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04487220197916031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027119414880871773,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22235046327114105,
      "backward_entropy": 0.02415301154057185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.055113911628723145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027122819796204567,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22206354141235352,
      "backward_entropy": 0.02408761779467265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04797114431858063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02712612971663475,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2217768430709839,
      "backward_entropy": 0.024023575087388355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0492287315428257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027129244059324265,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22149211168289185,
      "backward_entropy": 0.018952665229638416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053745754063129425,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027132442221045494,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2212105542421341,
      "backward_entropy": 0.01823841283718745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049933843314647675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02713579498231411,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22092807292938232,
      "backward_entropy": 0.023836260040601093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04261068254709244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027139117941260338,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2206457257270813,
      "backward_entropy": 0.023772689203421276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04440012946724892,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027142329141497612,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2203660011291504,
      "backward_entropy": 0.02371089905500412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03604331985116005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027145467698574066,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22008773684501648,
      "backward_entropy": 0.023650305966536205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040403272956609726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02714819833636284,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21981120109558105,
      "backward_entropy": 0.023595616221427917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037000950425863266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027151020243763924,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21953855454921722,
      "backward_entropy": 0.023539933065573376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037822410464286804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027153585106134415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21926718950271606,
      "backward_entropy": 0.023487967749436695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03191462531685829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027156252413988113,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21899986267089844,
      "backward_entropy": 0.023434855043888092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034696511924266815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027158932760357857,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2187383770942688,
      "backward_entropy": 0.023381955921649933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03860282525420189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02716171182692051,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21848121285438538,
      "backward_entropy": 0.023327964047590893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0337245874106884,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027164632454514503,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21822577714920044,
      "backward_entropy": 0.02327214429775874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030850181356072426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027167584747076035,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21797338128089905,
      "backward_entropy": 0.018658267954985302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03528005629777908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027170518413186073,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21772435307502747,
      "backward_entropy": 0.023161162932713825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029210662469267845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027173634618520737,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21747729182243347,
      "backward_entropy": 0.023103877902030945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030871450901031494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027176780626177788,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21723414957523346,
      "backward_entropy": 0.023046573003133137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027638426050543785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027179956436157227,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21699346601963043,
      "backward_entropy": 0.02298918863137563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025842204689979553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02718288265168667,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21675355732440948,
      "backward_entropy": 0.02293533831834793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03086293302476406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027185769751667976,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21651749312877655,
      "backward_entropy": 0.02288222312927246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026859408244490623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027188841253519058,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21628358960151672,
      "backward_entropy": 0.02282670388619105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030076300725340843,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02719184383749962,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21605131030082703,
      "backward_entropy": 0.018458933879931767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019355345517396927,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027194958180189133,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21581976115703583,
      "backward_entropy": 0.018432168910900753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019257932901382446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027197934687137604,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21559357643127441,
      "backward_entropy": 0.02266298731168111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021834617480635643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027200687676668167,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21537086367607117,
      "backward_entropy": 0.022612792750199635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023236196488142014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027203425765037537,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21515104174613953,
      "backward_entropy": 0.022563305993874867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01479845680296421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027206214144825935,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21493351459503174,
      "backward_entropy": 0.022513325015703838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01567031815648079,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027208874002099037,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21472270786762238,
      "backward_entropy": 0.022465442617734272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014886898919939995,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02721143513917923,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21451717615127563,
      "backward_entropy": 0.022419164578119915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01982215791940689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027213843539357185,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21431607007980347,
      "backward_entropy": 0.02237524340550105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017482738941907883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02721625380218029,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2141159474849701,
      "backward_entropy": 0.022331354518731434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015624100342392921,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0272186528891325,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21391841769218445,
      "backward_entropy": 0.01823700840274493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018760275095701218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027221018448472023,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21372443437576294,
      "backward_entropy": 0.02224476883808772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014496730640530586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027223462238907814,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21353158354759216,
      "backward_entropy": 0.0181973564128081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015826301649212837,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027225736528635025,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21334072947502136,
      "backward_entropy": 0.017806741098562878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012843598611652851,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02722802571952343,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21315211057662964,
      "backward_entropy": 0.01815948138634364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015091928653419018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723018079996109,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2129664272069931,
      "backward_entropy": 0.02207818627357483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012064347974956036,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027232393622398376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21278277039527893,
      "backward_entropy": 0.022038206458091736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011852936819195747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027234412729740143,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21260082721710205,
      "backward_entropy": 0.022000884016354878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011788146570324898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723635919392109,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2124219685792923,
      "backward_entropy": 0.021964895228544872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010109880939126015,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027238275855779648,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21224620938301086,
      "backward_entropy": 0.017742909491062164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012844564393162727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02724010869860649,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2120741903781891,
      "backward_entropy": 0.021895334124565125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010298548266291618,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027241939678788185,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21190306544303894,
      "backward_entropy": 0.021861252685387928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012205555103719234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02724365144968033,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21173401176929474,
      "backward_entropy": 0.021828927099704742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011003057472407818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027245506644248962,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21156755089759827,
      "backward_entropy": 0.021794783572355907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008244373835623264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027247369289398193,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21140307188034058,
      "backward_entropy": 0.02176062762737274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00977101270109415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02724900096654892,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2112404704093933,
      "backward_entropy": 0.01769326627254486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00816328078508377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02725067548453808,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21108077466487885,
      "backward_entropy": 0.021698320905367535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008575440384447575,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027252303436398506,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2109244465827942,
      "backward_entropy": 0.01796010509133339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008594779297709465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02725394442677498,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21077117323875427,
      "backward_entropy": 0.02163737267255783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008174865506589413,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027255576103925705,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21061983704566956,
      "backward_entropy": 0.021607252458731335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006230472587049007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027257155627012253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2104700654745102,
      "backward_entropy": 0.02157795677582423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006300653330981731,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027258599177002907,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21032336354255676,
      "backward_entropy": 0.017649323989947636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009149128571152687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027259988710284233,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2101801335811615,
      "backward_entropy": 0.021524466574192047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007042559329420328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027261538431048393,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21003834903240204,
      "backward_entropy": 0.01763602967063586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005099521018564701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027263076975941658,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2098987102508545,
      "backward_entropy": 0.01787116378545761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006102870684117079,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027264535427093506,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2097625434398651,
      "backward_entropy": 0.021441034972667694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006876025348901749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027266010642051697,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20962576568126678,
      "backward_entropy": 0.021414096156756084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006166216917335987,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027267513796687126,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20948860049247742,
      "backward_entropy": 0.017834061135848362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005909659434109926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02726902812719345,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20935218036174774,
      "backward_entropy": 0.021359811226526897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00644732266664505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027270548045635223,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2092168629169464,
      "backward_entropy": 0.02133273830016454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006389833986759186,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027272092178463936,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20908164978027344,
      "backward_entropy": 0.01779526099562645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005277925170958042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027273712679743767,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20894750952720642,
      "backward_entropy": 0.02127746244271596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004500796087086201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027275310829281807,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2088150680065155,
      "backward_entropy": 0.01776721701025963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0050012581050395966,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027276890352368355,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20868563652038574,
      "backward_entropy": 0.021222293376922607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004821501672267914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727850154042244,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20855838060379028,
      "backward_entropy": 0.021194664140542347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036626632791012526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02728009782731533,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2084324061870575,
      "backward_entropy": 0.017725278933842976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004253139719367027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027281617745757103,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20830905437469482,
      "backward_entropy": 0.021141332884629566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037740818224847317,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027283167466521263,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20818831026554108,
      "backward_entropy": 0.017508181432882946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037319506518542767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027284637093544006,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2080691158771515,
      "backward_entropy": 0.021089822053909302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037319823168218136,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728608250617981,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20795199275016785,
      "backward_entropy": 0.02106503148873647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032255728729069233,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027287516742944717,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2078365683555603,
      "backward_entropy": 0.021040548880894978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031444646883755922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027288908138871193,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20772325992584229,
      "backward_entropy": 0.021016870935757954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029297168366611004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290252968668938,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20761199295520782,
      "backward_entropy": 0.0176366592446963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003654510248452425,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729155868291855,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20750300586223602,
      "backward_entropy": 0.017625272274017334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031504451762884855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729293331503868,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2073954939842224,
      "backward_entropy": 0.020948196450869244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021337145008146763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729436755180359,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20729053020477295,
      "backward_entropy": 0.020924198130766552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00252848700620234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027295658364892006,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20718756318092346,
      "backward_entropy": 0.020902248720328014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026295497082173824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027296939864754677,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2070867270231247,
      "backward_entropy": 0.017577342689037323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002012773882597685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027298210188746452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20698733627796173,
      "backward_entropy": 0.020859186848004658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002127197338268161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729944884777069,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2068907618522644,
      "backward_entropy": 0.02083839972813924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014308628160506487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02730058878660202,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20679518580436707,
      "backward_entropy": 0.020818983515103657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018792186165228486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02730165608227253,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2067030668258667,
      "backward_entropy": 0.02080065260330836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001999347237870097,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027302665635943413,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2066124528646469,
      "backward_entropy": 0.017380913098653156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017426911508664489,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027303680777549744,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2065235674381256,
      "backward_entropy": 0.017374591281016667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017368994886055589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02730465680360794,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20643630623817444,
      "backward_entropy": 0.0207486388583978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015110058011487126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273056048899889,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20635053515434265,
      "backward_entropy": 0.020732057591279347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013908614637330174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027306485921144485,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20626623928546906,
      "backward_entropy": 0.017494233946005504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014358090702444315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027307329699397087,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20618389546871185,
      "backward_entropy": 0.020701433221499126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011227312497794628,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027308126911520958,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2061028778553009,
      "backward_entropy": 0.01748004804054896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013727601617574692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027308892458677292,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2060243934392929,
      "backward_entropy": 0.020673204213380814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011744636576622725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02730967476963997,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20594772696495056,
      "backward_entropy": 0.020659250517686207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011149112833663821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027310486882925034,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20587368309497833,
      "backward_entropy": 0.02064498762289683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009842668659985065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027311258018016815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2058010995388031,
      "backward_entropy": 0.02063127855459849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001108844648115337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027312034741044044,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20573103427886963,
      "backward_entropy": 0.020617672552665074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009330916218459606,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027312789112329483,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20566195249557495,
      "backward_entropy": 0.017439723014831543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009680056245997548,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027313508093357086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20559439063072205,
      "backward_entropy": 0.02059188609321912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000895290169864893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027314184233546257,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2055276334285736,
      "backward_entropy": 0.02057984968026479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000914636068046093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027314823120832443,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2054620087146759,
      "backward_entropy": 0.020568400621414185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009689003345556557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027315475046634674,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20539796352386475,
      "backward_entropy": 0.020556898166735966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008918369421735406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027316145598888397,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20533499121665955,
      "backward_entropy": 0.020545138667027157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007002857746556401,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027316810563206673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20527303218841553,
      "backward_entropy": 0.020533489684263866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008030504686757922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027317455038428307,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20521274209022522,
      "backward_entropy": 0.017399617781241734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007308077765628695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027318092063069344,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20515337586402893,
      "backward_entropy": 0.020511033634344738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006637061014771461,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027318714186549187,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2050950825214386,
      "backward_entropy": 0.017287656664848328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006575946463271976,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02731931582093239,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20503798127174377,
      "backward_entropy": 0.01738312467932701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007084630196914077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027319926768541336,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20498228073120117,
      "backward_entropy": 0.020478788763284683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004902604268863797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02732054889202118,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.204927459359169,
      "backward_entropy": 0.017276714245478313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004651497001759708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732114866375923,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20487432181835175,
      "backward_entropy": 0.020457737147808075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004275284300092608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027321707457304,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2048223912715912,
      "backward_entropy": 0.020447976887226105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004627870803233236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027322212234139442,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20477154850959778,
      "backward_entropy": 0.017357274889945984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00045394417247734964,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732272259891033,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20472222566604614,
      "backward_entropy": 0.020429935306310654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044568179873749614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732321433722973,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20467379689216614,
      "backward_entropy": 0.020421334852774937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004069886635988951,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027323666960000992,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20462597906589508,
      "backward_entropy": 0.020413223654031754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003733295598067343,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02732410468161106,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2045791745185852,
      "backward_entropy": 0.01734076937039693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003444746253080666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027324531227350235,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20453360676765442,
      "backward_entropy": 0.020397692918777466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003655782784335315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732493355870247,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20448905229568481,
      "backward_entropy": 0.020390381415685017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030974516994319856,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027325360104441643,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20444586873054504,
      "backward_entropy": 0.01732974002758662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002901957486756146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027325784787535667,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20440396666526794,
      "backward_entropy": 0.020375307649374008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002512763603590429,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027326222509145737,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2043636292219162,
      "backward_entropy": 0.0173220361272494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002965135790873319,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732662297785282,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20432427525520325,
      "backward_entropy": 0.02036056046684583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030252468422986567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027327032759785652,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2042858898639679,
      "backward_entropy": 0.020353374381860096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026261972379870713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027327435091137886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20424801111221313,
      "backward_entropy": 0.020346321165561676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023065446293912828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732781507074833,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20421072840690613,
      "backward_entropy": 0.020339562247196834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021106233180034906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02732817456126213,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2041742503643036,
      "backward_entropy": 0.017304377009471256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002161236188840121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732854150235653,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20413905382156372,
      "backward_entropy": 0.020326609412829082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019074208103120327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027328897267580032,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20410464704036713,
      "backward_entropy": 0.020320275177558262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017487184959463775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02732924558222294,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20407117903232574,
      "backward_entropy": 0.017230150600274403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013358624710235745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027329593896865845,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2040388584136963,
      "backward_entropy": 0.020307989170153935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015722736134193838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732991799712181,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20400762557983398,
      "backward_entropy": 0.02030222366253535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015939418517518789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027330253273248672,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.203977569937706,
      "backward_entropy": 0.017285334567228954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013043888611719012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027330558747053146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20394787192344666,
      "backward_entropy": 0.02029103289047877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012429487833287567,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027330853044986725,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20391900837421417,
      "backward_entropy": 0.020285832385222118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013012216368224472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027331143617630005,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20389112830162048,
      "backward_entropy": 0.02028074488043785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011760521738324314,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027331411838531494,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2038636952638626,
      "backward_entropy": 0.0172748863697052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010311433288734406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027331652119755745,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20383669435977936,
      "backward_entropy": 0.020271524786949158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011029095912817866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733187936246395,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20381054282188416,
      "backward_entropy": 0.020267359912395477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.634847810957581e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733209729194641,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20378492772579193,
      "backward_entropy": 0.02026333411534627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.671426621731371e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027332311496138573,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20376014709472656,
      "backward_entropy": 0.02025940641760826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.312576392199844e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733251452445984,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2037360668182373,
      "backward_entropy": 0.0172651248673598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.7876440375112e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733272686600685,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20371297001838684,
      "backward_entropy": 0.020251767088969547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32890291349031e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027332935482263565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20369042456150055,
      "backward_entropy": 0.020247966051101685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.226684101624414e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027333145961165428,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2036684900522232,
      "backward_entropy": 0.017259374260902405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.376277790172026e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027333354577422142,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20364730060100555,
      "backward_entropy": 0.017257464428742725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.123648199718446e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733355388045311,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2036265730857849,
      "backward_entropy": 0.02023683364192645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.317060615401715e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027333732694387436,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20360630750656128,
      "backward_entropy": 0.020233566562334698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.200205098139122e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027333911508321762,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2035866528749466,
      "backward_entropy": 0.020230259746313095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3823245252715424e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733408659696579,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2035675048828125,
      "backward_entropy": 0.02022702991962433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5119366152212024e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027334263548254967,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20354902744293213,
      "backward_entropy": 0.01724907010793686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.403355316957459e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027334438636898994,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20353099703788757,
      "backward_entropy": 0.02022068326671918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.552283644443378e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027334611862897873,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20351344347000122,
      "backward_entropy": 0.020217580099900562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2474646761547774e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733476459980011,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20349621772766113,
      "backward_entropy": 0.020214736461639404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.151197936153039e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733491361141205,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20347949862480164,
      "backward_entropy": 0.020211974779764812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.043339504278265e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027335066348314285,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2034633755683899,
      "backward_entropy": 0.017241530120372772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.473630542634055e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733522839844227,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2034478336572647,
      "backward_entropy": 0.017200735708077747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1049770516110584e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027335386723279953,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20343253016471863,
      "backward_entropy": 0.0172384778658549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7519210561877117e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733553573489189,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20341737568378448,
      "backward_entropy": 0.020200906942288082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7982092433376238e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027335675433278084,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2034028172492981,
      "backward_entropy": 0.02019835263490677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0702456569997594e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027335815131664276,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2033887803554535,
      "backward_entropy": 0.017234412332375843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.315867277502548e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027335945516824722,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20337504148483276,
      "backward_entropy": 0.020193564395109814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3832801161915995e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336064726114273,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20336174964904785,
      "backward_entropy": 0.020191341638565063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4528160793124698e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027336178347468376,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20334887504577637,
      "backward_entropy": 0.017196372151374817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.938372224685736e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336297556757927,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2033364623785019,
      "backward_entropy": 0.020187151928742725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3290038370760158e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733640745282173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20332446694374084,
      "backward_entropy": 0.02018518994251887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8995848222402856e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336515486240387,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20331278443336487,
      "backward_entropy": 0.02018323540687561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9001372493221425e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336614206433296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20330141484737396,
      "backward_entropy": 0.020181401322285335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.68391579791205e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027336712926626205,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2032904028892517,
      "backward_entropy": 0.017225943505764008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.731501834001392e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336811646819115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2032797783613205,
      "backward_entropy": 0.020177844911813736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5205446288746316e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336910367012024,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20326948165893555,
      "backward_entropy": 0.020176043113072712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6287976905005053e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027336999773979187,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2032594531774521,
      "backward_entropy": 0.020174371699492138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2655877981160302e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027337094768881798,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2032497227191925,
      "backward_entropy": 0.020172680417696636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2416286153893452e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027337176725268364,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20324024558067322,
      "backward_entropy": 0.02017117788394292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2170930858701468e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733725495636463,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2032310664653778,
      "backward_entropy": 0.020169708877801895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.295778201892972e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273373294621706,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2032221555709839,
      "backward_entropy": 0.020168347905079525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0799690244311932e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733740024268627,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2032134234905243,
      "backward_entropy": 0.017191699395577114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.725972631713375e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027337469160556793,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2032049596309662,
      "backward_entropy": 0.020165670663118362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0518636372580659e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027337539941072464,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20319682359695435,
      "backward_entropy": 0.01721777270237605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.36584092414705e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733760140836239,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20318882167339325,
      "backward_entropy": 0.017217164238293965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.594479484396288e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027337661013007164,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20318105816841125,
      "backward_entropy": 0.02016201118628184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.453080797859002e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733772061765194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20317363739013672,
      "backward_entropy": 0.020160876214504242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.81654853199143e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027337780222296715,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20316646993160248,
      "backward_entropy": 0.020159727583328884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7182945713284425e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027337845414876938,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20315957069396973,
      "backward_entropy": 0.0172146533926328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.941691935935523e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733790874481201,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20315295457839966,
      "backward_entropy": 0.020157412936290104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.417685654014349e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027337968349456787,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20314647257328033,
      "backward_entropy": 0.017189984520276386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.486005531769479e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338024228811264,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20314016938209534,
      "backward_entropy": 0.02015526716907819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.185666850593407e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338078245520592,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20313401520252228,
      "backward_entropy": 0.020154237747192383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.691141384682851e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733812853693962,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20312806963920593,
      "backward_entropy": 0.01718951513369878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.772180091094924e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0273381806910038,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20312243700027466,
      "backward_entropy": 0.01718933880329132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.760996489494573e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338234707713127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2031169831752777,
      "backward_entropy": 0.02015133450428645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6108722270000726e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338288724422455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2031116932630539,
      "backward_entropy": 0.020150405665238697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5184257285436615e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027338340878486633,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20310664176940918,
      "backward_entropy": 0.017188648382822674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.712626494234428e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027338393032550812,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20310184359550476,
      "backward_entropy": 0.017208896577358246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.073776269957307e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733844332396984,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2030971646308899,
      "backward_entropy": 0.0201477309068044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.871381522912998e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733849175274372,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2030927538871765,
      "backward_entropy": 0.017187957962354023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.542019840097055e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338538318872452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20308832824230194,
      "backward_entropy": 0.02014606197675069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9438979254337028e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027338583022356033,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20308399200439453,
      "backward_entropy": 0.01718759536743164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7106366360385437e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338625863194466,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20307984948158264,
      "backward_entropy": 0.020144483695427578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.170972604493727e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338668704032898,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2030758261680603,
      "backward_entropy": 0.020143752296765644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4768819457676727e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733871340751648,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20307186245918274,
      "backward_entropy": 0.017205461859703064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3354125460173236e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338756248354912,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2030680775642395,
      "backward_entropy": 0.02014227956533432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4961927920230664e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338797226548195,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20306438207626343,
      "backward_entropy": 0.02014154444138209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0594745819835225e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733883634209633,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20306074619293213,
      "backward_entropy": 0.01720414807399114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6645077494104044e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027338875457644463,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20305722951889038,
      "backward_entropy": 0.01720368613799413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5734397038613679e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027338916435837746,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20305395126342773,
      "backward_entropy": 0.01720326766371727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8210236021332094e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733895555138588,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20305077731609344,
      "backward_entropy": 0.01720280076066653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.63235768013692e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027338992804288864,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20304766297340393,
      "backward_entropy": 0.0201382078230381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5550695025012828e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733903005719185,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20304469764232635,
      "backward_entropy": 0.020137610534826916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3372589364735177e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339067310094833,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20304183661937714,
      "backward_entropy": 0.01718536764383316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6853525721671758e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733910270035267,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2030390352010727,
      "backward_entropy": 0.020136389881372452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4979698335082503e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339134365320206,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20303627848625183,
      "backward_entropy": 0.017200864851474762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3467380313159083e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339164167642593,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20303356647491455,
      "backward_entropy": 0.020135312030712765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2653295016207267e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339192107319832,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20303091406822205,
      "backward_entropy": 0.020134801665941875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1161221209476935e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733922004699707,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20302830636501312,
      "backward_entropy": 0.017199871440728504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1910318562513567e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733924612402916,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20302581787109375,
      "backward_entropy": 0.020133846749862034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1507006547617493e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733926847577095,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20302331447601318,
      "backward_entropy": 0.020133446902036667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.106335028263857e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733929082751274,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20302093029022217,
      "backward_entropy": 0.020133058230082195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.556933496744023e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339313179254532,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20301854610443115,
      "backward_entropy": 0.017198849469423294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.766139103499881e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339333668351173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20301631093025208,
      "backward_entropy": 0.02013224984208743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.790073593445413e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339354157447815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20301413536071777,
      "backward_entropy": 0.020131888488928478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.482639148292947e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339372783899307,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20301198959350586,
      "backward_entropy": 0.017198132971922558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.422914904964273e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0273393914103508,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20300991833209991,
      "backward_entropy": 0.017197924355665844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.608900093851844e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339408174157143,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20300792157649994,
      "backward_entropy": 0.02013091618816058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.289911998967e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339424937963486,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20300596952438354,
      "backward_entropy": 0.020130594571431477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.784176326211309e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733944170176983,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2030041217803955,
      "backward_entropy": 0.020130285372336704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.460112220134761e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339456602931023,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20300239324569702,
      "backward_entropy": 0.02013002832730611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1727042798811453e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339471504092216,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2030007541179657,
      "backward_entropy": 0.020129765073458355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.392869866227556e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733948640525341,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20299915969371796,
      "backward_entropy": 0.01719674716393153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2189640225842595e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339499443769455,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.202997624874115,
      "backward_entropy": 0.017196618020534515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.578755354283203e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273395124822855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029961347579956,
      "backward_entropy": 0.020129012564818066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.531895629294013e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339525520801544,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20299473404884338,
      "backward_entropy": 0.020128765453894932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8546539826711523e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733953855931759,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20299339294433594,
      "backward_entropy": 0.020128538211186726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0874002138480137e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339549735188484,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20299211144447327,
      "backward_entropy": 0.017184169342120487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4399538978723285e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733956091105938,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2029908150434494,
      "backward_entropy": 0.017184169342120487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.477846348687308e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339570224285126,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20298954844474792,
      "backward_entropy": 0.020127948373556137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.810376654200809e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339579537510872,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20298826694488525,
      "backward_entropy": 0.02012776955962181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5276614223912475e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339588850736618,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20298701524734497,
      "backward_entropy": 0.020127589503924053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.947274708731129e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339598163962364,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20298582315444946,
      "backward_entropy": 0.01719534272948901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.797930847009411e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733960747718811,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20298466086387634,
      "backward_entropy": 0.020127243051926296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.862789187929593e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339614927768707,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029835283756256,
      "backward_entropy": 0.020127092798550923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.359218112564122e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339622378349304,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20298247039318085,
      "backward_entropy": 0.020126933852831524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2227490009972826e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339627966284752,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2029813528060913,
      "backward_entropy": 0.017184298485517502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9298468007254996e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273396335542202,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20298022031784058,
      "backward_entropy": 0.020126658181349438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0027542291245481e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339637279510498,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297911763191223,
      "backward_entropy": 0.020126573741436005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.54809839614245e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339641004800797,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297804474830627,
      "backward_entropy": 0.020126452048619587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3066377846371324e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339646592736244,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297706127166748,
      "backward_entropy": 0.020126353949308395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5700300082244212e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339652180671692,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20297612249851227,
      "backward_entropy": 0.017194518198569615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2748137123708148e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733965776860714,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297521352767944,
      "backward_entropy": 0.020126119256019592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3517535535356728e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339663356542587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.202974334359169,
      "backward_entropy": 0.02012600749731064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.036109663094976e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339668944478035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297352969646454,
      "backward_entropy": 0.02012590318918228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.295249714734382e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339674532413483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297271013259888,
      "backward_entropy": 0.020125774045785267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2894237499949668e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733967825770378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029719054698944,
      "backward_entropy": 0.02012571195761363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.271994834605721e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733968198299408,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297108590602875,
      "backward_entropy": 0.020125612616539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1457586879259907e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339685708284378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20297037065029144,
      "backward_entropy": 0.020125533143679302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.856849203515594e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339689433574677,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20296967029571533,
      "backward_entropy": 0.01719392587741216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0402983718904579e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339693158864975,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2029689997434616,
      "backward_entropy": 0.017184897015492123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839798937287924e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339696884155273,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296838879585266,
      "backward_entropy": 0.02012525623043378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1213933248654939e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339700609445572,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296776294708252,
      "backward_entropy": 0.020125187933444977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.108706512326535e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733970433473587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296719670295715,
      "backward_entropy": 0.02012508362531662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.235161968490502e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733970806002617,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296664535999298,
      "backward_entropy": 0.020125016570091248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.795743866585326e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339711785316467,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029660940170288,
      "backward_entropy": 0.020124924679597218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.341898194430541e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339715510606766,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20296555757522583,
      "backward_entropy": 0.017184998840093613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.360330466279265e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339719235897064,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296503603458405,
      "backward_entropy": 0.020124807953834534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.125674190116115e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339722961187363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296452939510345,
      "backward_entropy": 0.020124728480974834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.680453796230722e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733972668647766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296403765678406,
      "backward_entropy": 0.020124672601620357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.039788047473849e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733973041176796,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296356081962585,
      "backward_entropy": 0.020124617964029312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879472801481825e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339734137058258,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20296308398246765,
      "backward_entropy": 0.017193154742320377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.080175296574453e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339735999703407,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20296260714530945,
      "backward_entropy": 0.02012448012828827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.721913254319588e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339737862348557,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20296216011047363,
      "backward_entropy": 0.017193042983611424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.449528200391796e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339739724993706,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20296171307563782,
      "backward_entropy": 0.017193004488945007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.134617791531127e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339741587638855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029612958431244,
      "backward_entropy": 0.020124332358439762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.832996663457379e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339743450284004,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20296084880828857,
      "backward_entropy": 0.017192910114924114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.708297751676582e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339745312929153,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20296043157577515,
      "backward_entropy": 0.017185335357983906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6390141505980864e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339747175574303,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029600292444229,
      "backward_entropy": 0.020124214390913647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7780037704114875e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339749038219452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295965671539307,
      "backward_entropy": 0.02012419079740842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0184630734074744e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339749038219452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295925438404083,
      "backward_entropy": 0.020124167203903198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.245627766546022e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273397509008646,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295891165733337,
      "backward_entropy": 0.02012413615981738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.446333269290335e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733975276350975,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295852422714233,
      "backward_entropy": 0.020124117533365887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.710498847591225e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273397546261549,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295819640159607,
      "backward_entropy": 0.02012408897280693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9446590943393858e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733975648880005,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029578983783722,
      "backward_entropy": 0.02012402315934499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9331085116268696e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339758351445198,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2029576301574707,
      "backward_entropy": 0.01719263195991516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.788382857943361e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339760214090347,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2029573768377304,
      "backward_entropy": 0.01719258849819501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5449617524486712e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339762076735497,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2029571235179901,
      "backward_entropy": 0.01719251771767934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9634287912472246e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339763939380646,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.202956885099411,
      "backward_entropy": 0.020123908917109173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3704323837137053e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339765802025795,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2029566615819931,
      "backward_entropy": 0.017192448178927105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7326783563476056e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339767664670944,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029564380645752,
      "backward_entropy": 0.020123821993668873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1513251624583063e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339769527316093,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029561996459961,
      "backward_entropy": 0.02012379840016365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5631265998526942e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339771389961243,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295599102973938,
      "backward_entropy": 0.02012377232313156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3319643105423893e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339773252606392,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20295578241348267,
      "backward_entropy": 0.017192304134368896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6402111668867292e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733977511525154,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20295557379722595,
      "backward_entropy": 0.017192281782627106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6906597011256963e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733977697789669,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295538008213043,
      "backward_entropy": 0.02012367422382037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4579768503608648e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733977884054184,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029551863670349,
      "backward_entropy": 0.020123654355605442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4658326108474284e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733978070318699,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295500755310059,
      "backward_entropy": 0.020123636970917385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4639567780250218e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339782565832138,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295485854148865,
      "backward_entropy": 0.020123610893885296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4353638277952996e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339784428477287,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20295469462871552,
      "backward_entropy": 0.017192117869853973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2736066423713055e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339786291122437,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295454561710358,
      "backward_entropy": 0.020123574882745743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.476843181080767e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339788153767586,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295444130897522,
      "backward_entropy": 0.02012356494863828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4327120823054429e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339790016412735,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029542624950409,
      "backward_entropy": 0.020123509069283802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.821444907880505e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339791879057884,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20295411348342896,
      "backward_entropy": 0.01718590905268987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788599987179623e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339793741703033,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295396447181702,
      "backward_entropy": 0.020123478025197983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.86327802870801e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339795604348183,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295387506484985,
      "backward_entropy": 0.020123453189929325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.780858706813888e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339797466993332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295372605323792,
      "backward_entropy": 0.020123440772294998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.133806268986518e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733979932963848,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20295363664627075,
      "backward_entropy": 0.017185986042022705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.156916919688229e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733980119228363,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2029535472393036,
      "backward_entropy": 0.017185986042022705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.886363396712113e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02733980305492878,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20295342803001404,
      "backward_entropy": 0.01719186082482338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.436721378122456e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733980491757393,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295336842536926,
      "backward_entropy": 0.020123330255349476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.567336979263928e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339806780219078,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2029532790184021,
      "backward_entropy": 0.017191773901383083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2554511853486474e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339808642864227,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20295318961143494,
      "backward_entropy": 0.017191751549641292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.1633402260195e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339810505509377,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295311510562897,
      "backward_entropy": 0.02012328679362933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.195300107312505e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339812368154526,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2029530107975006,
      "backward_entropy": 0.017186012119054794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.454104723412456e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027339814230799675,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20295298099517822,
      "backward_entropy": 0.01718602329492569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1851251353364205e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339816093444824,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295289158821106,
      "backward_entropy": 0.020123237123092014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0764228376465326e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027339817956089973,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.20295283198356628,
      "backward_entropy": 0.01719166710972786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6476565646335075e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339819818735123,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295274257659912,
      "backward_entropy": 0.020123214771350224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4989221237301535e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027339821681380272,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295268297195435,
      "backward_entropy": 0.020123161375522614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6068925624022086e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02733982354402542,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.20295262336730957,
      "backward_entropy": 0.01718604440490405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5200997672291123e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733982540667057,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2029525488615036,
      "backward_entropy": 0.020123143990834553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4707312579485006e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02733982540667057,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.20295250415802002,
      "backward_entropy": 0.020123130331436794,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.5299142997804437e-07,
    "avg_log_Z": 0.027339691407978536,
    "success_rate": 1.0,
    "avg_reward": 51.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.12,
      "1": 0.22,
      "2": 0.66
    },
    "avg_forward_entropy": 0.2029693005979061,
    "avg_backward_entropy": 0.019127718657255172,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}