{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13841651678085326,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13841651678085326,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13841651678085326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13841651678085326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13841651678085326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13841651678085326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.13833229541778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.441964626312256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249879280726114,
      "backward_entropy": 0.1383970260620117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.439914703369141,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250874678293863,
      "backward_entropy": 0.13831332921981812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.029918193817139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019999986398033798,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825186014175415,
      "backward_entropy": 0.13829376697540283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.620089054107666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0002998992567881942,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182518740495046,
      "backward_entropy": 0.1382739543914795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9181132316589355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00039962929440662265,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825137734413147,
      "backward_entropy": 0.1383533477783203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.732944011688232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004993508919142187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250747521718344,
      "backward_entropy": 0.13833647966384888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.516706943511963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005993063095957041,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250632286071777,
      "backward_entropy": 0.13821192979812622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.214327335357666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006993397837504745,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250815073649088,
      "backward_entropy": 0.13818917274475098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.028870582580566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000799342873506248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825100580851237,
      "backward_entropy": 0.13827929496765137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.726024150848389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008995826938189566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182515819867452,
      "backward_entropy": 0.13825740814208984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.110991477966309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009999164612963796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18252305189768472,
      "backward_entropy": 0.13811650276184081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.207858085632324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001100405235774815,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18253233035405478,
      "backward_entropy": 0.13809077739715575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.799436092376709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012007359182462096,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254067500432333,
      "backward_entropy": 0.1380642533302307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9099297523498535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013007847592234612,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254661560058594,
      "backward_entropy": 0.13803696632385254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.313307762145996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014010043814778328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18255412578582764,
      "backward_entropy": 0.13800864219665526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.524551391601562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015015075914561749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256354331970215,
      "backward_entropy": 0.13811657428741456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603641510009766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016023418866097927,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257455031077066,
      "backward_entropy": 0.13794896602630616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.089189052581787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017030960880219936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18258539835611978,
      "backward_entropy": 0.13809916973114014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.706181526184082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018035649554803967,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18259487549463907,
      "backward_entropy": 0.13803555965423583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.188593864440918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019040640909224749,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18260449171066284,
      "backward_entropy": 0.13800787925720215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0772066116333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00200473889708519,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18261502186457315,
      "backward_entropy": 0.1378178119659424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.96533727645874,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002105504274368286,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18262596925099692,
      "backward_entropy": 0.1377825379371643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.342799663543701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022062871139496565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826369563738505,
      "backward_entropy": 0.13798246383666993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.477349758148193,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023067956790328026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18264673153559366,
      "backward_entropy": 0.13795809745788573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.582795143127441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024071941152215004,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182655930519104,
      "backward_entropy": 0.13793306350708007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.070626258850098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025075559969991446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826647917429606,
      "backward_entropy": 0.1378248691558838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.051261901855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026076475623995066,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18267246087392172,
      "backward_entropy": 0.13759241104125977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.046774864196777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027079058345407248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18268056710561117,
      "backward_entropy": 0.13775761127471925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.352746486663818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0028083063662052155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18268891175587973,
      "backward_entropy": 0.13782601356506347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366707801818848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029085357673466206,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18269594510396323,
      "backward_entropy": 0.13746747970581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.167240142822266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003009097184985876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18270393212636313,
      "backward_entropy": 0.13764967918395996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.766623497009277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031094064470380545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18271092573801676,
      "backward_entropy": 0.13773784637451172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.78066349029541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032093075569719076,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18271634976069132,
      "backward_entropy": 0.13770689964294433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.556939125061035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033093541860580444,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18272223075230917,
      "backward_entropy": 0.13767499923706056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.267617702484131,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034093940630555153,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827280322710673,
      "backward_entropy": 0.1372368574142456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05832290649414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003509307047352195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18273339668909708,
      "backward_entropy": 0.13760850429534913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.326084136962891,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036094821989536285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827395757039388,
      "backward_entropy": 0.13757344484329223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.037806987762451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037094925064593554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274515867233276,
      "backward_entropy": 0.1375373125076294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.763645648956299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003809233894571662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274980783462524,
      "backward_entropy": 0.13750054836273193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.476531028747559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003909138962626457,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275497357050577,
      "backward_entropy": 0.13727207183837892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21346378326416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004009065218269825,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182760218779246,
      "backward_entropy": 0.13722474575042726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.037199974060059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004109305329620838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276635805765787,
      "backward_entropy": 0.13738393783569336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0735883712768555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00420976709574461,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277313311894736,
      "backward_entropy": 0.1373429536819458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.918295383453369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004309980198740959,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277915318806967,
      "backward_entropy": 0.13674622774124146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.238922119140625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004410345107316971,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827855904897054,
      "backward_entropy": 0.13668522834777833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.286569118499756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004510520491749048,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279147148132324,
      "backward_entropy": 0.13721413612365724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.409743309020996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004610618110746145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827970544497172,
      "backward_entropy": 0.13691290616989135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8421101570129395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004711146000772715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280371030171713,
      "backward_entropy": 0.1371232271194458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289880752563477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004811800085008144,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281062444051108,
      "backward_entropy": 0.1370760679244995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33464241027832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004912742413580418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18281815449396768,
      "backward_entropy": 0.13673958778381348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.608692169189453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005014025140553713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18282620112101236,
      "backward_entropy": 0.1366784930229187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.104565143585205,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005115188658237457,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18283385038375854,
      "backward_entropy": 0.1362241744995117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.991499900817871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00521596847102046,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18284048636754355,
      "backward_entropy": 0.13615323305130006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.76674222946167,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0053163315169513226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18284610907236734,
      "backward_entropy": 0.1368239164352417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0899019241333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00541672995314002,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285197019577026,
      "backward_entropy": 0.13600566387176513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.595894813537598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005517376586794853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285828828811646,
      "backward_entropy": 0.13592944145202637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.637578964233398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005618405994027853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286548058191934,
      "backward_entropy": 0.1362739086151123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.028536319732666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0057198600843548775,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828734278678894,
      "backward_entropy": 0.13576886653900147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45610237121582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005820326041430235,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287899096806845,
      "backward_entropy": 0.13654692173004152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.895020484924316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00592122133821249,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18288532892862955,
      "backward_entropy": 0.13648862838745118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7323198318481445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006022233981639147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289172649383545,
      "backward_entropy": 0.13642891645431518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.003950119018555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0061231800355017185,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289794524510702,
      "backward_entropy": 0.1363680601119995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.047118186950684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00622419361025095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290388584136963,
      "backward_entropy": 0.13579418659210205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.13527774810791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006325356662273407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291000525156656,
      "backward_entropy": 0.13624253273010253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.310893058776855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0064272754825651646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18291701873143515,
      "backward_entropy": 0.136177134513855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.645911693572998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006529359146952629,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292431036631265,
      "backward_entropy": 0.1350609302520752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4245195388793945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006631247699260712,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293118476867676,
      "backward_entropy": 0.13543174266815186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.124165534973145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006732807494699955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829375425974528,
      "backward_entropy": 0.13486692905426026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606343269348145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00683450186625123,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18294397989908853,
      "backward_entropy": 0.1347671627998352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.086147308349609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006936590187251568,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18295073509216309,
      "backward_entropy": 0.13513795137405396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.568130970001221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0070380838587880135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18295671542485556,
      "backward_entropy": 0.13503470420837402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.957709789276123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007139327935874462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18296241760253906,
      "backward_entropy": 0.13492906093597412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.117748737335205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0072400979697704315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296714623769125,
      "backward_entropy": 0.13557865619659423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4322123527526855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007340500131249428,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829712986946106,
      "backward_entropy": 0.1354957938194275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8040666580200195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007440799381583929,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182975172996521,
      "backward_entropy": 0.13541088104248047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.988913536071777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007541212253272533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297922611236572,
      "backward_entropy": 0.13449307680130004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.33168888092041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007642326410859823,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298429250717163,
      "backward_entropy": 0.13385753631591796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.028842449188232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0077437181025743484,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298963705698648,
      "backward_entropy": 0.13373191356658937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.103838920593262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00784466601908207,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299412727355957,
      "backward_entropy": 0.1336047649383545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787713050842285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007945749908685684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299879630406699,
      "backward_entropy": 0.13401761054992675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.502352237701416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008047382347285748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300398190816244,
      "backward_entropy": 0.13389129638671876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.229968070983887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008148702792823315,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300890922546387,
      "backward_entropy": 0.13320412635803222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.653770446777344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008250268176198006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301377693812051,
      "backward_entropy": 0.13465532064437866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91214656829834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00835223589092493,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301896254221597,
      "backward_entropy": 0.13292430639266967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.948405742645264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008454686030745506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302454551060995,
      "backward_entropy": 0.13335421085357665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.577943801879883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008556991815567017,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302996953328451,
      "backward_entropy": 0.13262947797775268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.982588768005371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008659504354000092,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18303563197453818,
      "backward_entropy": 0.13247554302215575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.34028148651123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008762490004301071,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830414334932963,
      "backward_entropy": 0.13291168212890625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.281371116638184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008866092190146446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304741382598877,
      "backward_entropy": 0.13399466276168823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.2671480178833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008970140479505062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830535332361857,
      "backward_entropy": 0.13259553909301758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.462215423583984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009074032306671143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830593148867289,
      "backward_entropy": 0.13243309259414673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.609553337097168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009177924133837223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306473890940347,
      "backward_entropy": 0.13226742744445802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.224167823791504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009281863458454609,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306994438171387,
      "backward_entropy": 0.1314793825149536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.400240898132324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009385739453136921,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307449420293173,
      "backward_entropy": 0.13337795734405516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.647314548492432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009488401003181934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830781102180481,
      "backward_entropy": 0.13324910402297974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.245210647583008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009590217843651772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308083216349283,
      "backward_entropy": 0.1315830111503601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.028520584106445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009692162275314331,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830834150314331,
      "backward_entropy": 0.130739426612854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.045884132385254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009794062934815884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308581908543906,
      "backward_entropy": 0.1312249183654785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.027909278869629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009896551258862019,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308820327123007,
      "backward_entropy": 0.1327167272567749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.250696182250977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009998372755944729,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309007088343301,
      "backward_entropy": 0.13015437126159668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.596327781677246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010100270621478558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309189875920615,
      "backward_entropy": 0.13243439197540283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.021507263183594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010202433913946152,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309366703033447,
      "backward_entropy": 0.13228752613067626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.243246555328369,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010304468683898449,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309533596038818,
      "backward_entropy": 0.13024073839187622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.587966442108154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01040598563849926,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309672673543295,
      "backward_entropy": 0.1293126106262207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.322419166564941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010507240891456604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830978790918986,
      "backward_entropy": 0.13183774948120117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.930384635925293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010608122684061527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309875329335532,
      "backward_entropy": 0.12959868907928468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.299233913421631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010709637776017189,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309946854909262,
      "backward_entropy": 0.12937574386596679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.035851955413818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010810735635459423,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830999255180359,
      "backward_entropy": 0.12840927839279176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.174323081970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010911321267485619,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18310010433197021,
      "backward_entropy": 0.1281758427619934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.113419532775879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011011498048901558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18310014406840006,
      "backward_entropy": 0.1310369610786438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.399738311767578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011111322790384293,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309996525446573,
      "backward_entropy": 0.12845921516418457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.384400367736816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011210937052965164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309974670410156,
      "backward_entropy": 0.13069589138031007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.527127742767334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011311515234410763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309948841730753,
      "backward_entropy": 0.13051865100860596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.3037691116333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011411314830183983,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309911092122397,
      "backward_entropy": 0.12694398164749146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.193339347839355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011511425487697124,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309865395228067,
      "backward_entropy": 0.1301567554473877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.531205654144287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011611845344305038,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309789896011353,
      "backward_entropy": 0.12641806602478028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.500101089477539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011712100356817245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18309696515401205,
      "backward_entropy": 0.1269455909729004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.256276607513428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011812718585133553,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18309593200683594,
      "backward_entropy": 0.12587449550628663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.920567989349365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011913001537322998,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830947001775106,
      "backward_entropy": 0.12938569784164428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1275739669799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01201326958835125,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830934683481852,
      "backward_entropy": 0.12530887126922607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8700642585754395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012113145552575588,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309207757314047,
      "backward_entropy": 0.1289806842803955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.823561668395996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012212532572448254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18309064706166586,
      "backward_entropy": 0.12877368927001953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.082379341125488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012311993166804314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308905760447183,
      "backward_entropy": 0.1285627841949463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.547584533691406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012411121279001236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308738867441812,
      "backward_entropy": 0.12834850549697877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5718464851379395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012510201893746853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18308560053507486,
      "backward_entropy": 0.12380115985870362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.373076438903809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012608712539076805,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830838918685913,
      "backward_entropy": 0.12348678112030029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.681387424468994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012707170099020004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18308204412460327,
      "backward_entropy": 0.12403234243392944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.200187683105469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012805158272385597,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18308031558990479,
      "backward_entropy": 0.1274559736251831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.479663372039795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012903079390525818,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830784479777018,
      "backward_entropy": 0.1234055757522583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.072348594665527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013001161627471447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.183076282342275,
      "backward_entropy": 0.12308685779571533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.088339805603027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013099687173962593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18307367960611978,
      "backward_entropy": 0.12674257755279542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.22749662399292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013197955675423145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18307109673817953,
      "backward_entropy": 0.12242785692214966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.386312961578369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013296163640916348,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18306831518809,
      "backward_entropy": 0.12116999626159668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.189876556396484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013393715023994446,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830658713976542,
      "backward_entropy": 0.12175241708755494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1120686531066895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013491260819137096,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830631891886393,
      "backward_entropy": 0.12573431730270385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.570277214050293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013588689267635345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18306048711140951,
      "backward_entropy": 0.12105841636657715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634565830230713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013687001541256905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305685122807822,
      "backward_entropy": 0.12517974376678467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.244414329528809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013785426504909992,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18305301666259766,
      "backward_entropy": 0.12489211559295654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.415576457977295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013883758336305618,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18304898341496786,
      "backward_entropy": 0.11894042491912842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.873528480529785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013982148841023445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304455280303955,
      "backward_entropy": 0.12430015802383423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.00807523727417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014080218970775604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18304014205932617,
      "backward_entropy": 0.12400004863739014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955586433410645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014177422970533371,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18303634723027548,
      "backward_entropy": 0.11879475116729736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.266571521759033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01427566260099411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830316185951233,
      "backward_entropy": 0.11839046478271484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.022191047668457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01437381561845541,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302671114603677,
      "backward_entropy": 0.11689671277999877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4449849128723145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014472338370978832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830212672551473,
      "backward_entropy": 0.12275893688201904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.871481418609619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014570844359695911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301554520924887,
      "backward_entropy": 0.12243363857269288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.032161712646484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01466898713260889,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300986289978027,
      "backward_entropy": 0.11668549776077271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.683719635009766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014767530374228954,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830033858617147,
      "backward_entropy": 0.12176822423934937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4457244873046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014866211451590061,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18299639225006104,
      "backward_entropy": 0.11465051174163818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.112689018249512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014964289031922817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298959732055664,
      "backward_entropy": 0.11532379388809204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.280433177947998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015063456259667873,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298121293385824,
      "backward_entropy": 0.11370993852615356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.404800891876221,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015162440948188305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18297247091929117,
      "backward_entropy": 0.11437035799026489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.035135269165039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015260713174939156,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18296416600545248,
      "backward_entropy": 0.11275738477706909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.746627807617188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015359422191977501,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829546888669332,
      "backward_entropy": 0.11339695453643799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.255298137664795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015458952635526657,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18294352293014526,
      "backward_entropy": 0.11177986860275269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.104022026062012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015558267943561077,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293195962905884,
      "backward_entropy": 0.11128123998641967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.686488151550293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015657326206564903,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292001883188883,
      "backward_entropy": 0.11847985982894897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.558934211730957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01575653813779354,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829071044921875,
      "backward_entropy": 0.11808375120162964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.98850679397583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01585579104721546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289337555567423,
      "backward_entropy": 0.11081075668334961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.260809421539307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015954770147800446,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18287940820058188,
      "backward_entropy": 0.10924398899078369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.855166912078857,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016053007915616035,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18286617596944174,
      "backward_entropy": 0.11686209440231324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.937092304229736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016150929033756256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828527251879374,
      "backward_entropy": 0.10921264886856079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.883401393890381,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016248589381575584,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18283885717391968,
      "backward_entropy": 0.11602150201797486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.942498683929443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016346033662557602,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828247308731079,
      "backward_entropy": 0.11559300422668457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.208545207977295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016443341970443726,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18281016747156778,
      "backward_entropy": 0.10756880044937134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5817952156066895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01654006727039814,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827963391939799,
      "backward_entropy": 0.11472100019454956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.458038806915283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016636492684483528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278268973032633,
      "backward_entropy": 0.11427701711654663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.915663719177246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016732551157474518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276919921239218,
      "backward_entropy": 0.10590126514434814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.121410369873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01682857796549797,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275501330693564,
      "backward_entropy": 0.1044120192527771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4771318435668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01692400500178337,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274152278900146,
      "backward_entropy": 0.10384719371795655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.46541690826416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017018547281622887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18272980054219565,
      "backward_entropy": 0.10419539213180543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.398467540740967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017112240195274353,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827197472254435,
      "backward_entropy": 0.10271308422088624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.447611331939697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01720578968524933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827093561490377,
      "backward_entropy": 0.10306518077850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.222739219665527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017299829050898552,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18269675970077515,
      "backward_entropy": 0.10247725248336792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.80122709274292,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017393603920936584,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18268418312072754,
      "backward_entropy": 0.10094996690750122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.591733455657959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017486881464719772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18267232179641724,
      "backward_entropy": 0.10035346746444702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.483790874481201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01757953315973282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266157309214273,
      "backward_entropy": 0.10958000421524047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.144354820251465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017672276124358177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18264989058176676,
      "backward_entropy": 0.10010112524032592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.269142150878906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017764165997505188,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18264007568359375,
      "backward_entropy": 0.09854589700698853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.992779731750488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017856694757938385,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18262751897176108,
      "backward_entropy": 0.09793384075164795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.812163352966309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017948266118764877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826171080271403,
      "backward_entropy": 0.09828195571899415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.645654201507568,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01803947426378727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826069951057434,
      "backward_entropy": 0.10701093673706055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.909058570861816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01813036948442459,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18259716033935547,
      "backward_entropy": 0.0970479667186737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4113054275512695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01822108030319214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825870672861735,
      "backward_entropy": 0.10593173503875733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.73217248916626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0183119960129261,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257546424865723,
      "backward_entropy": 0.10537992715835572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.705889701843262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01840263605117798,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256388107935587,
      "backward_entropy": 0.10482178926467896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.65335750579834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018492961302399635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18255239725112915,
      "backward_entropy": 0.09449375867843628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.035269260406494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018583018332719803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825408935546875,
      "backward_entropy": 0.0938409686088562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.656566619873047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018673833459615707,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18252597252527872,
      "backward_entropy": 0.09219729900360107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5205864906311035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018764356151223183,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825109918912252,
      "backward_entropy": 0.09153200387954712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.228847026824951,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018854552879929543,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249615033467612,
      "backward_entropy": 0.09182223081588745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.493668556213379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018944187089800835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18248224258422852,
      "backward_entropy": 0.09113874435424804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.002481937408447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01903422921895981,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18246575196584067,
      "backward_entropy": 0.10072671175003052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.443594455718994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019124338403344154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18244789044062296,
      "backward_entropy": 0.08973302841186523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.088123798370361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0192140843719244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18243014812469482,
      "backward_entropy": 0.08902454376220703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.696339130401611,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0193039383739233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824106971422831,
      "backward_entropy": 0.09887079000473023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.153280735015869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019393624737858772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239047129948935,
      "backward_entropy": 0.08757870197296143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.350993633270264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01948269084095955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18237111965815225,
      "backward_entropy": 0.0860374927520752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.218451023101807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01957141049206257,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823517084121704,
      "backward_entropy": 0.08612042665481567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.909244537353516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019659752026200294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233241637547812,
      "backward_entropy": 0.09633252620697022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.209140300750732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01974830962717533,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823108990987142,
      "backward_entropy": 0.08464660048484803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4029951095581055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01983647421002388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18228942155838013,
      "backward_entropy": 0.09502961635589599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4320173263549805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01992444507777691,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822671890258789,
      "backward_entropy": 0.09437131881713867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.506528377532959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02001229114830494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18224388360977173,
      "backward_entropy": 0.0817264437675476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.409385681152344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02009929157793522,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18222272396087646,
      "backward_entropy": 0.08100207448005677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.356208801269531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0201861709356308,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18220005432764688,
      "backward_entropy": 0.08089902400970458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.22376012802124,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020272959023714066,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18217571576436362,
      "backward_entropy": 0.0795348584651947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.632984638214111,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02035949006676674,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18214793999989828,
      "backward_entropy": 0.07879281044006348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8105268478393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02044619433581829,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18211708466211954,
      "backward_entropy": 0.07804627418518066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.74212121963501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02053235098719597,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1820863684018453,
      "backward_entropy": 0.0778380036354065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.716893196105957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020618829876184464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820516586303711,
      "backward_entropy": 0.08896839618682861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.180076599121094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02070482075214386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18201742569605509,
      "backward_entropy": 0.088273024559021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.487316608428955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020790744572877884,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18198142449061075,
      "backward_entropy": 0.07549903392791749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9986796379089355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020876863971352577,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18194238344828287,
      "backward_entropy": 0.07422919273376465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.082375526428223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020962797105312347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18190220991770426,
      "backward_entropy": 0.07392613291740417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.469131946563721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02104862779378891,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818601687749227,
      "backward_entropy": 0.08542944192886352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.330088138580322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021133903414011,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818196177482605,
      "backward_entropy": 0.07236119508743286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.102769374847412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02121848799288273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18178061644236246,
      "backward_entropy": 0.08398574590682983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.091523170471191,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021303102374076843,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1817380984624227,
      "backward_entropy": 0.0832595944404602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.205975294113159,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021386904641985893,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1816981633504232,
      "backward_entropy": 0.06967142224311829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.382319450378418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021469108760356903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18166540066401163,
      "backward_entropy": 0.06929279565811157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.19821834564209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021550970152020454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1816317637761434,
      "backward_entropy": 0.06854188442230225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.073243141174316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021632377058267593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.181598166624705,
      "backward_entropy": 0.06779313087463379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.091259956359863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021713245660066605,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18156492710113525,
      "backward_entropy": 0.06668466925621033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.444422721862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021793672814965248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18153162797292074,
      "backward_entropy": 0.06629650592803955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.526573896408081,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02187410369515419,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181496262550354,
      "backward_entropy": 0.07822166681289673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.227059841156006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021953584626317024,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18146395683288574,
      "backward_entropy": 0.06446486115455627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6509931087493896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0220328439027071,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18142877022425333,
      "backward_entropy": 0.06405332088470458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6340994834899902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02211151272058487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813961068789164,
      "backward_entropy": 0.07605974078178405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7003281116485596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022189544513821602,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1813646157582601,
      "backward_entropy": 0.062267571687698364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6817378997802734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0222670566290617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18133312463760376,
      "backward_entropy": 0.061839962005615236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8251841068267822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022344203665852547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18130246798197427,
      "backward_entropy": 0.06111125946044922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.820761203765869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02242102473974228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18126960595448813,
      "backward_entropy": 0.06037965416908264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.44049072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022496556863188744,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18124238650004068,
      "backward_entropy": 0.05939139127731323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.605886936187744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022571615874767303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18121546506881714,
      "backward_entropy": 0.0589506983757019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7779431343078613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022647429257631302,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18117908636728922,
      "backward_entropy": 0.05797020196914673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4209556579589844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022721927613019943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18114707867304483,
      "backward_entropy": 0.07034448385238648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.021821022033691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022795939818024635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1811136802037557,
      "backward_entropy": 0.05678756237030029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7914085388183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022870274260640144,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18107465902964273,
      "backward_entropy": 0.055846935510635375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.15107798576355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022944660857319832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810317039489746,
      "backward_entropy": 0.06822399497032165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4039900302886963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02301831543445587,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18098890781402588,
      "backward_entropy": 0.0544416606426239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2665538787841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023091701790690422,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18094476064046225,
      "backward_entropy": 0.05374649167060852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.150148391723633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023164622485637665,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18089914321899414,
      "backward_entropy": 0.05305466651916504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7038838863372803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02323697879910469,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18085233370463052,
      "backward_entropy": 0.0654129445552826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5861847400665283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02330942079424858,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18079853057861328,
      "backward_entropy": 0.05176239013671875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0175929069519043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02338196150958538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1807402769724528,
      "backward_entropy": 0.051045334339141844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9841136932373047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023453805595636368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18068063259124756,
      "backward_entropy": 0.05033385753631592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6231963634490967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02352505549788475,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18062023321787515,
      "backward_entropy": 0.04963218569755554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5487163066864014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02359544113278389,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18056370814641318,
      "backward_entropy": 0.04894090890884399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1632018089294434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02366490289568901,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18051008383433023,
      "backward_entropy": 0.048313194513320924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2455978393554688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023734288290143013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18045206864674887,
      "backward_entropy": 0.04758983552455902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.569004535675049,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023803727701306343,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18038843075434366,
      "backward_entropy": 0.04701378345489502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8479554653167725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02387244626879692,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18032757441202799,
      "backward_entropy": 0.04624919295310974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.358161687850952,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023940805345773697,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1802640755971273,
      "backward_entropy": 0.045743918418884276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.068155288696289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024008141830563545,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1802018086115519,
      "backward_entropy": 0.04494076073169708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.918976068496704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02407412976026535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1801425814628601,
      "backward_entropy": 0.04430570304393768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.475419521331787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024140218272805214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18007858594258627,
      "backward_entropy": 0.0436707854270935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.581024408340454,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024205803871154785,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18001470963160196,
      "backward_entropy": 0.04328690767288208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7375893592834473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02427116222679615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17995081345240274,
      "backward_entropy": 0.04242484569549561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.312896966934204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024336380884051323,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17988044023513794,
      "backward_entropy": 0.042098456621170045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.582275152206421,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024400878697633743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17980833848317465,
      "backward_entropy": 0.05403434634208679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5446343421936035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024465223774313927,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17973238229751587,
      "backward_entropy": 0.04058048725128174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.141505718231201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0245293527841568,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17965169747670492,
      "backward_entropy": 0.040354305505752565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1887285709381104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024592697620391846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17957115173339844,
      "backward_entropy": 0.03937452137470245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0120136737823486,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02465546503663063,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17949038743972778,
      "backward_entropy": 0.051508200168609616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.654046893119812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02471749857068062,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1794124444325765,
      "backward_entropy": 0.038208228349685666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8421590328216553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024778269231319427,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17934062083562216,
      "backward_entropy": 0.03814031183719635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.263221502304077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024838166311383247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1792695919672648,
      "backward_entropy": 0.03709927499294281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.005248785018921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024897998198866844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791923443476359,
      "backward_entropy": 0.03655065596103668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7559713125228882,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024957366287708282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17911279201507568,
      "backward_entropy": 0.048509296774864194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1743383407592773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02501591108739376,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17903423309326172,
      "backward_entropy": 0.035476043820381165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7557379007339478,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02507437765598297,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17894649505615234,
      "backward_entropy": 0.047350558638572696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6495294570922852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025132181122899055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1788603663444519,
      "backward_entropy": 0.03442083597183228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8837312459945679,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02518928237259388,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17877946297327676,
      "backward_entropy": 0.0339109480381012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9078656435012817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02524598129093647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17869208256403604,
      "backward_entropy": 0.03340331614017487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1162753105163574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025302477180957794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17859973510106406,
      "backward_entropy": 0.032898667454719546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0224432945251465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025359252467751503,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17849969863891602,
      "backward_entropy": 0.03239288926124573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4307018518447876,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025416111573576927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17839266856511435,
      "backward_entropy": 0.043977591395378116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2189905643463135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025471854954957962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17828698952992758,
      "backward_entropy": 0.03139547705650329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2155675888061523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02552623488008976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1781876484553019,
      "backward_entropy": 0.030920135974884033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4235342741012573,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025579456239938736,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17809613545735678,
      "backward_entropy": 0.031306919455528257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5738710165023804,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02563202567398548,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17800482114156088,
      "backward_entropy": 0.04186411499977112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2812994718551636,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02568436786532402,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17791038751602173,
      "backward_entropy": 0.030451342463493347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4250332117080688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025735782459378242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1778143048286438,
      "backward_entropy": 0.040851765871047975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9188638925552368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025786716490983963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1777134339014689,
      "backward_entropy": 0.02868437170982361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.275925636291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02583613246679306,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17762003342310587,
      "backward_entropy": 0.029224219918251037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1322561502456665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025884976610541344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1775231957435608,
      "backward_entropy": 0.027850401401519776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2003796100616455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02593306265771389,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1774284839630127,
      "backward_entropy": 0.027445575594902037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2329696416854858,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025980619713664055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17733234167099,
      "backward_entropy": 0.027046826481819154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1614110469818115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026027750223875046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17723214626312256,
      "backward_entropy": 0.038028812408447264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9731354713439941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026074418798089027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17713123559951782,
      "backward_entropy": 0.03758014440536499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.826921284198761,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026120241731405258,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17703459660212198,
      "backward_entropy": 0.037139487266540525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7772849798202515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026164887472987175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17694318294525146,
      "backward_entropy": 0.025520193576812743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.146670937538147,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02620822563767433,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17685216665267944,
      "backward_entropy": 0.036296382546424866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9742707014083862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02625144273042679,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17675240834554037,
      "backward_entropy": 0.02481318563222885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9159854650497437,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026294127106666565,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17664992809295654,
      "backward_entropy": 0.025630390644073485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8860641121864319,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336265727877617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17654804388682047,
      "backward_entropy": 0.035080206394195554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8076128959655762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026377948001027107,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1764515240987142,
      "backward_entropy": 0.024994610249996184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8095699548721313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026419058442115784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17636326948801676,
      "backward_entropy": 0.023466400802135468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9023924469947815,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026459498330950737,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1762742598851522,
      "backward_entropy": 0.033905941247940066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8991284370422363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02649972029030323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.176183819770813,
      "backward_entropy": 0.02283589541912079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7796187400817871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0265396349132061,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1760861078898112,
      "backward_entropy": 0.02380204349756241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5808798670768738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026578964665532112,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17598684628804526,
      "backward_entropy": 0.023516273498535155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6230549812316895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02661702409386635,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17588796218236288,
      "backward_entropy": 0.023240339756011964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6862815618515015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026654276996850967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1757944623629252,
      "backward_entropy": 0.03206537365913391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7021005749702454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026690933853387833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17569875717163086,
      "backward_entropy": 0.03172157108783722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7597638368606567,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02672729454934597,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17560585339864096,
      "backward_entropy": 0.03138007521629334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5445680618286133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02676336094737053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1755026380221049,
      "backward_entropy": 0.031043928861618043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.56061851978302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02679859660565853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1754048466682434,
      "backward_entropy": 0.02054358124732971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6858789324760437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026833325624465942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17531689008076987,
      "backward_entropy": 0.020286841690540312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6803160309791565,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02686784602701664,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17522215843200684,
      "backward_entropy": 0.021473783254623412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5724072456359863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02690216340124607,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17511959870656332,
      "backward_entropy": 0.02975003719329834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47310513257980347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02693602256476879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17501821120580038,
      "backward_entropy": 0.019526946544647216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.441541463136673,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02696903981268406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17492006222407022,
      "backward_entropy": 0.029130989313125612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36655208468437195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0270011518150568,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17482447624206543,
      "backward_entropy": 0.02883428931236267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4841156303882599,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027032122015953064,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1747336188952128,
      "backward_entropy": 0.020364409685134886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5099779367446899,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02706259675323963,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17464053630828857,
      "backward_entropy": 0.02826775312423706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4782227575778961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027092749252915382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17454258600870767,
      "backward_entropy": 0.018394714593887328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49831390380859375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027122516185045242,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17444185415903726,
      "backward_entropy": 0.018181157112121583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4463596045970917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027152162045240402,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1743400494257609,
      "backward_entropy": 0.027448824048042296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3677648603916168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027181314304471016,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17423383394877115,
      "backward_entropy": 0.01938706487417221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4335779547691345,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027209721505641937,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17412922779719034,
      "backward_entropy": 0.019204209744930267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3759060502052307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027237940579652786,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17402533690134683,
      "backward_entropy": 0.017360545694828033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.41844406723976135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027265574783086777,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17392019430796304,
      "backward_entropy": 0.01884826123714447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3375033736228943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027292873710393906,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17380841573079428,
      "backward_entropy": 0.016973622143268585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.346508264541626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027319541200995445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1736976703008016,
      "backward_entropy": 0.025936236977577208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3613605797290802,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02734566666185856,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17358487844467163,
      "backward_entropy": 0.01834401935338974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3175669014453888,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027371466159820557,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17346980174382529,
      "backward_entropy": 0.02547247111797333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3088546395301819,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02739681489765644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1733570694923401,
      "backward_entropy": 0.016247081756591796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28256756067276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027421604841947556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17324252923329672,
      "backward_entropy": 0.016075269877910615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2947520911693573,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027445968240499496,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17313375075658163,
      "backward_entropy": 0.024809053540229796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2113833874464035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02747010812163353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17302989959716797,
      "backward_entropy": 0.015744897723197936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27110227942466736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027493242174386978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17292888959248862,
      "backward_entropy": 0.02438722848892212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3112923800945282,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02751593478024006,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17282565434773764,
      "backward_entropy": 0.015435706079006194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24682708084583282,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027538571506738663,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1727166771888733,
      "backward_entropy": 0.023981383442878722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22353778779506683,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02756059169769287,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17260380585988364,
      "backward_entropy": 0.017042188346385954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25789085030555725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027582135051488876,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17249451080958048,
      "backward_entropy": 0.014984922111034393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16106931865215302,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02760339342057705,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17238054672876993,
      "backward_entropy": 0.023403891921043397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24893224239349365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027623658999800682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17227113246917725,
      "backward_entropy": 0.014702945947647095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19824950397014618,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02764379046857357,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17215647300084433,
      "backward_entropy": 0.02304435968399048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18853919208049774,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027663441374897957,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17204233010609946,
      "backward_entropy": 0.02286994457244873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15602849423885345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027682488784193993,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17192625999450684,
      "backward_entropy": 0.02270117700099945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16983245313167572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02770070545375347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17181092500686646,
      "backward_entropy": 0.014180156588554382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17613603174686432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771848440170288,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17169753710428873,
      "backward_entropy": 0.014060136675834656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13712826371192932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027736147865653038,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17158854007720947,
      "backward_entropy": 0.02222462445497513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13258694112300873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027753066271543503,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1714814305305481,
      "backward_entropy": 0.022073799371719362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1644572913646698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027769407257437706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17137851317723593,
      "backward_entropy": 0.013721160590648651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14597927033901215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027785588055849075,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1712743043899536,
      "backward_entropy": 0.01576515883207321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1314477175474167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027801331132650375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17116816838582358,
      "backward_entropy": 0.013509689271450043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10925447195768356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027816472575068474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17106016476949057,
      "backward_entropy": 0.013408911228179932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1401122361421585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027830936014652252,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17095494270324707,
      "backward_entropy": 0.013313093781471252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11182314157485962,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02784516103565693,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1708465019861857,
      "backward_entropy": 0.01544901728630066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12260139733552933,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02785874716937542,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1707369089126587,
      "backward_entropy": 0.021130847930908202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12079375982284546,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02787226252257824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17062987883885702,
      "backward_entropy": 0.021010315418243407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0957120880484581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027885515242815018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1705211599667867,
      "backward_entropy": 0.01294967085123062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09903489798307419,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027898240834474564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17041480541229248,
      "backward_entropy": 0.012865260243415833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09209857881069183,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027910513803362846,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1703085700670878,
      "backward_entropy": 0.01278376430273056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08598492294549942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02792232856154442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17020346721013388,
      "backward_entropy": 0.012705405056476594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09046365320682526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027933502569794655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17009741067886353,
      "backward_entropy": 0.012630912661552429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07957793027162552,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027944689616560936,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16999665896097818,
      "backward_entropy": 0.014948965609073639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07100702822208405,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0279551912099123,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1698939005533854,
      "backward_entropy": 0.014899519085884095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07615352421998978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027965255081653595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16979493697484335,
      "backward_entropy": 0.012421104311943054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09128434211015701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02797490544617176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16969593365987143,
      "backward_entropy": 0.012357233464717865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08784949779510498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027984552085399628,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16959406932195029,
      "backward_entropy": 0.012292968481779099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08202047646045685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027994172647595406,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16948970158894858,
      "backward_entropy": 0.01222854182124138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05923282355070114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028003724291920662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16938406229019165,
      "backward_entropy": 0.012164384871721268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07106871157884598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028012841939926147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16928203900655112,
      "backward_entropy": 0.012103527039289474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058814842253923416,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02802179381251335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1691787044207255,
      "backward_entropy": 0.01966177374124527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07007471472024918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02803013287484646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16907423734664917,
      "backward_entropy": 0.01198742464184761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06730182468891144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028038442134857178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1689684788386027,
      "backward_entropy": 0.011931216716766358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06664014607667923,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02804664708673954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1688610315322876,
      "backward_entropy": 0.01187547594308853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04212186485528946,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02805493213236332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1687533656756083,
      "backward_entropy": 0.0118192657828331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05441441014409065,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028062641620635986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16865086555480957,
      "backward_entropy": 0.019290825724601744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05377158895134926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028070250526070595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16854987541834512,
      "backward_entropy": 0.01922137141227722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04300237074494362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028077881783246994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16845093170801798,
      "backward_entropy": 0.011665155738592147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049511369317770004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02808496356010437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16835319995880127,
      "backward_entropy": 0.019086702167987822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04363337531685829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02809208072721958,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16825739542643228,
      "backward_entropy": 0.011570116132497787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04627091810107231,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028098998591303825,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16816365718841553,
      "backward_entropy": 0.014258329570293427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040875621140003204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02810577303171158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1680696209271749,
      "backward_entropy": 0.01147884428501129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03833707049489021,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028112245723605156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16797628005345663,
      "backward_entropy": 0.018835631012916566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04655345529317856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028118368238210678,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16788369417190552,
      "backward_entropy": 0.011394298076629639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03716369718313217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02812439203262329,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1677874525388082,
      "backward_entropy": 0.011353198438882828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02999197505414486,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028130054473876953,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16769101222356161,
      "backward_entropy": 0.018669717013835907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03870987892150879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028135303407907486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16759798924128214,
      "backward_entropy": 0.011278094351291656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03348494693636894,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140731155872345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16750568151474,
      "backward_entropy": 0.01856876015663147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034211527556180954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814614772796631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16741557916005453,
      "backward_entropy": 0.011204095929861069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02894335798919201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0281512551009655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16732370853424072,
      "backward_entropy": 0.011168806999921798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03287581726908684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02815617434680462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16723422209421793,
      "backward_entropy": 0.011134907603263855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03172985836863518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02816108986735344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16714431842168173,
      "backward_entropy": 0.011100924015045166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03103029727935791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028165841475129128,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1670529842376709,
      "backward_entropy": 0.018332071602344513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02717803604900837,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028170494362711906,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16696039835611978,
      "backward_entropy": 0.013986136019229888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0247203279286623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028174905106425285,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16686811049779257,
      "backward_entropy": 0.01824647784233093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024906542152166367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028179263696074486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16677852471669516,
      "backward_entropy": 0.018205133080482484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02311684750020504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02818363346159458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16669094562530518,
      "backward_entropy": 0.010942045599222183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021872837096452713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028187796473503113,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16660457849502563,
      "backward_entropy": 0.013926167786121369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023665521293878555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028191901743412018,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16652065515518188,
      "backward_entropy": 0.01088394969701767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023560907691717148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028195993974804878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16643672188123068,
      "backward_entropy": 0.010855232924222946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019249025732278824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028200220316648483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16635299722353616,
      "backward_entropy": 0.018006999790668488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020382309332489967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028204122558236122,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16627041498819986,
      "backward_entropy": 0.010798203200101853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019104180857539177,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028207672759890556,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1661867300669352,
      "backward_entropy": 0.017935700714588165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018406281247735023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02821125090122223,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16610464453697205,
      "backward_entropy": 0.013845528662204742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018363889306783676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028214624151587486,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16602283716201782,
      "backward_entropy": 0.017868725955486296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016344191506505013,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028217867016792297,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16594094038009644,
      "backward_entropy": 0.010699647665023803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01688981056213379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0282211322337389,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16586123903592428,
      "backward_entropy": 0.010676167905330658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015745315700769424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028224391862750053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1657821238040924,
      "backward_entropy": 0.010652679204940795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015797080472111702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028227629140019417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16570414106051126,
      "backward_entropy": 0.010629385709762573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013173051178455353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028230812400579453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16562626759211221,
      "backward_entropy": 0.010606372356414795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01396171934902668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02823389321565628,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1655509074529012,
      "backward_entropy": 0.01768328845500946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01346144825220108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02823682688176632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16547594467798868,
      "backward_entropy": 0.010562831163406372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013685030862689018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028239663690328598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.165401558081309,
      "backward_entropy": 0.010542064160108566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011320090852677822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028242506086826324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1653270423412323,
      "backward_entropy": 0.010521186888217926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010376699268817902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028245143592357635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16525437434514365,
      "backward_entropy": 0.017574073374271394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010752938687801361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028247695416212082,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16518454750378928,
      "backward_entropy": 0.010482892394065857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010064820758998394,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028250113129615784,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16511563460032144,
      "backward_entropy": 0.017524635791778563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009664821438491344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028252433985471725,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650472084681193,
      "backward_entropy": 0.010447759926319123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009555538184940815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02825470268726349,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16497997442881265,
      "backward_entropy": 0.01043097972869873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009549788199365139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02825707197189331,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1649139920870463,
      "backward_entropy": 0.010413723438978196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009161372669041157,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028259288519620895,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16484791040420532,
      "backward_entropy": 0.013700853288173675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009399427101016045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028261540457606316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16478228569030762,
      "backward_entropy": 0.010380715131759644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008177637122571468,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028263630345463753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1647156079610189,
      "backward_entropy": 0.010364902764558792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007820147089660168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028265614062547684,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16464974482854208,
      "backward_entropy": 0.010349760949611663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006552140694111586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028267499059438705,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16458471616109213,
      "backward_entropy": 0.010335257649421692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006987112108618021,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028269324451684952,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16452250878016153,
      "backward_entropy": 0.010321318358182906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006831683684140444,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02827102318406105,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1644612749417623,
      "backward_entropy": 0.017305400967597962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0064810276962816715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02827264368534088,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16440075635910034,
      "backward_entropy": 0.01728663146495819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006151049863547087,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028274312615394592,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16434137026468912,
      "backward_entropy": 0.010282692313194276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006353825330734253,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0282761100679636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16428337494532266,
      "backward_entropy": 0.017247971892356873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005475228186696768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028277887031435966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16422530015309653,
      "backward_entropy": 0.017228628695011138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0056495508179068565,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028279704973101616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16416879494984946,
      "backward_entropy": 0.017209117114543915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0054904138669371605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02828148566186428,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16411260763804117,
      "backward_entropy": 0.01719001829624176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004590123891830444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028283093124628067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1640563706556956,
      "backward_entropy": 0.010216351598501205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004653682000935078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028284626081585884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16400200128555298,
      "backward_entropy": 0.017155006527900696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004031226970255375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028286153450608253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1639487346013387,
      "backward_entropy": 0.010192786157131196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0044405353255569935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028287654742598534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1638976534207662,
      "backward_entropy": 0.010181400179862975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004446239210665226,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028289131820201874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16384689013163248,
      "backward_entropy": 0.01017012894153595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037727521266788244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028290465474128723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16379576921463013,
      "backward_entropy": 0.010159607231616973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003296619514003396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028291771188378334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16374595959981283,
      "backward_entropy": 0.010149338841438293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035012084990739822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028293009847402573,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16369836529095969,
      "backward_entropy": 0.013621419668197632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003431411925703287,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02829422987997532,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16365161538124084,
      "backward_entropy": 0.013619160652160645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029475227929651737,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02829541079699993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16360541184743246,
      "backward_entropy": 0.010120826959609985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031129494309425354,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028296513482928276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16356088717778525,
      "backward_entropy": 0.017017848789691925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030248346738517284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028297586366534233,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16351683934529623,
      "backward_entropy": 0.010103583335876465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024275812320411205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028298698365688324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.163473109404246,
      "backward_entropy": 0.01699177026748657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025344393216073513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02829979546368122,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1634314755598704,
      "backward_entropy": 0.010086293518543243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002412219997495413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02830088883638382,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16339091459910074,
      "backward_entropy": 0.016966035962104796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023259578738361597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02830197662115097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16335134704907736,
      "backward_entropy": 0.01006954163312912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002337408484891057,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028303077444434166,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16331263383229574,
      "backward_entropy": 0.010061157494783401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002384362043812871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028304118663072586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1632742484410604,
      "backward_entropy": 0.01692872941493988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019095195457339287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028305131942033768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16323548555374146,
      "backward_entropy": 0.016917064785957336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001858225790783763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028306113556027412,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16319812337557474,
      "backward_entropy": 0.010037554800510407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017281575128436089,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028307104483246803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1631618539492289,
      "backward_entropy": 0.010029932856559754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018037857953459024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028308097273111343,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16312682628631592,
      "backward_entropy": 0.016883036494255065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016301292926073074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0283090490847826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16309219598770142,
      "backward_entropy": 0.010015057027339935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017791931750252843,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02830997295677662,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16305841008822122,
      "backward_entropy": 0.010007964819669724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015845325542613864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02831081859767437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16302430629730225,
      "backward_entropy": 0.010001248866319656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001436342834495008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028311600908637047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16299053033192953,
      "backward_entropy": 0.016842171549797058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011664859484881163,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028312386944890022,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1629574497540792,
      "backward_entropy": 0.01683284789323807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012606127420440316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02831321954727173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16292613744735718,
      "backward_entropy": 0.009982165694236756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00115862931124866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028314072638750076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16289552052815756,
      "backward_entropy": 0.009975627064704895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011539285769686103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02831490896642208,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16286593675613403,
      "backward_entropy": 0.01680421531200409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009601336787454784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028315700590610504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16283702850341797,
      "backward_entropy": 0.009963181614875794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010104270186275244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028316527605056763,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16280949115753174,
      "backward_entropy": 0.009957020729780197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009736819774843752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02831733599305153,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16278264919916788,
      "backward_entropy": 0.009950968623161315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010092293377965689,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028318095952272415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16275649269421896,
      "backward_entropy": 0.00994526520371437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009107193909585476,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028318850323557854,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16273019711176553,
      "backward_entropy": 0.009939567744731903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008037711377255619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02831956371665001,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16270436843236288,
      "backward_entropy": 0.009934090077877045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008214400731958449,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028320271521806717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16267931461334229,
      "backward_entropy": 0.01674373894929886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006542417104355991,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02832094021141529,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16265467802683511,
      "backward_entropy": 0.009923583269119263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007642042473889887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02832162193953991,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1626313030719757,
      "backward_entropy": 0.01672840416431427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000706500664819032,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028322268277406693,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16260804732640585,
      "backward_entropy": 0.016721050441265106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006041897577233613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02832290343940258,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1625849703947703,
      "backward_entropy": 0.009908685833215714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006199442432262003,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028323529288172722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16256272792816162,
      "backward_entropy": 0.009903921186923981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005880902172066271,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028324127197265625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16254093249638876,
      "backward_entropy": 0.01670004576444626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005379911744967103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02832469902932644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1625195542971293,
      "backward_entropy": 0.00989493802189827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048069257172755897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028325267136096954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16249864300092062,
      "backward_entropy": 0.009890575706958771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005086399032734334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02832583524286747,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16247844696044922,
      "backward_entropy": 0.013548423349857331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004634130746126175,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028326377272605896,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16245856881141663,
      "backward_entropy": 0.013547027111053466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038229417987167835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028326891362667084,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1624392867088318,
      "backward_entropy": 0.016668571531772612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003942699986509979,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02832741290330887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16242090861002603,
      "backward_entropy": 0.01666264981031418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042655208380892873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028327912092208862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16240327556928,
      "backward_entropy": 0.009870435297489166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035842639044858515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028328368440270424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16238592068354288,
      "backward_entropy": 0.009866943955421448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003981230838689953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028328828513622284,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16236886382102966,
      "backward_entropy": 0.009863415360450744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035865401150658727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02832925133407116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1623518466949463,
      "backward_entropy": 0.009860093146562577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028099725022912025,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028329655528068542,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16233491897583008,
      "backward_entropy": 0.016636304557323456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035105380811728537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028330059722065926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16231882572174072,
      "backward_entropy": 0.009853743016719818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003089979582000524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028330421075224876,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1623027523358663,
      "backward_entropy": 0.013538238406181336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028352433582767844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028330758213996887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1622868776321411,
      "backward_entropy": 0.009848058223724365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027471809880807996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833108976483345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1622710426648458,
      "backward_entropy": 0.009845298528671265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026240426814183593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028331398963928223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1622555653254191,
      "backward_entropy": 0.009842704981565475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026546369190327823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028331687673926353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16224034627278647,
      "backward_entropy": 0.009840238094329833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022800781880505383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028331952169537544,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16222506761550903,
      "backward_entropy": 0.00983787328004837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019083691586274654,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02833220735192299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16221008698145548,
      "backward_entropy": 0.016604115068912507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018483222811482847,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02833246998488903,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16219560305277506,
      "backward_entropy": 0.016600710153579713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017331283015664667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028332732617855072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16218158602714539,
      "backward_entropy": 0.009830992668867111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019925231754314154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028332995250821114,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1621681253115336,
      "backward_entropy": 0.016594026982784272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015285662084352225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028333235532045364,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16215465466181436,
      "backward_entropy": 0.013536208868026733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013885872613172978,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028333473950624466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16214184959729513,
      "backward_entropy": 0.016587835550308228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001502325030742213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028333716094493866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16212964057922363,
      "backward_entropy": 0.009822540730237962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013250701886136085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833394519984722,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16211785872777304,
      "backward_entropy": 0.009820614010095596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001293883251491934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028334174305200577,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16210640470186868,
      "backward_entropy": 0.0098186694085598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001296490227105096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028334395959973335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16209532817204794,
      "backward_entropy": 0.009816837310791016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012179352779639885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0283346064388752,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1620844006538391,
      "backward_entropy": 0.016573244333267213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011437391367508098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028334805741906166,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16207373142242432,
      "backward_entropy": 0.016570617258548737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010860927432077006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833499386906624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620634396870931,
      "backward_entropy": 0.009811700880527496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010279984417138621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028335172683000565,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16205342610677084,
      "backward_entropy": 0.016565608978271484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010583712719380856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028335344046354294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16204365094502768,
      "backward_entropy": 0.009808667004108429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010012066923081875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02833549864590168,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16203415393829346,
      "backward_entropy": 0.016561013460159302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.051112283486873e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028335638344287872,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16202487548192343,
      "backward_entropy": 0.01655888855457306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.167070336639881e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833576872944832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620157559712728,
      "backward_entropy": 0.009804777801036835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.364516204688698e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028335893526673317,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16200692454973856,
      "backward_entropy": 0.009803590923547744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.281997048063204e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028336018323898315,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.161998450756073,
      "backward_entropy": 0.016552965342998504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.252648745430633e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02833614870905876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16199039419492087,
      "backward_entropy": 0.01655099093914032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.260609759716317e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028336280956864357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16198273499806723,
      "backward_entropy": 0.013536706566810608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.58403626200743e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833642065525055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16197534402211508,
      "backward_entropy": 0.00979899913072586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.96981774631422e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028336558490991592,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1619682808717092,
      "backward_entropy": 0.016545139253139496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.497733218362555e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028336700052022934,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16196149587631226,
      "backward_entropy": 0.01654321700334549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.890695709036663e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833683416247368,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16195489962895712,
      "backward_entropy": 0.009795637428760528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.824705345323309e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028336962684988976,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16194844245910645,
      "backward_entropy": 0.016539545357227327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0538888899609447e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02833710052073002,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16194246212641397,
      "backward_entropy": 0.013536618649959564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.405645086080767e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028337223455309868,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16193648179372153,
      "backward_entropy": 0.016535983979701997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3541738705243915e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02833734080195427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16193068027496338,
      "backward_entropy": 0.016534316539764404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.653551175375469e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028337448835372925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16192499796549478,
      "backward_entropy": 0.009790679812431336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0581315261079e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028337553143501282,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.161919375260671,
      "backward_entropy": 0.01653120666742325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8657468646997586e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028337646275758743,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16191383202870688,
      "backward_entropy": 0.009788991510868072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.026106787729077e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028337744995951653,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16190864642461142,
      "backward_entropy": 0.009788182377815247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1424049666384235e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028337843716144562,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16190367937088013,
      "backward_entropy": 0.016526848077774048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.458666313032154e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028337936848402023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16189887126286825,
      "backward_entropy": 0.009786636382341386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4927230697358027e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028338035568594933,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.161894420782725,
      "backward_entropy": 0.009785868972539902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7979100195807405e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028338132426142693,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16189007957776388,
      "backward_entropy": 0.013537177443504333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.453003435221035e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028338221833109856,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16188583771387735,
      "backward_entropy": 0.01652132123708725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.773889562173281e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833830565214157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618816057840983,
      "backward_entropy": 0.009783759713172913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.776121098373551e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028338395059108734,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16187767187754312,
      "backward_entropy": 0.009783081710338593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.340773426112719e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028338486328721046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16187392671902975,
      "backward_entropy": 0.009782399982213974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1810419639223255e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028338568285107613,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16187021136283875,
      "backward_entropy": 0.01353730857372284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4035481399332639e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028338640928268433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618664562702179,
      "backward_entropy": 0.009781192243099212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.356450047751423e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0283387191593647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618629495302836,
      "backward_entropy": 0.016514074802398682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5730200175312348e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028338801115751266,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1618596911430359,
      "backward_entropy": 0.013537408411502838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2088815310562495e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028338879346847534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16185649236043295,
      "backward_entropy": 0.009779434651136398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2129316928621847e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028338957577943802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16185339291890463,
      "backward_entropy": 0.016510707139968873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5464973330381326e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02833903767168522,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1618504822254181,
      "backward_entropy": 0.013537302613258362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3438009773381054e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02833911031484604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16184763113657633,
      "backward_entropy": 0.016508616507053375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2320434507273603e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833917737007141,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618447701136271,
      "backward_entropy": 0.009777247905731201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1546362657099962e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028339240700006485,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16184199849764505,
      "backward_entropy": 0.016506701707839966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.472042620473076e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02833929844200611,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1618392070134481,
      "backward_entropy": 0.013537380099296569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0778468094940763e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028339356184005737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618365248044332,
      "backward_entropy": 0.009775878489017486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0963836757582612e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028339412063360214,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16183394193649292,
      "backward_entropy": 0.01650412827730179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.66177436162252e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028339462354779243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16183141867319742,
      "backward_entropy": 0.009775043278932572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.039590855129063e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028339510783553123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618289351463318,
      "backward_entropy": 0.009774664044380188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.131610800570343e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028339561074972153,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618265708287557,
      "backward_entropy": 0.009774276614189148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.090469352988293e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833961322903633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16182440519332886,
      "backward_entropy": 0.009773899614810944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.491463748010574e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833966352045536,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16182228922843933,
      "backward_entropy": 0.009773533046245574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598481493507279e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02833971008658409,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16182019313176474,
      "backward_entropy": 0.013537733256816864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.564081559190527e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02833975851535797,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16181822617848715,
      "backward_entropy": 0.013537745177745818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.833153409184888e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028339803218841553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16181627909342447,
      "backward_entropy": 0.009772484749555587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.716835064755287e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028339846059679985,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16181437174479166,
      "backward_entropy": 0.009772185236215591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.036584414279787e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028339888900518417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618125836054484,
      "backward_entropy": 0.009771861135959625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.40910389443161e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028339933604002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16181087493896484,
      "backward_entropy": 0.016496196389198303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.168726147530833e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02833997830748558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180927554766336,
      "backward_entropy": 0.009771237522363663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.262951617623912e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340017423033714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180764635403952,
      "backward_entropy": 0.009770958125591278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.405657702794997e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834005281329155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618060270945231,
      "backward_entropy": 0.009770675748586654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.260985522501869e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340084478259087,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180441776911417,
      "backward_entropy": 0.009770441800355911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.28674547947594e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340116143226624,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180288791656494,
      "backward_entropy": 0.00977020114660263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.060219907842111e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340144082903862,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16180135806401572,
      "backward_entropy": 0.013538126647472382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7761205931019504e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340168297290802,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179980834325156,
      "backward_entropy": 0.009769771993160248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8360930173221277e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340190649032593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179829835891724,
      "backward_entropy": 0.009769570082426071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.345358436490642e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340213000774384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617968479792277,
      "backward_entropy": 0.009769394993782043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.869730451493524e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340233489871025,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16179541746775308,
      "backward_entropy": 0.013538533449172973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4173048132070107e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340253978967667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179404656092325,
      "backward_entropy": 0.009769023954868316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5688584628369426e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340274468064308,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179276506106058,
      "backward_entropy": 0.009768872708082198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.924044909173972e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834029495716095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617915133635203,
      "backward_entropy": 0.009768718481063842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4998382741614478e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834031544625759,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617903212706248,
      "backward_entropy": 0.016489695012569427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.105429985022056e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340332210063934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178907950719199,
      "backward_entropy": 0.009768404066562653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1937177027430153e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340348973870277,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178790728251138,
      "backward_entropy": 0.00976824089884758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1048922462796327e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340360149741173,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617866853872935,
      "backward_entropy": 0.013539227843284606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.043187350864173e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834036946296692,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178547342618307,
      "backward_entropy": 0.016488462686538696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1463249595399247e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340378776192665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178428133328757,
      "backward_entropy": 0.009767919033765792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7202173694386147e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340386226773262,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178311904271445,
      "backward_entropy": 0.016487953066825867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.431904024684627e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834039181470871,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178195675214133,
      "backward_entropy": 0.01648772954940796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5509874629060505e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340399265289307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178085406621298,
      "backward_entropy": 0.01648751348257065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4029271824256284e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340404853224754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177978118260702,
      "backward_entropy": 0.009767568111419678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3790679531666683e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340410441160202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617787480354309,
      "backward_entropy": 0.009767507016658784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4623702782046166e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834041602909565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177773475646973,
      "backward_entropy": 0.00976741686463356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2250569625393837e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340419754385948,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16177672147750854,
      "backward_entropy": 0.016486695408821105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0547179272180074e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340423479676247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617757280667623,
      "backward_entropy": 0.013540658354759216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2717067647827207e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340427204966545,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16177475452423096,
      "backward_entropy": 0.013540789484977722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.942522645658755e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340429067611694,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.161773810784022,
      "backward_entropy": 0.00976717695593834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.59852048556786e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340432792901993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177292664845785,
      "backward_entropy": 0.00976709946990013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1075809425165062e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02834043838083744,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617721120516459,
      "backward_entropy": 0.013541148602962494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.12495375915023e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02834044210612774,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16177129745483398,
      "backward_entropy": 0.01354125589132309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.218438102223445e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340447694063187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617705225944519,
      "backward_entropy": 0.016485455632209777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.814805371708644e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340455144643784,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176981727282205,
      "backward_entropy": 0.009766842424869537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.995232067514735e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02834046073257923,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176908214886984,
      "backward_entropy": 0.013541527092456818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.125845738504722e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02834046632051468,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176838676134744,
      "backward_entropy": 0.013541595637798309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.776190050710284e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340470045804977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176770130793253,
      "backward_entropy": 0.009766650944948196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.200192276788584e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340473771095276,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176704565684,
      "backward_entropy": 0.009766612201929092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.067014848871622e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340477496385574,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176639000574747,
      "backward_entropy": 0.013541871309280395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.711431020292366e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340481221675873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176573435465494,
      "backward_entropy": 0.009766508638858796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.847737037991465e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834048494696617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176509857177734,
      "backward_entropy": 0.0164842814207077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.422633080343076e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834048680961132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176448265711466,
      "backward_entropy": 0.009766419231891633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.217643774813041e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834048680961132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176384687423706,
      "backward_entropy": 0.009766395390033721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.627113068840117e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834048680961132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176324089368185,
      "backward_entropy": 0.009766347706317902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.754293516067264e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834048680961132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176263491312662,
      "backward_entropy": 0.00976632982492447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.656950866570696e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834048680961132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176207860310873,
      "backward_entropy": 0.0097663052380085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3306784530395817e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834048680961132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176152229309082,
      "backward_entropy": 0.00976628065109253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9577336135844234e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02834048680961132,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617609957853953,
      "backward_entropy": 0.013542757928371429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.844599578111229e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834048867225647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617604891459147,
      "backward_entropy": 0.01648346185684204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.082579667079699e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834048867225647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617599825064341,
      "backward_entropy": 0.009766196459531784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.026912054338027e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834049053490162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617595156033834,
      "backward_entropy": 0.016483280062675475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6912593398265017e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340492397546768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617590387662252,
      "backward_entropy": 0.016483187675476074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.817531654069171e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340494260191917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617585817972819,
      "backward_entropy": 0.009766106307506562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.019861966573444e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340496122837067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175816456476846,
      "backward_entropy": 0.00976608246564865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2233273000438203e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340497985482216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175774733225504,
      "backward_entropy": 0.016482943296432497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1375873870965734e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340499848127365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.161757359902064,
      "backward_entropy": 0.009766040742397309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5603318931644026e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340501710772514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617569923400879,
      "backward_entropy": 0.009765993058681487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9688127395056654e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340503573417664,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617566148440043,
      "backward_entropy": 0.013543453812599183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6144009862273379e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340505436062813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175625721613565,
      "backward_entropy": 0.009765950590372085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7947444064247975e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340507298707962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617559293905894,
      "backward_entropy": 0.009765931963920593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3877533433515055e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834050916135311,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175560156504312,
      "backward_entropy": 0.016482427716255188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4685846849715745e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834051102399826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617552936077118,
      "backward_entropy": 0.00976586937904358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12304969347133e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02834051288664341,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16175498565038046,
      "backward_entropy": 0.01354369819164276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1149429468559902e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340516611933708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617547074953715,
      "backward_entropy": 0.009765829890966415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.756170899459903e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340520337224007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175444920857748,
      "backward_entropy": 0.009765788912773132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.290681646234589e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340524062514305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175419092178345,
      "backward_entropy": 0.009765759110450745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1774152852694897e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340527787804604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175395250320435,
      "backward_entropy": 0.009765736758708954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.229170436545246e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340531513094902,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175373395284018,
      "backward_entropy": 0.01648184806108475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52230002124088e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0283405352383852,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175350546836853,
      "backward_entropy": 0.0097656711935997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.179137722663654e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0283405389636755,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16175327698389688,
      "backward_entropy": 0.013543902337551117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.062102724830766e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340542688965797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175305843353271,
      "backward_entropy": 0.016481634974479676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.665453694016833e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340546414256096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175285975138345,
      "backward_entropy": 0.009765610098838806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.034220317336803e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340550139546394,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16175268093744913,
      "backward_entropy": 0.013543972373008728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.504222500007927e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340553864836693,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617524822552999,
      "backward_entropy": 0.013543987274169922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.663877544748175e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834055759012699,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175232330958048,
      "backward_entropy": 0.016481342911720275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.248161810162856e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834056131541729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175216436386108,
      "backward_entropy": 0.00976550579071045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.738410635558466e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340565040707588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175201535224915,
      "backward_entropy": 0.009765487164258957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.549633558781352e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340568765997887,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175183653831482,
      "backward_entropy": 0.01648114025592804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0017348485198454e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340572491288185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175168752670288,
      "backward_entropy": 0.00976543053984642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8820794518178445e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340576216578484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175155838330588,
      "backward_entropy": 0.00976540967822075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.707854373009468e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340579941868782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617514193058014,
      "backward_entropy": 0.009765397012233733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.549828958033686e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834058366715908,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617512901624044,
      "backward_entropy": 0.016480898857116698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0422430796761546e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834058739244938,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175116101900736,
      "backward_entropy": 0.01648082733154297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.361828587207128e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340591117739677,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175106167793274,
      "backward_entropy": 0.009765318781137466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.476002419233737e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340594843029976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175095240275064,
      "backward_entropy": 0.009765306860208512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.120357743886416e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340598568320274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175084312756857,
      "backward_entropy": 0.009765289723873138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.195640374542563e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340602293610573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175074378649393,
      "backward_entropy": 0.009765271097421646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.033198581192664e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02834060601890087,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617506742477417,
      "backward_entropy": 0.013544128835201263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4827897959767142e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834060974419117,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175057490666708,
      "backward_entropy": 0.009765224158763885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.029636630458299e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340613469481468,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175049543380737,
      "backward_entropy": 0.016480425000190736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5051263346776977e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340617194771767,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617504060268402,
      "backward_entropy": 0.013544167578220367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3760792444704748e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340619057416916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175033648808798,
      "backward_entropy": 0.009765180945396423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5544835580149083e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340622782707214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175025701522827,
      "backward_entropy": 0.009765166044235229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2232253371612387e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340626507997513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617501974105835,
      "backward_entropy": 0.009765152633190156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9304255971519524e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834063023328781,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16175013780593872,
      "backward_entropy": 0.01648016571998596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3696535461349413e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834063395857811,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175007820129395,
      "backward_entropy": 0.009765103459358215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7649838923716743e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834063582122326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16175001859664917,
      "backward_entropy": 0.00976509153842926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9050077071369742e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340637683868408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617499589920044,
      "backward_entropy": 0.009765084832906723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.717737951878462e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340639546513557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174989938735962,
      "backward_entropy": 0.009765072911977767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2740990484871872e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340641409158707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174983978271484,
      "backward_entropy": 0.009765063971281051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5191567115380167e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340643271803856,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.161749800046285,
      "backward_entropy": 0.016479925811290742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.584126607667713e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340645134449005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174974044164023,
      "backward_entropy": 0.009765048325061799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.105752289731754e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340646997094154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174968083699545,
      "backward_entropy": 0.009765036404132843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1046495274058543e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340648859739304,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16174962123235068,
      "backward_entropy": 0.013544216752052307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0486644441698445e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340650722384453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174957156181335,
      "backward_entropy": 0.009765001386404038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.052495559240924e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340652585029602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174952189127603,
      "backward_entropy": 0.009765001386404038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.496154973476223e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834065444767475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174946228663126,
      "backward_entropy": 0.00976499542593956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.056360746242717e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0283406563103199,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174942255020142,
      "backward_entropy": 0.009764992445707322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.883148439053912e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02834065817296505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174938281377158,
      "backward_entropy": 0.009764985740184784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5933960513575585e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0283406600356102,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16174933314323425,
      "backward_entropy": 0.01354428380727768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.40951816674351e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340661898255348,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174928347269693,
      "backward_entropy": 0.009764979779720306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1685093416817836e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340663760900497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617492437362671,
      "backward_entropy": 0.01647963374853134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.054847290215548e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340665623545647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174922386805216,
      "backward_entropy": 0.01647958755493164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.38227975918926e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16174918413162231,
      "backward_entropy": 0.013544316589832305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.310123813411337e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174914439519247,
      "backward_entropy": 0.009764964878559112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.50746648286804e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617491046587626,
      "backward_entropy": 0.01647954434156418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2034678788004385e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16174906492233276,
      "backward_entropy": 0.013544327020645142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0648266147181857e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174903512001038,
      "backward_entropy": 0.016479507088661194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5117651009386464e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.161749005317688,
      "backward_entropy": 0.016479495167732238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.921979103120975e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617489755153656,
      "backward_entropy": 0.013544370234012604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.260552716710663e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617489457130432,
      "backward_entropy": 0.009764952212572097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.747146593013895e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174891591072083,
      "backward_entropy": 0.00976494923233986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.98161859038737e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617488960425059,
      "backward_entropy": 0.016479450464248657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.786894353652315e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617488662401835,
      "backward_entropy": 0.00976494625210762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5784209494995594e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617488463719686,
      "backward_entropy": 0.013544395565986633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3848443220231275e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617488165696462,
      "backward_entropy": 0.009764940291643143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6390907237328065e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174879670143127,
      "backward_entropy": 0.016479375958442687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7878428454641835e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174877683321634,
      "backward_entropy": 0.009764934331178666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.175340796384262e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174874703089395,
      "backward_entropy": 0.016479367017745973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6016451215582492e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174872716267905,
      "backward_entropy": 0.016479355096817017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.402870791229361e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617487072944641,
      "backward_entropy": 0.009764931350946426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.989974407479167e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174869736035666,
      "backward_entropy": 0.016479316353797912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0721486748698226e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174866755803427,
      "backward_entropy": 0.009764927625656127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4280772120400798e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617486576239268,
      "backward_entropy": 0.009764927625656127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9704273768184066e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174864768981934,
      "backward_entropy": 0.00976492464542389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.368753999031469e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617486278216044,
      "backward_entropy": 0.009764921665191651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7871784052658768e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174861788749695,
      "backward_entropy": 0.01647927165031433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4709513607158442e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617486079533895,
      "backward_entropy": 0.009764921665191651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8699921611187165e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174858808517456,
      "backward_entropy": 0.016479256749153137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.693703534845554e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174856821695963,
      "backward_entropy": 0.016479256749153137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5162484601205506e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174855828285217,
      "backward_entropy": 0.01647922247648239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1494307727843989e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174854834874472,
      "backward_entropy": 0.009764894843101501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0802168048940075e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174852848052979,
      "backward_entropy": 0.009764894843101501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972165232989937e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174850861231485,
      "backward_entropy": 0.009764894843101501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1066561000916408e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617484986782074,
      "backward_entropy": 0.013544486463069915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.270415380844497e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16174848874409994,
      "backward_entropy": 0.013544490933418274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1130865118502697e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.161748468875885,
      "backward_entropy": 0.009764890372753143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.418315016773704e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174845894177756,
      "backward_entropy": 0.009764890372753143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.640377137046016e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174844900767008,
      "backward_entropy": 0.009764887392520905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.873950380599126e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174844900767008,
      "backward_entropy": 0.009764887392520905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.836984312030836e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174842913945517,
      "backward_entropy": 0.009764884412288666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.231601901163231e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16174842913945517,
      "backward_entropy": 0.013544505834579468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.190426115106675e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174840927124023,
      "backward_entropy": 0.009764887392520905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.481677251533256e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174839933713278,
      "backward_entropy": 0.009764884412288666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.040874384576455e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174840927124023,
      "backward_entropy": 0.009764884412288666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.032276817473758e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617483894030253,
      "backward_entropy": 0.016479113698005678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.391367269818147e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174837946891785,
      "backward_entropy": 0.016479107737541198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5578295864979737e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617483695348104,
      "backward_entropy": 0.01647910326719284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6688874160972773e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617483695348104,
      "backward_entropy": 0.009764881432056427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9037749982308014e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16174834966659546,
      "backward_entropy": 0.009764881432056427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.668087972779176e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617483596007029,
      "backward_entropy": 0.016479088366031645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.935962584160734e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028340667486190796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16174834966659546,
      "backward_entropy": 0.016479088366031645,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.146557378068792e-08,
    "avg_log_Z": 0.028340632878243923,
    "success_rate": 1.0,
    "avg_reward": 47.0,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.28,
      "2": 0.57
    },
    "avg_forward_entropy": 0.1617499293883642,
    "avg_backward_entropy": 0.012212103798985484,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}