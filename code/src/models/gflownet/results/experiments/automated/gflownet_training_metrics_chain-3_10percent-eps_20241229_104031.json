{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23031127452850342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23104870319366455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.415665626525879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745811343193054,
      "backward_entropy": 0.23094326257705688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052225112915039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.99999901978299e-05,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745770812034607,
      "backward_entropy": 0.2310489813486735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.048749923706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019994039030279964,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745726704597473,
      "backward_entropy": 0.2310490608215332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.180929183959961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0002998641284648329,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745679020881653,
      "backward_entropy": 0.23018876711527506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.645251274108887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00039979990106076,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745625078678131,
      "backward_entropy": 0.23014708360036215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.774617195129395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004998623626306653,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745567858219147,
      "backward_entropy": 0.230106254418691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.3909912109375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006000248831696808,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27455079555511475,
      "backward_entropy": 0.23006494839986166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.519632339477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007001757621765137,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745448350906372,
      "backward_entropy": 0.2310453255971273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.916690826416016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008003389812074602,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27453818917274475,
      "backward_entropy": 0.23104353745778403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.641304969787598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009003379382193089,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745313048362732,
      "backward_entropy": 0.23079365491867065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.021187782287598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010004095965996385,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27452352643013,
      "backward_entropy": 0.23077269395192465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.983033180236816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011003785766661167,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27451592683792114,
      "backward_entropy": 0.23074940840403238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.143264770507812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012005353346467018,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450746297836304,
      "backward_entropy": 0.230725367863973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.825617790222168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013005912769585848,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744986116886139,
      "backward_entropy": 0.2297390103340149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.007169723510742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014008155558258295,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744901180267334,
      "backward_entropy": 0.23067321379979452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.876700401306152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001500895363278687,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27448177337646484,
      "backward_entropy": 0.22963035106658936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.684804916381836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016008287202566862,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744743525981903,
      "backward_entropy": 0.23061456282933554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.266977310180664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017009308794513345,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27446770668029785,
      "backward_entropy": 0.23058271408081055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.104246139526367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018013633089140058,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744613289833069,
      "backward_entropy": 0.23054921627044678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.907565116882324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0019016567384824157,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744550108909607,
      "backward_entropy": 0.2309896151224772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.443790435791016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002002129564061761,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744485139846802,
      "backward_entropy": 0.23098087310791016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.439213752746582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002102577593177557,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27444201707839966,
      "backward_entropy": 0.23043994108835855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.507284164428711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022030023392289877,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744354009628296,
      "backward_entropy": 0.23040014505386353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61491870880127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023030617740005255,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442941069602966,
      "backward_entropy": 0.2303584615389506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.156335830688477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002402858342975378,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442467212677,
      "backward_entropy": 0.23093740145365396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.53123664855957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025022353511303663,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442076802253723,
      "backward_entropy": 0.22897897164026895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.151077270507812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026017960626631975,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744166851043701,
      "backward_entropy": 0.22890381018320718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.755499839782715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002700964454561472,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744133174419403,
      "backward_entropy": 0.23017211755116782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.516824722290039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002800431102514267,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744092345237732,
      "backward_entropy": 0.23087739944458008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.196366310119629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029000737704336643,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744048833847046,
      "backward_entropy": 0.22866463661193848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.673593997955322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030001422856003046,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27439993619918823,
      "backward_entropy": 0.23000991344451904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.517677307128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003099562367424369,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27439695596694946,
      "backward_entropy": 0.23081664244333902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.620868682861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031991382129490376,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27439242601394653,
      "backward_entropy": 0.2307936946551005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.150749206542969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032989049796015024,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743866741657257,
      "backward_entropy": 0.22982867558797201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.162984848022461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003398664528504014,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27438119053840637,
      "backward_entropy": 0.22820383310317993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587158203125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034983919467777014,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274374783039093,
      "backward_entropy": 0.22969496250152588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.690370559692383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003598315641283989,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743681073188782,
      "backward_entropy": 0.22799424330393472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.126340866088867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0036980053409934044,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27436113357543945,
      "backward_entropy": 0.22954861323038736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.480501174926758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003798150923103094,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27435407042503357,
      "backward_entropy": 0.2306202252705892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.446250915527344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003898356109857559,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27434587478637695,
      "backward_entropy": 0.2276540199915568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.113908767700195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003998192027211189,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27433833479881287,
      "backward_entropy": 0.22753417491912842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.654502868652344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004098000004887581,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27433067560195923,
      "backward_entropy": 0.2274101972579956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.082738876342773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0041980440728366375,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743232250213623,
      "backward_entropy": 0.22912641366322836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.305549621582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004298054613173008,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743167579174042,
      "backward_entropy": 0.23041834433873495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.276970863342285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0043981242924928665,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743103504180908,
      "backward_entropy": 0.22893365224202475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.855264186859131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004497814457863569,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743062973022461,
      "backward_entropy": 0.22686644395192465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513387680053711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0045969304628670216,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743035554885864,
      "backward_entropy": 0.22672438621520996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.197522163391113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0046963016502559185,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742997407913208,
      "backward_entropy": 0.22861997286478677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.625259399414062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004795723129063845,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27429434657096863,
      "backward_entropy": 0.2264254887898763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.396184921264648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004895397927612066,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742873430252075,
      "backward_entropy": 0.23010635375976562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.593719482421875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0049947393126785755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742808163166046,
      "backward_entropy": 0.22610803445180258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.145607948303223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005093901883810759,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274275004863739,
      "backward_entropy": 0.2299821376800537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.052449226379395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005193155258893967,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742687463760376,
      "backward_entropy": 0.22802793979644775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.38672924041748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005292869172990322,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742597460746765,
      "backward_entropy": 0.22560060024261475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.794999122619629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0053926813416182995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27424919605255127,
      "backward_entropy": 0.22542027632395426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.91601276397705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005492346361279488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27423906326293945,
      "backward_entropy": 0.22762827078501383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.008001327514648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00559191731736064,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742285132408142,
      "backward_entropy": 0.22504701217015585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.07707405090332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005691461265087128,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27421778440475464,
      "backward_entropy": 0.22953601678212485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.120782852172852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0057915011420845985,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742057144641876,
      "backward_entropy": 0.22945133845011392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.014581680297852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005891493521630764,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741927206516266,
      "backward_entropy": 0.22703959544499716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.074358940124512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005991382524371147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741788625717163,
      "backward_entropy": 0.22425854206085205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.224172592163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006091253366321325,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27416518330574036,
      "backward_entropy": 0.22917763392130533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.282232284545898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006191127467900515,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741495370864868,
      "backward_entropy": 0.22384285926818848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.078981399536133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006291077006608248,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741336226463318,
      "backward_entropy": 0.22897998491923013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.973447799682617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006390973925590515,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741173505783081,
      "backward_entropy": 0.2288756767908732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.604740142822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006490763276815414,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27410024404525757,
      "backward_entropy": 0.2287677526473999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.05168342590332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006590766832232475,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740813195705414,
      "backward_entropy": 0.2258406082789103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.960446357727051,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006690701469779015,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27406173944473267,
      "backward_entropy": 0.22854169209798178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.254650115966797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00679005729034543,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740442454814911,
      "backward_entropy": 0.22249186038970947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.801572799682617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006889509968459606,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740253210067749,
      "backward_entropy": 0.22829933961232504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.402562618255615,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00698884716257453,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27400636672973633,
      "backward_entropy": 0.22505515813827515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.287665367126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007087402045726776,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739909589290619,
      "backward_entropy": 0.22804037729899088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.527297019958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007186211179941893,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739754021167755,
      "backward_entropy": 0.22145150105158487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.04544734954834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007285324856638908,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739576995372772,
      "backward_entropy": 0.22776579856872559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.941054344177246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007384524215012789,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739403545856476,
      "backward_entropy": 0.22762292623519897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.864768981933594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007484175264835358,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27392083406448364,
      "backward_entropy": 0.22395567099253336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.165864944458008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0075841485522687435,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27389708161354065,
      "backward_entropy": 0.22732730706532797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.532873153686523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007684122771024704,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738722562789917,
      "backward_entropy": 0.2234837214152018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.873771667480469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007783778011798859,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738483250141144,
      "backward_entropy": 0.22323870658874512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.975484848022461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007882845588028431,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27382710576057434,
      "backward_entropy": 0.2229869763056437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5481719970703125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007981976494193077,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738063931465149,
      "backward_entropy": 0.22668339808781943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.030885696411133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00808041077107191,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737889885902405,
      "backward_entropy": 0.2265084187189738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.08902359008789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008178496733307838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27377402782440186,
      "backward_entropy": 0.21819937229156494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.741263389587402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008276768960058689,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737572193145752,
      "backward_entropy": 0.22190634409586588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.060591697692871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008375061675906181,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27374032139778137,
      "backward_entropy": 0.21746893723805746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.503137588500977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00847308523952961,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737273573875427,
      "backward_entropy": 0.22575044631958008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823690414428711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008571049198508263,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27371492981910706,
      "backward_entropy": 0.2167067527770996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29637622833252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008669097907841206,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737010717391968,
      "backward_entropy": 0.22533845901489258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706491470336914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008766960352659225,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736876606941223,
      "backward_entropy": 0.22038880983988443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.759364128112793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008864853531122208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27367281913757324,
      "backward_entropy": 0.22490171591440836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.168542861938477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008962309919297695,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736603915691376,
      "backward_entropy": 0.22467315196990967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0336332321167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009059574455022812,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736482620239258,
      "backward_entropy": 0.22443735599517822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.755302429199219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009156621061265469,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27363741397857666,
      "backward_entropy": 0.21413719654083252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.884850978851318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009253296069800854,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736276686191559,
      "backward_entropy": 0.21366679668426514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.58541202545166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009349765256047249,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736203372478485,
      "backward_entropy": 0.21318817138671875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.012014389038086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009446406736969948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736121118068695,
      "backward_entropy": 0.21269635359446207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.841574192047119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009542867541313171,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27360400557518005,
      "backward_entropy": 0.22314373652140299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.866156578063965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009639131836593151,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27359768748283386,
      "backward_entropy": 0.22285930315653482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.296549797058105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009735722094774246,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27358826994895935,
      "backward_entropy": 0.22256791591644287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.451818466186523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009832271374762058,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27357739210128784,
      "backward_entropy": 0.21062239011128744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142256736755371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009928891435265541,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27356502413749695,
      "backward_entropy": 0.2219615379969279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.501739501953125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010025410912930965,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273552268743515,
      "backward_entropy": 0.20951221386591592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.4830961227417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01012204959988594,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27353811264038086,
      "backward_entropy": 0.2151687741279602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.634366035461426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010218788869678974,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27352261543273926,
      "backward_entropy": 0.208361546198527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.867785453796387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010315724648535252,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27350571751594543,
      "backward_entropy": 0.2142969767252604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.659144401550293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010412399657070637,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27348971366882324,
      "backward_entropy": 0.20716768503189087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.544610500335693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010509833693504333,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734684348106384,
      "backward_entropy": 0.20654467741648355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.81210470199585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010606781579554081,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27344948053359985,
      "backward_entropy": 0.21960131327311197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.077249526977539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01070344541221857,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27343159914016724,
      "backward_entropy": 0.20527994632720947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.458282470703125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010800005868077278,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734135389328003,
      "backward_entropy": 0.20463232199350992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.669625282287598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010896163992583752,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27339857816696167,
      "backward_entropy": 0.21129031976064047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983462333679199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010992043651640415,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733844816684723,
      "backward_entropy": 0.21809172630310059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75110149383545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011087893508374691,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733708620071411,
      "backward_entropy": 0.20264965295791626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.363487243652344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011184108443558216,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733534276485443,
      "backward_entropy": 0.2019549012184143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.86498498916626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011280427686870098,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2733336389064789,
      "backward_entropy": 0.20905146996180216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.895203590393066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011376573704183102,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2733139395713806,
      "backward_entropy": 0.20847590764363608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.154821872711182,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011472627520561218,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732951045036316,
      "backward_entropy": 0.20788904031117758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.205894470214844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011568162590265274,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732796370983124,
      "backward_entropy": 0.19905499617258707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.920737266540527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011663863435387611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27326345443725586,
      "backward_entropy": 0.19830248753229776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.827441215515137,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011760110966861248,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732430696487427,
      "backward_entropy": 0.19752738873163858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7203474044799805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01185620203614235,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27322080731391907,
      "backward_entropy": 0.20540865262349448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.018304824829102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011952085420489311,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27319854497909546,
      "backward_entropy": 0.19594363371531168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.125795364379883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012047996744513512,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27317601442337036,
      "backward_entropy": 0.19513189792633057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981051445007324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01214394997805357,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731509506702423,
      "backward_entropy": 0.1943045457204183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03943157196045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012240445241332054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731200158596039,
      "backward_entropy": 0.19345319271087646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.300213813781738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012336908839643002,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273088276386261,
      "backward_entropy": 0.20200534661610922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.001564979553223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012433469295501709,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27305349707603455,
      "backward_entropy": 0.21069069703420004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.025590896606445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012529405765235424,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2730236053466797,
      "backward_entropy": 0.20056049029032388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.786584377288818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012625384144484997,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27299270033836365,
      "backward_entropy": 0.2094727357228597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.441075801849365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012721303850412369,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27296343445777893,
      "backward_entropy": 0.18902275959650675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.624637603759766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012816933915019035,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729353904724121,
      "backward_entropy": 0.19828903675079346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.917413234710693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0129129933193326,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729003429412842,
      "backward_entropy": 0.197502334912618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.650740146636963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013009008020162582,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2728632688522339,
      "backward_entropy": 0.19670522212982178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.822504997253418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013104800134897232,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27282455563545227,
      "backward_entropy": 0.18521674474080405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.358234405517578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013200557790696621,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27278515696525574,
      "backward_entropy": 0.1842228372891744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.767563819885254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013296022079885006,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727481722831726,
      "backward_entropy": 0.2048248052597046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.887280464172363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013390233740210533,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27272212505340576,
      "backward_entropy": 0.19338295857111612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.247415542602539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013484622351825237,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27269282937049866,
      "backward_entropy": 0.1812279224395752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4893012046813965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013579409569501877,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27265894412994385,
      "backward_entropy": 0.18019707997639975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.067489624023438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013674073852598667,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27262407541275024,
      "backward_entropy": 0.19076057275136313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.973125457763672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013769030570983887,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27258652448654175,
      "backward_entropy": 0.17808864514033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.542226314544678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01386415958404541,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27254509925842285,
      "backward_entropy": 0.17700465520222983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718947410583496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013959167525172234,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27250176668167114,
      "backward_entropy": 0.18799149990081787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.033683776855469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014054208993911743,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2724563777446747,
      "backward_entropy": 0.17479546864827475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.066037654876709,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014148873277008533,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2724139392375946,
      "backward_entropy": 0.18608113129933676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.140543460845947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014243233948946,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27237409353256226,
      "backward_entropy": 0.19710570573806763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.009056091308594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014337328262627125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723335325717926,
      "backward_entropy": 0.1714247465133667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.567513465881348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014431755989789963,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.272287517786026,
      "backward_entropy": 0.1831266681353251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.880139350891113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014526222832500935,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27223968505859375,
      "backward_entropy": 0.1821117401123047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.199091911315918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014620334841310978,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27219676971435547,
      "backward_entropy": 0.18108320236206055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.063760280609131,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014714264310896397,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27215200662612915,
      "backward_entropy": 0.19276710351308188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.10784912109375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014807968400418758,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2721068561077118,
      "backward_entropy": 0.16554294029871622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.461544036865234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014901487156748772,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2720596492290497,
      "backward_entropy": 0.17794746160507202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.529482364654541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014994441531598568,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2720159888267517,
      "backward_entropy": 0.16312367717425028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2298126220703125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015086894854903221,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2719726860523224,
      "backward_entropy": 0.16190940141677856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.266177177429199,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015179425477981567,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27192652225494385,
      "backward_entropy": 0.18808138370513916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.279160499572754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01527203805744648,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2718762159347534,
      "backward_entropy": 0.18710577487945557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.47844934463501,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015364748425781727,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2718219459056854,
      "backward_entropy": 0.18611945708592734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.705994606018066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015456989407539368,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2717685103416443,
      "backward_entropy": 0.1568942666053772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7021989822387695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01554897241294384,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2717137038707733,
      "backward_entropy": 0.1556166410446167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.792944431304932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015641387552022934,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2716484069824219,
      "backward_entropy": 0.1543112794558207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.935858726501465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015733622014522552,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27158209681510925,
      "backward_entropy": 0.18203834692637125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.872905254364014,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01582510583102703,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27152159810066223,
      "backward_entropy": 0.1809859275817871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.656238555908203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015915904194116592,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2714681625366211,
      "backward_entropy": 0.16579598188400269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.115294456481934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01600726880133152,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2714017331600189,
      "backward_entropy": 0.1490658720334371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4477643966674805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016098802909255028,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713286280632019,
      "backward_entropy": 0.1477182904879252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.783548831939697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016190068796277046,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2712570130825043,
      "backward_entropy": 0.16227600971857706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.856581687927246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016281330958008766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2711828947067261,
      "backward_entropy": 0.1450056234995524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.232947826385498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016372641548514366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27110451459884644,
      "backward_entropy": 0.143621563911438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2461676597595215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016463547945022583,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2710263431072235,
      "backward_entropy": 0.14222448070844015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.352569103240967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016554094851017,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2709464430809021,
      "backward_entropy": 0.14081754287083945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.292217254638672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016644448041915894,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2708665430545807,
      "backward_entropy": 0.13940383990605673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.943195819854736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016734594479203224,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2707868814468384,
      "backward_entropy": 0.16990580161412558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.047256946563721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016824277117848396,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27070799469947815,
      "backward_entropy": 0.15369815627733865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.753091335296631,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016913671046495438,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27063167095184326,
      "backward_entropy": 0.15244263410568237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.759288787841797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017002597451210022,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27055972814559937,
      "backward_entropy": 0.15118196606636047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.582381725311279,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01709109917283058,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27048951387405396,
      "backward_entropy": 0.1499179204305013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.298737525939941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017179107293486595,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2704232931137085,
      "backward_entropy": 0.13086469968159994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.866500377655029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017266463488340378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2703632712364197,
      "backward_entropy": 0.1294564207394918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.515781402587891,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01735365390777588,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2702990174293518,
      "backward_entropy": 0.1615521510442098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.239916801452637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017440473660826683,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2702380418777466,
      "backward_entropy": 0.12658028801282248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.836126327514648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017527461051940918,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2701634168624878,
      "backward_entropy": 0.1251185933748881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.60701847076416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017614327371120453,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2700831890106201,
      "backward_entropy": 0.15778868397076926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7502312660217285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01770092360675335,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27000030875205994,
      "backward_entropy": 0.12217286229133606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.055539608001709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017787402495741844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26991257071495056,
      "backward_entropy": 0.12069124976793925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.787437438964844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0178732518106699,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2698304355144501,
      "backward_entropy": 0.13833671808242798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.948584079742432,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017958350479602814,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26975950598716736,
      "backward_entropy": 0.15264720718065897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.221560001373291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018043648451566696,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.269673228263855,
      "backward_entropy": 0.1163007418314616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.811318397521973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01812858134508133,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26958537101745605,
      "backward_entropy": 0.11483136812845866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.940454006195068,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01821283996105194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2694993317127228,
      "backward_entropy": 0.11337234576543172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.731223106384277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018296634778380394,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26941436529159546,
      "backward_entropy": 0.11188785235087077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.183907508850098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0183806624263525,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26931607723236084,
      "backward_entropy": 0.13033627470334372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.969602584838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018464501947164536,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2692180573940277,
      "backward_entropy": 0.14466861883799234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.71530294418335,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018547989428043365,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2691192924976349,
      "backward_entropy": 0.14331725239753723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.051329612731934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01863095350563526,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26902255415916443,
      "backward_entropy": 0.12628597021102905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.455952167510986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018713759258389473,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2689228355884552,
      "backward_entropy": 0.12492827574412028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3785295486450195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018795952200889587,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2688341438770294,
      "backward_entropy": 0.12356815735499065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.571134090423584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01887749880552292,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2687499523162842,
      "backward_entropy": 0.10140073299407959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.288556098937988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01895865984261036,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2686668932437897,
      "backward_entropy": 0.13649028539657593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.970097303390503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019039226695895195,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26858752965927124,
      "backward_entropy": 0.09849226474761963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.352351188659668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01911897026002407,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2685147225856781,
      "backward_entropy": 0.1181785265604655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9688496589660645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019198335707187653,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26843899488449097,
      "backward_entropy": 0.1168057918548584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.986163377761841,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01927703432738781,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2683694362640381,
      "backward_entropy": 0.09423744678497314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8058555126190186,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0193551704287529,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2683054506778717,
      "backward_entropy": 0.11407666405042012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.262394905090332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01943264529109001,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26825010776519775,
      "backward_entropy": 0.09147626161575317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.669525623321533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019509952515363693,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26818737387657166,
      "backward_entropy": 0.1113588015238444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.783215045928955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019586553797125816,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26813024282455444,
      "backward_entropy": 0.11001088221867879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.353978157043457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019662633538246155,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26807186007499695,
      "backward_entropy": 0.0874070127805074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6773948669433594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019738800823688507,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26799488067626953,
      "backward_entropy": 0.12279210488001506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.626344680786133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019814396277070045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26791563630104065,
      "backward_entropy": 0.08470972379048665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3307793140411377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019889475777745247,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26784026622772217,
      "backward_entropy": 0.10468053817749023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.599334239959717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01996382139623165,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26777738332748413,
      "backward_entropy": 0.10336498419443767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6529898643493652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02003779076039791,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2677167057991028,
      "backward_entropy": 0.11737477779388428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4780654907226562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020111478865146637,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26765215396881104,
      "backward_entropy": 0.11604281266530354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4930450916290283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020184729248285294,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26758408546447754,
      "backward_entropy": 0.09942609071731567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1582579612731934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020257599651813507,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2675071358680725,
      "backward_entropy": 0.1133873462677002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.045431137084961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020329806953668594,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2674344778060913,
      "backward_entropy": 0.07572817305723827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.045757532119751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020401330664753914,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2673710286617279,
      "backward_entropy": 0.07450592517852783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.167357921600342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020472262054681778,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26731622219085693,
      "backward_entropy": 0.07330428560574849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8193280696868896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020542776212096214,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2672582268714905,
      "backward_entropy": 0.07211014131704967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7585129737854004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02061253786087036,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26720765233039856,
      "backward_entropy": 0.09178696076075236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5607292652130127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02068156562745571,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.267162024974823,
      "backward_entropy": 0.06978700558344524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7455897331237793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020749706774950027,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26712408661842346,
      "backward_entropy": 0.08934623003005981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.586122512817383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020817287266254425,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2670864164829254,
      "backward_entropy": 0.08814794818560283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.780458927154541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0208841972053051,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26705488562583923,
      "backward_entropy": 0.06645525495211284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4218571186065674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02095074951648712,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2670193910598755,
      "backward_entropy": 0.08577798803647359,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6910948753356934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021016564220190048,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26699262857437134,
      "backward_entropy": 0.06431112190087636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.703490972518921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021082013845443726,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26695331931114197,
      "backward_entropy": 0.06325440605481465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.455970287322998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02114718034863472,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26690226793289185,
      "backward_entropy": 0.06220168868700663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.34851336479187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02121180295944214,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2668495178222656,
      "backward_entropy": 0.06116291880607605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.204979419708252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021275803446769714,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2667956054210663,
      "backward_entropy": 0.06013965606689453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.104459285736084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02133908122777939,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.266746461391449,
      "backward_entropy": 0.059136430422465004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.451216220855713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021401578560471535,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2667020559310913,
      "backward_entropy": 0.07783900698026021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.283834934234619,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021463844925165176,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26664358377456665,
      "backward_entropy": 0.05717355012893677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0860822200775146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021525686606764793,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2665756940841675,
      "backward_entropy": 0.0756729245185852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.033546209335327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02158690057694912,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2665084898471832,
      "backward_entropy": 0.05524600545565287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.00980281829834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021647503599524498,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2664439082145691,
      "backward_entropy": 0.08766149481137593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1436591148376465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021707503125071526,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2663740813732147,
      "backward_entropy": 0.07252438366413116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8168449401855469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021767182275652885,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26629361510276794,
      "backward_entropy": 0.08544284105300903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8520931005477905,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021826129406690598,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2662213444709778,
      "backward_entropy": 0.051565458377202354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7507215738296509,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021884474903345108,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26615098118782043,
      "backward_entropy": 0.05068338910738627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8936805725097656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021942153573036194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2660869359970093,
      "backward_entropy": 0.049820502599080406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8211438655853271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021999435499310493,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26601147651672363,
      "backward_entropy": 0.04896507660547892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6421480178833008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022056259214878082,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26592597365379333,
      "backward_entropy": 0.04811866581439972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.54874849319458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02211240865290165,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2658398747444153,
      "backward_entropy": 0.047288541992505394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6469275951385498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02216782607138157,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26576071977615356,
      "backward_entropy": 0.06467246512571971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.608546257019043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022222748026251793,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2656775712966919,
      "backward_entropy": 0.0456780344247818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.351914644241333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022277168929576874,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26558610796928406,
      "backward_entropy": 0.06284577647844951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4572163820266724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02233072929084301,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26550471782684326,
      "backward_entropy": 0.04412025213241577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.355530858039856,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022383717820048332,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26542210578918457,
      "backward_entropy": 0.061080724000930786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.275068998336792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022436007857322693,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2653392255306244,
      "backward_entropy": 0.042628899216651917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3515654802322388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022487549111247063,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2652621865272522,
      "backward_entropy": 0.04190930724143982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3060033321380615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022538548335433006,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26517578959465027,
      "backward_entropy": 0.04119979838530222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0682018995285034,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02258898876607418,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26508116722106934,
      "backward_entropy": 0.07055700818697612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2079594135284424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022638492286205292,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.264997661113739,
      "backward_entropy": 0.0696695347627004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1039211750030518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022687437012791634,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26490846276283264,
      "backward_entropy": 0.039157480001449585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.06497061252594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022735698148608208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2648226022720337,
      "backward_entropy": 0.055389334758122764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9758032560348511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022783277556300163,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2647397816181183,
      "backward_entropy": 0.03787181774775187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.901329517364502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022830061614513397,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26466330885887146,
      "backward_entropy": 0.06626637776692708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9720392227172852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02287597768008709,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26459580659866333,
      "backward_entropy": 0.036654179294904075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9806361198425293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022921280935406685,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26452726125717163,
      "backward_entropy": 0.05246741076310476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9015202522277832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022966058924794197,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2644522488117218,
      "backward_entropy": 0.03548862785100937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7417373657226562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02301020547747612,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26437702775001526,
      "backward_entropy": 0.03492299218972524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6976615190505981,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023053426295518875,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26431626081466675,
      "backward_entropy": 0.06231337785720825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9036633372306824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023095719516277313,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2642710208892822,
      "backward_entropy": 0.061566938956578575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7265390753746033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023137666285037994,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2642097473144531,
      "backward_entropy": 0.03332811345656713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7718161940574646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023178890347480774,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26415279507637024,
      "backward_entropy": 0.032819358011086784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7258257269859314,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02321958914399147,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2640916109085083,
      "backward_entropy": 0.047877296805381775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6836658716201782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023259704932570457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2640269100666046,
      "backward_entropy": 0.031830097238222756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6198109984397888,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0232991985976696,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2639620900154114,
      "backward_entropy": 0.04667396346728007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6787635087966919,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02333795465528965,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26389768719673157,
      "backward_entropy": 0.030883704622586567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6024337410926819,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023376232013106346,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2638252377510071,
      "backward_entropy": 0.056713362534840904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6073855757713318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02341388165950775,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26375359296798706,
      "backward_entropy": 0.04496624072392782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.527098536491394,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023450998589396477,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2636803090572357,
      "backward_entropy": 0.055444926023483276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5526860952377319,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023487389087677002,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2636079490184784,
      "backward_entropy": 0.04388128717740377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5105390548706055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02352321334183216,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26352930068969727,
      "backward_entropy": 0.043358479936917625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4616897702217102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023558426648378372,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2634517550468445,
      "backward_entropy": 0.05363305409749349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5142688155174255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023592937737703323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2633777856826782,
      "backward_entropy": 0.027878465751806896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4323588013648987,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023626981303095818,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2632916271686554,
      "backward_entropy": 0.052485873301823936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42025336623191833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02366035059094429,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2632061839103699,
      "backward_entropy": 0.05192829171816508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3588540256023407,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023693077266216278,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26311883330345154,
      "backward_entropy": 0.026729491849740345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4195002019405365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02372504025697708,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2630426287651062,
      "backward_entropy": 0.04046450058619181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3534315824508667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02375653199851513,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26295948028564453,
      "backward_entropy": 0.04002063721418381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33609917759895325,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02378736436367035,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2628786563873291,
      "backward_entropy": 0.0395858163634936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3155304491519928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02381756156682968,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2628040909767151,
      "backward_entropy": 0.025338756541411083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3078443109989166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023847095668315887,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2627314031124115,
      "backward_entropy": 0.025015053649743397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32148537039756775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023876000195741653,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2626568078994751,
      "backward_entropy": 0.04836427668730418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26646700501441956,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02390442043542862,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2625783681869507,
      "backward_entropy": 0.047900617122650146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2285146713256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023932170122861862,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2625022232532501,
      "backward_entropy": 0.02408995230992635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2647457420825958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023959161713719368,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2624359428882599,
      "backward_entropy": 0.023801493148008983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20978260040283203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023985635489225388,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2623654305934906,
      "backward_entropy": 0.04657520353794098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1975480616092682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02401139587163925,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2623022496700287,
      "backward_entropy": 0.046155119935671486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21114814281463623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0240364670753479,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2622475028038025,
      "backward_entropy": 0.02298547327518463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20592765510082245,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02406099997460842,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2621968388557434,
      "backward_entropy": 0.03577721615632375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1854018270969391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024085013195872307,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26214462518692017,
      "backward_entropy": 0.03544620176156362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17737683653831482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02410845458507538,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2620927393436432,
      "backward_entropy": 0.02224251627922058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16288356482982635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024131353944540024,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26204290986061096,
      "backward_entropy": 0.022008642554283142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14623603224754333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024153705686330795,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2619999945163727,
      "backward_entropy": 0.02178264657656352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17457695305347443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024175461381673813,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2619631290435791,
      "backward_entropy": 0.03420162697633108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13447469472885132,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024196859449148178,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2619209289550781,
      "backward_entropy": 0.021350284417470295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12589667737483978,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024217680096626282,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26187974214553833,
      "backward_entropy": 0.03362108518679937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10444952547550201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024237964302301407,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2618473172187805,
      "backward_entropy": 0.020942844450473785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14123308658599854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02425759844481945,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2618207335472107,
      "backward_entropy": 0.03307161728541056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09869913756847382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024276895448565483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2617839574813843,
      "backward_entropy": 0.02056162804365158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1260000765323639,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024295607581734657,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2617519795894623,
      "backward_entropy": 0.04163371523221334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09868727624416351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02431398816406727,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2617107927799225,
      "backward_entropy": 0.02019939323266347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10706661641597748,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024331891909241676,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2616721987724304,
      "backward_entropy": 0.04107093314329783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07894878089427948,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024349432438611984,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2616300582885742,
      "backward_entropy": 0.04080095887184143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08901428431272507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02436642162501812,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26159149408340454,
      "backward_entropy": 0.019689762343962986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07414401322603226,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024382995441555977,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2615486681461334,
      "backward_entropy": 0.03137622276941935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07943417876958847,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024399084970355034,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26150816679000854,
      "backward_entropy": 0.01937423398097356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08568444848060608,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0244147889316082,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2614651918411255,
      "backward_entropy": 0.01922300085425377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060325462371110916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024430206045508385,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.261414498090744,
      "backward_entropy": 0.03956286112467448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06905405223369598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024445129558444023,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2613655626773834,
      "backward_entropy": 0.0189300278822581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06202539801597595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02445969730615616,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2613121271133423,
      "backward_entropy": 0.030360395709673565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04517480358481407,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024473901838064194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2612593173980713,
      "backward_entropy": 0.01865228017171224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044045884162187576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02448759600520134,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2612115740776062,
      "backward_entropy": 0.03869260102510452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04021253064274788,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024500828236341476,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2611684799194336,
      "backward_entropy": 0.038493109246095024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04703652858734131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024513600394129753,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2611294686794281,
      "backward_entropy": 0.018275247265895207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041768647730350494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024526037275791168,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26108863949775696,
      "backward_entropy": 0.018157903105020523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03930804505944252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02453812025487423,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26104819774627686,
      "backward_entropy": 0.029317451020081837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02822483703494072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024549851194024086,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2610071301460266,
      "backward_entropy": 0.02916084478298823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0323791466653347,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024561114609241486,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.260969340801239,
      "backward_entropy": 0.03759042670329412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03350552171468735,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02457202784717083,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26093241572380066,
      "backward_entropy": 0.01772657409310341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033245157450437546,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024582644924521446,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26089411973953247,
      "backward_entropy": 0.028723607460657757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027545074000954628,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024592984467744827,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2608521282672882,
      "backward_entropy": 0.037117235362529755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024128111079335213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02460300922393799,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2608107924461365,
      "backward_entropy": 0.03696932395299276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025060731917619705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024612687528133392,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2607698440551758,
      "backward_entropy": 0.028325863182544708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017730168998241425,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02462208829820156,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2607291638851166,
      "backward_entropy": 0.02820146083831787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020660987123847008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024631105363368988,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26069146394729614,
      "backward_entropy": 0.01717392106850942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01866890676319599,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02463984116911888,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26065418124198914,
      "backward_entropy": 0.03642888863881429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02008255198597908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02464827336370945,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2606162130832672,
      "backward_entropy": 0.017014247675736744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01821318082511425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024656489491462708,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26057782769203186,
      "backward_entropy": 0.01693777988354365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013660462573170662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024664463475346565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26053810119628906,
      "backward_entropy": 0.016863393286863964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012767103500664234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024672117084264755,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2604992389678955,
      "backward_entropy": 0.02754008024930954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015684824436903,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024679476395249367,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2604619860649109,
      "backward_entropy": 0.016723667581876118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010540665127336979,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0246866587549448,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2604241669178009,
      "backward_entropy": 0.027348250150680542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008907193318009377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024693546816706657,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26038843393325806,
      "backward_entropy": 0.03565313915411631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008869435638189316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024700121954083443,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26035481691360474,
      "backward_entropy": 0.03555935869614283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009815034456551075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024706430733203888,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2603234052658081,
      "backward_entropy": 0.016474080582459767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00843589473515749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024712512269616127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2602914869785309,
      "backward_entropy": 0.016417978952328365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009282365441322327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02471834421157837,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2602593004703522,
      "backward_entropy": 0.016364070276419323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007711877580732107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02472398802638054,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26022613048553467,
      "backward_entropy": 0.035221442580223083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00673044566065073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02472943812608719,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26019415259361267,
      "backward_entropy": 0.01626097907622655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00707336375489831,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024734679609537125,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26016342639923096,
      "backward_entropy": 0.035071556766827904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006322472356259823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02473972924053669,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2601318061351776,
      "backward_entropy": 0.016165399303038914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0066041238605976105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024744585156440735,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2600999176502228,
      "backward_entropy": 0.016120115915934246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005944496486335993,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024749305099248886,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26006805896759033,
      "backward_entropy": 0.026519482334454853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004483010619878769,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0247538723051548,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26003605127334595,
      "backward_entropy": 0.034805141389369965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004773695021867752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024758221581578255,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2600044012069702,
      "backward_entropy": 0.01599255825082461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031856161076575518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024762403219938278,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2599727511405945,
      "backward_entropy": 0.015953267614046734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043631126172840595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02476636692881584,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2599429190158844,
      "backward_entropy": 0.026294603943824768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003808199195191264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02477017417550087,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2599121928215027,
      "backward_entropy": 0.02624448388814926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002658843295648694,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02477385103702545,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.259882390499115,
      "backward_entropy": 0.01584554711977641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003860797267407179,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024777326732873917,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2598537802696228,
      "backward_entropy": 0.03448605537414551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028864985797554255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02478070929646492,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2598246932029724,
      "backward_entropy": 0.026105249921480816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003154529258608818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02478393353521824,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2597957253456116,
      "backward_entropy": 0.026062699655691784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022880255710333586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024787047877907753,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25976642966270447,
      "backward_entropy": 0.0157201886177063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028787420596927404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02479000948369503,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2597379982471466,
      "backward_entropy": 0.02598259598016739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002116740681231022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024792887270450592,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25970932841300964,
      "backward_entropy": 0.01566416894396146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002333768643438816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024795640259981155,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25968146324157715,
      "backward_entropy": 0.01563768833875656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018207367975264788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024798264726996422,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25965288281440735,
      "backward_entropy": 0.015612275650103888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015255056787282228,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024800758808851242,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2596248984336853,
      "backward_entropy": 0.02584097037712733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001754407538101077,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02480311691761017,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2595979571342468,
      "backward_entropy": 0.025809742510318756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011814490426331758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024805381894111633,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.259571373462677,
      "backward_entropy": 0.025779731571674347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013966375263407826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024807510897517204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25954610109329224,
      "backward_entropy": 0.015522041668494543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014398556668311357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02480953186750412,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2595212459564209,
      "backward_entropy": 0.02572436382373174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000957766838837415,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02481146529316902,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2594964802265167,
      "backward_entropy": 0.025698522726694744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001219813129864633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024813242256641388,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25947239995002747,
      "backward_entropy": 0.03402167558670044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010581112001091242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02481493540108204,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25944846868515015,
      "backward_entropy": 0.025651747981707256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012700132792815566,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024816561490297318,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25942519307136536,
      "backward_entropy": 0.015431998918453852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010657338425517082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024818137288093567,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2594016492366791,
      "backward_entropy": 0.03396365294853846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009174261358566582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024819666519761086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25937843322753906,
      "backward_entropy": 0.015400577336549759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009261877276003361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02482111193239689,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2593556046485901,
      "backward_entropy": 0.03392875691254934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009752633050084114,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024822475388646126,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2593328654766083,
      "backward_entropy": 0.03391316036383311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009328080341219902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024823801591992378,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.259310245513916,
      "backward_entropy": 0.03389800091584524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007684141164645553,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0248250849545002,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25928759574890137,
      "backward_entropy": 0.033883472283681236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006751010078005493,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0248262956738472,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2592652440071106,
      "backward_entropy": 0.03386994699637095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000664555816911161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024827441200613976,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25924330949783325,
      "backward_entropy": 0.01531984657049179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006068605580367148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02482854202389717,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2592218518257141,
      "backward_entropy": 0.025468595325946808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005445208516903222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024829605594277382,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2592009902000427,
      "backward_entropy": 0.025454290211200714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004841818008571863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02483060397207737,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25918063521385193,
      "backward_entropy": 0.03382309774557749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005246447981335223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024831527844071388,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25916093587875366,
      "backward_entropy": 0.015276228388150534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005353550659492612,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024832377210259438,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2591415047645569,
      "backward_entropy": 0.015266918887694677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005044262506999075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024833183735609055,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25912219285964966,
      "backward_entropy": 0.015257934729258219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038420004420913756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024833934381604195,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25910308957099915,
      "backward_entropy": 0.033790367345015206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000422582495957613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024834640324115753,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25908464193344116,
      "backward_entropy": 0.03378397226333618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004561718087643385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02483530528843403,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25906649231910706,
      "backward_entropy": 0.015233938892682394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003990432305727154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024835940450429916,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2590484917163849,
      "backward_entropy": 0.015226572751998901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034012531978078187,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024836547672748566,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2590307593345642,
      "backward_entropy": 0.015219452480475107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039072701474651694,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02483714558184147,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2590135335922241,
      "backward_entropy": 0.033762454986572266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003469465300440788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02483772113919258,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25899645686149597,
      "backward_entropy": 0.015205721060434977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003855295362882316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024838237091898918,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25897958874702454,
      "backward_entropy": 0.015199482440948486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035398785257712007,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024838710203766823,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2589626908302307,
      "backward_entropy": 0.025327689945697784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003654325264506042,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024839162826538086,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25894588232040405,
      "backward_entropy": 0.025321175654729206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024157925508916378,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02483956143260002,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258929044008255,
      "backward_entropy": 0.033745417992273964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024623185163363814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024839917197823524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2589128017425537,
      "backward_entropy": 0.015177872031927109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002363002422498539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484024502336979,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25889700651168823,
      "backward_entropy": 0.015173359463612238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024677737383171916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024840572848916054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25888168811798096,
      "backward_entropy": 0.015168913950522741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002488578320480883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024840887635946274,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2588665783405304,
      "backward_entropy": 0.015164585163195929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001827533997129649,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024841176345944405,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2588517367839813,
      "backward_entropy": 0.015160455058018366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025234383065253496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024841472506523132,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25883737206459045,
      "backward_entropy": 0.015156318744023642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026119936956092715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024841759353876114,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258823037147522,
      "backward_entropy": 0.015152296672264734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017684829072095454,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024842001497745514,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2588087022304535,
      "backward_entropy": 0.025278498729070027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022768675989937037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024842219427227974,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25879478454589844,
      "backward_entropy": 0.015145236005385717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023695346317254007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484241873025894,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25878089666366577,
      "backward_entropy": 0.015142002453406652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001583907287567854,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024842599406838417,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25876694917678833,
      "backward_entropy": 0.015138939023017883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016288137703668326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484278380870819,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2587534189224243,
      "backward_entropy": 0.015135825922091803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017524788563605398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024842968210577965,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2587401270866394,
      "backward_entropy": 0.03373869756857554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001547660504002124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024843135848641396,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2587270736694336,
      "backward_entropy": 0.015129895259936651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018916625413112342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024843299761414528,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2587142288684845,
      "backward_entropy": 0.015127085149288177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013922790822107345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024843435734510422,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2587014138698578,
      "backward_entropy": 0.015124525874853134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011682566400850192,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484356053173542,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25868892669677734,
      "backward_entropy": 0.02525303264458974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012896984117105603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484368160367012,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25867679715156555,
      "backward_entropy": 0.015119671821594238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001233200018759817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484380081295967,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25866496562957764,
      "backward_entropy": 0.015117360899845758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001382048794766888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024843916296958923,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25865331292152405,
      "backward_entropy": 0.015115077296892801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014205837214831263,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844007566571236,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2586418688297272,
      "backward_entropy": 0.01511299858490626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011562601139303297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844083935022354,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2586304545402527,
      "backward_entropy": 0.025243679682413738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.918456296669319e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02484414167702198,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2586192488670349,
      "backward_entropy": 0.03374981631835302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012490546214394271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844206869602203,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2586084306240082,
      "backward_entropy": 0.015107554694016775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001323893666267395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484426647424698,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25859761238098145,
      "backward_entropy": 0.015105837335189184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.009383211378008e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844305589795113,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2585867941379547,
      "backward_entropy": 0.03375524034102758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.511057967552915e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484433352947235,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25857630372047424,
      "backward_entropy": 0.015102922916412354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.96239692135714e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844376370310783,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2585659921169281,
      "backward_entropy": 0.02523663391669591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.358370152767748e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844419211149216,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25855597853660583,
      "backward_entropy": 0.025235566000143688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.252179446164519e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844452738761902,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2585461139678955,
      "backward_entropy": 0.03376304109891256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.084592991508543e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844486266374588,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25853654742240906,
      "backward_entropy": 0.015097104012966156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256221190094948e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844521656632423,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25852712988853455,
      "backward_entropy": 0.01509574552377065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.286368104862049e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844542145729065,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.258517861366272,
      "backward_entropy": 0.025232017040252686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.202382792253047e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844562634825706,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25850895047187805,
      "backward_entropy": 0.015093387415011724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.952405313611962e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844584986567497,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25850024819374084,
      "backward_entropy": 0.015092228849728903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.638599446276203e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844612926244736,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25849196314811707,
      "backward_entropy": 0.033773861825466156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7743709476199e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844642728567123,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2584840655326843,
      "backward_entropy": 0.01508993903795878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.741477096104063e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844670668244362,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25847628712654114,
      "backward_entropy": 0.03377679238716761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.512385905603878e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484470047056675,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25846871733665466,
      "backward_entropy": 0.025227539241313934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.159290933283046e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484472282230854,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25846126675605774,
      "backward_entropy": 0.02522689352432887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.098346784710884e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844741448760033,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2584537863731384,
      "backward_entropy": 0.033781200647354126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.969133831560612e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484475076198578,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2584463059902191,
      "backward_entropy": 0.015084760884443918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.644060754799284e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844763800501823,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2584390640258789,
      "backward_entropy": 0.025225174923737843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3514756069052964e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484477125108242,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25843191146850586,
      "backward_entropy": 0.025224690635999043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.704983803094365e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844784289598465,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2584250271320343,
      "backward_entropy": 0.015082091093063354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.400558100314811e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844786152243614,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2584182322025299,
      "backward_entropy": 0.033789257208506264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.180327621521428e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844786152243614,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2584114670753479,
      "backward_entropy": 0.033790960907936096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.477814243524335e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844786152243614,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2584049701690674,
      "backward_entropy": 0.033792595068613686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1667437471915036e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844788014888763,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2583985924720764,
      "backward_entropy": 0.033794124921162925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.262852260377258e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844782426953316,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25839224457740784,
      "backward_entropy": 0.02522234121958415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.260063335299492e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844776839017868,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2583860158920288,
      "backward_entropy": 0.0150777796904246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4767234208411537e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844752624630928,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2583796977996826,
      "backward_entropy": 0.015077276776234308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.94716937787598e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844728410243988,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25837358832359314,
      "backward_entropy": 0.015076772620280584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.617202673922293e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844707921147346,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2583676278591156,
      "backward_entropy": 0.015076308200756708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.219273639842868e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484467625617981,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25836166739463806,
      "backward_entropy": 0.02522171785434087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0072451661690138e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844639003276825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2583558261394501,
      "backward_entropy": 0.015075566867987314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.100671892752871e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844611063599586,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2583501636981964,
      "backward_entropy": 0.03380950540304184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3263932234840468e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484457939863205,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25834453105926514,
      "backward_entropy": 0.025221737722555797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0726383809233084e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844547733664513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2583390474319458,
      "backward_entropy": 0.015074451764424643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7588357877684757e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844517931342125,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2583337128162384,
      "backward_entropy": 0.025221745173136394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6539697753614746e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844491854310036,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2583285868167877,
      "backward_entropy": 0.03381713728109995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5964491467457265e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844475090503693,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2583235800266266,
      "backward_entropy": 0.02522158871094386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4520676813845057e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0248444601893425,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25831878185272217,
      "backward_entropy": 0.03382021685441335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0893219698336907e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844445288181305,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2583141624927521,
      "backward_entropy": 0.03382167965173721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5197176253423095e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844428524374962,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258309543132782,
      "backward_entropy": 0.015072149535020193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.837122908909805e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484441176056862,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25830507278442383,
      "backward_entropy": 0.025221116840839386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8146947695640847e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844393134117126,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25830066204071045,
      "backward_entropy": 0.03382613758246104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5465840988326818e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844368919730186,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25829628109931946,
      "backward_entropy": 0.0338276798526446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2943506590090692e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844344705343246,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25829198956489563,
      "backward_entropy": 0.03382924944162369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.126647384808166e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844326078891754,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25828781723976135,
      "backward_entropy": 0.03383068988720576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5066138075781055e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484431304037571,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25828370451927185,
      "backward_entropy": 0.025220856070518494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.582092050346546e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844296276569366,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2582796514034271,
      "backward_entropy": 0.025220751762390137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.647216418466996e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484428510069847,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582758069038391,
      "backward_entropy": 0.01506960391998291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0606981049932074e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844275787472725,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25827205181121826,
      "backward_entropy": 0.015069253742694855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.17870932223741e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02484426647424698,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25826844573020935,
      "backward_entropy": 0.03383683909972509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1726895536412485e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484426274895668,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582648992538452,
      "backward_entropy": 0.015068542212247849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.282227438234258e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844257161021233,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25826138257980347,
      "backward_entropy": 0.015068179617325464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.933262284292141e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844253435730934,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582579255104065,
      "backward_entropy": 0.01506782074769338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.710250206902856e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844251573085785,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2582545876502991,
      "backward_entropy": 0.025219537317752838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.785719390085433e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844255298376083,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258251428604126,
      "backward_entropy": 0.015067062030235926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.737026524206158e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844257161021233,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25824832916259766,
      "backward_entropy": 0.03384229044119517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.498613856820157e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484426088631153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582452893257141,
      "backward_entropy": 0.015066339323918024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.810166946204845e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484426274895668,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2582423686981201,
      "backward_entropy": 0.025218576192855835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7092070164799225e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484426088631153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25823941826820374,
      "backward_entropy": 0.015065693606932959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6481417232134845e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484426088631153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582365870475769,
      "backward_entropy": 0.015065362056096395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.853851689607836e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484426274895668,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25823381543159485,
      "backward_entropy": 0.025217950344085693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.046842372597894e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02484426274895668,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25823113322257996,
      "backward_entropy": 0.03384679804245631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.739468517480418e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484426088631153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25822848081588745,
      "backward_entropy": 0.015064507722854614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.126148269278929e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844255298376083,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25822585821151733,
      "backward_entropy": 0.025217436254024506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.71455597714521e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844251573085785,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582233250141144,
      "backward_entropy": 0.01506399487455686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9658194762305357e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02484424039721489,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25822076201438904,
      "backward_entropy": 0.03385003904501597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6203061881678877e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844232946634293,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25821831822395325,
      "backward_entropy": 0.015063591301441193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7156682992645074e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844227358698845,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258215993642807,
      "backward_entropy": 0.033851576348145805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.259268735040678e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844223633408546,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25821372866630554,
      "backward_entropy": 0.015063179035981497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8601768917724257e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0248442180454731,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25821149349212646,
      "backward_entropy": 0.015062980353832245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3234943000716157e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484421618282795,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25820934772491455,
      "backward_entropy": 0.015062771737575531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1752336983336136e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484421618282795,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2582073509693146,
      "backward_entropy": 0.025216353436311085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3862384043459315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0248442143201828,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2582053244113922,
      "backward_entropy": 0.025216206908226013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5500382889731554e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484421245753765,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25820332765579224,
      "backward_entropy": 0.015062121053536734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0492659587034723e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484421245753765,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582014203071594,
      "backward_entropy": 0.015061916162570318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4531101391621633e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0248442143201828,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581995725631714,
      "backward_entropy": 0.03385653098424276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.562469944678014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02484421245753765,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25819775462150574,
      "backward_entropy": 0.03385708977778753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4181077808170812e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844210594892502,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581959664821625,
      "backward_entropy": 0.015061327566703161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.84869065581006e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844206869602203,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581941783428192,
      "backward_entropy": 0.03385817507902781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9781937226071022e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844201281666756,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25819242000579834,
      "backward_entropy": 0.02521525075038274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.567846422607545e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844195693731308,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25819072127342224,
      "backward_entropy": 0.0338593473037084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7265931546717184e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02484419010579586,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25818902254104614,
      "backward_entropy": 0.03385994086662928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4785127859795466e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844184517860413,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581874132156372,
      "backward_entropy": 0.015060597409804663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5655929246349842e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844180792570114,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25818589329719543,
      "backward_entropy": 0.0252148633201917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9472545318421908e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844178929924965,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25818440318107605,
      "backward_entropy": 0.015060331672430038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7359656112603261e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844177067279816,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25818294286727905,
      "backward_entropy": 0.025214662154515583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8669097698875703e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844173341989517,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25818154215812683,
      "backward_entropy": 0.015060052275657654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.15079842544219e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484416961669922,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581801116466522,
      "backward_entropy": 0.015059952934583029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4104589354246855e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484416589140892,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581787705421448,
      "backward_entropy": 0.01505982130765915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4153799838823033e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02484416402876377,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581774592399597,
      "backward_entropy": 0.03386383503675461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5219600300042657e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844160303473473,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25817620754241943,
      "backward_entropy": 0.015059581647316614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1255868912485312e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25817492604255676,
      "backward_entropy": 0.0338647315899531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.997892907951609e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844152852892876,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25817370414733887,
      "backward_entropy": 0.015059391657511393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2125793773520854e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844150990247726,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25817257165908813,
      "backward_entropy": 0.015059264997641245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.790443644102197e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844149127602577,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258171409368515,
      "backward_entropy": 0.03386594851811727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.621430538369168e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844149127602577,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25817030668258667,
      "backward_entropy": 0.02521362652381261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1456269248810713e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844150990247726,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581692039966583,
      "backward_entropy": 0.02521352966626485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.270165838235698e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844150990247726,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25816813111305237,
      "backward_entropy": 0.025213412940502167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0458671795277041e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844152852892876,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581670880317688,
      "backward_entropy": 0.025213271379470825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.285816880335915e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844152852892876,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25816604495048523,
      "backward_entropy": 0.025213186939557392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.719810923845216e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844154715538025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25816506147384644,
      "backward_entropy": 0.015058406939109167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.978806249615445e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25816407799720764,
      "backward_entropy": 0.033868059515953064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.796770435357757e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25816312432289124,
      "backward_entropy": 0.03386835753917694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.301396524577285e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25816217064857483,
      "backward_entropy": 0.03386864314476649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.091360885169706e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581612765789032,
      "backward_entropy": 0.025212655464808147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.334623895374534e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581603527069092,
      "backward_entropy": 0.015057874222596487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.175762680664775e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25815948843955994,
      "backward_entropy": 0.033869437873363495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.637919571199745e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844158440828323,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581586539745331,
      "backward_entropy": 0.033869676291942596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.617776762141148e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844158440828323,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581578493118286,
      "backward_entropy": 0.02521226058403651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.122362267684366e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844158440828323,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25815701484680176,
      "backward_entropy": 0.0338701531291008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.821776767334086e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844158440828323,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581562399864197,
      "backward_entropy": 0.02521210660537084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.724234029003128e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844156578183174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581554651260376,
      "backward_entropy": 0.015057319154342016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.672723091265652e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844154715538025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25815466046333313,
      "backward_entropy": 0.015057267000277838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3516303094293107e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844150990247726,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25815388560295105,
      "backward_entropy": 0.015057183802127838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.515226521561999e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844147264957428,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25815311074256897,
      "backward_entropy": 0.033871578673521675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1617972834064858e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484414353966713,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581523656845093,
      "backward_entropy": 0.015057101845741272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0445448235004733e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02484414167702198,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258151650428772,
      "backward_entropy": 0.015057016164064407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.203690823738725e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484413981437683,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25815096497535706,
      "backward_entropy": 0.02521176387866338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4812447918520775e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844137951731682,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25815027952194214,
      "backward_entropy": 0.015056936691204706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0370478043550975e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844136089086533,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258149653673172,
      "backward_entropy": 0.033872837821642555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5207805265381467e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844134226441383,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25814899802207947,
      "backward_entropy": 0.015056802580753962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1359536478703376e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844132363796234,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581484019756317,
      "backward_entropy": 0.015056765327850977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8837161519513757e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844130501151085,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25814780592918396,
      "backward_entropy": 0.015056716899077097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9778607313346583e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844128638505936,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581472396850586,
      "backward_entropy": 0.015056684613227844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.701141343346535e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844126775860786,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581466734409332,
      "backward_entropy": 0.02521142115195592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2050555514852022e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844124913215637,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25814613699913025,
      "backward_entropy": 0.03387413422266642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5332595637573831e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25814560055732727,
      "backward_entropy": 0.015056526909271875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6812634839880047e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581450939178467,
      "backward_entropy": 0.01505648841460546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.453930309480711e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581446170806885,
      "backward_entropy": 0.025211234887440998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9749612079067447e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581441402435303,
      "backward_entropy": 0.0252111554145813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4353989286064461e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25814369320869446,
      "backward_entropy": 0.025211100776990254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6424118598479254e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25814324617385864,
      "backward_entropy": 0.025211066007614136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1882377748406725e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581427991390228,
      "backward_entropy": 0.03387529402971268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0260068705747472e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581424117088318,
      "backward_entropy": 0.015056196600198746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1652912235149415e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25814199447631836,
      "backward_entropy": 0.025210907061894734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.550106389913708e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581416070461273,
      "backward_entropy": 0.02521081765492757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.677321261529869e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581412196159363,
      "backward_entropy": 0.015056058764457703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.111112482021781e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581408619880676,
      "backward_entropy": 0.015056030203898748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.956002269158489e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258140504360199,
      "backward_entropy": 0.015055996676286062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.769003384008101e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581401467323303,
      "backward_entropy": 0.033876205484072365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.346165086299152e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813978910446167,
      "backward_entropy": 0.025210604071617126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.765508852093262e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581394612789154,
      "backward_entropy": 0.03387644390265147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.771436282335344e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813913345336914,
      "backward_entropy": 0.01505581537882487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.777669708275425e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813883543014526,
      "backward_entropy": 0.015055796752373377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.884655334715717e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581385374069214,
      "backward_entropy": 0.025210422774155933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.759252902886146e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581382095813751,
      "backward_entropy": 0.033876895904541016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.537892005553658e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258137971162796,
      "backward_entropy": 0.015055721004803976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0103182047678274e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813770294189453,
      "backward_entropy": 0.015055653949578604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.74007890716166e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813743472099304,
      "backward_entropy": 0.015055635323127111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.125152486267325e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813719630241394,
      "backward_entropy": 0.015055606762568155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.867375125172657e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813692808151245,
      "backward_entropy": 0.015055588136116663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.429827692500112e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813671946525574,
      "backward_entropy": 0.015055568267901739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.628077476809267e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813648104667664,
      "backward_entropy": 0.025210087498029072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.816837335079981e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581362724304199,
      "backward_entropy": 0.025210040311018627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6019258686792455e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581360638141632,
      "backward_entropy": 0.015055470168590546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.856680308444993e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581358551979065,
      "backward_entropy": 0.025209973255793255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.636935730355617e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581356465816498,
      "backward_entropy": 0.03387780239184698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.01291152027261e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813543796539307,
      "backward_entropy": 0.03387788931528727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.213436710642782e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813522934913635,
      "backward_entropy": 0.015055399388074875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.686614664071385e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.258135050535202,
      "backward_entropy": 0.025209846595923107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.172725288573929e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581348717212677,
      "backward_entropy": 0.01505537579456965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.848144120548568e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581346929073334,
      "backward_entropy": 0.01505536213517189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0997532601541025e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813451409339905,
      "backward_entropy": 0.033878241976102196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3773445434471796e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581343352794647,
      "backward_entropy": 0.015055285145839056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.984477648875327e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581341862678528,
      "backward_entropy": 0.025209705034891765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9969874642811192e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813400745391846,
      "backward_entropy": 0.025209665298461914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7715548139562998e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581338882446289,
      "backward_entropy": 0.015055247892936071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.084465222651488e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813373923301697,
      "backward_entropy": 0.015055236717065176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8545438962291882e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813359022140503,
      "backward_entropy": 0.03387860208749771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4630591849140728e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581334412097931,
      "backward_entropy": 0.025209563473860424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4505914691653743e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813332200050354,
      "backward_entropy": 0.033878691494464874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.844342230280745e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581331729888916,
      "backward_entropy": 0.03387875606616338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1974464086961234e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813305377960205,
      "backward_entropy": 0.03387879580259323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2961573148118077e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581329345703125,
      "backward_entropy": 0.025209481517473858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0843605124932765e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813281536102295,
      "backward_entropy": 0.03387888272603353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0186738563788822e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581326961517334,
      "backward_entropy": 0.033878917495409645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.883471653258312e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813257694244385,
      "backward_entropy": 0.025209384659926098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.982620786606276e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581324875354767,
      "backward_entropy": 0.015055065353711447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.473881957764661e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581323981285095,
      "backward_entropy": 0.025209339956442516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.577718174114125e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813227891921997,
      "backward_entropy": 0.015055046727259954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.159201231843326e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581322193145752,
      "backward_entropy": 0.025209295252958935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.792026940871665e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813210010528564,
      "backward_entropy": 0.015055018166700998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9499321853072615e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581320106983185,
      "backward_entropy": 0.015054999540249506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.923673995766876e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581319212913513,
      "backward_entropy": 0.03387910375992457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.793246771190752e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813186168670654,
      "backward_entropy": 0.025209176043669384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.53406023837033e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581317722797394,
      "backward_entropy": 0.033879188199838005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.969621159034432e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581317126750946,
      "backward_entropy": 0.015054913858572641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.08804021137621e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813165307044983,
      "backward_entropy": 0.03387921551863352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.69370506298128e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813156366348267,
      "backward_entropy": 0.033879230419794716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.850523455639632e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581315040588379,
      "backward_entropy": 0.015054885298013687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.317211559940915e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581314444541931,
      "backward_entropy": 0.015054876605669657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.673367470786616e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813138484954834,
      "backward_entropy": 0.015054867913325628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.881236748133233e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813132524490356,
      "backward_entropy": 0.015054867913325628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.587352637168806e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581312656402588,
      "backward_entropy": 0.02520898977915446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5583358481972027e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258131206035614,
      "backward_entropy": 0.015054848045110703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0372024067683014e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813114643096924,
      "backward_entropy": 0.01505483811100324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.546549637827411e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813108682632446,
      "backward_entropy": 0.01505483811100324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0366926750957646e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581310272216797,
      "backward_entropy": 0.03387939433256785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8119586659158813e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581309974193573,
      "backward_entropy": 0.015054819484551748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.294154282684758e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581309676170349,
      "backward_entropy": 0.015054809550444284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.989708036693628e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813090801239014,
      "backward_entropy": 0.015054804583390554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4373072449179745e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813084840774536,
      "backward_entropy": 0.015054799616336823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.13722728403809e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.258130818605423,
      "backward_entropy": 0.025208855668703716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3564723505842267e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581307590007782,
      "backward_entropy": 0.0338795135418574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3582237556875043e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581307291984558,
      "backward_entropy": 0.015054790923992792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9175914189872856e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813066959381104,
      "backward_entropy": 0.03387953837712606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.971477203710492e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813063979148865,
      "backward_entropy": 0.015054785956939062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.49791645753794e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813058018684387,
      "backward_entropy": 0.025208820899327595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.658207793298061e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581305503845215,
      "backward_entropy": 0.03387957811355591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4700844985782169e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581305205821991,
      "backward_entropy": 0.0150547722975413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3714824831367878e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581304907798767,
      "backward_entropy": 0.02520879606405894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5102727957128081e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813043117523193,
      "backward_entropy": 0.0150547722975413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3963159517516033e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813043117523193,
      "backward_entropy": 0.025208788613478344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.395346640099888e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813037157058716,
      "backward_entropy": 0.0150547722975413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1386092069187725e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813034176826477,
      "backward_entropy": 0.03387969980637232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.106884135690052e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581303119659424,
      "backward_entropy": 0.015054726352294287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.480771557766275e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813028216362,
      "backward_entropy": 0.015054726352294287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.600604590152216e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581302523612976,
      "backward_entropy": 0.025208724041779835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0473826250745333e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813019275665283,
      "backward_entropy": 0.025208724041779835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.477023362094769e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813019275665283,
      "backward_entropy": 0.025208724041779835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.95647975387692e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25813016295433044,
      "backward_entropy": 0.03387978176275889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.924327860564517e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25813013315200806,
      "backward_entropy": 0.015054716418186823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.869082997378428e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25813010334968567,
      "backward_entropy": 0.02520870914061864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.353264663834125e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581300735473633,
      "backward_entropy": 0.02520870914061864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.132960723130964e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581300735473633,
      "backward_entropy": 0.02520869920651118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.466063157655299e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581300139427185,
      "backward_entropy": 0.033879831433296204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.991402763858787e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581300139427185,
      "backward_entropy": 0.015054711451133093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5907277979040373e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581299841403961,
      "backward_entropy": 0.025208694239457447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.701039640371164e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812995433807373,
      "backward_entropy": 0.0338798463344574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.845546103775632e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812995433807373,
      "backward_entropy": 0.015054706484079361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.706510736696146e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812992453575134,
      "backward_entropy": 0.015054706484079361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6548186699292273e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812989473342896,
      "backward_entropy": 0.02520867685476939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3653435593805625e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812989473342896,
      "backward_entropy": 0.02520867685476939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.766942313632171e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812989473342896,
      "backward_entropy": 0.015054706484079361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9322856082435464e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812986493110657,
      "backward_entropy": 0.015054706484079361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8902036319777835e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581298351287842,
      "backward_entropy": 0.025208661953608196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8474644864218135e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581298351287842,
      "backward_entropy": 0.015054706484079361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0302516051960993e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581298053264618,
      "backward_entropy": 0.015054706484079361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.965663270515506e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581297755241394,
      "backward_entropy": 0.015054706484079361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1874768663110444e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581297755241394,
      "backward_entropy": 0.025208647052447002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0269652623028378e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581297755241394,
      "backward_entropy": 0.025208647052447002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0018120494569303e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.258129745721817,
      "backward_entropy": 0.015054696549971899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0733637029479723e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258129745721817,
      "backward_entropy": 0.033879960576693215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8196999462816166e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258129745721817,
      "backward_entropy": 0.033879960576693215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.737401333912203e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812971591949463,
      "backward_entropy": 0.03387997051080068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6576962025283137e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812968611717224,
      "backward_entropy": 0.03387997051080068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.574562702444382e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812968611717224,
      "backward_entropy": 0.015054696549971899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.382236547442517e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812968611717224,
      "backward_entropy": 0.015054696549971899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3634249285132682e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812965631484985,
      "backward_entropy": 0.02520863215128581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2599343790498096e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812965631484985,
      "backward_entropy": 0.02520863215128581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.297308926950791e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812965631484985,
      "backward_entropy": 0.03388000031312307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1151968237754772e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812962651252747,
      "backward_entropy": 0.0150546928246816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2604317589648417e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812962651252747,
      "backward_entropy": 0.02520863215128581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0869705135974073e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812962651252747,
      "backward_entropy": 0.015054687857627869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0255973847961286e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812962651252747,
      "backward_entropy": 0.03388001024723053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0331291377951857e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812962651252747,
      "backward_entropy": 0.015054687857627869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.097789188672323e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812962651252747,
      "backward_entropy": 0.03388001521428426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.181633231492015e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295967102051,
      "backward_entropy": 0.03388001024723053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93578544491902e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581295967102051,
      "backward_entropy": 0.025208617250124615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.465050882477954e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.015054687857627869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.594724931754172e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.015054682890574137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.229061793623259e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.025208575030167896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.145217750803567e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.015054682890574137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.038636340439552e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.015054682890574137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.17106366007647e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.03388006488482157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.876543696103909e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.03388006488482157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.702460725842684e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295669078827,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5138116294983774e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.508482558980177e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7757353627275734e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.916422824408073e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.03388006488482157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.533262654149439e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.03388007481892904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5716319618804846e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.193445590772171e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.03388007481892904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.320099833421409e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.025208560129006703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0536463075113716e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581295371055603,
      "backward_entropy": 0.025208552678426106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7701397559430916e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295073032379,
      "backward_entropy": 0.03388007481892904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.736033704626607e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295073032379,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.682742999444599e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295073032379,
      "backward_entropy": 0.03388007481892904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.738165332833887e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581295073032379,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5697667044587433e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581295073032379,
      "backward_entropy": 0.03388007481892904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.399236447876319e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.015054677923520407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2240876635114546e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.015054674198230108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.98001623377786e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.033880069851875305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5933033498404257e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.033880069851875305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.532907217300817e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.025208537777264912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5554669491612003e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.015054669231176376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6759039428725373e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.015054674198230108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4650503860357276e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.025208537777264912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.19753104602205e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.025208537777264912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.19753104602205e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.015054669231176376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2390977960640157e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2581294775009155,
      "backward_entropy": 0.033880069851875305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1792345705762273e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812944769859314,
      "backward_entropy": 0.025208537777264912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1927348825556692e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812944769859314,
      "backward_entropy": 0.033880069851875305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0765611452588928e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812944769859314,
      "backward_entropy": 0.025208537777264912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0962787061762356e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25812944769859314,
      "backward_entropy": 0.015054669231176376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.135713828010921e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25812944769859314,
      "backward_entropy": 0.025208537777264912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0179413695586845e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024844123050570488,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25812944769859314,
      "backward_entropy": 0.033880069851875305,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 4.942061337942505e-10,
    "avg_log_Z": 0.024844123050570488,
    "success_rate": 1.0,
    "avg_reward": 38.7,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.28,
      "1": 0.29,
      "2": 0.43
    },
    "avg_forward_entropy": 0.2581298580765724,
    "avg_backward_entropy": 0.023270422158141933,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}