{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.22988750537236533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23049024740854898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.832049369812012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743302583694458,
      "backward_entropy": 0.23080305258433023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.829607009887695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000001202570274,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27432456612586975,
      "backward_entropy": 0.2307859261830648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.567380905151367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019999983487650752,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27431875467300415,
      "backward_entropy": 0.2304340402285258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.658400535583496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000299948500469327,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274311363697052,
      "backward_entropy": 0.23074938853581747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.220760345458984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003998798783868551,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743058204650879,
      "backward_entropy": 0.23073023557662964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39500904083252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004997010692022741,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742999494075775,
      "backward_entropy": 0.23070998986562094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.475963592529297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005994916427880526,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742946445941925,
      "backward_entropy": 0.23030934731165567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.615540504455566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006992931012064219,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742891311645508,
      "backward_entropy": 0.23027553160985312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.637242317199707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007988453144207597,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742839455604553,
      "backward_entropy": 0.23024078210194907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788243770599365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008985402528196573,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742779850959778,
      "backward_entropy": 0.23061992724736533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528317928314209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009980571921914816,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742728590965271,
      "backward_entropy": 0.23059495290120444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.12550163269043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010973543394356966,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27426856756210327,
      "backward_entropy": 0.2301300366719564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.041662216186523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011966800084337592,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27426445484161377,
      "backward_entropy": 0.22945241133371988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.720560073852539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00129599473439157,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742609679698944,
      "backward_entropy": 0.23005330562591553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.766793251037598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001395537401549518,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27425718307495117,
      "backward_entropy": 0.23048563798268637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.458134651184082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014949706383049488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742530107498169,
      "backward_entropy": 0.22997385263442993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.279106140136719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001594533328898251,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27424880862236023,
      "backward_entropy": 0.23042680819829306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71249008178711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016941564390435815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27424412965774536,
      "backward_entropy": 0.22923537095387778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289545059204102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017939656972885132,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27423936128616333,
      "backward_entropy": 0.22918937603632608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.708070755004883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018937683198601007,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27423524856567383,
      "backward_entropy": 0.2303308049837748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.68799352645874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019937308970838785,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742310166358948,
      "backward_entropy": 0.229758620262146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.686184883117676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002093437360599637,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742277979850769,
      "backward_entropy": 0.23026116689046225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.184778213500977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00219292426481843,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742254436016083,
      "backward_entropy": 0.22966504096984863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.343926429748535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022924395743757486,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274222731590271,
      "backward_entropy": 0.2296162247657776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.825137138366699,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023920610547065735,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742190659046173,
      "backward_entropy": 0.22956605752309164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.581068515777588,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024915828835219145,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742149531841278,
      "backward_entropy": 0.2295147180557251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.997312068939209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002590891672298312,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27421119809150696,
      "backward_entropy": 0.22878052790959677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.028127670288086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002690199762582779,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742070257663727,
      "backward_entropy": 0.2300267219543457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.090421676635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002789898309856653,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742023468017578,
      "backward_entropy": 0.22998424371083578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9743146896362305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002889556111767888,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27419790625572205,
      "backward_entropy": 0.22929632663726807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.667863368988037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029887245036661625,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27419427037239075,
      "backward_entropy": 0.22989596923192343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.600683212280273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0030877329409122467,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741917371749878,
      "backward_entropy": 0.22984997431437174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.159910202026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003186998888850212,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27418917417526245,
      "backward_entropy": 0.22980268796284994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.063946723937988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032863274682313204,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741863429546356,
      "backward_entropy": 0.2297541300455729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.334546089172363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003385214600712061,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27418479323387146,
      "backward_entropy": 0.22899466753005981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.813834190368652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003484276356175542,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741832733154297,
      "backward_entropy": 0.2282196283340454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.402973175048828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003583278739824891,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27418169379234314,
      "backward_entropy": 0.22815120220184326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.470300197601318,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036815302446484566,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741829454898834,
      "backward_entropy": 0.2295454740524292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.388719081878662,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003779669525101781,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741842269897461,
      "backward_entropy": 0.2287353277206421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.204978942871094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0038776651490479708,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741858661174774,
      "backward_entropy": 0.22794200976689658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.059676170349121,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0039754705503582954,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741873562335968,
      "backward_entropy": 0.22937432924906412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65538501739502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004073493182659149,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741885185241699,
      "backward_entropy": 0.2277961572011312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.652745246887207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0041719782166182995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741890549659729,
      "backward_entropy": 0.22772061824798584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.885263442993164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004270871169865131,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274188756942749,
      "backward_entropy": 0.22764341036478677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.568575859069824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004370263312011957,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741866409778595,
      "backward_entropy": 0.2291333278020223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.446889400482178,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004469908773899078,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27418461441993713,
      "backward_entropy": 0.22825473546981812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.057120323181152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004569274373352528,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741827964782715,
      "backward_entropy": 0.2274015744527181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.117260932922363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004669150337576866,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27418002486228943,
      "backward_entropy": 0.22810329993565878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.100032806396484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004769039805978537,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741768956184387,
      "backward_entropy": 0.22723235686620077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.694915771484375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004868448246270418,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27417445182800293,
      "backward_entropy": 0.22794389724731445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.58718729019165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004967711865901947,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741723358631134,
      "backward_entropy": 0.22705835103988647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.286422729492188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00506682600826025,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741696834564209,
      "backward_entropy": 0.2277768055597941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.283112525939941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005166111048310995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27416712045669556,
      "backward_entropy": 0.22687959671020508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.539953231811523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0052655464969575405,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274164617061615,
      "backward_entropy": 0.22760585943857828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76835823059082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005365231540054083,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27416232228279114,
      "backward_entropy": 0.2275210420290629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.012590408325195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0054652807302773,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27415892481803894,
      "backward_entropy": 0.2283675273259481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.020380020141602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00556526891887188,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741556167602539,
      "backward_entropy": 0.22734546661376953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.082369804382324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005665701348334551,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741515040397644,
      "backward_entropy": 0.22725486755371094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.818742275238037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00576607184484601,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274147093296051,
      "backward_entropy": 0.22716228167215982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.526670455932617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00586626585572958,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27414244413375854,
      "backward_entropy": 0.22803195317586264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.879049777984619,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0059671117924153805,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741372585296631,
      "backward_entropy": 0.22793893019358316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.967941284179688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006067256443202496,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741323709487915,
      "backward_entropy": 0.22598799069722494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.733838081359863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006167844869196415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741256356239319,
      "backward_entropy": 0.2258808215459188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.241297721862793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006268676836043596,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741183638572693,
      "backward_entropy": 0.22667352358500162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.940464973449707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006369454320520163,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741115391254425,
      "backward_entropy": 0.22754422823588052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.054499626159668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006469569634646177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27410489320755005,
      "backward_entropy": 0.22555347283681235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.200393676757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006570144556462765,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27409738302230835,
      "backward_entropy": 0.227332870165507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.931506156921387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006671220995485783,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27408847212791443,
      "backward_entropy": 0.22623085975646973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8132963180542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006772104650735855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27407902479171753,
      "backward_entropy": 0.22522079944610596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.621873378753662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006873204838484526,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274070143699646,
      "backward_entropy": 0.22510520617167154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.802134037017822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006973904557526112,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740621566772461,
      "backward_entropy": 0.2268901268641154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53934097290039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007074319291859865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274055540561676,
      "backward_entropy": 0.2248664697011312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.644731521606445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007174872327595949,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740490734577179,
      "backward_entropy": 0.22665510574976602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.713662147521973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0072755711153149605,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27404364943504333,
      "backward_entropy": 0.22461599111557007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.004255294799805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007376444526016712,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27403873205184937,
      "backward_entropy": 0.22535632054011026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.367677688598633,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0074776639230549335,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27403274178504944,
      "backward_entropy": 0.22628418604532877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438224792480469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007579428143799305,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740241587162018,
      "backward_entropy": 0.22421123584111533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54310131072998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00768111040815711,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740163207054138,
      "backward_entropy": 0.22602450847625732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.058258056640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007782741449773312,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740098536014557,
      "backward_entropy": 0.2258897622426351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.08971118927002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00788414478302002,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740030586719513,
      "backward_entropy": 0.2257514993349711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.378216743469238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007985319010913372,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27399706840515137,
      "backward_entropy": 0.22560977935791016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.397748947143555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008086387999355793,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27399295568466187,
      "backward_entropy": 0.22347807884216309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.961960792541504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008187947794795036,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27398809790611267,
      "backward_entropy": 0.224186638991038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.029073715209961,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008289220742881298,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27398306131362915,
      "backward_entropy": 0.2240278720855713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.986171722412109,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008390282280743122,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739775478839874,
      "backward_entropy": 0.225011944770813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.308011054992676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008491079322993755,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739730477333069,
      "backward_entropy": 0.22369960943857828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9371843338012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00859181210398674,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739691138267517,
      "backward_entropy": 0.22469117244084677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.148158073425293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008692330680787563,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27396494150161743,
      "backward_entropy": 0.22244298458099365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.778351783752441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008792707696557045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27396202087402344,
      "backward_entropy": 0.22225797176361084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.897767066955566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008892802521586418,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739594876766205,
      "backward_entropy": 0.22418193022410074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.365725040435791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008993267081677914,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27395594120025635,
      "backward_entropy": 0.22400490442911783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.903820037841797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009093204513192177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739540636539459,
      "backward_entropy": 0.22168119748433432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.801074028015137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009192995727062225,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27395176887512207,
      "backward_entropy": 0.22363843520482382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.865644454956055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009293128736317158,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739483118057251,
      "backward_entropy": 0.22127815087636313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.125749111175537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009393611922860146,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27394330501556396,
      "backward_entropy": 0.2220655083656311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.40491247177124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009493496268987656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27393823862075806,
      "backward_entropy": 0.220858633518219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.443172454833984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009592944756150246,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27393436431884766,
      "backward_entropy": 0.22286190589269003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.831218719482422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009692581370472908,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739298939704895,
      "backward_entropy": 0.220426877339681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53278923034668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00979260727763176,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739240229129791,
      "backward_entropy": 0.22020304203033447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.949679374694824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009892775677144527,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739185690879822,
      "backward_entropy": 0.22223520278930664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.577845096588135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00999276340007782,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739138603210449,
      "backward_entropy": 0.2207865516344706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.327383041381836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010091823525726795,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273912250995636,
      "backward_entropy": 0.21950763463974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.068249702453613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010191041976213455,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27391016483306885,
      "backward_entropy": 0.2203298012415568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630976676940918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010290270671248436,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27390772104263306,
      "backward_entropy": 0.22009376684824625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.763068199157715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010389807634055614,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739045023918152,
      "backward_entropy": 0.22107911109924316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9723687171936035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010490217246115208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738996148109436,
      "backward_entropy": 0.21960826714833578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.671333312988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010589933022856712,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27389514446258545,
      "backward_entropy": 0.22056527932484946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.596519470214844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010689331218600273,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738925814628601,
      "backward_entropy": 0.21910725037256876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.083537101745605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010788490064442158,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27388930320739746,
      "backward_entropy": 0.21773970127105713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.24952507019043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010887686163187027,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738853096961975,
      "backward_entropy": 0.21975207328796387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.18700122833252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010986986570060253,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738810181617737,
      "backward_entropy": 0.21833409865697226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.041017532348633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011087407357990742,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27387499809265137,
      "backward_entropy": 0.21691399812698364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.965218544006348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011188216507434845,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273868203163147,
      "backward_entropy": 0.2177956501642863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.722118377685547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011289414949715137,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27385905385017395,
      "backward_entropy": 0.21751590569814047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.170317649841309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01139130350202322,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27384841442108154,
      "backward_entropy": 0.2172317107518514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.354822158813477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01149238646030426,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738398313522339,
      "backward_entropy": 0.2156910498936971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.168978691101074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011593401432037354,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738316059112549,
      "backward_entropy": 0.2176209290822347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.067563056945801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011694272980093956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738233208656311,
      "backward_entropy": 0.21504604816436768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.540058135986328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011794374324381351,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27381736040115356,
      "backward_entropy": 0.2169522444407145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6453537940979,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011893551796674728,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27381274104118347,
      "backward_entropy": 0.21439123153686523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.119180679321289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011992508545517921,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738080620765686,
      "backward_entropy": 0.21405907471974692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.905076026916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012091516517102718,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27380308508872986,
      "backward_entropy": 0.21589624881744385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99023151397705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012190992943942547,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27379700541496277,
      "backward_entropy": 0.21553011735280356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.875328063964844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012290903367102146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273790568113327,
      "backward_entropy": 0.21301382780075073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.242928504943848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012391169555485249,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737831175327301,
      "backward_entropy": 0.21413115660349527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.531816482543945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01249197218567133,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737738788127899,
      "backward_entropy": 0.21227176984151205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.923925399780273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012592840008437634,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27376431226730347,
      "backward_entropy": 0.2118912935256958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.667202949523926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01269395649433136,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27375444769859314,
      "backward_entropy": 0.21307679017384848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220777988433838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012795159593224525,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737444043159485,
      "backward_entropy": 0.21111945311228433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.442642211914062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012895677238702774,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737352252006531,
      "backward_entropy": 0.21234520276387533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.520668029785156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012996282428503036,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27372461557388306,
      "backward_entropy": 0.21032901604970297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.432108879089355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013096978887915611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737124562263489,
      "backward_entropy": 0.20992294947306314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41450309753418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013197693973779678,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27369973063468933,
      "backward_entropy": 0.20951040585835776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.079767227172852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013298416510224342,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27368655800819397,
      "backward_entropy": 0.2090911070505778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.605243682861328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013399538584053516,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27367156744003296,
      "backward_entropy": 0.21053818861643472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9646759033203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01350017823278904,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27365732192993164,
      "backward_entropy": 0.2100688616434733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.483539581298828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013600606471300125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736428380012512,
      "backward_entropy": 0.2077900767326355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41151237487793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013701134361326694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27362748980522156,
      "backward_entropy": 0.2090973456700643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7696213722229,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013801656663417816,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736124098300934,
      "backward_entropy": 0.20865947008132935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.346667289733887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013901843689382076,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2735978364944458,
      "backward_entropy": 0.20642775297164917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.001749038696289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01400261465460062,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27358096837997437,
      "backward_entropy": 0.2077630360921224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.384908676147461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014103246852755547,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27356255054473877,
      "backward_entropy": 0.2072977821032206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.121143341064453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014203901402652264,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27354320883750916,
      "backward_entropy": 0.20682400465011597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5850248336792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014304476790130138,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27352267503738403,
      "backward_entropy": 0.20450234413146973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8825507164001465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0144051443785429,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27350175380706787,
      "backward_entropy": 0.20584962765375772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.18417501449585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01450551487505436,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27348142862319946,
      "backward_entropy": 0.20350795984268188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.982464790344238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01460523996502161,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27346277236938477,
      "backward_entropy": 0.20300392309824625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.595494747161865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014704848639667034,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27344369888305664,
      "backward_entropy": 0.20249221722284952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.166092872619629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014804114587605,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734253704547882,
      "backward_entropy": 0.2019741733868917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.645814895629883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014904538169503212,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27340275049209595,
      "backward_entropy": 0.2023704449335734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.876000881195068,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015005187131464481,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733779549598694,
      "backward_entropy": 0.20174030462900797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.218134880065918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015104941092431545,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733563184738159,
      "backward_entropy": 0.20034833749135336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.501839637756348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015204109251499176,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27333635091781616,
      "backward_entropy": 0.19978739817937216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.045589447021484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015303544700145721,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27331411838531494,
      "backward_entropy": 0.20117262999216715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.091264724731445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01540292426943779,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27329128980636597,
      "backward_entropy": 0.20061242580413818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.213991165161133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015502294525504112,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732675075531006,
      "backward_entropy": 0.19804624716440836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6822509765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015601708553731441,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27324265241622925,
      "backward_entropy": 0.19772078593571982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.007037162780762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01570085436105728,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732178866863251,
      "backward_entropy": 0.19881429274876913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.919196128845215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01579938270151615,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27319473028182983,
      "backward_entropy": 0.1962231993675232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.035120964050293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015897249802947044,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27317413687705994,
      "backward_entropy": 0.1956043243408203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.929430961608887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015994619578123093,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2731550633907318,
      "backward_entropy": 0.194806436697642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840625762939453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016092145815491676,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27313387393951416,
      "backward_entropy": 0.19624809424082437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.808749198913574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016189660876989365,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27311214804649353,
      "backward_entropy": 0.19558346271514893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.99267053604126,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016287192702293396,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27308928966522217,
      "backward_entropy": 0.1949081023534139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5547590255737305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016384843736886978,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27306485176086426,
      "backward_entropy": 0.19170554478963217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8635759353637695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016481759026646614,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27304309606552124,
      "backward_entropy": 0.19169924656550089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.923801422119141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01657877117395401,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2730206251144409,
      "backward_entropy": 0.19101566076278687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.244693756103516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016675321385264397,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27299970388412476,
      "backward_entropy": 0.18925418456395468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.189081192016602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016771672293543816,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729785442352295,
      "backward_entropy": 0.19135713577270508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.393866539001465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016868412494659424,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2729541063308716,
      "backward_entropy": 0.18756401538848877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.330415725708008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016964973881840706,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27292969822883606,
      "backward_entropy": 0.18985827763875326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.744747161865234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017061986029148102,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27290159463882446,
      "backward_entropy": 0.18582195043563843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.436724662780762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01715903729200363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27287203073501587,
      "backward_entropy": 0.18671202659606934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.583159446716309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017255930230021477,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2728421092033386,
      "backward_entropy": 0.18595528602600098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.280039310455322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017352143302559853,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2728150188922882,
      "backward_entropy": 0.18673117955525717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.388364315032959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01744755171239376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27279171347618103,
      "backward_entropy": 0.18443159262339273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6981306076049805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017542332410812378,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27277350425720215,
      "backward_entropy": 0.18125985066095987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.747763633728027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01763676293194294,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2727561295032501,
      "backward_entropy": 0.18031609058380127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.765803337097168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01773155853152275,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27273455262184143,
      "backward_entropy": 0.1834565003712972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.401017665863037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017826026305556297,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727135419845581,
      "backward_entropy": 0.18260838588078818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.836297512054443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017920592799782753,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27269020676612854,
      "backward_entropy": 0.18175152937571207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.328293800354004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018014928326010704,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27266672253608704,
      "backward_entropy": 0.17643638451894125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.436458587646484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018109332770109177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27264100313186646,
      "backward_entropy": 0.17881623903910318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.646864414215088,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018203945830464363,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27261221408843994,
      "backward_entropy": 0.1791086196899414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.23525333404541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018298791721463203,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725800573825836,
      "backward_entropy": 0.1771074334780375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6740546226501465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018393002450466156,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2725507915019989,
      "backward_entropy": 0.17624302705128989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.672190189361572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018486270681023598,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2725267708301544,
      "backward_entropy": 0.17637179295221964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.962655544281006,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018580013886094093,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27249783277511597,
      "backward_entropy": 0.17030485471089682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.126171112060547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018673641607165337,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2724677324295044,
      "backward_entropy": 0.17361032962799072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.182575225830078,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01876731589436531,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27243536710739136,
      "backward_entropy": 0.17353943983713785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.336472034454346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01886042207479477,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27240514755249023,
      "backward_entropy": 0.17257903019587198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.566938877105713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0189531147480011,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723759710788727,
      "backward_entropy": 0.17088774840037027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.028929710388184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019045643508434296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723461389541626,
      "backward_entropy": 0.16996767123540243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.720132827758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019138295203447342,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723132371902466,
      "backward_entropy": 0.16963026920954385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.191689491271973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01923021301627159,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722840905189514,
      "backward_entropy": 0.16862444082895914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.10338306427002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019321799278259277,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27225548028945923,
      "backward_entropy": 0.16716376940409342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.615933895111084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019414346665143967,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27221786975860596,
      "backward_entropy": 0.16657433907190958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.417964935302734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019506797194480896,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2721790671348572,
      "backward_entropy": 0.15936269362767538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.647940158843994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01959890127182007,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2721402645111084,
      "backward_entropy": 0.1644878089427948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220407009124756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01969095878303051,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2720995545387268,
      "backward_entropy": 0.15705163280169168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.694723606109619,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01978335715830326,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27205395698547363,
      "backward_entropy": 0.15588364998499551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3935747146606445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019875038415193558,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2720116674900055,
      "backward_entropy": 0.1612480878829956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.254543304443359,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019966576248407364,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271968275308609,
      "backward_entropy": 0.16022735834121704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.044488430023193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020058538764715195,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27191904187202454,
      "backward_entropy": 0.1523441274960836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.205134868621826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020150035619735718,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27187058329582214,
      "backward_entropy": 0.15800952911376953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.900982856750488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020240498706698418,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2718278765678406,
      "backward_entropy": 0.1499397655328115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.020971298217773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02033059112727642,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2717857360839844,
      "backward_entropy": 0.15605942408243814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2249755859375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02042037807404995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2717430293560028,
      "backward_entropy": 0.1550057828426361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.590284824371338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020510096102952957,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27169811725616455,
      "backward_entropy": 0.15394318103790283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0012640953063965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020600013434886932,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271648645401001,
      "backward_entropy": 0.15286742647488913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.54122257232666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020688964053988457,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27160486578941345,
      "backward_entropy": 0.15125157435735068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.075099468231201,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020777424797415733,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2715620994567871,
      "backward_entropy": 0.14238480726877847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7866644859313965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020865824073553085,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27151644229888916,
      "backward_entropy": 0.14109722773234049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6286821365356445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020954720675945282,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27146437764167786,
      "backward_entropy": 0.14850057164827982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.566255569458008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021043209359049797,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27141252160072327,
      "backward_entropy": 0.14738382895787558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.878097057342529,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021131234243512154,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713610827922821,
      "backward_entropy": 0.14626149336496988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.933048248291016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021219167858362198,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27130746841430664,
      "backward_entropy": 0.13588533798853555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.909614086151123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021307040005922318,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2712509036064148,
      "backward_entropy": 0.14301331837972006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.813390254974365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02139405533671379,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2711985111236572,
      "backward_entropy": 0.1418155829111735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8709025382995605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021480267867445946,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27115046977996826,
      "backward_entropy": 0.14173134167989096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7621750831604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02156578004360199,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27110549807548523,
      "backward_entropy": 0.13940896590550741,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.490754127502441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021651331335306168,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27105581760406494,
      "backward_entropy": 0.1382033427556356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.988321304321289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021735936403274536,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2710115313529968,
      "backward_entropy": 0.1383111278216044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3876848220825195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0218200646340847,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.270967572927475,
      "backward_entropy": 0.13579830527305603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.390070915222168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021904148161411285,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27092012763023376,
      "backward_entropy": 0.13458621501922607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.263668060302734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021988214924931526,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27086910605430603,
      "backward_entropy": 0.1347739895184835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.334183692932129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022072097286581993,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2708149552345276,
      "backward_entropy": 0.13214091459910074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.835415840148926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022155966609716415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27075743675231934,
      "backward_entropy": 0.13237722714742026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.162297248840332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022239357233047485,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2707001864910126,
      "backward_entropy": 0.12967193126678467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.470736026763916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02232264168560505,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.270640105009079,
      "backward_entropy": 0.12996764977773032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.045825958251953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02240608260035515,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2705741226673126,
      "backward_entropy": 0.1287508507569631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.335287094116211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022489327937364578,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2705058753490448,
      "backward_entropy": 0.12592693169911703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8302106857299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022572578862309456,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2704318165779114,
      "backward_entropy": 0.11457717418670654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4694952964782715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022655511274933815,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2703571915626526,
      "backward_entropy": 0.12341399987538655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.44268798828125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022738631814718246,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2702751159667969,
      "backward_entropy": 0.12380115191141765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.089400768280029,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02282104641199112,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27019476890563965,
      "backward_entropy": 0.11058021585146587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8334221839904785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02290255017578602,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27011919021606445,
      "backward_entropy": 0.12132469813028972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.573853015899658,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02298390306532383,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2700401246547699,
      "backward_entropy": 0.10793252786000569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.154505729675293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02306489460170269,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26995956897735596,
      "backward_entropy": 0.11710800727208455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.931919813156128,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023146113380789757,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26987171173095703,
      "backward_entropy": 0.11583898464838664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.250965595245361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02322649210691452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26978933811187744,
      "backward_entropy": 0.11637891332308452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8097586631774902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02330635115504265,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2697070837020874,
      "backward_entropy": 0.11330342292785645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.881992816925049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023385336622595787,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26962924003601074,
      "backward_entropy": 0.11393727858861287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9270758628845215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023464487865567207,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2695425748825073,
      "backward_entropy": 0.11270917455355327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7884864807128906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02354290895164013,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26945722103118896,
      "backward_entropy": 0.09886529048283894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.317661285400391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023620644584298134,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26937535405158997,
      "backward_entropy": 0.10829175511995952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5389790534973145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023698166012763977,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2692885398864746,
      "backward_entropy": 0.09633432825406392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.48285174369812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023774875327944756,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2692071497440338,
      "backward_entropy": 0.09508455793062846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5553741455078125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023850804194808006,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2691304385662079,
      "backward_entropy": 0.10455192128817241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8801627159118652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0239260233938694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26905882358551025,
      "backward_entropy": 0.1033148964246114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.400074005126953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023999962955713272,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26899710297584534,
      "backward_entropy": 0.10434103012084961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.174187183380127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024073228240013123,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2689361870288849,
      "backward_entropy": 0.09019610285758972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9029159545898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024146668612957,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.268865168094635,
      "backward_entropy": 0.08899019161860149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.280447006225586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024218959733843803,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26880067586898804,
      "backward_entropy": 0.0984761913617452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9069526195526123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024290647357702255,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26873672008514404,
      "backward_entropy": 0.09974817434946696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.962860345840454,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024362390860915184,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.268663227558136,
      "backward_entropy": 0.08542370796203613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.329002857208252,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024433238431811333,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26859354972839355,
      "backward_entropy": 0.08425134420394897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.394564151763916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024503642693161964,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2685210108757019,
      "backward_entropy": 0.09379975001017253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.214486598968506,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024573778733611107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26844465732574463,
      "backward_entropy": 0.09265138705571492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.518650531768799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02464350312948227,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2683667540550232,
      "backward_entropy": 0.09410383303960164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1487925052642822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024712011218070984,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2682960331439972,
      "backward_entropy": 0.09300466378529866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4546775817871094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02478015422821045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26822182536125183,
      "backward_entropy": 0.09190911054611206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3902370929718018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024848271161317825,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.268138587474823,
      "backward_entropy": 0.08816661437352498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.713300943374634,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024916376918554306,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26804792881011963,
      "backward_entropy": 0.0763132522503535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.542672634124756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024983692914247513,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2679595947265625,
      "backward_entropy": 0.07521991928418477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.913163661956787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025051264092326164,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26785993576049805,
      "backward_entropy": 0.07413371404012044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.674133777618408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025118347257375717,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26775842905044556,
      "backward_entropy": 0.08644414941469829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2157950401306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025184690952301025,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26765793561935425,
      "backward_entropy": 0.07199810942014058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6907405853271484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02524982951581478,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2675650715827942,
      "backward_entropy": 0.07095378637313843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.775386333465576,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02531435340642929,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2674691081047058,
      "backward_entropy": 0.08065517246723175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8297628164291382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025378519669175148,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2673685848712921,
      "backward_entropy": 0.08224355181058247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.877114772796631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02544122375547886,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26728004217147827,
      "backward_entropy": 0.06789347529411316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.830734968185425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025503946468234062,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2671830952167511,
      "backward_entropy": 0.08022538820902507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7401669025421143,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025566553696990013,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2670772969722748,
      "backward_entropy": 0.0659156044324239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7401546239852905,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0256277434527874,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26698315143585205,
      "backward_entropy": 0.0649523635705312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1398472785949707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02568758837878704,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2668983042240143,
      "backward_entropy": 0.07727804780006409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5121383666992188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025746699422597885,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2668125629425049,
      "backward_entropy": 0.07633256912231445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.432201385498047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025805780664086342,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2667195200920105,
      "backward_entropy": 0.07280927399794261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.677733898162842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02586471289396286,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.266620010137558,
      "backward_entropy": 0.07187506556510925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1107819080352783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025923803448677063,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2665083408355713,
      "backward_entropy": 0.07350113987922668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7247767448425293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02598232589662075,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26639607548713684,
      "backward_entropy": 0.059454545378685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.047722339630127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026041176170110703,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26627057790756226,
      "backward_entropy": 0.05857399106025696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4923423528671265,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02609942853450775,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2661453187465668,
      "backward_entropy": 0.0707025279601415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4185142517089844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026156285777688026,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2660302221775055,
      "backward_entropy": 0.06730953852335612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0050148963928223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02621184103190899,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2659264802932739,
      "backward_entropy": 0.06893121699492137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.500053882598877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626706473529339,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26581871509552,
      "backward_entropy": 0.06806315978368123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3976569175720215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026321198791265488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26571714878082275,
      "backward_entropy": 0.0647209386030833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0362327098846436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026375818997621536,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26560190320014954,
      "backward_entropy": 0.066355566183726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.064262866973877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026430336758494377,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26548081636428833,
      "backward_entropy": 0.06550104419390361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.319129467010498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026484668254852295,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2653502821922302,
      "backward_entropy": 0.06464906533559163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0024421215057373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02653777413070202,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2652289569377899,
      "backward_entropy": 0.06382163365681966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9083760976791382,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026589151471853256,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26512137055397034,
      "backward_entropy": 0.05063775181770325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.483341932296753,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026640407741069794,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2650028467178345,
      "backward_entropy": 0.062231242656707764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8677494525909424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026690980419516563,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2648853361606598,
      "backward_entropy": 0.05900769432385763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3116470575332642,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026741525158286095,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2647574543952942,
      "backward_entropy": 0.06066819032033285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8041536808013916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026791153475642204,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2646336555480957,
      "backward_entropy": 0.05749008059501648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.493713617324829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02684079296886921,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2644999027252197,
      "backward_entropy": 0.059141005078951515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2490489482879639,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026889901608228683,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2643634080886841,
      "backward_entropy": 0.0464787632226944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7908254861831665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026938041672110558,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26422786712646484,
      "backward_entropy": 0.05529214938481649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9857732057571411,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0269862599670887,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2640782594680786,
      "backward_entropy": 0.04517625272274017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.118948221206665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02703319676220417,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2639382779598236,
      "backward_entropy": 0.04454695185025533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1785210371017456,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02707921899855137,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26380228996276855,
      "backward_entropy": 0.04393326242764791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2826021909713745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027124391868710518,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26366478204727173,
      "backward_entropy": 0.05255206425984701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9675809144973755,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02716926671564579,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2635262906551361,
      "backward_entropy": 0.05189478894074758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3400585651397705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027212994173169136,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26339060068130493,
      "backward_entropy": 0.051257347067197166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.125060796737671,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027256470173597336,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26324617862701416,
      "backward_entropy": 0.0416057805220286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.045964002609253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729937992990017,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2631009519100189,
      "backward_entropy": 0.052201966444651283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1028244495391846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027341673150658607,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26295730471611023,
      "backward_entropy": 0.04940267403920492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.074899435043335,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027383388951420784,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2628096640110016,
      "backward_entropy": 0.039980520804723106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9860271215438843,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02742452546954155,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26265814900398254,
      "backward_entropy": 0.039460944632689156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9604323506355286,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02746497094631195,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2625051736831665,
      "backward_entropy": 0.047650416692097984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8540071249008179,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02750473842024803,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2623506486415863,
      "backward_entropy": 0.038457728922367096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0399086475372314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027543805539608,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26220008730888367,
      "backward_entropy": 0.04859318335851034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.784398078918457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02758251316845417,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26204320788383484,
      "backward_entropy": 0.048027560114860535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8762990832328796,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027620386332273483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26188981533050537,
      "backward_entropy": 0.047476823131243386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9506468772888184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02765747159719467,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2617310583591461,
      "backward_entropy": 0.04495896895726522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0031611919403076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027694374322891235,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26156994700431824,
      "backward_entropy": 0.036144502460956573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9774411916732788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027731092646718025,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26140066981315613,
      "backward_entropy": 0.0458713968594869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6817177534103394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027767589315772057,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2612237334251404,
      "backward_entropy": 0.045343756675720215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0298287868499756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0278032049536705,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26105353236198425,
      "backward_entropy": 0.04296848177909851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9204451441764832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027838824316859245,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26087504625320435,
      "backward_entropy": 0.04249085485935211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7393825054168701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278742965310812,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2606903910636902,
      "backward_entropy": 0.04381093382835388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4392627775669098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02790891006588936,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.260501891374588,
      "backward_entropy": 0.033642073472340904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5997045636177063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027942096814513206,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26032453775405884,
      "backward_entropy": 0.04284411668777466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8050360679626465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027974264696240425,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2601466178894043,
      "backward_entropy": 0.0423881858587265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4991236627101898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02800622582435608,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25996068120002747,
      "backward_entropy": 0.041935483614603676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6954202055931091,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028037164360284805,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.259780615568161,
      "backward_entropy": 0.041499651968479156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7512971758842468,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02806788869202137,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25959888100624084,
      "backward_entropy": 0.03186709682146708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6466068625450134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028098464012145996,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2594095766544342,
      "backward_entropy": 0.0406390850742658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6236941814422607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028128638863563538,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25921767950057983,
      "backward_entropy": 0.04021707673867544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6582874059677124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028158342465758324,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25902318954467773,
      "backward_entropy": 0.03828295071919759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46611976623535156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02818780578672886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2588249742984772,
      "backward_entropy": 0.039392332235972084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5796304941177368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028216388076543808,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25863057374954224,
      "backward_entropy": 0.03899430731932322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6915339827537537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02824457734823227,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25843364000320435,
      "backward_entropy": 0.038601318995157875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4444006085395813,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028272872790694237,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582290470600128,
      "backward_entropy": 0.038206666707992554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4892548620700836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028300516307353973,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2580306828022003,
      "backward_entropy": 0.03646106024583181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4185768663883209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028327492997050285,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2578308880329132,
      "backward_entropy": 0.03744892030954361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5079144239425659,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0283538568764925,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25763681530952454,
      "backward_entropy": 0.03708508610725403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3543584644794464,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028379879891872406,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2574405074119568,
      "backward_entropy": 0.028603985905647278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4444735646247864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028405072167515755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2572503685951233,
      "backward_entropy": 0.03638083736101786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5706044435501099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02842978574335575,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.257058709859848,
      "backward_entropy": 0.03604232768217722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45248064398765564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028454624116420746,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2568584084510803,
      "backward_entropy": 0.03570203731457392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5045503973960876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028479039669036865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2566550672054291,
      "backward_entropy": 0.03536805013815562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42794591188430786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0285032968968153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25644534826278687,
      "backward_entropy": 0.03503630061944326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35044193267822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02852710336446762,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25623345375061035,
      "backward_entropy": 0.027162139614423115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5488017797470093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028550023213028908,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25602078437805176,
      "backward_entropy": 0.03332027792930603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44904789328575134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028572995215654373,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25579431653022766,
      "backward_entropy": 0.0330410897731781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49673524498939514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028595667332410812,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25556156039237976,
      "backward_entropy": 0.03276766836643219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4259681701660156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028618518263101578,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2553226351737976,
      "backward_entropy": 0.032493844628334045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5177839994430542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864111214876175,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25508010387420654,
      "backward_entropy": 0.03315586348374685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34860843420028687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866377681493759,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25482499599456787,
      "backward_entropy": 0.03284720083077749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28974446654319763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02868569642305374,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25456881523132324,
      "backward_entropy": 0.03254916767279307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2570190131664276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02870682254433632,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25431686639785767,
      "backward_entropy": 0.032262941201527916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3202205300331116,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028726933524012566,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25406861305236816,
      "backward_entropy": 0.031218220790227253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4027046263217926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028746886178851128,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25382447242736816,
      "backward_entropy": 0.030984821418921154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25708097219467163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02876676805317402,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2535722255706787,
      "backward_entropy": 0.03145507971445719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3569108545780182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02878613956272602,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2533257007598877,
      "backward_entropy": 0.031195710102717083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3268393576145172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02880554459989071,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25307565927505493,
      "backward_entropy": 0.03030482679605484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2574058175086975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028824685141444206,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2528219223022461,
      "backward_entropy": 0.02447192370891571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30890369415283203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028843162581324577,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25256913900375366,
      "backward_entropy": 0.030435149868329365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2816757559776306,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02886134199798107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25231245160102844,
      "backward_entropy": 0.029665763179461162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32692307233810425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0288790725171566,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25205332040786743,
      "backward_entropy": 0.029957304398218792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22839589416980743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028896799311041832,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2517886757850647,
      "backward_entropy": 0.029721674819787342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2242114543914795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02891392633318901,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2515265643596649,
      "backward_entropy": 0.023723050951957703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23397576808929443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028930380940437317,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2512650489807129,
      "backward_entropy": 0.028886524339516956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21351055800914764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028946340084075928,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25100332498550415,
      "backward_entropy": 0.029064831634362537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2536809742450714,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028961632400751114,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25074145197868347,
      "backward_entropy": 0.028536883493264515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26240605115890503,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028976665809750557,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2504754066467285,
      "backward_entropy": 0.02836984892686208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2703368663787842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028991524130105972,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25020408630371094,
      "backward_entropy": 0.02820574740568797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20643138885498047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02900628186762333,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24992656707763672,
      "backward_entropy": 0.02827007571856181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2503734230995178,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029020478948950768,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2496488094329834,
      "backward_entropy": 0.028081672887007397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24124129116535187,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029034731909632683,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2493678331375122,
      "backward_entropy": 0.027732573449611664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17292055487632751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02904905192553997,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24908487498760223,
      "backward_entropy": 0.027703215678532917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20219893753528595,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029062794521450996,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24880549311637878,
      "backward_entropy": 0.02257212996482849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1431257426738739,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029076382517814636,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24852696061134338,
      "backward_entropy": 0.027341745793819427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23435702919960022,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02908910997211933,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24825230240821838,
      "backward_entropy": 0.02237750341494878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1727011501789093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029102196916937828,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24797427654266357,
      "backward_entropy": 0.027000156541665394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16751515865325928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029115036129951477,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24769875407218933,
      "backward_entropy": 0.026830727855364483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1157955676317215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02912762574851513,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24742555618286133,
      "backward_entropy": 0.022091127932071686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17571483552455902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029139695689082146,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2471616566181183,
      "backward_entropy": 0.026506289839744568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15310320258140564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02915179170668125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24689745903015137,
      "backward_entropy": 0.026347778737545013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15633085370063782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02916363812983036,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24663439393043518,
      "backward_entropy": 0.026192595561345417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16398552060127258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029175059869885445,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24636879563331604,
      "backward_entropy": 0.026042647659778595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1134759783744812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02918640524148941,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2461017668247223,
      "backward_entropy": 0.02589375029007594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14518341422080994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02919694408774376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24583712220191956,
      "backward_entropy": 0.025754769643147785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15782642364501953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029207373037934303,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24557265639305115,
      "backward_entropy": 0.025617234408855438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13598701357841492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029217584058642387,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24530333280563354,
      "backward_entropy": 0.025769243637720745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10692747682332993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02922743186354637,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24503260850906372,
      "backward_entropy": 0.025351335604985554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11386962980031967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029236719012260437,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.244765043258667,
      "backward_entropy": 0.025227516889572144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11737050116062164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029245277866721153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2444959282875061,
      "backward_entropy": 0.02511228124300639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09863783419132233,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029253754764795303,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24422898888587952,
      "backward_entropy": 0.025388387342294056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09973074495792389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029261767864227295,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24396482110023499,
      "backward_entropy": 0.02530426283677419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12234537303447723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029269501566886902,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24370358884334564,
      "backward_entropy": 0.0247855211297671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11923325061798096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02927732653915882,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24344173073768616,
      "backward_entropy": 0.024680006007353466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09545870125293732,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029284993186593056,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2431771159172058,
      "backward_entropy": 0.025061520437399547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08320295065641403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029292302206158638,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2429141104221344,
      "backward_entropy": 0.024476672212282818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12850075960159302,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029299069195985794,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24265354871749878,
      "backward_entropy": 0.020964759091536205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10431373119354248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029306162148714066,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24238893389701843,
      "backward_entropy": 0.02092706908782323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10465319454669952,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02931337244808674,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24212545156478882,
      "backward_entropy": 0.024188630282878876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08062084019184113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029320601373910904,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2418614625930786,
      "backward_entropy": 0.024090451498826344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08081662654876709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029327712953090668,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2416025996208191,
      "backward_entropy": 0.02399408568938573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08475521951913834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02933446317911148,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24134542047977448,
      "backward_entropy": 0.020768892019987106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07801352441310883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029341109097003937,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24108999967575073,
      "backward_entropy": 0.02381143718957901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06236574798822403,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029347386211156845,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2408352792263031,
      "backward_entropy": 0.02070029576619466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08475679159164429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029353270307183266,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2405852973461151,
      "backward_entropy": 0.02364386369784673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08381547033786774,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02935929223895073,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24033614993095398,
      "backward_entropy": 0.020640903462966282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0952749028801918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02936539240181446,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24008707702159882,
      "backward_entropy": 0.023477633794148762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06929318606853485,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02937156893312931,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2398330569267273,
      "backward_entropy": 0.02057553082704544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060049332678318024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029377352446317673,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23957940936088562,
      "backward_entropy": 0.024110098679860432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06974218785762787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02938278391957283,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23932893574237823,
      "backward_entropy": 0.023237744967142742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07758534699678421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02938794158399105,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23907773196697235,
      "backward_entropy": 0.023165230949719746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06182063743472099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02939307875931263,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23882445693016052,
      "backward_entropy": 0.023092853526274364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07326691597700119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029398053884506226,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2385735660791397,
      "backward_entropy": 0.023022522528966267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05940905213356018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029403306543827057,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2383236289024353,
      "backward_entropy": 0.022949260969956715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056444935500621796,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029408195987343788,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2380739152431488,
      "backward_entropy": 0.022880728046099346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060799531638622284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029412787407636642,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23782560229301453,
      "backward_entropy": 0.022815624872843426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06126974895596504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029417380690574646,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23757880926132202,
      "backward_entropy": 0.022750499347845714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06392776221036911,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029421912506222725,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2373320460319519,
      "backward_entropy": 0.023656576871871948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05978972837328911,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029426541179418564,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23708505928516388,
      "backward_entropy": 0.020341043670972187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05999379605054855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029431305825710297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23683959245681763,
      "backward_entropy": 0.02255308876434962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04485664516687393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943599410355091,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23659296333789825,
      "backward_entropy": 0.020298463602860767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04642150551080704,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029440436512231827,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23635005950927734,
      "backward_entropy": 0.023469120264053345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048754267394542694,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02944457158446312,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23610854148864746,
      "backward_entropy": 0.022363218168417614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03612323850393295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029448704794049263,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23586931824684143,
      "backward_entropy": 0.02230339248975118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05290738865733147,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02945263870060444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2356361299753189,
      "backward_entropy": 0.02224620183308919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03821251168847084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029456743970513344,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23540286719799042,
      "backward_entropy": 0.02218703180551529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03368912264704704,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029460884630680084,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23517552018165588,
      "backward_entropy": 0.023262135684490204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03913843631744385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029464786872267723,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23495280742645264,
      "backward_entropy": 0.022071965038776398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03476935252547264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029468633234500885,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23473237454891205,
      "backward_entropy": 0.022017111380894978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04511932656168938,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02947240136563778,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23451575636863708,
      "backward_entropy": 0.021963347991307575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03566077724099159,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029476312920451164,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.234298437833786,
      "backward_entropy": 0.02190811683734258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035213105380535126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029480036348104477,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23408226668834686,
      "backward_entropy": 0.02185504635175069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027250150218605995,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029483675956726074,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2338678389787674,
      "backward_entropy": 0.023032277822494507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039050307124853134,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029487019404768944,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23365715146064758,
      "backward_entropy": 0.020071239521106083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031985677778720856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029490431770682335,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2334456741809845,
      "backward_entropy": 0.02170538653930028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032780762761831284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029493775218725204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23323608934879303,
      "backward_entropy": 0.021657076974709828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027025198563933372,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02949719876050949,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23302876949310303,
      "backward_entropy": 0.021608099341392517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0296710766851902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029500341042876244,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2328231781721115,
      "backward_entropy": 0.020013414323329926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028608065098524094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02950330637395382,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2326178401708603,
      "backward_entropy": 0.021518513560295105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02555449865758419,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02950631082057953,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.232415109872818,
      "backward_entropy": 0.0214747687180837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030001144856214523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029509132727980614,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2322143316268921,
      "backward_entropy": 0.021433112521966297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0321408174932003,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0295120757073164,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23201486468315125,
      "backward_entropy": 0.019969495634237926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020084593445062637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02951510064303875,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23181426525115967,
      "backward_entropy": 0.022712220748265583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022301627323031425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02951795607805252,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23161852359771729,
      "backward_entropy": 0.0213043416539828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020166954025626183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029520822688937187,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23142695426940918,
      "backward_entropy": 0.022653823097546894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021314751356840134,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029523657634854317,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23124009370803833,
      "backward_entropy": 0.019920427352190018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021488090977072716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029526477679610252,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2310563623905182,
      "backward_entropy": 0.02118060241142909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019935833290219307,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029529333114624023,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23087547719478607,
      "backward_entropy": 0.021139564613501232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015615487471222878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029532162472605705,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2306973785161972,
      "backward_entropy": 0.021099254488945007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017471935600042343,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029534779489040375,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.230523020029068,
      "backward_entropy": 0.021061462660630543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02149534970521927,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029537353664636612,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23035185039043427,
      "backward_entropy": 0.021024403472741444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01562452595680952,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029540015384554863,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23018108308315277,
      "backward_entropy": 0.020986442764600117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021178115159273148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02954249270260334,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2300126701593399,
      "backward_entropy": 0.0198312575618426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019088033586740494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029545169323682785,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2298451066017151,
      "backward_entropy": 0.020912783841292065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01545054279267788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02954792231321335,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22967876493930817,
      "backward_entropy": 0.022380247712135315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015548433177173138,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029550569131970406,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22951462864875793,
      "backward_entropy": 0.020837006469567616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015334680676460266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029553240165114403,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22935353219509125,
      "backward_entropy": 0.020799773434797924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016571849584579468,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0295559111982584,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22919492423534393,
      "backward_entropy": 0.022300367554028828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012041506357491016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029558708891272545,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22903843224048615,
      "backward_entropy": 0.020724304020404816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013259095139801502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02956131100654602,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22888463735580444,
      "backward_entropy": 0.020688260595003765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014928890392184258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029563860967755318,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22873300313949585,
      "backward_entropy": 0.020652918765942257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01474405825138092,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029566457495093346,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22858235239982605,
      "backward_entropy": 0.022195649643739063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01199503242969513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029569005593657494,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22843137383460999,
      "backward_entropy": 0.020582031458616257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010265027172863483,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029571425169706345,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22828194499015808,
      "backward_entropy": 0.02214611570040385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013691785745322704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029573794454336166,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2281363606452942,
      "backward_entropy": 0.02051541954278946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012958724983036518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029576165601611137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22799062728881836,
      "backward_entropy": 0.02048252522945404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011609358713030815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029578546062111855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2278454601764679,
      "backward_entropy": 0.020449566344420116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00925267580896616,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029580917209386826,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2277018278837204,
      "backward_entropy": 0.022051580250263214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0122360335662961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029583264142274857,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2275620549917221,
      "backward_entropy": 0.020384530226389568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011071419343352318,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029585743322968483,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22742310166358948,
      "backward_entropy": 0.022003938754399616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009552464820444584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029588261619210243,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2272852659225464,
      "backward_entropy": 0.020317388077576954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009824862703680992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029590651392936707,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22714832425117493,
      "backward_entropy": 0.020285127063592274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00986828189343214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02959299273788929,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22701245546340942,
      "backward_entropy": 0.020253526667753857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00933312438428402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029595261439681053,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22687701880931854,
      "backward_entropy": 0.021910394231478374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009538773447275162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029597623273730278,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22674420475959778,
      "backward_entropy": 0.02019097035129865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009285279549658298,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029600026085972786,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2266126573085785,
      "backward_entropy": 0.021863738695780437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007795142941176891,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029602402821183205,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22648152709007263,
      "backward_entropy": 0.021840403477350872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0070274146273732185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029604630544781685,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2263513207435608,
      "backward_entropy": 0.02181843916575114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008395916782319546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029606841504573822,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2262241393327713,
      "backward_entropy": 0.020067399988571804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007173729129135609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029609017074108124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22609710693359375,
      "backward_entropy": 0.02003809188803037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007748582400381565,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029611166566610336,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22597190737724304,
      "backward_entropy": 0.02000918984413147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00709107518196106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029613317921757698,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22584755718708038,
      "backward_entropy": 0.021733080347379048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006156395189464092,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02961544506251812,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22572451829910278,
      "backward_entropy": 0.02171214669942856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005885432008653879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02961750701069832,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22560334205627441,
      "backward_entropy": 0.01938623438278834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0056266626343131065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02961958386003971,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2254847288131714,
      "backward_entropy": 0.019896275053421657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004847935400903225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0296216681599617,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2253686785697937,
      "backward_entropy": 0.01935902362068494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0048472038470208645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02962368167936802,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22525539994239807,
      "backward_entropy": 0.01984201620022456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004768448416143656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029625538736581802,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22514355182647705,
      "backward_entropy": 0.019817031919956207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004165865946561098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029627282172441483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2250332534313202,
      "backward_entropy": 0.019793306787808735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004588257987052202,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029628947377204895,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22492551803588867,
      "backward_entropy": 0.01931388924519221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0045767249539494514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029630562290549278,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2248193621635437,
      "backward_entropy": 0.019304439425468445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003472084179520607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02963208593428135,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22471395134925842,
      "backward_entropy": 0.019727088510990143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004082743544131517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029633529484272003,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22461122274398804,
      "backward_entropy": 0.019706873844067257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029167234897613525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296349935233593,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22451049089431763,
      "backward_entropy": 0.019686542451381683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003189070848748088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029636282473802567,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2244119942188263,
      "backward_entropy": 0.01966812585790952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003651592181995511,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029637500643730164,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22431567311286926,
      "backward_entropy": 0.01965053876241048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036241929046809673,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02963871881365776,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22422060370445251,
      "backward_entropy": 0.021488976975282032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002718257252126932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02963998168706894,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2241271436214447,
      "backward_entropy": 0.02147699644168218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003123699687421322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029641125351190567,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22403545677661896,
      "backward_entropy": 0.021466165781021118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002905893372371793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029642172157764435,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22394448518753052,
      "backward_entropy": 0.019583215316136677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003448889125138521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029643243178725243,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22385552525520325,
      "backward_entropy": 0.019567546745141346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002994604641571641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029644325375556946,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22376684844493866,
      "backward_entropy": 0.019551788767178852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019202918047085404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029645370319485664,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22367891669273376,
      "backward_entropy": 0.019536481549342472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002803879091516137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029646320268511772,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22359368205070496,
      "backward_entropy": 0.019226552297671635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002685058629140258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029647214338183403,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2235087752342224,
      "backward_entropy": 0.021407850086688995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021900630090385675,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029648104682564735,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2234247624874115,
      "backward_entropy": 0.02139924466609955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025048230309039354,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029648980125784874,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22334274649620056,
      "backward_entropy": 0.019481953233480453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002118588425219059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029649870470166206,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22326166927814484,
      "backward_entropy": 0.019468598067760468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018918508430942893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02965075522661209,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22318227589130402,
      "backward_entropy": 0.019455375770727795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020503851119428873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029651649296283722,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22310498356819153,
      "backward_entropy": 0.01944218948483467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00182945909909904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02965250238776207,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22302865982055664,
      "backward_entropy": 0.019429487486680348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001770049100741744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02965337410569191,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22295424342155457,
      "backward_entropy": 0.021348312497138977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020274356938898563,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029654178768396378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22288084030151367,
      "backward_entropy": 0.019404660910367966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001893919543363154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029655002057552338,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22280819714069366,
      "backward_entropy": 0.01939245065053304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016710892086848617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029655806720256805,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2227361500263214,
      "backward_entropy": 0.019380465149879456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014921894762665033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029656630009412766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22266560792922974,
      "backward_entropy": 0.019368380308151245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012966229114681482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029657388105988503,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2225961536169052,
      "backward_entropy": 0.019357051700353622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016388923395425081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296581219881773,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2225286215543747,
      "backward_entropy": 0.019346032291650772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012347424635663629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029658924788236618,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2224622666835785,
      "backward_entropy": 0.019334393242994945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012773772468790412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029659690335392952,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22239750623703003,
      "backward_entropy": 0.021286651492118835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013992281164973974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029660459607839584,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22233417630195618,
      "backward_entropy": 0.019312089929978054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014208273496478796,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029661256819963455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2222718894481659,
      "backward_entropy": 0.019300741453965504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011697623413056135,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029662063345313072,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2222101092338562,
      "backward_entropy": 0.01928931971391042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001091473619453609,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02966282330453396,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22214925289154053,
      "backward_entropy": 0.021256066858768463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009186971001327038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029663560912013054,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22208958864212036,
      "backward_entropy": 0.019267798711856205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009040144504979253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029664281755685806,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22203168272972107,
      "backward_entropy": 0.019257478415966034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000971440807916224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029664965346455574,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22197513282299042,
      "backward_entropy": 0.01924758404493332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008095678058452904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02966565452516079,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22191983461380005,
      "backward_entropy": 0.019237730652093887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008964784210547805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029666339978575706,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22186622023582458,
      "backward_entropy": 0.01922800640265147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008261663606390357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02966698445379734,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22181326150894165,
      "backward_entropy": 0.01921866958340009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007172057521529496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029667599126696587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22176125645637512,
      "backward_entropy": 0.01920974627137184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000523419410455972,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0296681709587574,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2217104136943817,
      "backward_entropy": 0.02120359241962433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007497012848034501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029668694362044334,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2216614931821823,
      "backward_entropy": 0.019193476686875027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000756165012717247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029669253155589104,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22161372005939484,
      "backward_entropy": 0.019185315817594528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006712725735269487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02966979704797268,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22156640887260437,
      "backward_entropy": 0.019177384674549103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006165786762721837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029670337215065956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22152002155780792,
      "backward_entropy": 0.019169458498557407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004723022284451872,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029670879244804382,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22147467732429504,
      "backward_entropy": 0.019161637872457504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005806219414807856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029671374708414078,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22143074870109558,
      "backward_entropy": 0.01915435368816058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005556445685215294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029671847820281982,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22138750553131104,
      "backward_entropy": 0.019147291779518127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005365501274354756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029672300443053246,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22134500741958618,
      "backward_entropy": 0.01914052665233612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046945532085374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967275306582451,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.221303328871727,
      "backward_entropy": 0.02115811159213384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000516285770572722,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029673203825950623,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22126272320747375,
      "backward_entropy": 0.019127144167820614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000513621314894408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029673675075173378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2212228924036026,
      "backward_entropy": 0.019120299567778904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004871471901424229,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029674170538783073,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22118371725082397,
      "backward_entropy": 0.021143987774848938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004065954708494246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967466600239277,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22114507853984833,
      "backward_entropy": 0.019106224179267883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003899253497365862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029675129801034927,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22110718488693237,
      "backward_entropy": 0.019099605580170948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044021810754202306,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967558056116104,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22107018530368805,
      "backward_entropy": 0.021129896243413288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035542852128855884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029676036909222603,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22103366255760193,
      "backward_entropy": 0.021125296751658123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003546986263245344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967650629580021,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22099816799163818,
      "backward_entropy": 0.019080060223738354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033937161788344383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029676945880055428,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22096332907676697,
      "backward_entropy": 0.019073788076639175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039111520163714886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967735193669796,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22092896699905396,
      "backward_entropy": 0.01906791205207507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022792052186559886,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029677771031856537,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22089490294456482,
      "backward_entropy": 0.021107874810695648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002960512356366962,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029678164049983025,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22086217999458313,
      "backward_entropy": 0.019086427986621857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002418613585177809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029678527265787125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22082991898059845,
      "backward_entropy": 0.019050930937131245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002455341746099293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029678886756300926,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22079873085021973,
      "backward_entropy": 0.01908341298500697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029446216649375856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029679225757718086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22076831758022308,
      "backward_entropy": 0.019040711224079132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025134708266705275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029679587110877037,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22073835134506226,
      "backward_entropy": 0.019035466015338898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022350429208017886,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029679950326681137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.220708966255188,
      "backward_entropy": 0.019030272960662842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020418599888216704,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680339619517326,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22068047523498535,
      "backward_entropy": 0.02108180771271388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019790875376202166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029680702835321426,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22065265476703644,
      "backward_entropy": 0.021078142027060192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022677001834381372,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681064188480377,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22062557935714722,
      "backward_entropy": 0.021074508627255756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022243650164455175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029681388288736343,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22059860825538635,
      "backward_entropy": 0.01901012783249219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019659195095300674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968168631196022,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22057180106639862,
      "backward_entropy": 0.021068118512630463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020990727352909744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029681982472538948,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22054548561573029,
      "backward_entropy": 0.02106502652168274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019749195780605078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029682280495762825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22051939368247986,
      "backward_entropy": 0.0189970259865125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015728545258753002,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029682582244277,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2204935997724533,
      "backward_entropy": 0.019066572189331055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001483519736211747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029682856053113937,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22046834230422974,
      "backward_entropy": 0.01898861179749171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001253246155101806,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968314103782177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22044382989406586,
      "backward_entropy": 0.01898447920878728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011117027315776795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968340925872326,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22042009234428406,
      "backward_entropy": 0.021050214767456055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001360839232802391,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968365140259266,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2203972041606903,
      "backward_entropy": 0.021047669152418774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001403174683218822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029683897271752357,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22037476301193237,
      "backward_entropy": 0.021045111119747162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011846120469272137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029684120789170265,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22035256028175354,
      "backward_entropy": 0.019061002880334854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011487753363326192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029684333130717278,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2203308343887329,
      "backward_entropy": 0.01896667604645093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.537941903341562e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029684530571103096,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22030958533287048,
      "backward_entropy": 0.019060006986061733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011722995986929163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029684726148843765,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22028914093971252,
      "backward_entropy": 0.018960570295651753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.536159632261842e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029684919863939285,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22026899456977844,
      "backward_entropy": 0.021034101645151775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010461495548952371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029685109853744507,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22024931013584137,
      "backward_entropy": 0.019058572749296825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010270295751979575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968529239296913,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2202298939228058,
      "backward_entropy": 0.01895177736878395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.37468178360723e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968546934425831,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22021067142486572,
      "backward_entropy": 0.018949029346307118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.846576772863045e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968563884496689,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22019195556640625,
      "backward_entropy": 0.018946364521980286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.17437976365909e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029685821384191513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22017376124858856,
      "backward_entropy": 0.018943554411331814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.283918239409104e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029685989022254944,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22015589475631714,
      "backward_entropy": 0.01894098271926244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.077249756548554e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029686152935028076,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22013849020004272,
      "backward_entropy": 0.01905624692638715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2747018344234675e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968631125986576,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22012144327163696,
      "backward_entropy": 0.018935939917961758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.972215487621725e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029686463996767998,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22010508179664612,
      "backward_entropy": 0.018933566908041637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.929166218265891e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029686611145734787,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22008898854255676,
      "backward_entropy": 0.018931259711583454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.576221155934036e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029686756432056427,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22007329761981964,
      "backward_entropy": 0.019055140515168507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.531093484023586e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968689426779747,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22005799412727356,
      "backward_entropy": 0.018926817923784256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3955599064938724e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029687032103538513,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2200430929660797,
      "backward_entropy": 0.021010860800743103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1158374844817445e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029687177389860153,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22002895176410675,
      "backward_entropy": 0.018922484169403713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.909882070729509e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029687317088246346,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2200150489807129,
      "backward_entropy": 0.018920353303352993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5122502595186234e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029687462374567986,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2200017124414444,
      "backward_entropy": 0.021006132165590923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.558112777885981e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968760021030903,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2199888527393341,
      "backward_entropy": 0.021004592378934223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0650793632958084e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968773804605007,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21997618675231934,
      "backward_entropy": 0.018914130826791126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.636686960817315e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029687872156500816,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21996405720710754,
      "backward_entropy": 0.018912148972352345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.111438491032459e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968800626695156,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21995219588279724,
      "backward_entropy": 0.018910198161999386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9613282094942406e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029688136652112007,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21994075179100037,
      "backward_entropy": 0.020998674134413402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.123482383671217e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029688261449337006,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21992963552474976,
      "backward_entropy": 0.019050842771927517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6624713427736424e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029688386246562004,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2199188470840454,
      "backward_entropy": 0.0189046673476696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9432174414978363e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296885147690773,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21990838646888733,
      "backward_entropy": 0.018902829537789028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.36459218285745e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029688633978366852,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21989814937114716,
      "backward_entropy": 0.018901096036036808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0970961233833805e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029688743874430656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21988822519779205,
      "backward_entropy": 0.018899470567703247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3534816136816517e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029688848182559013,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21987834572792053,
      "backward_entropy": 0.01889791339635849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9814071492874064e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968895062804222,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2198687195777893,
      "backward_entropy": 0.018896362433830898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1035142708569765e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029689045622944832,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21985945105552673,
      "backward_entropy": 0.018894925713539124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3081613107933663e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029689142480492592,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21985043585300446,
      "backward_entropy": 0.020987314482529957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9004077330464497e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029689237475395203,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21984153985977173,
      "backward_entropy": 0.02098623663187027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6938327462412417e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029689326882362366,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2198329120874405,
      "backward_entropy": 0.019047642747561138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8240752979181707e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02968941628932953,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21982455253601074,
      "backward_entropy": 0.020984165370464325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.10811758734053e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029689490795135498,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2198164165019989,
      "backward_entropy": 0.0190473273396492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4108898540143855e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968956157565117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21980831027030945,
      "backward_entropy": 0.018887144823869068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.912980224005878e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968963235616684,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21980047225952148,
      "backward_entropy": 0.018886002401510876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6541558579774573e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029689699411392212,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21979272365570068,
      "backward_entropy": 0.018884914616743725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3942481018602848e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029689760878682137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21978503465652466,
      "backward_entropy": 0.018883933623631794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0740088328020647e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029689820483326912,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21977759897708893,
      "backward_entropy": 0.018882932762304943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1987105608568527e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02968987636268139,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21977049112319946,
      "backward_entropy": 0.019047350933154423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4315986845758744e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029689932242035866,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2197636067867279,
      "backward_entropy": 0.020977705717086792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1775458915508352e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029689986258745193,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21975676715373993,
      "backward_entropy": 0.020977027714252472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2648006304516457e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690038412809372,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21975012123584747,
      "backward_entropy": 0.018879337857166927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991495633381419e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029690086841583252,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2197435200214386,
      "backward_entropy": 0.019047642747561138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0400576684332918e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690133407711983,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.219737246632576,
      "backward_entropy": 0.018877713630596798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.64743139775237e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029690181836485863,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21973109245300293,
      "backward_entropy": 0.02097448209921519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.19606100069359e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690228402614594,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21972505748271942,
      "backward_entropy": 0.018876115481058758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.38968947189278e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029690271243453026,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21971918642520905,
      "backward_entropy": 0.02097328007221222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.504772616404807e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690314084291458,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21971359848976135,
      "backward_entropy": 0.018874692420164745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.287476026045624e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969035878777504,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21970829367637634,
      "backward_entropy": 0.01887396350502968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.593958914891118e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969040349125862,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21970327198505402,
      "backward_entropy": 0.018873243282238644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.828952220734209e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029690448194742203,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21969839930534363,
      "backward_entropy": 0.01904807984828949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.26236021364457e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690487310290337,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21969357132911682,
      "backward_entropy": 0.01887187734246254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.041230335540604e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969052456319332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21968886256217957,
      "backward_entropy": 0.018871294955412548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.950894203328062e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690561816096306,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21968424320220947,
      "backward_entropy": 0.018870646754900616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.871344455954386e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029690595343708992,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21967974305152893,
      "backward_entropy": 0.02096885194381078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.282057372824056e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02969062700867653,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21967531740665436,
      "backward_entropy": 0.019048531850179035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.234195668890607e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690656810998917,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21967104077339172,
      "backward_entropy": 0.01886901135245959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.579589585773647e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029690688475966454,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21966686844825745,
      "backward_entropy": 0.019048755367596943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.419441095000366e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969072200357914,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21966278553009033,
      "backward_entropy": 0.01886795088648796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.480208074004622e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690753668546677,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21965879201889038,
      "backward_entropy": 0.018867430587609608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8133010750461835e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690781608223915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21965479850769043,
      "backward_entropy": 0.018866993486881256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.767066002386855e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690807685256004,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21965086460113525,
      "backward_entropy": 0.018866495539744694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.625933343049837e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029690833762288094,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21964699029922485,
      "backward_entropy": 0.020965392390886944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.831634785456117e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690856114029884,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21964316070079803,
      "backward_entropy": 0.018865615129470825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.645353672254714e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690878465771675,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21963946521282196,
      "backward_entropy": 0.018865214039882023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.346937657828676e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029690900817513466,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21963584423065186,
      "backward_entropy": 0.020964314540227253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.978850600105943e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029690921306610107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21963223814964294,
      "backward_entropy": 0.02096397429704666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3586759400350275e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296909399330616,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21962863206863403,
      "backward_entropy": 0.018864018221696217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.798790092128911e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690958559513092,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21962514519691467,
      "backward_entropy": 0.018863660593827564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.140060243822518e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029690977185964584,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21962174773216248,
      "backward_entropy": 0.02096301813920339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.88849878415931e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690995812416077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21961843967437744,
      "backward_entropy": 0.01886291801929474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.113086904704687e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691016301512718,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2196151465177536,
      "backward_entropy": 0.018862560391426086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2632582385995192e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969103679060936,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21961188316345215,
      "backward_entropy": 0.018862194071213405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0232714632584248e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029691057279706,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21960875391960144,
      "backward_entropy": 0.019050925970077515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9749465991480974e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691079631447792,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21960574388504028,
      "backward_entropy": 0.018861403067906696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2258625449467218e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691101983189583,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21960288286209106,
      "backward_entropy": 0.018861026813586552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8177339597968967e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691122472286224,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.219600111246109,
      "backward_entropy": 0.02096077799797058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3966794085717993e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691142961382866,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21959742903709412,
      "backward_entropy": 0.018860322733720142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0576530914695468e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029691165313124657,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21959492564201355,
      "backward_entropy": 0.019051257520914078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8568358655102202e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691185802221298,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21959242224693298,
      "backward_entropy": 0.018859614928563435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6773452671259292e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969120629131794,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21959000825881958,
      "backward_entropy": 0.01885932187239329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.64266111823963e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691224917769432,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21958759427070618,
      "backward_entropy": 0.018859005222717922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4310692222352372e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691243544220924,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21958529949188232,
      "backward_entropy": 0.01885867863893509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2847351626987802e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691260308027267,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21958306431770325,
      "backward_entropy": 0.01885842780272166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.328417738477583e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969127707183361,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21958091855049133,
      "backward_entropy": 0.01885814592242241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2620938605323317e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029691293835639954,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2195787876844406,
      "backward_entropy": 0.01905172069867452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.201768875755079e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691310599446297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21957674622535706,
      "backward_entropy": 0.018857598304748535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1531345762705314e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969132736325264,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21957483887672424,
      "backward_entropy": 0.018857352435588837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.051052873270237e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691344127058983,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21957296133041382,
      "backward_entropy": 0.020957378049691517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.378232910719817e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691362753510475,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21957120299339294,
      "backward_entropy": 0.01885675514737765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.922578220131982e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029691383242607117,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21956956386566162,
      "backward_entropy": 0.019051842391490936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.638377835268329e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691403731703758,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21956801414489746,
      "backward_entropy": 0.02095651129881541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0107926300406689e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0296914242208004,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21956652402877808,
      "backward_entropy": 0.019051795204480488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.676706559323065e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691442847251892,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195650041103363,
      "backward_entropy": 0.01885565494497617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.368031565922138e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691459611058235,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2195635437965393,
      "backward_entropy": 0.020955669383207958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.541298489537439e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691478237509727,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21956220269203186,
      "backward_entropy": 0.018855137129624683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.59441241168679e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02969149686396122,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21956084668636322,
      "backward_entropy": 0.02095513790845871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.934341740816308e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029691515490412712,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21955953538417816,
      "backward_entropy": 0.019051735599835713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.150589797471184e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691534116864204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195582240819931,
      "backward_entropy": 0.018854383379220963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.959720172337256e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691550880670547,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21955695748329163,
      "backward_entropy": 0.01885414868593216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.909295512334211e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02969156764447689,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2195557802915573,
      "backward_entropy": 0.020954137047131855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.816655743728916e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691584408283234,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195546180009842,
      "backward_entropy": 0.018853684266408283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.95411143219826e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691599309444427,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21955344080924988,
      "backward_entropy": 0.018853473166624706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.515447926678462e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969161421060562,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21955233812332153,
      "backward_entropy": 0.018853274484475453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.448245588013378e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691629111766815,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21955126523971558,
      "backward_entropy": 0.0188530795276165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4010090505253174e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969164215028286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21955016255378723,
      "backward_entropy": 0.018852899471918743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3778072722489014e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691653326153755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21954910457134247,
      "backward_entropy": 0.018852720657984417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1111962900686194e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969166450202465,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195480614900589,
      "backward_entropy": 0.018852544327576954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.71445401267556e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691675677895546,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21954703330993652,
      "backward_entropy": 0.01885238041480382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.47322270499717e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969168685376644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195460945367813,
      "backward_entropy": 0.018852209051450092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0260741823440185e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691698029637337,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195451557636261,
      "backward_entropy": 0.01885203644633293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2668830013117258e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691709205508232,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21954426169395447,
      "backward_entropy": 0.018851878742376964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.577324096364464e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691720381379128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21954339742660522,
      "backward_entropy": 0.018851713587840397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.668295451258018e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691731557250023,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21954256296157837,
      "backward_entropy": 0.01885155960917473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.969125603158318e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969174273312092,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195417582988739,
      "backward_entropy": 0.01885140190521876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.679012709450035e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691753908991814,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21954095363616943,
      "backward_entropy": 0.02095130831003189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0499416564234707e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969176322221756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21954013407230377,
      "backward_entropy": 0.018851131200790405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4034280582109204e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691772535443306,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21953937411308289,
      "backward_entropy": 0.01885097846388817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6358264904047246e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0296917837113142,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21953865885734558,
      "backward_entropy": 0.01905162384112676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3216159661387792e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691793024539948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195378988981247,
      "backward_entropy": 0.018850682924191158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.873477515346167e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691802337765694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21953719854354858,
      "backward_entropy": 0.020950570702552795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5927375329738425e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02969181165099144,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21953651309013367,
      "backward_entropy": 0.02095046142737071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.452984233514144e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029691819101572037,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21953582763671875,
      "backward_entropy": 0.019051631291707356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9151465835420822e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691826552152634,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21953515708446503,
      "backward_entropy": 0.01885024458169937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.271954346293569e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969183214008808,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195344716310501,
      "backward_entropy": 0.018850119163592655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.438612571291742e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969183959066868,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21953381597995758,
      "backward_entropy": 0.01885003720720609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2449194741748215e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691845178604126,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21953319013118744,
      "backward_entropy": 0.020949875315030415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6519402379344683e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029691850766539574,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21953260898590088,
      "backward_entropy": 0.02094978342453639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1507647457165149e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969185635447502,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21953201293945312,
      "backward_entropy": 0.01884975532690684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0673788608528412e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969186194241047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21953143179416656,
      "backward_entropy": 0.018849685788154602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3666223708241887e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691867530345917,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195308953523636,
      "backward_entropy": 0.018849577754735947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.067934931597847e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029691873118281364,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2195303589105606,
      "backward_entropy": 0.019051772852738697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.136659619760394e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691878706216812,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952979266643524,
      "backward_entropy": 0.01884942998488744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.550592411893376e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969188429415226,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952927112579346,
      "backward_entropy": 0.01884937286376953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.166919940322259e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691889882087708,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952879428863525,
      "backward_entropy": 0.018849266072114308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.861489592642101e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691895470023155,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952831745147705,
      "backward_entropy": 0.01884921391805013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.229083275386074e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691901057958603,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952787041664124,
      "backward_entropy": 0.018849150588115055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.870510643215312e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296919047832489,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952742338180542,
      "backward_entropy": 0.01884905993938446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.674618902025031e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296919085085392,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.219527006149292,
      "backward_entropy": 0.01884901523590088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07344946451849e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0296919122338295,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952657401561737,
      "backward_entropy": 0.018848925828933716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.085351848625578e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691915959119797,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21952617168426514,
      "backward_entropy": 0.018848878641923267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.649547567074478e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029691919684410095,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2195257544517517,
      "backward_entropy": 0.018848837663729984,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 2.13714752177907e-06,
    "avg_log_Z": 0.029691302254796027,
    "success_rate": 1.0,
    "avg_reward": 53.2,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.13,
      "1": 0.18,
      "2": 0.69
    },
    "avg_forward_entropy": 0.21959021866321562,
    "avg_backward_entropy": 0.019261010450621445,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}