{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09898264067513603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894100257328578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.960683822631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701891899108887,
      "backward_entropy": 0.09894159861973353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.956650733947754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702601194381714,
      "backward_entropy": 0.09893723045076643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.351966857910156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0001999995729420334,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370328664779663,
      "backward_entropy": 0.09893080166407994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.139257431030273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003000734723173082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370396614074707,
      "backward_entropy": 0.0989281449999128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.135509490966797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00040012309909798205,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704665005207062,
      "backward_entropy": 0.09896832704544067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.338593482971191,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005001577665098011,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370537430047989,
      "backward_entropy": 0.09896437610898699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.628255844116211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006002517766319215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706055283546448,
      "backward_entropy": 0.09891346522739955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93311882019043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007004535291343927,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706736266613007,
      "backward_entropy": 0.09890270233154297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.826837539672852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008005457348190248,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707371056079865,
      "backward_entropy": 0.0989516292299543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512335777282715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009005146566778421,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13707971572875977,
      "backward_entropy": 0.0988976103918893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.801301956176758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001000588177703321,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370859295129776,
      "backward_entropy": 0.09889204161507743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.706677436828613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011008197907358408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370925009250641,
      "backward_entropy": 0.098886319569179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.105578422546387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0012011753860861063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709887862205505,
      "backward_entropy": 0.09888044425419398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.59597396850586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013014203868806362,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13710513710975647,
      "backward_entropy": 0.0989271913255964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.782824516296387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014017438516020775,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711129128932953,
      "backward_entropy": 0.0988560404096331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.079140663146973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001502172090113163,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371176689863205,
      "backward_entropy": 0.09886186463492257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.873431205749512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001602811273187399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712389767169952,
      "backward_entropy": 0.09885532515389579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.377694129943848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0017035373020917177,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713018596172333,
      "backward_entropy": 0.09884861537388392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.692607879638672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018041552975773811,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13713645935058594,
      "backward_entropy": 0.09882517371858869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.53832721710205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019044468645006418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714230060577393,
      "backward_entropy": 0.0988339866910662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.234838485717773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020051004830747843,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13714846968650818,
      "backward_entropy": 0.09888571500778198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.10484790802002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002105924766510725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13715508580207825,
      "backward_entropy": 0.09881854057312012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.709686279296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022072040010243654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13716202974319458,
      "backward_entropy": 0.09887252535138812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.676861763000488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002308731898665428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13716916739940643,
      "backward_entropy": 0.09886563675744194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.832818031311035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024097568821161985,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717569410800934,
      "backward_entropy": 0.09885833944593157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.114938735961914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0025107807014137506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718202710151672,
      "backward_entropy": 0.0987849235534668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.404391288757324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026118960231542587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718827068805695,
      "backward_entropy": 0.09877594879695348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.719198226928711,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027132288087159395,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719424605369568,
      "backward_entropy": 0.09874077354158674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.669111251831055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002814455656334758,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13720005750656128,
      "backward_entropy": 0.09875724996839251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.709046363830566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002915928140282631,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372060477733612,
      "backward_entropy": 0.09881797858646937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.085811614990234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003017264883965254,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13721182942390442,
      "backward_entropy": 0.0987077099936349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.79687213897705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031178633216768503,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372167021036148,
      "backward_entropy": 0.09880002907344274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.791988372802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032184843439608812,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722121715545654,
      "backward_entropy": 0.09868414061410087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.548257827758789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033191225957125425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372254192829132,
      "backward_entropy": 0.09878097261701312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.457047462463379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034200772643089294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722962141036987,
      "backward_entropy": 0.09877099309648786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.156864166259766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0035204763989895582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723315298557281,
      "backward_entropy": 0.09876070703778948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.587691307067871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003621067386120558,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723666965961456,
      "backward_entropy": 0.09863154377256121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.709074974060059,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037216150667518377,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723982870578766,
      "backward_entropy": 0.09861728123256139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.043941497802734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003822539933025837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724324107170105,
      "backward_entropy": 0.09872797557285853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.626681327819824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003923531621694565,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724665343761444,
      "backward_entropy": 0.09858752999986921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.280269622802734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0040239919908344746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372496634721756,
      "backward_entropy": 0.09857198170253209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.931939125061035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004124252591282129,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372525691986084,
      "backward_entropy": 0.09869240011487689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.529679298400879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004224604461342096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725556433200836,
      "backward_entropy": 0.09867988313947405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.901365280151367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004324489273130894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372579038143158,
      "backward_entropy": 0.09866702556610107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706483840942383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004424125421792269,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725970685482025,
      "backward_entropy": 0.0985751748085022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.729255676269531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00452343188226223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726118206977844,
      "backward_entropy": 0.09848776885441371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.048257827758789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0046228887513279915,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726262748241425,
      "backward_entropy": 0.09846963201250349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.974512100219727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004721753299236298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726355135440826,
      "backward_entropy": 0.09853318759373256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.065731048583984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004820489324629307,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372644007205963,
      "backward_entropy": 0.09859811408179146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.229307174682617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0049191671423614025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726505637168884,
      "backward_entropy": 0.09850368329456874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.964029312133789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005017452407628298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372651606798172,
      "backward_entropy": 0.09848858628954206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.683256149291992,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00511567946523428,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726525008678436,
      "backward_entropy": 0.09837128434862409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.402755737304688,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005213741213083267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372651755809784,
      "backward_entropy": 0.09835004806518555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.676545143127441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0053115421906113625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726478815078735,
      "backward_entropy": 0.09844131980623518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673184394836426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005409230012446642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726426661014557,
      "backward_entropy": 0.0984253968511309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.946696281433105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0055068195797502995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13726364076137543,
      "backward_entropy": 0.09848531654902867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.927342891693115,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005604441277682781,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13726305961608887,
      "backward_entropy": 0.09846746921539307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.755548477172852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005701626650989056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13726221024990082,
      "backward_entropy": 0.0984492472239903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56741714477539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005798833444714546,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726119697093964,
      "backward_entropy": 0.09821139063153948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.933547019958496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005895949434489012,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13726018369197845,
      "backward_entropy": 0.09841137272971016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.837594985961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005993112456053495,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725969195365906,
      "backward_entropy": 0.0981604882649013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.373164176940918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006090313661843538,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372593492269516,
      "backward_entropy": 0.0981339727129255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.9358491897583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006187368184328079,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725867867469788,
      "backward_entropy": 0.098351103918893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.09067153930664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0062849554233253,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725876808166504,
      "backward_entropy": 0.0980790342603411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.454439163208008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006382234860211611,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137258380651474,
      "backward_entropy": 0.0980506454195295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.453984260559082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006479420233517885,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725759088993073,
      "backward_entropy": 0.09828637327466692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.356603622436523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006576474756002426,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725687563419342,
      "backward_entropy": 0.0982050895690918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.821002960205078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0066734072752296925,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725587725639343,
      "backward_entropy": 0.09818424497331892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.259421348571777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0067708962596952915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725532591342926,
      "backward_entropy": 0.09816268512180873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991487503051758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006868160795420408,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725455105304718,
      "backward_entropy": 0.09789987121309553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.442611694335938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006965537089854479,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725420832633972,
      "backward_entropy": 0.09816785369600568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52425765991211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007063249591737986,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725408911705017,
      "backward_entropy": 0.09783514908381871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.243474960327148,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007160839159041643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725388050079346,
      "backward_entropy": 0.09807171140398298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.87529468536377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0072577111423015594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725320994853973,
      "backward_entropy": 0.09804809093475342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.610188484191895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00735478475689888,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137252077460289,
      "backward_entropy": 0.09773307187216622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.325098991394043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0074523030780255795,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725152611732483,
      "backward_entropy": 0.09769747938428607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.690851211547852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007549659349024296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13725066184997559,
      "backward_entropy": 0.09797401087624687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.767494201660156,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007647005841135979,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724999129772186,
      "backward_entropy": 0.09797700813838414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.04765510559082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007744932547211647,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.137249156832695,
      "backward_entropy": 0.09758623157228742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.675681114196777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007842482067644596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724832236766815,
      "backward_entropy": 0.09791650090898786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.220695495605469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007940487936139107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724787533283234,
      "backward_entropy": 0.09786699499402728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.125645637512207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008038663305342197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724784553050995,
      "backward_entropy": 0.09785330295562744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.203444480895996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008136492222547531,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724760711193085,
      "backward_entropy": 0.09742483070918492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.74284553527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008234558627009392,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724729418754578,
      "backward_entropy": 0.09738214526857648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.290526390075684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00833264458924532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372464895248413,
      "backward_entropy": 0.09775291170392718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.643343925476074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008430508896708488,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724523782730103,
      "backward_entropy": 0.09729482446398054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.462198257446289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008528797887265682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724438846111298,
      "backward_entropy": 0.09768797670091901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.373394012451172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008627352304756641,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372441053390503,
      "backward_entropy": 0.09764529977525983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.822193145751953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008725643157958984,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724373281002045,
      "backward_entropy": 0.09715427671160017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.437105178833008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008823891170322895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724368810653687,
      "backward_entropy": 0.0971048389162336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.003012657165527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0089224549010396,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724355399608612,
      "backward_entropy": 0.0970543452671596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.60707950592041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009020568802952766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724330067634583,
      "backward_entropy": 0.09749059166227068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.975767135620117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009119079448282719,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724318146705627,
      "backward_entropy": 0.09748712607792445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.057501792907715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009217635728418827,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372430920600891,
      "backward_entropy": 0.09740803922925677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.057506561279297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00931628979742527,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724282383918762,
      "backward_entropy": 0.09684092657906669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.580486297607422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009414982050657272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372428834438324,
      "backward_entropy": 0.09732179130826678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.952442169189453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009514003992080688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724297285079956,
      "backward_entropy": 0.09733969824654716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.771507263183594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00961301103234291,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724292814731598,
      "backward_entropy": 0.09666761330195836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.646282196044922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009711888618767262,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724301755428314,
      "backward_entropy": 0.09726013456072126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.610950946807861,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009811127558350563,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724276423454285,
      "backward_entropy": 0.09721887111663818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.63155746459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00990964937955141,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13724234700202942,
      "backward_entropy": 0.09648259196962629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.866379737854004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010008568875491619,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724184036254883,
      "backward_entropy": 0.09703632763453893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.475035667419434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010106927715241909,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724131882190704,
      "backward_entropy": 0.09698443753378731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.207046508789062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010205144062638283,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724032044410706,
      "backward_entropy": 0.09704717567988805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.151041507720947,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010303055867552757,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723936676979065,
      "backward_entropy": 0.09621843269893102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.370988845825195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010400193743407726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372380554676056,
      "backward_entropy": 0.09695755583899361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.325688362121582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01049720961600542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372370719909668,
      "backward_entropy": 0.09691160917282104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.796135902404785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010594607330858707,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372363269329071,
      "backward_entropy": 0.09686437674931117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787264823913574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01069214753806591,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372351348400116,
      "backward_entropy": 0.09593299457005092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.002110481262207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010789711028337479,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372344195842743,
      "backward_entropy": 0.09585779053824288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.295137405395508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010887022130191326,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13723300397396088,
      "backward_entropy": 0.09578178610120501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.248603820800781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01098467968404293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13723179697990417,
      "backward_entropy": 0.09666585922241211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15494441986084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011082147248089314,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723045587539673,
      "backward_entropy": 0.09640049934387207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.981288433074951,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011179383844137192,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372290849685669,
      "backward_entropy": 0.09633529186248779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.796607971191406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011276401579380035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372271478176117,
      "backward_entropy": 0.09626847505569458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.997971534729004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011373049579560757,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722534477710724,
      "backward_entropy": 0.0962003299168178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.165122032165527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011469986289739609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13722360134124756,
      "backward_entropy": 0.09639724663325719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.46781063079834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011567298322916031,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13722164928913116,
      "backward_entropy": 0.09520910467420306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.635324478149414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011664575897157192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372196525335312,
      "backward_entropy": 0.09628163065229144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.196844100952148,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011761941015720367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721735775470734,
      "backward_entropy": 0.09591390405382429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.388863563537598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011859138496220112,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372150182723999,
      "backward_entropy": 0.09583840199879237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.298606872558594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011956801638007164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721251487731934,
      "backward_entropy": 0.09576129061835152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.34954833984375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012054872699081898,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720956444740295,
      "backward_entropy": 0.09474389042173113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.193495750427246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01215281430631876,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372063159942627,
      "backward_entropy": 0.09560155868530273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.575122833251953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012251069769263268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13720276951789856,
      "backward_entropy": 0.09551898070744105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.25471305847168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012349185533821583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371997594833374,
      "backward_entropy": 0.09543532984597343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.911818504333496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012447596527636051,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371966004371643,
      "backward_entropy": 0.09432571274893624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.408072471618652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01254613883793354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371930092573166,
      "backward_entropy": 0.09569289003099714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.979964256286621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012645041570067406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718903064727783,
      "backward_entropy": 0.0956195592880249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.457561492919922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012744075618684292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13718454539775848,
      "backward_entropy": 0.09554486615317208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.598385334014893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012842920608818531,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717998564243317,
      "backward_entropy": 0.09546883617128644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.014659881591797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012941104359924793,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13717582821846008,
      "backward_entropy": 0.09489533730915614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.363935470581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013038937933743,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13717179000377655,
      "backward_entropy": 0.09362895148141044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.083765983581543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013136752881109715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716715574264526,
      "backward_entropy": 0.0952343259538923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.334617614746094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013234310783445835,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716262578964233,
      "backward_entropy": 0.09515383413859776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.829869270324707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013331816531717777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13715793192386627,
      "backward_entropy": 0.0944951857839312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.969671249389648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013430067338049412,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13715249300003052,
      "backward_entropy": 0.09312526668821063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142772674560547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013527944684028625,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13714736700057983,
      "backward_entropy": 0.09299651214054652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.208760261535645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013625659979879856,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13714201748371124,
      "backward_entropy": 0.09286609717777797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.190194129943848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013723230920732021,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713660836219788,
      "backward_entropy": 0.09472802707127162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.18761920928955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013821163214743137,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371309459209442,
      "backward_entropy": 0.09259732280458723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.510018348693848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013919468969106674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13712474703788757,
      "backward_entropy": 0.09454338039670672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.482881546020508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014017737470567226,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13711833953857422,
      "backward_entropy": 0.09371045657566615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.894858360290527,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014117006212472916,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13711094856262207,
      "backward_entropy": 0.09217665876661028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.220417976379395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01421631220728159,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371033936738968,
      "backward_entropy": 0.09424870354788643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71679401397705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014315280131995678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709601759910583,
      "backward_entropy": 0.09414620058877128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.028131484985352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014414296485483646,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1370881348848343,
      "backward_entropy": 0.09173123325620379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.100817680358887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01451287604868412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13708066940307617,
      "backward_entropy": 0.09393572807312012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.928894996643066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014611118473112583,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13707348704338074,
      "backward_entropy": 0.09295240470341273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.656645774841309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014708991162478924,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13706649839878082,
      "backward_entropy": 0.0912571634565081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.50262975692749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014806951396167278,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705916702747345,
      "backward_entropy": 0.09360362802233015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.1067476272583,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014904373325407505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13705219328403473,
      "backward_entropy": 0.09348935740334648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.911027908325195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015002110973000526,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704489171504974,
      "backward_entropy": 0.09337168080466134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.759549140930176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015100604854524136,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703668117523193,
      "backward_entropy": 0.09325027465820312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.586822509765625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015199161134660244,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137028306722641,
      "backward_entropy": 0.0920802014214652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.405122756958008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015297702513635159,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701963424682617,
      "backward_entropy": 0.09022436823163714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.59992504119873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01539610605686903,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701091706752777,
      "backward_entropy": 0.0928708825792585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.374897956848145,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01549504417926073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13700133562088013,
      "backward_entropy": 0.09159642457962036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.252680778503418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015593787655234337,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13699176907539368,
      "backward_entropy": 0.09261073384966169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.105663299560547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01569288969039917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369813084602356,
      "backward_entropy": 0.09247748340879168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256352424621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015791643410921097,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136971116065979,
      "backward_entropy": 0.08926163400922503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07485580444336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015890195965766907,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13696083426475525,
      "backward_entropy": 0.09220494542803083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.42106819152832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015988441184163094,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13695070147514343,
      "backward_entropy": 0.08885305268423897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5149564743042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016086041927337646,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369413137435913,
      "backward_entropy": 0.08864270789282662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.733064651489258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01618366502225399,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369316130876541,
      "backward_entropy": 0.08842822483607701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.397708892822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01628142036497593,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1369214504957199,
      "backward_entropy": 0.08820959499904088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.095026016235352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016379106789827347,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13691109418869019,
      "backward_entropy": 0.08798715046473912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.045622825622559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01647714152932167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13689981400966644,
      "backward_entropy": 0.09132947240556989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82226276397705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016574880108237267,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688860833644867,
      "backward_entropy": 0.0911733593259539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.463063716888428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016672823578119278,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13687652349472046,
      "backward_entropy": 0.0893620422908238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.468899726867676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01677015982568264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686515390872955,
      "backward_entropy": 0.09085266079221453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.367122650146484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016867544502019882,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13685329258441925,
      "backward_entropy": 0.08681505067007882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429420471191406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016964904963970184,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368410587310791,
      "backward_entropy": 0.09052072252546038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.262094497680664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017062293365597725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13682834804058075,
      "backward_entropy": 0.09035004888262067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.767258644104004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017159638926386833,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13681529462337494,
      "backward_entropy": 0.08828105245317731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.28581714630127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017256634309887886,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13680250942707062,
      "backward_entropy": 0.08580047743661064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.56425142288208,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017353607341647148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678932189941406,
      "backward_entropy": 0.08982095548084804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.161299705505371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017450129613280296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1367766410112381,
      "backward_entropy": 0.08963540622166224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.303308486938477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017546597868204117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676370680332184,
      "backward_entropy": 0.08944192954472133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.670037269592285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01764312945306301,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367504894733429,
      "backward_entropy": 0.08712207419531685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.257988929748535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017739947885274887,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13673625886440277,
      "backward_entropy": 0.08440821511404854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.504246234893799,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01783677004277706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13672156631946564,
      "backward_entropy": 0.08662819010870797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.437743186950684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017933230847120285,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13670755922794342,
      "backward_entropy": 0.08637339728219169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.579092979431152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01802922785282135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669410347938538,
      "backward_entropy": 0.0884136472429548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941506385803223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01812492124736309,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668093085289001,
      "backward_entropy": 0.08585114138466972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.301922798156738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018220573663711548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13666749000549316,
      "backward_entropy": 0.08797769887106759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.81165075302124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018316416069865227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13665322959423065,
      "backward_entropy": 0.08775320223399571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.102930068969727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018412116914987564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366388350725174,
      "backward_entropy": 0.08502725192478724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2987847328186035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018507253378629684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13662534952163696,
      "backward_entropy": 0.08728986127035958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47401237487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01860199309885502,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13661228120326996,
      "backward_entropy": 0.08161181211471558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.100414276123047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018697082996368408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365976780653,
      "backward_entropy": 0.0868087751524789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.732924938201904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018792828544974327,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13658058643341064,
      "backward_entropy": 0.08655854633876256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.115936279296875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01888784021139145,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365651935338974,
      "backward_entropy": 0.08059182337352208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.06096076965332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01898302137851715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365489661693573,
      "backward_entropy": 0.08604839869907924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.861258506774902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019078271463513374,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365315020084381,
      "backward_entropy": 0.08578578063419887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.606305122375488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019174637272953987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13650977611541748,
      "backward_entropy": 0.08551527772630964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.220598220825195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01927007921040058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13648994266986847,
      "backward_entropy": 0.08524268865585327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.352323532104492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019365031272172928,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13647055625915527,
      "backward_entropy": 0.07879608869552612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.060005187988281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01945965364575386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645127415657043,
      "backward_entropy": 0.08160897663661412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.664341449737549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019553855061531067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13643281161785126,
      "backward_entropy": 0.08127001353672572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0514984130859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01964801549911499,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13641369342803955,
      "backward_entropy": 0.0776458467755999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.971183776855469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019741762429475784,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13639509677886963,
      "backward_entropy": 0.0838174479348319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.905332088470459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01983572542667389,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13637509942054749,
      "backward_entropy": 0.0802211080278669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.615594863891602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01992979273200035,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13635359704494476,
      "backward_entropy": 0.07644534962517875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.628249168395996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020023828372359276,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363314390182495,
      "backward_entropy": 0.08290691035134452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.753503799438477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020117806270718575,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13630816340446472,
      "backward_entropy": 0.07561838626861572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.977635383605957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02021184377372265,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13628363609313965,
      "backward_entropy": 0.07519704954964775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9446120262146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020305514335632324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362602561712265,
      "backward_entropy": 0.08194197075707572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.688514709472656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020398836582899094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362379491329193,
      "backward_entropy": 0.08161187171936035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.325242042541504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02049221657216549,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13621386885643005,
      "backward_entropy": 0.07758285318102155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.487422466278076,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02058546058833599,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13618919253349304,
      "backward_entropy": 0.07718407256262642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4898786544799805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02067800611257553,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136165589094162,
      "backward_entropy": 0.0730266911642892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8935699462890625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020769985392689705,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13614332675933838,
      "backward_entropy": 0.08024223361696516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.017441272735596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02086232416331768,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361183226108551,
      "backward_entropy": 0.07988742419651576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.859745979309082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020954420790076256,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13609273731708527,
      "backward_entropy": 0.07554996013641357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.413665771484375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02104623056948185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136067196726799,
      "backward_entropy": 0.07512938124792916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.624890327453613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021138107404112816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13603967428207397,
      "backward_entropy": 0.0787937981741769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.33369255065918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021229542791843414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13601243495941162,
      "backward_entropy": 0.07841987269265312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.050774574279785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021321136504411697,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13598433136940002,
      "backward_entropy": 0.06976698551859174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.541967391967773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021412551403045654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13595451414585114,
      "backward_entropy": 0.07340077842984881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.165090560913086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02150348573923111,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13592450320720673,
      "backward_entropy": 0.07726653984614781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.740224838256836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021594475954771042,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358930766582489,
      "backward_entropy": 0.07687200818743024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.887171745300293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021685922518372536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585877418518066,
      "backward_entropy": 0.07206004858016968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.497303009033203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021777210757136345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358240842819214,
      "backward_entropy": 0.07606409277234759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.720837593078613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021868083626031876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357899010181427,
      "backward_entropy": 0.07565455777304513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.941525459289551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021958738565444946,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13575534522533417,
      "backward_entropy": 0.07066574266978673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.709478378295898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022049354389309883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13571949303150177,
      "backward_entropy": 0.0748215913772583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6637701988220215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022139795124530792,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13568329811096191,
      "backward_entropy": 0.07439819404057094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3842926025390625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022230051457881927,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1356467306613922,
      "backward_entropy": 0.07397047962461199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.196525573730469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022319911047816277,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13560985028743744,
      "backward_entropy": 0.07353904417582921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.586180686950684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022409996017813683,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13556994497776031,
      "backward_entropy": 0.0637081435748509,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.428416728973389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022500546649098396,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13552553951740265,
      "backward_entropy": 0.06774451902934484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.991312026977539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022591441869735718,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13547806441783905,
      "backward_entropy": 0.0626526687826429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.27605676651001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022681673988699913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13543298840522766,
      "backward_entropy": 0.0717483673776899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.441615581512451,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022771529853343964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13538908958435059,
      "backward_entropy": 0.07129193203789848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.926054000854492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022861821576952934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13534069061279297,
      "backward_entropy": 0.06569809573037284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.976754188537598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022951489314436913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13529470562934875,
      "backward_entropy": 0.07036284463746208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.599009037017822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023040607571601868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13524994254112244,
      "backward_entropy": 0.06464941586766924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.470312118530273,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023129673674702644,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13520322740077972,
      "backward_entropy": 0.06942314761025566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.192878246307373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023218588903546333,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1351546049118042,
      "backward_entropy": 0.058899836880820136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.243396759033203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023307127878069878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13510411977767944,
      "backward_entropy": 0.06846518175942558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.76895809173584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023395493626594543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13505418598651886,
      "backward_entropy": 0.06798112392425537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7350029945373535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023483222350478172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13500341773033142,
      "backward_entropy": 0.06749486071722847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.529842376708984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023571163415908813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1349487006664276,
      "backward_entropy": 0.06144230280603681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.973636150360107,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02365911938250065,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13489025831222534,
      "backward_entropy": 0.05615176047597613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.279812812805176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023746725171804428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134831503033638,
      "backward_entropy": 0.06035629340580532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.842648506164551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023833511397242546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13477593660354614,
      "backward_entropy": 0.06549102919442314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.076302528381348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023920027539134026,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13472111523151398,
      "backward_entropy": 0.05924808979034424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.605607986450195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024006346240639687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13466203212738037,
      "backward_entropy": 0.06446825180734907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.389528751373291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024092193692922592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13460242748260498,
      "backward_entropy": 0.06395207132611956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.847647190093994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024177473038434982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1345435529947281,
      "backward_entropy": 0.05757393155779157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.649951457977295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024263421073555946,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13447853922843933,
      "backward_entropy": 0.052244986806597025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.844518184661865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02434827946126461,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1344199776649475,
      "backward_entropy": 0.056440378938402445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.457899570465088,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024432985112071037,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13435693085193634,
      "backward_entropy": 0.055874449866158624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.398711681365967,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024517333135008812,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1342935860157013,
      "backward_entropy": 0.05056550247328622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.830174922943115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024601319804787636,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13423021137714386,
      "backward_entropy": 0.05000565307480948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.294708251953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02468450926244259,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1341690570116043,
      "backward_entropy": 0.054167943341391425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.152591228485107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02476733736693859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1341058611869812,
      "backward_entropy": 0.05971840449741909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.294234275817871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02484976127743721,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13404209911823273,
      "backward_entropy": 0.053031712770462036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.24683952331543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024931998923420906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13397805392742157,
      "backward_entropy": 0.05863812140056065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.549422740936279,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025013988837599754,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1339120864868164,
      "backward_entropy": 0.051884587321962626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.348053455352783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025095175951719284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1338483840227127,
      "backward_entropy": 0.05755228655678885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.500916957855225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025175489485263824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13378825783729553,
      "backward_entropy": 0.05701274105480739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.70172119140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025255154818296432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1337299793958664,
      "backward_entropy": 0.056474106652396064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8234968185424805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02533448487520218,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13367390632629395,
      "backward_entropy": 0.05593538710049221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.875883102416992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025413455441594124,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1336129903793335,
      "backward_entropy": 0.055394504751477926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.383303165435791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025492243468761444,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13354922831058502,
      "backward_entropy": 0.0438797048160008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.35084342956543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025570543482899666,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13348989188671112,
      "backward_entropy": 0.04786954607282366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.093426704406738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02564827725291252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13343040645122528,
      "backward_entropy": 0.05376849004200527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.097392559051514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02572527341544628,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13337230682373047,
      "backward_entropy": 0.042241041149411886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.029689311981201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025801634415984154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13331566751003265,
      "backward_entropy": 0.052691719361713955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.576052188873291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025878235697746277,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13325080275535583,
      "backward_entropy": 0.052148525203977315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1607561111450195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02595464326441288,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13318133354187012,
      "backward_entropy": 0.04062234078134809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.544323682785034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603062614798546,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13311482965946198,
      "backward_entropy": 0.05105985062462943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.488189697265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026105595752596855,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1330537050962448,
      "backward_entropy": 0.03956090978213719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.681692600250244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026180578395724297,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1329897940158844,
      "backward_entropy": 0.03903603553771973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9324047565460205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026255734264850616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1329198181629181,
      "backward_entropy": 0.04278529967580523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9122250080108643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633034996688366,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13285057246685028,
      "backward_entropy": 0.04889187642506191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8107523918151855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026404542848467827,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1327844262123108,
      "backward_entropy": 0.04166412779263088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9092063903808594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02647818811237812,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13271862268447876,
      "backward_entropy": 0.041105057512010844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9913227558135986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02655045874416828,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1326615810394287,
      "backward_entropy": 0.04728067772729056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6125004291534424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026622556149959564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13260063529014587,
      "backward_entropy": 0.03999848025185721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.570237874984741,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026694197207689285,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1325417160987854,
      "backward_entropy": 0.03547971163477216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5612826347351074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026765335351228714,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1324823498725891,
      "backward_entropy": 0.034989897693906515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.35050106048584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026836037635803223,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13242271542549133,
      "backward_entropy": 0.03835548673357282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9070422649383545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026906074956059456,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13236212730407715,
      "backward_entropy": 0.03402253772531237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4017536640167236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02697502262890339,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13230375945568085,
      "backward_entropy": 0.04410284757614136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.883953094482422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027043551206588745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1322426199913025,
      "backward_entropy": 0.04357887591634478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.864694833755493,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027112262323498726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1321742683649063,
      "backward_entropy": 0.036241931574685235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.063964366912842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027179958298802376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1321067363023758,
      "backward_entropy": 0.03572856102670942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2567520141601562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02724701166152954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13203860819339752,
      "backward_entropy": 0.04201078840664455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4663846492767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027313755825161934,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1319686472415924,
      "backward_entropy": 0.04149360741887774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.471001625061035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027380451560020447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1318933665752411,
      "backward_entropy": 0.04097534077508109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9243552684783936,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027447083964943886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13181106746196747,
      "backward_entropy": 0.033714703151157925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.481099843978882,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027513092383742332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1317295879125595,
      "backward_entropy": 0.033220616834504266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.430609703063965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027577977627515793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13165175914764404,
      "backward_entropy": 0.03943331752504621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6726393699645996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027642982080578804,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1315651834011078,
      "backward_entropy": 0.03225335478782654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5660786628723145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027707204222679138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13147908449172974,
      "backward_entropy": 0.038420719759804864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6159658432006836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027771886438131332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1313839852809906,
      "backward_entropy": 0.03130174960408892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7385950088500977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02783587947487831,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13129305839538574,
      "backward_entropy": 0.027724534273147583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7059545516967773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02789944037795067,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1312044858932495,
      "backward_entropy": 0.03691522564206805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5017542839050293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027962515130639076,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13111549615859985,
      "backward_entropy": 0.02690138348511287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.224012851715088,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028024807572364807,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13102491199970245,
      "backward_entropy": 0.02943697146006993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5969934463500977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02808615006506443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13093940913677216,
      "backward_entropy": 0.03545604007584708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5748181343078613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028147079050540924,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13085070252418518,
      "backward_entropy": 0.02854235257421221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.19533109664917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02820764295756817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13075926899909973,
      "backward_entropy": 0.028102206332342967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3686861991882324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02826731838285923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13066813349723816,
      "backward_entropy": 0.03403793488230024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.882138967514038,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028326518833637238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13057632744312286,
      "backward_entropy": 0.033575126102992466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.290837287902832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028384655714035034,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13049153983592987,
      "backward_entropy": 0.02419757843017578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8792980909347534,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02844231389462948,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13040275871753693,
      "backward_entropy": 0.03267278415816171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1869313716888428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028499044477939606,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13031847774982452,
      "backward_entropy": 0.023476336683545793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1085684299468994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028555409982800484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1302330195903778,
      "backward_entropy": 0.03179431600230081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.056185722351074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028611214831471443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13014307618141174,
      "backward_entropy": 0.03136108602796282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3468170166015625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028666548430919647,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13005192577838898,
      "backward_entropy": 0.030932192291532244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8727384805679321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028721828013658524,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1299506425857544,
      "backward_entropy": 0.030503483755247935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9646971225738525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02877645008265972,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1298508644104004,
      "backward_entropy": 0.024041501539094106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.127798080444336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02883056551218033,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12974786758422852,
      "backward_entropy": 0.02366232020514352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.211228370666504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028884511440992355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12963852286338806,
      "backward_entropy": 0.023287108966282437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.101055383682251,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02893838658928871,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12951910495758057,
      "backward_entropy": 0.02078911874975477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7380638122558594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02899209037423134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12939272820949554,
      "backward_entropy": 0.02841740846633911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7771639823913574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029045138508081436,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12926793098449707,
      "backward_entropy": 0.020157113671302795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.28275728225708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029097547754645348,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12913942337036133,
      "backward_entropy": 0.0276092461177281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.337451457977295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029150288552045822,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12899768352508545,
      "backward_entropy": 0.027205965348652432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2582508325576782,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029201814904808998,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128864124417305,
      "backward_entropy": 0.02114362801824297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1961039304733276,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029252054169774055,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12873731553554535,
      "backward_entropy": 0.018957968269075667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7752223014831543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029300851747393608,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1286126673221588,
      "backward_entropy": 0.01867770935807909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3535733222961426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029349487274885178,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1284784972667694,
      "backward_entropy": 0.018400507313864573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4679908752441406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029397249221801758,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12834466993808746,
      "backward_entropy": 0.01986481887953622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8652814626693726,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029444586485624313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12821105122566223,
      "backward_entropy": 0.019559898546763828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.224552035331726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029492150992155075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1280636191368103,
      "backward_entropy": 0.02463239218507494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1096819639205933,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029538840055465698,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12792067229747772,
      "backward_entropy": 0.01734095173222678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0459020137786865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029584508389234543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12778347730636597,
      "backward_entropy": 0.0186732964856284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1027531623840332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029629068449139595,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12765063345432281,
      "backward_entropy": 0.016846748335020884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0558637380599976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967279776930809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12752053141593933,
      "backward_entropy": 0.02329899157796587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3204137086868286,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029715653508901596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12739241123199463,
      "backward_entropy": 0.022986062935420444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1183844804763794,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029758384451270103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12726016342639923,
      "backward_entropy": 0.02267484792641231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3058087825775146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02980048768222332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12712636590003967,
      "backward_entropy": 0.017324450824941908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6933262944221497,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029842374846339226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12698328495025635,
      "backward_entropy": 0.022065301026616777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9456045627593994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02988278865814209,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12685012817382812,
      "backward_entropy": 0.021774047187396457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0935431718826294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02992239221930504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12671640515327454,
      "backward_entropy": 0.021489475454602922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7780123949050903,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029961636289954185,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12657709419727325,
      "backward_entropy": 0.01634852055992399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.86246657371521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029999801889061928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12644101679325104,
      "backward_entropy": 0.020935354488236562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0274503231048584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030037201941013336,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12630434334278107,
      "backward_entropy": 0.01469623829637255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7334868311882019,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030074456706643105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1261635571718216,
      "backward_entropy": 0.02040418131010873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8867996335029602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030110836029052734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12602722644805908,
      "backward_entropy": 0.015466375010354179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8835406303405762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03014671616256237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1258867383003235,
      "backward_entropy": 0.019893618566649302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5539648532867432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030182262882590294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257437914609909,
      "backward_entropy": 0.015051767230033875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9955451488494873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030216556042432785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12560756504535675,
      "backward_entropy": 0.01940328734261649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5468541979789734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030250901356339455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1254606395959854,
      "backward_entropy": 0.014657833746501378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.737756609916687,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030283991247415543,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12531757354736328,
      "backward_entropy": 0.018932061535971507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7144433856010437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03031669370830059,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12517400085926056,
      "backward_entropy": 0.014285224889005934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6916763186454773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030348991975188255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12502986192703247,
      "backward_entropy": 0.01315432574067797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.552051842212677,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030380871146917343,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12488517165184021,
      "backward_entropy": 0.01392509468964168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5171687602996826,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030411673709750175,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12473952770233154,
      "backward_entropy": 0.012856228010995048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.451068252325058,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03044157847762108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1245967298746109,
      "backward_entropy": 0.0135886584009443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5167094469070435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030470363795757294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12445667386054993,
      "backward_entropy": 0.01764615625143051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45887020230293274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03049839660525322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12431645393371582,
      "backward_entropy": 0.017454677394458225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5309166312217712,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03052549809217453,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12417672574520111,
      "backward_entropy": 0.012327869023595537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5511862635612488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030552178621292114,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12403644621372223,
      "backward_entropy": 0.012206345796585083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5314085483551025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030578583478927612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1238943338394165,
      "backward_entropy": 0.016909033060073853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44964277744293213,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030604640021920204,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12375004589557648,
      "backward_entropy": 0.011969566345214844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4076826870441437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030630091205239296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12360654026269913,
      "backward_entropy": 0.016560199005263194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5123974680900574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065490908920765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12346592545509338,
      "backward_entropy": 0.016392870673111508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37458255887031555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03067943826317787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1233205795288086,
      "backward_entropy": 0.016227314514773234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4594411849975586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070313110947609,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12317589670419693,
      "backward_entropy": 0.01606760174036026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43748939037323,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030726619064807892,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12303002178668976,
      "backward_entropy": 0.011432530624525887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3734362721443176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030749624595046043,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12288036942481995,
      "backward_entropy": 0.011333530502659934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3849475085735321,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030772067606449127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1227312684059143,
      "backward_entropy": 0.015603972332818168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37959229946136475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03079390525817871,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12257911264896393,
      "backward_entropy": 0.011145342673574175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33891937136650085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030815456062555313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12242758274078369,
      "backward_entropy": 0.01531202026775905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3295489549636841,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03083636984229088,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12227542698383331,
      "backward_entropy": 0.015170570995126451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2721768319606781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030856721103191376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12212318181991577,
      "backward_entropy": 0.015032727803502764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4712892770767212,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030876297503709793,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12197326123714447,
      "backward_entropy": 0.01490007873092379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32404443621635437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030896050855517387,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1218130886554718,
      "backward_entropy": 0.014765710702964239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3135402202606201,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030915575101971626,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12165459990501404,
      "backward_entropy": 0.011086251054491316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36660587787628174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030934570357203484,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12149430811405182,
      "backward_entropy": 0.014504089951515198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2334604263305664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030953601002693176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1213313490152359,
      "backward_entropy": 0.014374884111540658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3843313455581665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030971864238381386,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1211717426776886,
      "backward_entropy": 0.010420860988753182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20005100965499878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03099019266664982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12100504338741302,
      "backward_entropy": 0.014126577547618322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26629865169525146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031007669866085052,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12084326148033142,
      "backward_entropy": 0.0106279690350805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2787051200866699,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0310248751193285,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12068259716033936,
      "backward_entropy": 0.010214586343084062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25190216302871704,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03104170598089695,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12051936984062195,
      "backward_entropy": 0.010150205876146044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24681824445724487,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03105812706053257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12035566568374634,
      "backward_entropy": 0.01038041923727308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1871025711297989,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03107401542365551,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12018987536430359,
      "backward_entropy": 0.010303131171635218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2777928113937378,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03108927421271801,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12002771347761154,
      "backward_entropy": 0.009972440344946725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.223735973238945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0311044342815876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11986115574836731,
      "backward_entropy": 0.013352151427950178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1996309757232666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03111918643116951,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11969385296106339,
      "backward_entropy": 0.009863319141524178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18252013623714447,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031133543699979782,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11952818930149078,
      "backward_entropy": 0.009811576988015856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23525826632976532,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031147312372922897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11936359852552414,
      "backward_entropy": 0.009762808680534363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1720973402261734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031160805374383926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11919461190700531,
      "backward_entropy": 0.009885575090135847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19647639989852905,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031173747032880783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11902694404125214,
      "backward_entropy": 0.012880169919558935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19974498450756073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031186247244477272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11885707825422287,
      "backward_entropy": 0.01279436903340476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21887916326522827,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031198523938655853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11868569254875183,
      "backward_entropy": 0.009706756898335047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13432976603507996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031210731714963913,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11851069331169128,
      "backward_entropy": 0.012625956109591894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21204176545143127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03122212179005146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1183377057313919,
      "backward_entropy": 0.012547110872609275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.179774671792984,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031233711168169975,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11816245317459106,
      "backward_entropy": 0.009473620780876704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13267838954925537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031245002523064613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11798536777496338,
      "backward_entropy": 0.012388949947697776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14066921174526215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03125600516796112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11781303584575653,
      "backward_entropy": 0.012312995535986764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1258663833141327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126676380634308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11764343082904816,
      "backward_entropy": 0.012238865452153342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1408233642578125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0312768779695034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.117474764585495,
      "backward_entropy": 0.012168706527778081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17683745920658112,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031286902725696564,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11730809509754181,
      "backward_entropy": 0.009304608617510115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14602406322956085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03129708021879196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11713866889476776,
      "backward_entropy": 0.012029054973806654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09898905456066132,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03130709007382393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1169687956571579,
      "backward_entropy": 0.011959885912282127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14465753734111786,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03131650760769844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11680243164300919,
      "backward_entropy": 0.009162275918892451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10484006255865097,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031325895339250565,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1166350245475769,
      "backward_entropy": 0.011829436889716558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15642142295837402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03133472427725792,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11646893620491028,
      "backward_entropy": 0.009156370801585061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11206380277872086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03134385123848915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11630070209503174,
      "backward_entropy": 0.01170438528060913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12762820720672607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03135262057185173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11613309383392334,
      "backward_entropy": 0.011643241558756148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12319275736808777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031361352652311325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11596492677927017,
      "backward_entropy": 0.011582410761288233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11386978626251221,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031369805335998535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11579474806785583,
      "backward_entropy": 0.008924227207899094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11587680876255035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031378116458654404,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1156248152256012,
      "backward_entropy": 0.009026543370315008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08382139354944229,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03138638287782669,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11545488238334656,
      "backward_entropy": 0.00885109496968133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1099216565489769,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031394366174936295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11528892815113068,
      "backward_entropy": 0.008816003799438477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08125178515911102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03140227496623993,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11512231081724167,
      "backward_entropy": 0.008781347955976213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08744791150093079,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0314098484814167,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11495848000049591,
      "backward_entropy": 0.011242515274456568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1181274950504303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031417109072208405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11479547619819641,
      "backward_entropy": 0.011191244636263167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07571855187416077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03142467886209488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11463063955307007,
      "backward_entropy": 0.011138235884053367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09092318266630173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03143205866217613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11446928232908249,
      "backward_entropy": 0.01108664380652564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08915717899799347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0314394012093544,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11430837213993073,
      "backward_entropy": 0.011035400841917311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0914522334933281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0314466692507267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11414746940135956,
      "backward_entropy": 0.008588613676173347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06733160465955734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03145407885313034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11398714780807495,
      "backward_entropy": 0.010933354496955872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06289258599281311,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03146106377243996,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11382852494716644,
      "backward_entropy": 0.010884611734322138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07921535521745682,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03146754577755928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11367128044366837,
      "backward_entropy": 0.008499199258429664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06973238289356232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031473785638809204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11351257562637329,
      "backward_entropy": 0.010794388396399361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06119373068213463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031479958444833755,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11335547268390656,
      "backward_entropy": 0.0107504917042596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05400511622428894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031485896557569504,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11320032924413681,
      "backward_entropy": 0.010708078742027283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06522630155086517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031491588801145554,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1130482405424118,
      "backward_entropy": 0.010667285748890467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07685180008411407,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03149718418717384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11289656162261963,
      "backward_entropy": 0.010627132441316332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05100308358669281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031503062695264816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11274439841508865,
      "backward_entropy": 0.008348131818430764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05131920054554939,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03150862455368042,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11259438097476959,
      "backward_entropy": 0.008657235120024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04093280807137489,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03151411563158035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11244738101959229,
      "backward_entropy": 0.010506755539349147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06774020195007324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03151921555399895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1123034656047821,
      "backward_entropy": 0.008629266704831804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.047652795910835266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03152456134557724,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11215865612030029,
      "backward_entropy": 0.0086147455232484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053686127066612244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03152954578399658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11201436817646027,
      "backward_entropy": 0.010396213403769903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05462855100631714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031534500420093536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11187057197093964,
      "backward_entropy": 0.010360545345715113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0377873033285141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031539350748062134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11172603070735931,
      "backward_entropy": 0.010325428630624498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034530460834503174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03154400363564491,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11158493161201477,
      "backward_entropy": 0.010291655148778642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052168235182762146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03154829517006874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11144643276929855,
      "backward_entropy": 0.010260048721517836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03839637339115143,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031552787870168686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11130805313587189,
      "backward_entropy": 0.010227382183074951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04035557806491852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03155721351504326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11117219924926758,
      "backward_entropy": 0.010195293596812658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04688729718327522,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03156159073114395,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11103777587413788,
      "backward_entropy": 0.008103703281709127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03988786041736603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03156591206789017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11090215295553207,
      "backward_entropy": 0.010132154183728355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03639440983533859,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03157021850347519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11076772212982178,
      "backward_entropy": 0.010100903255598885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030830658972263336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03157425671815872,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11063358187675476,
      "backward_entropy": 0.010071146701063429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036520082503557205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03157806769013405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11050152778625488,
      "backward_entropy": 0.010042792984417506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039857637137174606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03158187121152878,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11037062108516693,
      "backward_entropy": 0.010014564863273076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03127820044755936,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03158571943640709,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11023936420679092,
      "backward_entropy": 0.008004082100731986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02479015663266182,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03158961981534958,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11011078208684921,
      "backward_entropy": 0.007988072399582182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03252739831805229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03159334883093834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10998542606830597,
      "backward_entropy": 0.009930194488593511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03103196620941162,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03159719705581665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1098615825176239,
      "backward_entropy": 0.009902292064258031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024440089240670204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03160097822546959,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10973823070526123,
      "backward_entropy": 0.009874803679330009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023765958845615387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03160460293292999,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10961713641881943,
      "backward_entropy": 0.0098483573113169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027066875249147415,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031607989221811295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10949747264385223,
      "backward_entropy": 0.007913092417376382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027447862550616264,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03161118924617767,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10937772691249847,
      "backward_entropy": 0.007900006004742213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028782116249203682,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031614501029253006,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10925931483507156,
      "backward_entropy": 0.007886507681437902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027846165001392365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031617745757102966,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10914015769958496,
      "backward_entropy": 0.008390996605157852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020304033532738686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03162122890353203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10902319848537445,
      "backward_entropy": 0.009724976761000497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01953200064599514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031624604016542435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10890893638134003,
      "backward_entropy": 0.009700325982911246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02396741881966591,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031627729535102844,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10879601538181305,
      "backward_entropy": 0.007832604327372142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018316172063350677,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031630877405405045,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10868361592292786,
      "backward_entropy": 0.00965380881513868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016350071877241135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031633857637643814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10857294499874115,
      "backward_entropy": 0.0078076305133955816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018609708175063133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163658827543259,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10846398770809174,
      "backward_entropy": 0.009610733815601893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016906296834349632,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031639259308576584,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10835637152194977,
      "backward_entropy": 0.009590653436524528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016835609450936317,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03164184093475342,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10825051367282867,
      "backward_entropy": 0.0077750129359109065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01658833771944046,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03164438530802727,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10814644396305084,
      "backward_entropy": 0.007764543805803571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014924509450793266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03164687752723694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10804377496242523,
      "backward_entropy": 0.009533437235014779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015495819970965385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031649231910705566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10794247686862946,
      "backward_entropy": 0.007744427238191877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014211484231054783,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03165160119533539,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10784290730953217,
      "backward_entropy": 0.008318904787302017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017044484615325928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031654007732868195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10774566233158112,
      "backward_entropy": 0.00947908844266619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01192297413945198,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031656477600336075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1076488047838211,
      "backward_entropy": 0.009460510952132089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014166404493153095,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031658899039030075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10755454003810883,
      "backward_entropy": 0.009442320891789027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012513399124145508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0316612683236599,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10746096074581146,
      "backward_entropy": 0.00942440118108477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012112533673644066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031663522124290466,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10736837983131409,
      "backward_entropy": 0.00829259678721428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010344520211219788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166572377085686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10727714002132416,
      "backward_entropy": 0.00939022536788668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011098185554146767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166782483458519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10718781501054764,
      "backward_entropy": 0.009373966072286879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010807741433382034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03166982904076576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10709947347640991,
      "backward_entropy": 0.00935824534722737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009737140499055386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167184069752693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10701276361942291,
      "backward_entropy": 0.00934255016701562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01068721991032362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03167378902435303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10692757368087769,
      "backward_entropy": 0.009327338210174016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011078471317887306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031675707548856735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10684317350387573,
      "backward_entropy": 0.009312354028224945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007545071188360453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031677648425102234,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10675936937332153,
      "backward_entropy": 0.008264130779675074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007082263473421335,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031679436564445496,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10667742788791656,
      "backward_entropy": 0.007616135690893445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009381120093166828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03168114274740219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10659778118133545,
      "backward_entropy": 0.009269372693129949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009145678952336311,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031682904809713364,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10651920735836029,
      "backward_entropy": 0.009255476295948029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007915480062365532,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03168465942144394,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1064412072300911,
      "backward_entropy": 0.007593431643077305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007178883533924818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031686365604400635,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10636425018310547,
      "backward_entropy": 0.009228096476622991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007319134194403887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03168800473213196,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10628862679004669,
      "backward_entropy": 0.0075788189257894245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006385510787367821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03168964385986328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10621435195207596,
      "backward_entropy": 0.009201961968626295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00511985132470727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03169118985533714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1061413586139679,
      "backward_entropy": 0.009189480117389135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00540880486369133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03169267624616623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10607077181339264,
      "backward_entropy": 0.009177475103310176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0068901111371815205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031694117933511734,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10600198805332184,
      "backward_entropy": 0.009165803236620767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006284994073212147,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03169563412666321,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10593418776988983,
      "backward_entropy": 0.00915379183632987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005002174060791731,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03169719874858856,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10586759448051453,
      "backward_entropy": 0.0075384144272123066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005054614041000605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031698647886514664,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10580195486545563,
      "backward_entropy": 0.009130361889089857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006218675523996353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031699974089860916,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10573683679103851,
      "backward_entropy": 0.009119676692145211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005472742952406406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031701378524303436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10567228496074677,
      "backward_entropy": 0.009108624288014002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0051537915132939816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03170274198055267,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1056080311536789,
      "backward_entropy": 0.008215716906956263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005421583075076342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03170410916209221,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10554461181163788,
      "backward_entropy": 0.009087008024965013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005811656359583139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03170550614595413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10548170655965805,
      "backward_entropy": 0.0090761056968144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004644555039703846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03170701116323471,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10541920363903046,
      "backward_entropy": 0.007495902478694916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00468754256144166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031708549708127975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10535794496536255,
      "backward_entropy": 0.009053110011986323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004263540729880333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171006217598915,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10529708862304688,
      "backward_entropy": 0.009041755327156611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036245319060981274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031711529940366745,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10523688793182373,
      "backward_entropy": 0.009030652897698539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037848076317459345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171299770474434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1051783412694931,
      "backward_entropy": 0.009019714381013597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00326904165558517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03171442821621895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1051206886768341,
      "backward_entropy": 0.0074644871056079865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028693382628262043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171582892537117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10506455600261688,
      "backward_entropy": 0.008998616465500422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026381933130323887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03171719238162041,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10501010715961456,
      "backward_entropy": 0.008183860353061132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031396544072777033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171847388148308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10495708882808685,
      "backward_entropy": 0.008978783019951411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002903932938352227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03171980381011963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10490546375513077,
      "backward_entropy": 0.008968889713287354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002143782563507557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03172113001346588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10485488921403885,
      "backward_entropy": 0.008959084749221802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025663403794169426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03172233700752258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10480555891990662,
      "backward_entropy": 0.008949955659253257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002135991118848324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03172355145215988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10475742071866989,
      "backward_entropy": 0.008940840406077248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002265394199639559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031724732369184494,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.104710653424263,
      "backward_entropy": 0.008931982730116163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002267048694193363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03172587603330612,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10466478765010834,
      "backward_entropy": 0.007415512310607093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00205641845241189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03172699734568596,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10461968183517456,
      "backward_entropy": 0.008914909724678313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002391057088971138,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03172805905342102,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10457521677017212,
      "backward_entropy": 0.007406061781304223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001626769546419382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031729187816381454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10453146696090698,
      "backward_entropy": 0.008898488112858363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001619662158191204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03173024207353592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10448877513408661,
      "backward_entropy": 0.008890567081315177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001896388246677816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03173130005598068,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10444749891757965,
      "backward_entropy": 0.008882728006158556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015273906756192446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031732331961393356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10440660268068314,
      "backward_entropy": 0.008875036878245217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019661381375044584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031733300536870956,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10436640679836273,
      "backward_entropy": 0.008145216320242201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015871725045144558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03173430636525154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10432654619216919,
      "backward_entropy": 0.008860304419483458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015249542193487287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031735289841890335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10428732633590698,
      "backward_entropy": 0.007375291415623256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011243369663134217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031736280769109726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10424899309873581,
      "backward_entropy": 0.008845706071172441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014886814169585705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03173723816871643,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10421198606491089,
      "backward_entropy": 0.008838629616158349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013414174318313599,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031738217920064926,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10417558997869492,
      "backward_entropy": 0.00813294734273638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010896078310906887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03173917531967163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10413973033428192,
      "backward_entropy": 0.007358720792191369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011389096034690738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174007683992386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1041046530008316,
      "backward_entropy": 0.008817733930689948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009327890002168715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174096718430519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10407034307718277,
      "backward_entropy": 0.008811154003654207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008405104745179415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174179792404175,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10403680801391602,
      "backward_entropy": 0.008804944476911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007829169626347721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174259513616562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10400427877902985,
      "backward_entropy": 0.00879896485379764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00087502202950418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174334764480591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10397270321846008,
      "backward_entropy": 0.00879328272172383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006708189030177891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0317440889775753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10394182056188583,
      "backward_entropy": 0.008787695850644792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007651792839169502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031744759529829025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10391172021627426,
      "backward_entropy": 0.008782531533922468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007788200746290386,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03174540027976036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10388222336769104,
      "backward_entropy": 0.007332048778023038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006280795205384493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031746041029691696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10385335981845856,
      "backward_entropy": 0.008772632905415126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005947917234152555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174667805433273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10382546484470367,
      "backward_entropy": 0.008767764483179365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005492601194418967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174730762839317,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10379850119352341,
      "backward_entropy": 0.008762987064463752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005084595177322626,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031747911125421524,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1037723571062088,
      "backward_entropy": 0.00811035345707621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005872113979421556,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174847364425659,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10374687612056732,
      "backward_entropy": 0.008754003260816847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004348976945038885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03174898773431778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10372164845466614,
      "backward_entropy": 0.00874991129551615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005041598924435675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031749460846185684,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10369718819856644,
      "backward_entropy": 0.008746055620057243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039242603816092014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0317499153316021,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10367318987846375,
      "backward_entropy": 0.00874232713665281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004631563788279891,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03175033628940582,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10364989936351776,
      "backward_entropy": 0.0073105889771665844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004202610580250621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175076097249985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10362717509269714,
      "backward_entropy": 0.008735325719629015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004212903731968254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031751181930303574,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10360501706600189,
      "backward_entropy": 0.008104739444596427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000347105844411999,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03175157681107521,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1035831868648529,
      "backward_entropy": 0.008104162556784493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003893248504027724,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03175197169184685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10356200486421585,
      "backward_entropy": 0.007303318274872643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003183224762324244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031752362847328186,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10354124754667282,
      "backward_entropy": 0.008102968867336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028413214022293687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03175276517868042,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10352121293544769,
      "backward_entropy": 0.007299839385918209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028557138284668326,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031753163784742355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10350187122821808,
      "backward_entropy": 0.007298102336270469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002889330207835883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0317535325884819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10348296910524368,
      "backward_entropy": 0.008712794099535261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000328649184666574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175392746925354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.103464774787426,
      "backward_entropy": 0.008709714881011419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026354967849329114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175433725118637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1034468561410904,
      "backward_entropy": 0.00870658244405474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023433573369402438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0317547433078289,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10342942923307419,
      "backward_entropy": 0.00809825211763382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002657855220604688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031755123287439346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1034124493598938,
      "backward_entropy": 0.008700565035854067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019382558821234852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175549581646919,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10339567065238953,
      "backward_entropy": 0.00869767154966082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002111360663548112,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03175585716962814,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10337948799133301,
      "backward_entropy": 0.007286322968346732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019030977273359895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0317562110722065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10336368530988693,
      "backward_entropy": 0.008692155991281782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019050911942031235,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03175653889775276,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1033482477068901,
      "backward_entropy": 0.008094544921602522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018737767823040485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175687789916992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10333329439163208,
      "backward_entropy": 0.008687014026301247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019989210704807192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031757205724716187,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10331863909959793,
      "backward_entropy": 0.008684495730059487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015387839812319726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175750747323036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10330405086278915,
      "backward_entropy": 0.008682096643107278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015784191782586277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175780922174454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10328998416662216,
      "backward_entropy": 0.0086797262941088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001554452464915812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031758129596710205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10327637195587158,
      "backward_entropy": 0.008677264941590173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016070382844191045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03175846114754677,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10326310992240906,
      "backward_entropy": 0.008090468921831675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012903238530270755,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03175877779722214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10324997454881668,
      "backward_entropy": 0.007273478167397636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011949944746447727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03175908327102661,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10323716700077057,
      "backward_entropy": 0.008670113980770111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012475661060307175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031759392470121384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10322476923465729,
      "backward_entropy": 0.008667818137577601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001022583746816963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03175969049334526,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1032126396894455,
      "backward_entropy": 0.007269504347017833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010486654355190694,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03175996243953705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10320082306861877,
      "backward_entropy": 0.007268282451799938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011286420340184122,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031760234385728836,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10318934917449951,
      "backward_entropy": 0.008661450019904546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010081571963382885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031760502606630325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10317805409431458,
      "backward_entropy": 0.007265900394746235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.808814941905439e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031760744750499725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10316693782806396,
      "backward_entropy": 0.008657520903008325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.820469570811838e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031760986894369125,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10315634310245514,
      "backward_entropy": 0.008655666772808348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.625823491252959e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176121413707733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10314618051052094,
      "backward_entropy": 0.008653891938073295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.085999823175371e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031761426478624344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10313623398542404,
      "backward_entropy": 0.008652223540203912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.002436905167997e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176162764430046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10312657058238983,
      "backward_entropy": 0.008650634969983782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.87080794502981e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031761813908815384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10311709344387054,
      "backward_entropy": 0.008649135806730815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.934689736226574e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176198899745941,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10310793668031693,
      "backward_entropy": 0.008647719132048743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.918850001762621e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176216036081314,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10309894382953644,
      "backward_entropy": 0.008082799081291472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.662841067533009e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176232427358627,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10309016704559326,
      "backward_entropy": 0.008644954434462957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.068673272035085e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031762488186359406,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10308163613080978,
      "backward_entropy": 0.008082329162529536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.8266417909180745e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031762637197971344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10307334363460541,
      "backward_entropy": 0.00864238025886672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.524275962263346e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031762778759002686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10306514799594879,
      "backward_entropy": 0.008641148784330912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.200693314895034e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176292032003403,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10305735468864441,
      "backward_entropy": 0.008081817733389991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.988225919078104e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176303952932358,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10304947197437286,
      "backward_entropy": 0.008081757596560888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.066763696959242e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176316246390343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10304170846939087,
      "backward_entropy": 0.008637815713882446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2958130507031456e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176327422261238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10303401947021484,
      "backward_entropy": 0.008636788065944399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.234429459553212e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176337853074074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10302649438381195,
      "backward_entropy": 0.008635810975517546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.163766814395785e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031763482838869095,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10301921516656876,
      "backward_entropy": 0.008634857833385468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3072938094846904e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031763579696416855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10301223397254944,
      "backward_entropy": 0.00863394673381533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.226671105949208e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031763672828674316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10300543904304504,
      "backward_entropy": 0.008633056921618325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2922517018741928e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176375851035118,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10299880802631378,
      "backward_entropy": 0.008081732051713126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8760692657670006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031763844192028046,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10299249738454819,
      "backward_entropy": 0.008631414600781031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6376666937721893e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176393359899521,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10298633575439453,
      "backward_entropy": 0.008630610470260893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3306887669605203e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176401928067207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1029803603887558,
      "backward_entropy": 0.008081752274717604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.183582000725437e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176410496234894,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10297457873821259,
      "backward_entropy": 0.00862901019198554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5922261809464544e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0317641980946064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10296899825334549,
      "backward_entropy": 0.007247929594346455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9793724277406e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176428750157356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10296373069286346,
      "backward_entropy": 0.008627434926373618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1267671399982646e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176437318325043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10295860469341278,
      "backward_entropy": 0.008626693593604224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.885236633825116e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176445513963699,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10295356810092926,
      "backward_entropy": 0.008625988981553487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.505414729763288e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176453337073326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10294868052005768,
      "backward_entropy": 0.008625308317797524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7438087525079027e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176460787653923,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10294398665428162,
      "backward_entropy": 0.007245648120130811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4210328117769677e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0317646749317646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10293939709663391,
      "backward_entropy": 0.008624010320220674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4061602996662259e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031764741986989975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10293498635292053,
      "backward_entropy": 0.008623410548482622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4497989468509331e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176480904221535,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1029307097196579,
      "backward_entropy": 0.00808145957333701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1082431228714995e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176487982273102,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10292653739452362,
      "backward_entropy": 0.008622175880840846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2471269656089135e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176494687795639,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10292253643274307,
      "backward_entropy": 0.007243656154189791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0060627573693637e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031765010207891464,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10291865468025208,
      "backward_entropy": 0.00724327244928905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1355863534845412e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176507353782654,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10291491448879242,
      "backward_entropy": 0.008620501096759523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.517026228422765e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176514059305191,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10291124880313873,
      "backward_entropy": 0.007242498653275626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.108214109990513e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031765203922986984,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10290774703025818,
      "backward_entropy": 0.008619395749909537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2717080608126707e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176526352763176,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1029042974114418,
      "backward_entropy": 0.008081241909946715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.463598871661816e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176531940698624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10290079563856125,
      "backward_entropy": 0.007241440138646534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.162750757241156e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031765375286340714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10289737582206726,
      "backward_entropy": 0.008617898715393884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0131173439731356e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176543116569519,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10289403796195984,
      "backward_entropy": 0.008081212639808655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.623945516068488e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176548331975937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10289069265127182,
      "backward_entropy": 0.008616962603160314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.180027296271874e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176553174853325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10288738459348679,
      "backward_entropy": 0.008616521954536438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.285725364956306e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176557645201683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1028841957449913,
      "backward_entropy": 0.00861609194959913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.943623818893684e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176562115550041,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10288117080926895,
      "backward_entropy": 0.00808126905134746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.323303750832565e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031765665858983994,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10287822782993317,
      "backward_entropy": 0.0086152617420469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2153750402794685e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031765710562467575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10287537425756454,
      "backward_entropy": 0.0072390202965055194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3016336753207725e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176575154066086,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10287265479564667,
      "backward_entropy": 0.00861449699316706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.464343419385841e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176578879356384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10287000983953476,
      "backward_entropy": 0.008614146283694677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.240750397206284e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176582604646683,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10286745429039001,
      "backward_entropy": 0.008613811539752143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.529526788450312e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031765859574079514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10286495089530945,
      "backward_entropy": 0.008613471473966326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0508847380115185e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0317658893764019,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10286246240139008,
      "backward_entropy": 0.008081439882516861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.88376872453955e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176591545343399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10286006331443787,
      "backward_entropy": 0.008612880749361855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.105601308561745e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176593780517578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10285766422748566,
      "backward_entropy": 0.008612622107778276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.137473868264351e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176596388220787,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10285542905330658,
      "backward_entropy": 0.00808164690222059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4875217806984438e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176598995923996,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10285328328609467,
      "backward_entropy": 0.007236974579947335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7916269118577475e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176601603627205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10285118967294693,
      "backward_entropy": 0.008611834474972315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8446434043871704e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176604211330414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284917056560516,
      "backward_entropy": 0.008611589670181274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8405004286469193e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176606819033623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284727811813354,
      "backward_entropy": 0.0086113517837865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5506569727440365e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176609426736832,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284540057182312,
      "backward_entropy": 0.008611088884728295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2149633878143504e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176611661911011,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284363478422165,
      "backward_entropy": 0.008610861642020089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7697402654448524e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0317661389708519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284192860126495,
      "backward_entropy": 0.008610630141837257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9406666069698986e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176616504788399,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10284030437469482,
      "backward_entropy": 0.008610406092235021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3337092898145784e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176619112491608,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10283874720335007,
      "backward_entropy": 0.0086101767207895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4063999717327533e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176621347665787,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1028372049331665,
      "backward_entropy": 0.008609963314873832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9191477349522756e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176623582839966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10283570736646652,
      "backward_entropy": 0.008609768535409654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2813476359951892e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176625445485115,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10283424705266953,
      "backward_entropy": 0.00723489693232945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9183196400263114e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176627680659294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1028328537940979,
      "backward_entropy": 0.00860938589487757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0238489923940506e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766295433044434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10283149033784866,
      "backward_entropy": 0.008609193776335036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.705423185034306e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766314059495926,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10283014178276062,
      "backward_entropy": 0.007234424884830203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1815274092441541e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176632523536682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10282871872186661,
      "backward_entropy": 0.007234289177826473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1013871699105948e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176633641123772,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282739996910095,
      "backward_entropy": 0.0086087238575731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1653980891423998e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176635131239891,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10282614082098007,
      "backward_entropy": 0.008082303617681776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.34092033476918e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766366213560104,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282491892576218,
      "backward_entropy": 0.008608421576874596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.993405001296196e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766377389431,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282373428344727,
      "backward_entropy": 0.008608282676764898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.15348143481242e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766388565301895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282261669635773,
      "backward_entropy": 0.008608150695051466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0589650401016115e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176639974117279,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282151401042938,
      "backward_entropy": 0.008608031485761915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0335833167118835e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766410917043686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10282047092914581,
      "backward_entropy": 0.008607902697154455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.329196816703188e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176642209291458,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10281944274902344,
      "backward_entropy": 0.007233302508081708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.319323132520367e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176643326878548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10281844437122345,
      "backward_entropy": 0.00860766853604998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.187944349112513e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766440719366074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10281746834516525,
      "backward_entropy": 0.0086075525198664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0610634717522771e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176644444465637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10281646251678467,
      "backward_entropy": 0.008607462580714906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1446414873717004e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176644816994667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10281547904014587,
      "backward_entropy": 0.0086073779634067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.618907259005937e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176645189523697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10281448066234589,
      "backward_entropy": 0.008607304521969386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.939880682286457e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176645189523697,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10281349718570709,
      "backward_entropy": 0.007232761808804103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.957690518698655e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176645562052727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10281258821487427,
      "backward_entropy": 0.008607167218412672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.937066933052847e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766459345817566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10281171649694443,
      "backward_entropy": 0.008607088455132075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.78883850468992e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031766463071107864,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10281087458133698,
      "backward_entropy": 0.008083201944828033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.418182868448639e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176646679639816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10281005501747131,
      "backward_entropy": 0.007232470171792167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3873280358420743e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176647052168846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10280928760766983,
      "backward_entropy": 0.007232395133801869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4323659292567754e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176647424697876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280855000019073,
      "backward_entropy": 0.008606798946857452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.381874075283122e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03176648169755936,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10280787944793701,
      "backward_entropy": 0.007232235478503364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2891011275969504e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766485422849655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1028071790933609,
      "backward_entropy": 0.008606650467429842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9411455670924624e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766489148139954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280653834342957,
      "backward_entropy": 0.008606598313365663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1079423479241086e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176649287343025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280591249465942,
      "backward_entropy": 0.008606529661587306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.883834267526254e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176650032401085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280533134937286,
      "backward_entropy": 0.008606466863836561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7340965402800066e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176650404930115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280478000640869,
      "backward_entropy": 0.008606395551136561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0211834339534107e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766507774591446,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1028042733669281,
      "backward_entropy": 0.008606329560279846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7969039706476906e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03176651522517204,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10280376672744751,
      "backward_entropy": 0.008083663880825043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9161725478843437e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176652267575264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1028032898902893,
      "backward_entropy": 0.008606200771672385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7873380759046995e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176652640104294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1028028279542923,
      "backward_entropy": 0.008606132119894028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6227633043163223e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176653012633324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280236601829529,
      "backward_entropy": 0.008606090609516417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7393250573149999e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766533851623535,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280191153287888,
      "backward_entropy": 0.008606032601424627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.73728198610479e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031766537576913834,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10280147939920425,
      "backward_entropy": 0.008083792669432504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9885543167674768e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176654130220413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280103981494904,
      "backward_entropy": 0.008605931486402239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4723565300300834e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176654502749443,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280060768127441,
      "backward_entropy": 0.008605884121997016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5697940486679727e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176654875278473,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10280022025108337,
      "backward_entropy": 0.008605831967932838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4387392727476254e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03176655247807503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279980301856995,
      "backward_entropy": 0.008605800036873137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5796381092059164e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766556203365326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279940813779831,
      "backward_entropy": 0.008605753204652242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3383437053325906e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279902815818787,
      "backward_entropy": 0.00723102263041905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7300345689363894e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279867053031921,
      "backward_entropy": 0.008605683488505227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.197763026539178e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279829800128937,
      "backward_entropy": 0.008605665394238063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2642854585465102e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279794037342072,
      "backward_entropy": 0.007230882665940693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4472723819380917e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279761254787445,
      "backward_entropy": 0.007230846477406365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.369892572711251e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10279727727174759,
      "backward_entropy": 0.008084170520305634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1715142989032756e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279695689678192,
      "backward_entropy": 0.00860556321484702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1052834025804259e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279665887355804,
      "backward_entropy": 0.008605525961944036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0412001216764111e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279633849859238,
      "backward_entropy": 0.008605505206755229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.844390464446406e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1027960330247879,
      "backward_entropy": 0.008605489241225379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.5329980597207395e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279574990272522,
      "backward_entropy": 0.008605457842350006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9815456527067e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10279548913240433,
      "backward_entropy": 0.00808435252734593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0717977261265332e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279525816440582,
      "backward_entropy": 0.007230542600154877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.326644345719615e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10279498994350433,
      "backward_entropy": 0.008084410003253393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.660409220174188e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279476642608643,
      "backward_entropy": 0.008605367371014186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.539884995187094e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279452800750732,
      "backward_entropy": 0.008605351405484336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.869443597816826e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10279429703950882,
      "backward_entropy": 0.008084482912506376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.18012165887194e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1027940884232521,
      "backward_entropy": 0.00860530138015747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.249319201539038e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279390215873718,
      "backward_entropy": 0.008605283818074636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2617414547075896e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.10279367864131927,
      "backward_entropy": 0.008084546774625778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7966303756984416e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279349982738495,
      "backward_entropy": 0.007230287683861596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.005317487733919e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279331356287003,
      "backward_entropy": 0.007230252027511597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2148087686655344e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1027931421995163,
      "backward_entropy": 0.007230230207954135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.961469374758053e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279296338558197,
      "backward_entropy": 0.00860519175018583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.189218927308502e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279278457164764,
      "backward_entropy": 0.008605183235236577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3809706085085054e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1027926355600357,
      "backward_entropy": 0.008605155029467173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.923700203107728e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279245674610138,
      "backward_entropy": 0.008605144385780607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.642419071387849e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279229283332825,
      "backward_entropy": 0.008605131613356727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.94767321662448e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279210656881332,
      "backward_entropy": 0.008605120437485831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7775257649409468e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279196500778198,
      "backward_entropy": 0.0072300418147018975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6149646004114402e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.10279180854558945,
      "backward_entropy": 0.007230028510093689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7613667796799746e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1027916669845581,
      "backward_entropy": 0.008605080523661204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0532326061584172e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279153287410736,
      "backward_entropy": 0.008605067751237325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.726179104683979e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279139876365662,
      "backward_entropy": 0.008605061897209712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.033329676327412e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031766559928655624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.10279125720262527,
      "backward_entropy": 0.008605051785707474,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.1670261946505888e-06,
    "avg_log_Z": 0.03176638148725033,
    "success_rate": 1.0,
    "avg_reward": 53.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.12,
      "1": 0.19,
      "2": 0.69
    },
    "avg_forward_entropy": 0.10281596906483173,
    "avg_backward_entropy": 0.008283510719026837,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}