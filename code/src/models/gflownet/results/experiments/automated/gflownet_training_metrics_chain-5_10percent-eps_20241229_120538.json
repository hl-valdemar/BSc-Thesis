{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13832147121429444,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13832147121429444,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13832147121429444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13832147121429444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13832147121429444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.1382184147834778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13832147121429444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.130258083343506,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827994386355082,
      "backward_entropy": 0.13857877254486084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835083484649658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279739220937094,
      "backward_entropy": 0.1385737419128418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.833101749420166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00019995054753962904,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18279280265172324,
      "backward_entropy": 0.1385688900947571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.537938117980957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00029988624737598,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18278706073760986,
      "backward_entropy": 0.13816453218460084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.618595123291016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00039973901584744453,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277994791666666,
      "backward_entropy": 0.13826339244842528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9106125831604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004998313379473984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827761729558309,
      "backward_entropy": 0.1382477641105652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.513873100280762,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006001447909511626,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277557690938315,
      "backward_entropy": 0.13810765743255615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.219216346740723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007004980579949915,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277589480082193,
      "backward_entropy": 0.1385406494140625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.822417259216309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008007949800230563,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277601401011148,
      "backward_entropy": 0.13806498050689697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.425367832183838,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009009127970784903,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277492125829062,
      "backward_entropy": 0.13804302215576172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.005468368530273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0010007467353716493,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277211983998617,
      "backward_entropy": 0.13802106380462648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.504890441894531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001100913155823946,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277148405710855,
      "backward_entropy": 0.1379980683326721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.606802940368652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001201160834170878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277152379353842,
      "backward_entropy": 0.13812313079833985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.501695156097412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013015198055654764,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277227878570557,
      "backward_entropy": 0.1379496693611145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.999065399169922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014015124179422855,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827718416849772,
      "backward_entropy": 0.13792481422424316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.81036376953125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001501412014476955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277116616566977,
      "backward_entropy": 0.13789933919906616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.598400115966797,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001601184019818902,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276959657669067,
      "backward_entropy": 0.13846893310546876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.305197715759277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017007370479404926,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276719252268472,
      "backward_entropy": 0.1378469944000244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.596973896026611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001799995545297861,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276351690292358,
      "backward_entropy": 0.13782007694244386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.802641868591309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001899555092677474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276079495747885,
      "backward_entropy": 0.13843897581100464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.806530475616455,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019990415312349796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275745709737143,
      "backward_entropy": 0.13795410394668578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.088626384735107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002098910976201296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275533119837442,
      "backward_entropy": 0.13793058395385743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.193482875823975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021987666841596365,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275320529937744,
      "backward_entropy": 0.13770245313644408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.009337425231934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022986691910773516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275117874145508,
      "backward_entropy": 0.13788154125213622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.97482967376709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0023985595908015966,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827486753463745,
      "backward_entropy": 0.13763868808746338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.467764377593994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024983673356473446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274617195129395,
      "backward_entropy": 0.138366961479187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.945050239562988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025978581979870796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274287382761636,
      "backward_entropy": 0.13757147789001464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7613844871521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026977264788001776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274134397506714,
      "backward_entropy": 0.13777620792388917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.470215797424316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027978685684502125,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274088700612387,
      "backward_entropy": 0.13750054836273193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.358827114105225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028981307987123728,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274088700612387,
      "backward_entropy": 0.13771791458129884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.040637016296387,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002998430747538805,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827410658200582,
      "backward_entropy": 0.1374267816543579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.778640270233154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003099060384556651,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274245659510294,
      "backward_entropy": 0.13765578269958495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.886474609375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003199433209374547,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274283409118652,
      "backward_entropy": 0.13826029300689696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.487982749938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032996467780321836,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274253606796265,
      "backward_entropy": 0.13730859756469727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.837522029876709,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003399526933208108,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274090687433878,
      "backward_entropy": 0.13726814985275268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849262714385986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003499221056699753,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18273874123891196,
      "backward_entropy": 0.13722655773162842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02114200592041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035992739722132683,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827378273010254,
      "backward_entropy": 0.13749008178710936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.302759170532227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036996915005147457,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18273822466532388,
      "backward_entropy": 0.13745396137237548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.221085071563721,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0038005472160875797,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827399730682373,
      "backward_entropy": 0.13709393739700318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.725582122802734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003901273710653186,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827413042386373,
      "backward_entropy": 0.138127601146698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.326122760772705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004002150148153305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274317185084024,
      "backward_entropy": 0.13733856678009032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.605856418609619,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004102958831936121,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274492025375366,
      "backward_entropy": 0.1369471073150635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.562373161315918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004203829448670149,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18274694681167603,
      "backward_entropy": 0.1380608320236206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.033778190612793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004305195063352585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275014559427896,
      "backward_entropy": 0.13721389770507814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312087535858154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004406292922794819,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827526092529297,
      "backward_entropy": 0.13717036247253417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.378329277038574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004507277626544237,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275471528371176,
      "backward_entropy": 0.13672902584075927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.516239643096924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0046086846850812435,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18275793393452963,
      "backward_entropy": 0.13667056560516358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.974437236785889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0047095222398638725,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18275956312815347,
      "backward_entropy": 0.13793463706970216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.230965614318848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00481059355661273,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276174863179526,
      "backward_entropy": 0.13790664672851563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8019866943359375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004910992458462715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276208639144897,
      "backward_entropy": 0.13787809610366822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.734045505523682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005011621862649918,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18276309967041016,
      "backward_entropy": 0.1364232063293457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.078547477722168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005111909005790949,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276325861612955,
      "backward_entropy": 0.1378182888031006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.576521873474121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005212128162384033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276357650756836,
      "backward_entropy": 0.1367896318435669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.848432540893555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005313004832714796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18276572227478027,
      "backward_entropy": 0.13775488138198852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.78281831741333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005414584651589394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827696164449056,
      "backward_entropy": 0.13772112131118774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.053841590881348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005516241304576397,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277378877003989,
      "backward_entropy": 0.13768630027770995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.424098968505859,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005618089344352484,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277843793233237,
      "backward_entropy": 0.13656628131866455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.729499816894531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005719732493162155,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827823519706726,
      "backward_entropy": 0.13761333227157593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.819791793823242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005821462720632553,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827868421872457,
      "backward_entropy": 0.137575364112854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.11206340789795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005923777353018522,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18279258410135904,
      "backward_entropy": 0.13576438426971435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.910621166229248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006026299670338631,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827991008758545,
      "backward_entropy": 0.13631632328033447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.324885368347168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006128805689513683,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280539909998575,
      "backward_entropy": 0.13745397329330444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.35728120803833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006231066305190325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18281145890553793,
      "backward_entropy": 0.13618206977844238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.470337390899658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006333069875836372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828169822692871,
      "backward_entropy": 0.1361133098602295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5109281539917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006434922572225332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18282226721445718,
      "backward_entropy": 0.13732340335845947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8481764793396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006537188775837421,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18282834688822427,
      "backward_entropy": 0.13596947193145753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.111648559570312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006639475002884865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18283458550771078,
      "backward_entropy": 0.1372296094894409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.11328411102295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006741903256624937,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18284104267756143,
      "backward_entropy": 0.13718066215515137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.446288585662842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006845034658908844,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18284881114959717,
      "backward_entropy": 0.1348966360092163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.446511268615723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006947855465114117,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285600344340006,
      "backward_entropy": 0.13478639125823974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.820102691650391,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007050984539091587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286389112472534,
      "backward_entropy": 0.13557355403900145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.66335916519165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007154002320021391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18287154038747153,
      "backward_entropy": 0.13548967838287354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6905131340026855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007256271783262491,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18287783861160278,
      "backward_entropy": 0.13444125652313232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.213428020477295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007358431350439787,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18288381894429526,
      "backward_entropy": 0.13685934543609618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.414241790771484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007460149470716715,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18288850784301758,
      "backward_entropy": 0.13680230379104613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.936007499694824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0075616780668497086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289287885030112,
      "backward_entropy": 0.13514548540115356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.310234069824219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007663294207304716,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828970511754354,
      "backward_entropy": 0.1339336156845093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.160585880279541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007765196729451418,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829015016555786,
      "backward_entropy": 0.13496072292327882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.126077651977539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007866701111197472,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829050381978353,
      "backward_entropy": 0.13656105995178222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.523411750793457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007968489080667496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829096476236979,
      "backward_entropy": 0.13475940227508545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2127509117126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008070697076618671,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18291491270065308,
      "backward_entropy": 0.13337351083755494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.513257026672363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008172623813152313,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829205354054769,
      "backward_entropy": 0.13322761058807372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720597267150879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008274341002106667,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292546272277832,
      "backward_entropy": 0.1330812931060791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86793041229248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008376081474125385,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293080727259317,
      "backward_entropy": 0.1329332947731018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.470046043395996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008478437550365925,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293682734171549,
      "backward_entropy": 0.1341911792755127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.699629783630371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00858056079596281,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829425891240438,
      "backward_entropy": 0.13262646198272704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.236482620239258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008682643063366413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294854958852133,
      "backward_entropy": 0.13394556045532227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.336894035339355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00878545455634594,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829547882080078,
      "backward_entropy": 0.132307767868042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.169416427612305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008888434618711472,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296096722284952,
      "backward_entropy": 0.1358515739440918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.430722236633301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008991558104753494,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18296764294306436,
      "backward_entropy": 0.13197739124298097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5618462562561035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009093763306736946,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18297328551610312,
      "backward_entropy": 0.13180824518203735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.044675827026367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009195186197757721,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297781546910605,
      "backward_entropy": 0.13560683727264405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.271089553833008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009296774864196777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18298238515853882,
      "backward_entropy": 0.13313419818878175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2028961181640625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00939867738634348,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298739194869995,
      "backward_entropy": 0.13127589225769043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.269651412963867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009500070475041866,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299070994059244,
      "backward_entropy": 0.13534398078918458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.502044677734375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009601741097867489,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299408753712973,
      "backward_entropy": 0.13524956703186036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.77065372467041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009703265503048897,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829975644747416,
      "backward_entropy": 0.13069512844085693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.979960441589355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009804170578718185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830002268155416,
      "backward_entropy": 0.1323401927947998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.476606369018555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009906326420605183,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300320704778036,
      "backward_entropy": 0.13028333187103272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.082804679870605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010008773766458035,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300606807072958,
      "backward_entropy": 0.13199273347854615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.084394454956055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010111304000020027,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830090880393982,
      "backward_entropy": 0.13181281089782715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.685822486877441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010213851928710938,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301177024841309,
      "backward_entropy": 0.1296265244483948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.716704368591309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010316748172044754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301417430241904,
      "backward_entropy": 0.13143768310546874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.435793876647949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010418824851512909,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301578362782797,
      "backward_entropy": 0.13440557718276977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.397040367126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010520596988499165,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301701545715332,
      "backward_entropy": 0.12892181873321534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.012961387634277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01062264759093523,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301808834075928,
      "backward_entropy": 0.1341691493988037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.913890838623047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010724772699177265,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830193599065145,
      "backward_entropy": 0.13404650688171388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.754849433898926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01082630641758442,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302043279012045,
      "backward_entropy": 0.1304248571395874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.335780143737793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010927722789347172,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18302077054977417,
      "backward_entropy": 0.13020488023757934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.964192867279053,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011029472574591637,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1830214262008667,
      "backward_entropy": 0.12997937202453613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.429122924804688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011131240986287594,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830217440923055,
      "backward_entropy": 0.13353095054626465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.33707857131958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011233266443014145,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302148580551147,
      "backward_entropy": 0.13339686393737793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.397697448730469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011334918439388275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18302090962727866,
      "backward_entropy": 0.13325996398925782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.499436378479004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011436930857598782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.183020810286204,
      "backward_entropy": 0.12900185585021973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.531148433685303,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011539287865161896,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18302051226298013,
      "backward_entropy": 0.12623815536499022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.585787773132324,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011641329154372215,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301955858866373,
      "backward_entropy": 0.1259398341178894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.389342308044434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011743780225515366,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301878372828165,
      "backward_entropy": 0.13267526626586915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.724106788635254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011847042478621006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1830177903175354,
      "backward_entropy": 0.1325153589248657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8933587074279785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011950038373470306,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18301657835642496,
      "backward_entropy": 0.1276319742202759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.381792068481445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012052325531840324,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18301566441853842,
      "backward_entropy": 0.12469327449798584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.55334997177124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012154793366789818,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.183013916015625,
      "backward_entropy": 0.1320038318634033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.884715557098389,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012256952933967113,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18301177024841309,
      "backward_entropy": 0.13181949853897096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.122506141662598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01235903985798359,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18300926685333252,
      "backward_entropy": 0.12368321418762207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41915512084961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012461298145353794,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18300755818684897,
      "backward_entropy": 0.12611876726150512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5469889640808105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012563779950141907,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1830050746599833,
      "backward_entropy": 0.12297117710113525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.911673545837402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012665283866226673,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18300163745880127,
      "backward_entropy": 0.13100816011428834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251660346984863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012766251340508461,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829990347226461,
      "backward_entropy": 0.12221343517303467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372517585754395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012867514975368977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18299617369969687,
      "backward_entropy": 0.13057360649108887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.645378112792969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012969192117452621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18299398819605509,
      "backward_entropy": 0.1244616985321045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.624990940093994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013070729561150074,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829917828241984,
      "backward_entropy": 0.12411266565322876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.163049697875977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013172129169106483,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18298953771591187,
      "backward_entropy": 0.12062060832977295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.243414878845215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013273721560835838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829867959022522,
      "backward_entropy": 0.12961843013763427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.751997470855713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013374929316341877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829837759335836,
      "backward_entropy": 0.1293604254722595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73839282989502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013476037420332432,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829793651898702,
      "backward_entropy": 0.11933190822601318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5147247314453125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013577675446867943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18297352393468222,
      "backward_entropy": 0.12882742881774903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.126007556915283,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01367909088730812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18296780188878378,
      "backward_entropy": 0.12854599952697754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.464596748352051,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013780004344880581,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829617420832316,
      "backward_entropy": 0.12825568914413452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.231697082519531,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013880101032555103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18295647700627646,
      "backward_entropy": 0.12795987129211425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3280510902404785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013979334384202957,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829523245493571,
      "backward_entropy": 0.11689774990081787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.146525859832764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014078518375754356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294890721638998,
      "backward_entropy": 0.12009338140487671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.423973083496094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014177465811371803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18294499317804971,
      "backward_entropy": 0.12702407836914062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.788456439971924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01427567657083273,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18294032414754233,
      "backward_entropy": 0.11917880773544312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.225699424743652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014374228194355965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293583393096924,
      "backward_entropy": 0.11870591640472412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.076383113861084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014472737908363342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293205897013345,
      "backward_entropy": 0.11822584867477418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.029313087463379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014571095816791058,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829287608464559,
      "backward_entropy": 0.11365149021148682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.549448490142822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014668571762740612,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829256018002828,
      "backward_entropy": 0.1252908229827881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8698039054870605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014766296371817589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18292216459910074,
      "backward_entropy": 0.11674009561538697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890406131744385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014863798394799232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829188664754232,
      "backward_entropy": 0.11622741222381591,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.732678413391113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014961736276745796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829142967859904,
      "backward_entropy": 0.12415771484375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.336238384246826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015059376135468483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829106609026591,
      "backward_entropy": 0.12376420497894287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.023316860198975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015156426467001438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290720383326212,
      "backward_entropy": 0.12335951328277588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3089985847473145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015253370627760887,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829026738802592,
      "backward_entropy": 0.10940172672271728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.051945209503174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01535041257739067,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289669354756674,
      "backward_entropy": 0.12252511978149414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.089413642883301,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01544748805463314,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289126952489218,
      "backward_entropy": 0.12209501266479492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.128322124481201,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015543843619525433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18288586537043253,
      "backward_entropy": 0.11237366199493408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.266663074493408,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01564028114080429,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287988503774008,
      "backward_entropy": 0.1212119221687317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6863627433776855,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01573696732521057,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828745206197103,
      "backward_entropy": 0.10597203969955445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.328026294708252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01583334058523178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286722898483276,
      "backward_entropy": 0.11057558059692382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.353550910949707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015928534790873528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286073207855225,
      "backward_entropy": 0.10996366739273071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.12163782119751,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016023404896259308,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285423517227173,
      "backward_entropy": 0.10374780893325805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.461498737335205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016117945313453674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182850182056427,
      "backward_entropy": 0.11886866092681884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.733347415924072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01621238701045513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18284722169240317,
      "backward_entropy": 0.11837911605834961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.003631114959717,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016306933015584946,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828449567159017,
      "backward_entropy": 0.11788067817687989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.574016094207764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016401663422584534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18284102280934653,
      "backward_entropy": 0.10677119493484497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.650025367736816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016496963798999786,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18283488353093466,
      "backward_entropy": 0.09990118741989136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.965187072753906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016592852771282196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828269362449646,
      "backward_entropy": 0.11631340980529785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.285872459411621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016688155010342598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828205188115438,
      "backward_entropy": 0.10468720197677613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.902292728424072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01678312011063099,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18281441926956177,
      "backward_entropy": 0.09747395515441895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3229193687438965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016878187656402588,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18280704816182455,
      "backward_entropy": 0.09664818048477172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.315463542938232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016972994431853294,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280017375946045,
      "backward_entropy": 0.11410058736801147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.58828067779541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017066767439246178,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279403448104858,
      "backward_entropy": 0.10180810689926148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.754638195037842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017159920185804367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18278996149698892,
      "backward_entropy": 0.10108405351638794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7746381759643555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017252469435334206,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278467655181885,
      "backward_entropy": 0.11235384941101074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.613262176513672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017343789339065552,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278032541275024,
      "backward_entropy": 0.11174778938293457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.689393043518066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017434632405638695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827755570411682,
      "backward_entropy": 0.0988700270652771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6846771240234375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01752512902021408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277057011922201,
      "backward_entropy": 0.09811859726905822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.71753454208374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017616046592593193,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276349703470865,
      "backward_entropy": 0.09734951853752136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.079267978668213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017706656828522682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827571988105774,
      "backward_entropy": 0.09657474756240844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0984344482421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01779729127883911,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18275074164072672,
      "backward_entropy": 0.10857738256454467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.814323902130127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017888667061924934,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18274136384328207,
      "backward_entropy": 0.08711516857147217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.522025108337402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017979811877012253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18273266156514487,
      "backward_entropy": 0.09418420791625977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.907783031463623,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01807047799229622,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18272419770558676,
      "backward_entropy": 0.0853013813495636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.701155662536621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01816023327410221,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18271698554356894,
      "backward_entropy": 0.09254405498504639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.085203647613525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01824980042874813,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18270941575368246,
      "backward_entropy": 0.08347688913345337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.47400426864624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018339484930038452,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18270029624303183,
      "backward_entropy": 0.08255609273910522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.64115571975708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01842878945171833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18269073963165283,
      "backward_entropy": 0.09001550674438477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.244865894317627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0185187216848135,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18267899751663208,
      "backward_entropy": 0.08914885520935059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.449517250061035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01860804297029972,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18266677856445312,
      "backward_entropy": 0.10231239795684814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.641497611999512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01869794726371765,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18265416224797568,
      "backward_entropy": 0.08739997744560242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.148269176483154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018787624314427376,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1826409101486206,
      "backward_entropy": 0.07790058255195617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.935460567474365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018877476453781128,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18262515465418497,
      "backward_entropy": 0.10006484985351563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.67030668258667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018967339769005775,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18260773022969565,
      "backward_entropy": 0.09929959177970886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.263195514678955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01905711740255356,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182591180006663,
      "backward_entropy": 0.07507995367050171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.54987096786499,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019145451486110687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257564306259155,
      "backward_entropy": 0.09777039885520936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.138701438903809,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019233768805861473,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18256179491678873,
      "backward_entropy": 0.07321003079414368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.707432746887207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01932165026664734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254820505777994,
      "backward_entropy": 0.09622454047203063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.534501075744629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01940874010324478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182535191377004,
      "backward_entropy": 0.0954470157623291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.306240081787109,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01949494518339634,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825224757194519,
      "backward_entropy": 0.07933927774429321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.034621715545654,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019581172615289688,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18251027663548788,
      "backward_entropy": 0.06950297951698303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.478157997131348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019667083397507668,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249714374542236,
      "backward_entropy": 0.09309099912643433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.324538230895996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01975220814347267,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18248446782430014,
      "backward_entropy": 0.06766491532325744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.335448741912842,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019836412742733955,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18247095743815103,
      "backward_entropy": 0.09150679707527161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.22324275970459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01992080919444561,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18245530128479004,
      "backward_entropy": 0.07487401366233826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.582364082336426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020004216581583023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18243797620137533,
      "backward_entropy": 0.08990910649299622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2991838455200195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020087286829948425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242168426513672,
      "backward_entropy": 0.08910695314407349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.030957221984863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020169736817479134,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240614732106528,
      "backward_entropy": 0.08830246925354004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.181350231170654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02025126852095127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823898752530416,
      "backward_entropy": 0.07130293846130371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3524065017700195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020332232117652893,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18237431844075522,
      "backward_entropy": 0.061310756206512454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9535434246063232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020412858575582504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823586424191793,
      "backward_entropy": 0.06954081654548645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.46375036239624,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020492764189839363,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823434034983317,
      "backward_entropy": 0.05954082608222962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.274033546447754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020572513341903687,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823261777559916,
      "backward_entropy": 0.08415275812149048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2186737060546875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02065202035009861,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823090116182963,
      "backward_entropy": 0.08330355882644654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.723865509033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020731206983327866,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18229079246520996,
      "backward_entropy": 0.05691895484924316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8741888999938965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020809542387723923,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18227197726567587,
      "backward_entropy": 0.056056588888168335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.131348133087158,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020887330174446106,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18225292364756265,
      "backward_entropy": 0.08075219392776489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.190508842468262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020964937284588814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18223297595977783,
      "backward_entropy": 0.063426673412323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.997166395187378,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02104225568473339,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18220816055933634,
      "backward_entropy": 0.06255319118499755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.662452697753906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02111937664449215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18218394120534262,
      "backward_entropy": 0.07819108963012696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3553340435028076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02119698002934456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821561654408773,
      "backward_entropy": 0.06080976128578186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.605686664581299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021273689344525337,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18213164806365967,
      "backward_entropy": 0.07646850943565368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.742107629776001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02134973742067814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821061372756958,
      "backward_entropy": 0.05909915566444397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3799526691436768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021425357088446617,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18207891782124838,
      "backward_entropy": 0.049379435181617734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8072450160980225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021500270813703537,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18205291032791138,
      "backward_entropy": 0.07390609383583069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.313336372375488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021574851125478745,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820222536722819,
      "backward_entropy": 0.04778526723384857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.443228006362915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021649938076734543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18198835849761963,
      "backward_entropy": 0.07220216393470764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.858196973800659,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02172325737774372,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18195937077204385,
      "backward_entropy": 0.04622134268283844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.35422682762146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021795401349663734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819311579068502,
      "backward_entropy": 0.07052872180938721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6624608039855957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021867116913199425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819011370340983,
      "backward_entropy": 0.06969947814941406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5015103816986084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021937737241387367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18187516927719116,
      "backward_entropy": 0.052519971132278444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8261401653289795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022008398547768593,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18184761206309,
      "backward_entropy": 0.043247073888778687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.755232572555542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022078391164541245,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18182416756947836,
      "backward_entropy": 0.050979888439178465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.221496105194092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022147301584482193,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18179766337076822,
      "backward_entropy": 0.04183072149753571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.992969036102295,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022216076031327248,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18176927169164023,
      "backward_entropy": 0.041133838891983035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.679940700531006,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022284500300884247,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18174099922180176,
      "backward_entropy": 0.06479297280311584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8743557929992676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022352086380124092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18171238899230957,
      "backward_entropy": 0.06398938298225403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.886899948120117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022419307380914688,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18168425559997559,
      "backward_entropy": 0.04726360440254211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.071674346923828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022485991939902306,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18165175120035806,
      "backward_entropy": 0.06239231824874878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3075809478759766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02255265600979328,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18161680301030478,
      "backward_entropy": 0.03779381513595581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5580201148986816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02261822111904621,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18158380190531412,
      "backward_entropy": 0.04510406255722046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.658487319946289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02268304117023945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1815485159556071,
      "backward_entropy": 0.03652783930301666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2969303131103516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022747507318854332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815126140912374,
      "backward_entropy": 0.043709355592727664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.178868055343628,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022810883820056915,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18147424856821695,
      "backward_entropy": 0.04302553534507751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.560776472091675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0228732880204916,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1814367969830831,
      "backward_entropy": 0.04235629737377167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1516661643981934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022935524582862854,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18139886856079102,
      "backward_entropy": 0.0341220885515213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3776333332061768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022996915504336357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18136191368103027,
      "backward_entropy": 0.033548560738563535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.456780195236206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02305794134736061,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18132408459981283,
      "backward_entropy": 0.04039972424507141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8726478815078735,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023118719458580017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18128339449564615,
      "backward_entropy": 0.05472416877746582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8233612775802612,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023178432136774063,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18124582370122275,
      "backward_entropy": 0.03188264667987824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7807213068008423,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023236867040395737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18120775620142618,
      "backward_entropy": 0.03853093981742859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8013381958007812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02329416200518608,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18117002646128336,
      "backward_entropy": 0.05257509350776672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.94186270236969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02335060015320778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18113396565119425,
      "backward_entropy": 0.051882266998291016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3781421184539795,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02340642176568508,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18109619617462158,
      "backward_entropy": 0.05119791030883789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2598506212234497,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023462465032935143,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1810524066289266,
      "backward_entropy": 0.05051494836807251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5181739330291748,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023516617715358734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18101155757904053,
      "backward_entropy": 0.04985403716564178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4787057638168335,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02356945537030697,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18096941709518433,
      "backward_entropy": 0.049210429191589355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.996803879737854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0236212071031332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18092846870422363,
      "backward_entropy": 0.04857921898365021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.895546317100525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023673081770539284,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18088442087173462,
      "backward_entropy": 0.027530813217163087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6367913484573364,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023724835366010666,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18083731333414713,
      "backward_entropy": 0.027093547582626342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5958125591278076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023775942623615265,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18078885475794473,
      "backward_entropy": 0.026665490865707398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6139914989471436,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023826396092772484,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18073914448420206,
      "backward_entropy": 0.026246657967567442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.410499930381775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023876087740063667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18068480491638184,
      "backward_entropy": 0.04549051523208618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1375794410705566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023925069719552994,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1806328296661377,
      "backward_entropy": 0.044899779558181765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3048735857009888,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023972628638148308,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18058268229166666,
      "backward_entropy": 0.04432581663131714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5841071605682373,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02401912212371826,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1805302898089091,
      "backward_entropy": 0.024681541323661804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1792452335357666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024065624922513962,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18047604958216348,
      "backward_entropy": 0.02431267499923706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3331595659255981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024111231788992882,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18042453130086264,
      "backward_entropy": 0.02967122197151184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2133721113204956,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024156244471669197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18037128448486328,
      "backward_entropy": 0.029229193925857544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.176247477531433,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024200422689318657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1803171435991923,
      "backward_entropy": 0.0287969708442688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4386317729949951,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024243872612714767,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18026340007781982,
      "backward_entropy": 0.04106703996658325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1277015209197998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02428726851940155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18020538489023843,
      "backward_entropy": 0.027952522039413452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8260020613670349,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024329695850610733,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18014540274937949,
      "backward_entropy": 0.02754027247428894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9210754036903381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024370426312088966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18008685111999512,
      "backward_entropy": 0.027147457003593445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9962247014045715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024409860372543335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1800276835759481,
      "backward_entropy": 0.03907489776611328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1440315246582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024448547512292862,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17996867497762045,
      "backward_entropy": 0.0214200422167778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0751429796218872,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024487115442752838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17990849415461221,
      "backward_entropy": 0.021143263578414916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.585329532623291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024525444954633713,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1798482338587443,
      "backward_entropy": 0.02087058126926422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0181653499603271,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024561811238527298,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17979160944620767,
      "backward_entropy": 0.03725174963474274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0110279321670532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024597596377134323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1797302563985189,
      "backward_entropy": 0.024994823336601257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7904371023178101,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024633049964904785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17966614166895548,
      "backward_entropy": 0.024662333726882934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9651479125022888,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024667557328939438,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1796027421951294,
      "backward_entropy": 0.01989113539457321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.859621524810791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024702081456780434,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1795395016670227,
      "backward_entropy": 0.02402210533618927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9467331767082214,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024736519902944565,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17947969834009805,
      "backward_entropy": 0.02370857298374176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7465501427650452,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02477092668414116,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1794186234474182,
      "backward_entropy": 0.034760701656341556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8863282203674316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02480398491024971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17935375372568765,
      "backward_entropy": 0.023095862567424776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7476939558982849,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02483677864074707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17928630113601685,
      "backward_entropy": 0.02279777079820633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8465886116027832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0248689204454422,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1792189677556356,
      "backward_entropy": 0.033605927228927614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7641525864601135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024901017546653748,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1791507601737976,
      "backward_entropy": 0.018359342217445375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6255217790603638,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02493230253458023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1790790557861328,
      "backward_entropy": 0.032864639163017274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8042439818382263,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024962538853287697,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17900784810384116,
      "backward_entropy": 0.01797498166561127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6228732466697693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0249925646930933,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17893336216608682,
      "backward_entropy": 0.0321646898984909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8048953413963318,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025021623820066452,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17885851860046387,
      "backward_entropy": 0.017614202201366426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.551131546497345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0250506941229105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1787801186243693,
      "backward_entropy": 0.020880664885044097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5888972878456116,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02507857047021389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1787020762761434,
      "backward_entropy": 0.03117472231388092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6014458537101746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025105930864810944,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17862568298975626,
      "backward_entropy": 0.030860358476638795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6233178973197937,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025132598355412483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17854823668797812,
      "backward_entropy": 0.030554834008216857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7352799773216248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025158805772662163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17846866448720297,
      "backward_entropy": 0.019931375980377197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5816097855567932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025185490027070045,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1783867081006368,
      "backward_entropy": 0.029952210187911988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5941522717475891,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025211462751030922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17830284436543783,
      "backward_entropy": 0.016509553790092467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5056354999542236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02523719146847725,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17821836471557617,
      "backward_entropy": 0.029367318749427794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5618012547492981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025262078270316124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1781338850657145,
      "backward_entropy": 0.019034664332866668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6578072905540466,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025286726653575897,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17804876963297525,
      "backward_entropy": 0.028808999061584472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46791940927505493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025311417877674103,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17795870701471964,
      "backward_entropy": 0.018609839677810668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42892783880233765,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02533522993326187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.177868922551473,
      "backward_entropy": 0.02826775312423706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5020914673805237,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02535799704492092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1777797738711039,
      "backward_entropy": 0.028013932704925536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.398990660905838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025380538776516914,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1776902675628662,
      "backward_entropy": 0.01801987886428833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.503653883934021,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02540178783237934,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17760036389033,
      "backward_entropy": 0.015481105446815491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4896228611469269,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025423217564821243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17751012245814005,
      "backward_entropy": 0.017659327387809752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42229217290878296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025444110855460167,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17741652329762778,
      "backward_entropy": 0.017482365667819976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4714800715446472,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025465093553066254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17732600371042886,
      "backward_entropy": 0.026827087998390196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36493784189224243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025485781952738762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17723282178243002,
      "backward_entropy": 0.0171335831284523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.408383846282959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025505591183900833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17714055379231772,
      "backward_entropy": 0.01696867644786835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3845262825489044,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025524741038680077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17704649766286215,
      "backward_entropy": 0.02617180049419403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3723331093788147,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02554347924888134,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1769526799519857,
      "backward_entropy": 0.02596653699874878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3325645923614502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025561532005667686,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17685802777608237,
      "backward_entropy": 0.025769045948982237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32323792576789856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025579089298844337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1767650842666626,
      "backward_entropy": 0.016359567642211914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3001233637332916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0255958940833807,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17667214075724283,
      "backward_entropy": 0.02539221942424774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3386893570423126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025611797347664833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17657981316248575,
      "backward_entropy": 0.016092345118522644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3467267155647278,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02562716230750084,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17648609479268393,
      "backward_entropy": 0.01596691906452179,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33790573477745056,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025641802698373795,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1763892968495687,
      "backward_entropy": 0.014355427026748658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35110214352607727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02565602771937847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17629065116246542,
      "backward_entropy": 0.0157288521528244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33519718050956726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025671007111668587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1761928598086039,
      "backward_entropy": 0.01560591459274292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26885178685188293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025685666128993034,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17609300216039023,
      "backward_entropy": 0.0154851034283638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30445417761802673,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025700172409415245,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17599614461263022,
      "backward_entropy": 0.024252691864967348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32082274556159973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025714419782161713,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17589841286341348,
      "backward_entropy": 0.015250737965106963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30819669365882874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025728637352585793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17579877376556396,
      "backward_entropy": 0.023944245278835298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29445308446884155,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025742238387465477,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17569607496261597,
      "backward_entropy": 0.023797689378261565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25347816944122314,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025755632668733597,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17559226353963217,
      "backward_entropy": 0.013896995782852173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2629593014717102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025769200176000595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17549119393030801,
      "backward_entropy": 0.02350788116455078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27552634477615356,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025782698765397072,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17539066076278687,
      "backward_entropy": 0.023362967371940612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26069554686546326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025795789435505867,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17528818051020303,
      "backward_entropy": 0.014584304392337799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2345302850008011,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025808311998844147,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17518413066864014,
      "backward_entropy": 0.023088882863521575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2357039600610733,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02582060545682907,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1750810742378235,
      "backward_entropy": 0.01363937258720398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2530405819416046,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025832833722233772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17497875293095908,
      "backward_entropy": 0.013592197000980378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21377043426036835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025844555348157883,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17487406730651855,
      "backward_entropy": 0.022701606154441833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21119141578674316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025855761021375656,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17476999759674072,
      "backward_entropy": 0.014093682169914246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23937834799289703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025866759940981865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.174666961034139,
      "backward_entropy": 0.01400391161441803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2209813892841339,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02587719075381756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1745610237121582,
      "backward_entropy": 0.01391773521900177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19273141026496887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025887152180075645,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17445379495620728,
      "backward_entropy": 0.013404418528079987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21569178998470306,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025896409526467323,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17434702316919962,
      "backward_entropy": 0.013378483057022095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21824109554290771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025905439630150795,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17423888047536215,
      "backward_entropy": 0.013353775441646575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16942179203033447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0259140245616436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17412837346394858,
      "backward_entropy": 0.021957474946975707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16809861361980438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025922866538167,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17402136325836182,
      "backward_entropy": 0.021862564980983733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19557234644889832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025931276381015778,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17391594250996908,
      "backward_entropy": 0.021771745383739473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16779640316963196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02593894675374031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17380819718043009,
      "backward_entropy": 0.013398511707782746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18591272830963135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02594658173620701,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17370192209879556,
      "backward_entropy": 0.013252848386764526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1301775872707367,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02595456875860691,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17359534899393717,
      "backward_entropy": 0.021519429981708527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1958870142698288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02596226893365383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1734929879506429,
      "backward_entropy": 0.013201989233493805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18569697439670563,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02596975676715374,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17338709036509195,
      "backward_entropy": 0.013195860385894775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16811081767082214,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025977643206715584,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17327960332234701,
      "backward_entropy": 0.02127038538455963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19013187289237976,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02598552778363228,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.173171599706014,
      "backward_entropy": 0.013004715740680694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14938239753246307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025993572548031807,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1730604569117228,
      "backward_entropy": 0.013128003478050232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14269809424877167,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026000984013080597,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1729494333267212,
      "backward_entropy": 0.021022829413414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15063314139842987,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026008296757936478,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17283964157104492,
      "backward_entropy": 0.01280914843082428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1391967535018921,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026015210896730423,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1727291742960612,
      "backward_entropy": 0.013073320686817168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13749872148036957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026021946221590042,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17261932293574014,
      "backward_entropy": 0.020799192786216735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14152219891548157,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026028646156191826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.172510027885437,
      "backward_entropy": 0.020727619528770447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13194306194782257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026035109534859657,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17240005731582642,
      "backward_entropy": 0.020658454298973082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14317640662193298,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02604166977107525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17229012648264566,
      "backward_entropy": 0.020588591694831848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12716801464557648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02604878880083561,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17217928171157837,
      "backward_entropy": 0.020513942837715148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09929580241441727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026055678725242615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17206845680872598,
      "backward_entropy": 0.012970885634422303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1327291876077652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026062145829200745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17196083068847656,
      "backward_entropy": 0.012342293560504914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10629849135875702,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026068279519677162,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17185111840566,
      "backward_entropy": 0.02030765116214752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1166679635643959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02607450634241104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17174339294433594,
      "backward_entropy": 0.020241543650627136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09098773449659348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026080919429659843,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17163554827372232,
      "backward_entropy": 0.012179576605558396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11973388493061066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026087163016200066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17153076330820718,
      "backward_entropy": 0.020107920467853545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10994676500558853,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026093043386936188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17142383257548013,
      "backward_entropy": 0.012075217813253403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.093691386282444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026098880916833878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17131632566452026,
      "backward_entropy": 0.012024346739053726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10312549769878387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026104062795639038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1712100108464559,
      "backward_entropy": 0.011978329718112945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1043895035982132,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02610887959599495,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17110308011372885,
      "backward_entropy": 0.012841005623340607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08797778189182281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026113515719771385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17099511623382568,
      "backward_entropy": 0.011892306059598923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09543633460998535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026118310168385506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17088874181111655,
      "backward_entropy": 0.011849014461040497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07978816330432892,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02612287364900112,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1707819104194641,
      "backward_entropy": 0.012820227444171906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0741436630487442,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0261277724057436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17067734400431314,
      "backward_entropy": 0.019670319557189942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06585180014371872,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02613246627151966,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17057520151138306,
      "backward_entropy": 0.012801192700862885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07058192789554596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026136895641684532,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17047647635142008,
      "backward_entropy": 0.019570137560367584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0746287852525711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026140812784433365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17037951946258545,
      "backward_entropy": 0.011647060513496399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0760805606842041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026144439354538918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17028323809305826,
      "backward_entropy": 0.019482943415641784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07628817111253738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0261475071310997,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17018679777781168,
      "backward_entropy": 0.019445563852787017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06030714884400368,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02615053579211235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17008997996648154,
      "backward_entropy": 0.011554726213216782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06962800025939941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02615346759557724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1699957251548767,
      "backward_entropy": 0.011526398360729218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06499885022640228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026156332343816757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16990158955256143,
      "backward_entropy": 0.01149848997592926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.053168851882219315,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02615920640528202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16980820894241333,
      "backward_entropy": 0.019301524758338927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07974933087825775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02616184949874878,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16971762975056967,
      "backward_entropy": 0.011444738507270813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059799280017614365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026164326816797256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16962363322575888,
      "backward_entropy": 0.011419402062892913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06827480345964432,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02616693824529648,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16953063011169434,
      "backward_entropy": 0.019203345477581023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056590158492326736,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026169391348958015,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16943621635437012,
      "backward_entropy": 0.019172075390815734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06435495615005493,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0261719711124897,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16934295495351157,
      "backward_entropy": 0.0191397950053215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05077603459358215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02617458626627922,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16924860080083212,
      "backward_entropy": 0.011315374821424484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05255281180143356,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026177654042840004,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16915623346964517,
      "backward_entropy": 0.01282663494348526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.058855753391981125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026180388405919075,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16906472047170004,
      "backward_entropy": 0.019037824869155884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05530165508389473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026183314621448517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1689722736676534,
      "backward_entropy": 0.011230934411287308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05815531685948372,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02618628367781639,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16887950897216797,
      "backward_entropy": 0.018968155980110167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05440983921289444,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026189066469669342,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16878533363342285,
      "backward_entropy": 0.011174575239419938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.044495027512311935,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02619173936545849,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16869052251180014,
      "backward_entropy": 0.018903009593486786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052870165556669235,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02619464509189129,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16859749952952066,
      "backward_entropy": 0.01886909604072571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042893003672361374,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026197535917162895,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16850348313649496,
      "backward_entropy": 0.012819865345954895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04285641387104988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026200180873274803,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16841089725494385,
      "backward_entropy": 0.012819233536720275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04462866857647896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02620280161499977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1683193842569987,
      "backward_entropy": 0.011038129031658173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040576186031103134,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02620491199195385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1682279904683431,
      "backward_entropy": 0.011015472561120987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0406615175306797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026206959038972855,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16813764969507852,
      "backward_entropy": 0.010993417352437973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04114407300949097,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02620905265212059,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16804798444112143,
      "backward_entropy": 0.012827886641025544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03539412468671799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026211131364107132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1679584582646688,
      "backward_entropy": 0.010948889702558518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02973197028040886,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02621319517493248,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16787056128184,
      "backward_entropy": 0.018641449511051178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03152529150247574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0262153260409832,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16778568426767984,
      "backward_entropy": 0.018614859879016878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031016474589705467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026217563077807426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1677027146021525,
      "backward_entropy": 0.010882700234651566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03247997909784317,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02621973492205143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16762137413024902,
      "backward_entropy": 0.012834088504314422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030222948640584946,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026221485808491707,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16754070917765299,
      "backward_entropy": 0.012837556004524232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03571582958102226,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026223311200737953,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16746127605438232,
      "backward_entropy": 0.012840043008327483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03423414006829262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026225170120596886,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.167380690574646,
      "backward_entropy": 0.01848978251218796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031759392470121384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026227202266454697,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16729936997095743,
      "backward_entropy": 0.018464651703834534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033842433243989944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026229048147797585,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16721793015797934,
      "backward_entropy": 0.010762740671634675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02797236666083336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026230866089463234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1671353578567505,
      "backward_entropy": 0.010743027180433273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028500806540250778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026232775300741196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16705365975697836,
      "backward_entropy": 0.01072285920381546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026616087183356285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026234647259116173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16697227954864502,
      "backward_entropy": 0.010702964663505555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023674199357628822,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026236459612846375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16689167420069376,
      "backward_entropy": 0.012848268449306487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023438168689608574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02623823843896389,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16681269804636636,
      "backward_entropy": 0.018326060473918916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025527413934469223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026240140199661255,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1667346159617106,
      "backward_entropy": 0.010644952952861785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024854077026247978,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026242142543196678,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1666556199391683,
      "backward_entropy": 0.01827872693538666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017695840448141098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624388597905636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16657630602518717,
      "backward_entropy": 0.010606098175048827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022512340918183327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624572068452835,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16649975379308066,
      "backward_entropy": 0.010587286949157716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020575981587171555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026247292757034302,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1664232313632965,
      "backward_entropy": 0.018214179575443266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020625507459044456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026248998939990997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16634749372800192,
      "backward_entropy": 0.010552430897951126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018497725948691368,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026250839233398438,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16627216339111328,
      "backward_entropy": 0.018170654773712158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020538004115223885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026252755895256996,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1661979854106903,
      "backward_entropy": 0.012844911217689515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017432767897844315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02625461481511593,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16612361868222555,
      "backward_entropy": 0.010496215522289276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015391082502901554,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02625628560781479,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16605047384897867,
      "backward_entropy": 0.018104995787143707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01713680662214756,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02625780738890171,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16597928603490195,
      "backward_entropy": 0.018085668981075286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018724458292126656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026259135454893112,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1659087042013804,
      "backward_entropy": 0.018067996203899383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015249299816787243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026260411366820335,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16583756605784097,
      "backward_entropy": 0.010433734953403473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016740838065743446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026261555030941963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16576762994130453,
      "backward_entropy": 0.010420265793800353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015638157725334167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02626270055770874,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16569767395655313,
      "backward_entropy": 0.012852172553539275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012859189882874489,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026263829320669174,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16562811533610025,
      "backward_entropy": 0.010393381863832474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014283714815974236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0262651015073061,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16556031505266824,
      "backward_entropy": 0.012856125831604004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013767578639090061,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026266105473041534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16549315055211386,
      "backward_entropy": 0.01036701500415802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015443616546690464,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02626703679561615,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16542656222979227,
      "backward_entropy": 0.012863253057003022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011482564732432365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026267865672707558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16535923878351846,
      "backward_entropy": 0.010344038903713226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011513353325426579,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02626875601708889,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16529356439908346,
      "backward_entropy": 0.017932434380054475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011092065833508968,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026269715279340744,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1652291715145111,
      "backward_entropy": 0.01791864335536957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014037842862308025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026270579546689987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16516607999801636,
      "backward_entropy": 0.010309872031211854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010580025613307953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026271427050232887,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16510178645451865,
      "backward_entropy": 0.01029881089925766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010683337226510048,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026272252202033997,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1650386850039164,
      "backward_entropy": 0.012885433435440064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007344027515500784,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026273025199770927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1649762988090515,
      "backward_entropy": 0.017868651449680327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007938799448311329,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026273833587765694,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16491695245107016,
      "backward_entropy": 0.012895007431507111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00844548549503088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026274800300598145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.164859801530838,
      "backward_entropy": 0.010256493836641312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009443062357604504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02627570554614067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16480392217636108,
      "backward_entropy": 0.010246062278747558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007363483775407076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026276608929038048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16474820176760355,
      "backward_entropy": 0.010235654562711716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010511895641684532,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02627752721309662,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16469420989354452,
      "backward_entropy": 0.017804238200187682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008093888871371746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026278382167220116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16463875770568848,
      "backward_entropy": 0.010215263068675994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0057423911057412624,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02627943456172943,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16458405057589212,
      "backward_entropy": 0.01020396500825882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00828237272799015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026280615478754044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16453198591868082,
      "backward_entropy": 0.010192172229290008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007121413946151733,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026281658560037613,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16447961330413818,
      "backward_entropy": 0.010181230306625367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007039181888103485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026282578706741333,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1644278665383657,
      "backward_entropy": 0.010171126574277878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006358278449624777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026283439248800278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16437658667564392,
      "backward_entropy": 0.017725351452827453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006269175559282303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026284342631697655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16432629028956094,
      "backward_entropy": 0.010151578485965729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007198526058346033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02628517523407936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1642767290274302,
      "backward_entropy": 0.01014222502708435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005781121551990509,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026285964995622635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1642266313234965,
      "backward_entropy": 0.01769038140773773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004760731477290392,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026286697015166283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16417738795280457,
      "backward_entropy": 0.010124374926090241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004647810943424702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02628748118877411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16412994265556335,
      "backward_entropy": 0.01011555790901184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00426963297650218,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026288243010640144,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1640840470790863,
      "backward_entropy": 0.010107003152370453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005694050341844559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026288975030183792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1640398403008779,
      "backward_entropy": 0.010098866373300552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005026028025895357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026289666071534157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16399524609247842,
      "backward_entropy": 0.010090909153223037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005353371612727642,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026290392503142357,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16395101944605509,
      "backward_entropy": 0.010082732141017913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004739790689200163,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629118040204048,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16390653451283774,
      "backward_entropy": 0.010074128210544587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00416082888841629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026292091235518456,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16386245687802634,
      "backward_entropy": 0.017604938149452208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003989615477621555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026292935013771057,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1638192137082418,
      "backward_entropy": 0.017593935132026672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00349230132997036,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026293719187378883,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16377676526705423,
      "backward_entropy": 0.010047559440135957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004142498131841421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026294486597180367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16373562812805176,
      "backward_entropy": 0.010039429366588592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032674844842404127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026295144110918045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16369442145029703,
      "backward_entropy": 0.010031943023204804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00351145351305604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026295967400074005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16365460554758707,
      "backward_entropy": 0.010023583471775056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034568265546113253,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026296714320778847,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16361528635025024,
      "backward_entropy": 0.010015720129013061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034661281388252974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02629747800529003,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16357640425364176,
      "backward_entropy": 0.01753358244895935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029304020572453737,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02629818767309189,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16353764136632284,
      "backward_entropy": 0.012975461781024933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002806971315294504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026298925280570984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16349982221921286,
      "backward_entropy": 0.017514543235301973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024818547535687685,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629968523979187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16346288720766702,
      "backward_entropy": 0.009984798729419708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028992039151489735,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026300424709916115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1634270946184794,
      "backward_entropy": 0.01749531030654907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020717696752399206,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026301158592104912,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1633915106455485,
      "backward_entropy": 0.009969889372587203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024635805748403072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026301881298422813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1633574366569519,
      "backward_entropy": 0.009962669014930725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002437436720356345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026302604004740715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1633238693078359,
      "backward_entropy": 0.009955473244190216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018991873366758227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026303378865122795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1632907291253408,
      "backward_entropy": 0.017457848787307738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020801080390810966,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02630416303873062,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16325886050860086,
      "backward_entropy": 0.017448261380195618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020919444505125284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026304930448532104,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16322759787241617,
      "backward_entropy": 0.00993335098028183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002217474626377225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026305625215172768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16319666306177774,
      "backward_entropy": 0.01743012070655823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018177885795012116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026306316256523132,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16316571831703186,
      "backward_entropy": 0.012983281910419465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001940375310368836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026307014748454094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16313544909159342,
      "backward_entropy": 0.00991305559873581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017423013923689723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026307757943868637,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16310548782348633,
      "backward_entropy": 0.017403902113437654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001413695514202118,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026308467611670494,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1630759835243225,
      "backward_entropy": 0.017395275831222533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013911224668845534,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026309123262763023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1630475123723348,
      "backward_entropy": 0.017387157678604125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001525048166513443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026309790089726448,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16301997502644858,
      "backward_entropy": 0.017378976941108702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00158372160512954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026310427114367485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1629928151766459,
      "backward_entropy": 0.009880583733320236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001141454791650176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026311011984944344,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1629656950632731,
      "backward_entropy": 0.009874805063009261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014921908732503653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026311656460165977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16293973724047342,
      "backward_entropy": 0.00986877828836441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012940175365656614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026312271133065224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16291371981302896,
      "backward_entropy": 0.009862935543060303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001264604041352868,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026312928646802902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16288810968399048,
      "backward_entropy": 0.009856818616390229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012947473442181945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026313558220863342,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16286277770996094,
      "backward_entropy": 0.017333009839057924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001259813318029046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631417103111744,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1628375252087911,
      "backward_entropy": 0.009845113009214401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010064697125926614,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026314720511436462,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16281225283940634,
      "backward_entropy": 0.017318931221961976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011243772460147738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02631518803536892,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16278761625289917,
      "backward_entropy": 0.01731286495923996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009222310618497431,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02631564997136593,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16276309887568155,
      "backward_entropy": 0.012985002994537354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008046088041737676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026316102594137192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1627392371495565,
      "backward_entropy": 0.01730104088783264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008518334361724555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026316551491618156,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1627162496248881,
      "backward_entropy": 0.00982067957520485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000713599962182343,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026316963136196136,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16269373893737793,
      "backward_entropy": 0.01298753172159195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007808204973116517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263174157589674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16267210245132446,
      "backward_entropy": 0.009811843931674957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00070013856748119,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026317887008190155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16265096267064413,
      "backward_entropy": 0.009807264804840088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008131714421324432,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026318341493606567,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1626303791999817,
      "backward_entropy": 0.012988409399986267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00074439262971282,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631877362728119,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16260985533396402,
      "backward_entropy": 0.009798553586006165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005237014847807586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026319192722439766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1625895301500956,
      "backward_entropy": 0.0097943514585495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006588926771655679,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026319609954953194,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16257010897000632,
      "backward_entropy": 0.012989543378353119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006114335847087204,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026319997385144234,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16255091627438864,
      "backward_entropy": 0.012990054488182069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005422437679953873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632034383714199,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16253201166788736,
      "backward_entropy": 0.012990850210189819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005214196862652898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026320695877075195,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1625136137008667,
      "backward_entropy": 0.009779103845357896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005630016094073653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026321040466427803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16249563296635947,
      "backward_entropy": 0.009775560349225998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041588794556446373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632136642932892,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16247783104578653,
      "backward_entropy": 0.009772135317325592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042970431968569756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026321686804294586,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16246074438095093,
      "backward_entropy": 0.01299358606338501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041732631507329643,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632196433842182,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16244413455327353,
      "backward_entropy": 0.017228999733924867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039290302083827555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632228098809719,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16242805123329163,
      "backward_entropy": 0.017225638031959534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003336326335556805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632259763777256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16241242488225302,
      "backward_entropy": 0.009759452193975449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040386043838225305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026322895660996437,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16239744424819946,
      "backward_entropy": 0.017218929529190064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033901541610248387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026323195546865463,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16238264242808023,
      "backward_entropy": 0.009753457456827163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003365117299836129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026323504745960236,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1623682975769043,
      "backward_entropy": 0.017212283611297608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003607211110647768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026323825120925903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16235429048538208,
      "backward_entropy": 0.009747394919395446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003640782961156219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026324154809117317,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16234040260314941,
      "backward_entropy": 0.012996453046798705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035000868956558406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632446587085724,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16232653458913168,
      "backward_entropy": 0.012996470928192139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003521819890011102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02632475271821022,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1623126765092214,
      "backward_entropy": 0.0129966601729393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002647885703481734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632499486207962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16229873895645142,
      "backward_entropy": 0.009735815972089768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023538616369478405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026325250044465065,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16228521863619486,
      "backward_entropy": 0.009733200073242188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024491024669259787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026325538754463196,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1622722347577413,
      "backward_entropy": 0.01719028353691101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020433179452084005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632581815123558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16225957870483398,
      "backward_entropy": 0.009727682918310165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023384745873045176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326065883040428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16224743922551474,
      "backward_entropy": 0.009725214540958404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025987095432356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632632665336132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16223552823066711,
      "backward_entropy": 0.009722701460123061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020627905905712396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326585561037064,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16222357749938965,
      "backward_entropy": 0.009720170497894287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019031971169169992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026326822116971016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1622119148572286,
      "backward_entropy": 0.017176230251789094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020442917593754828,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026327082887291908,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16220057010650635,
      "backward_entropy": 0.017173418402671815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022734752565156668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026327334344387054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16218937436739603,
      "backward_entropy": 0.017170700430870055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000171777923242189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026327557861804962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16217801968256632,
      "backward_entropy": 0.00971064269542694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017908184963744134,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632775530219078,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16216697295506796,
      "backward_entropy": 0.01716603636741638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013880824553780258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026327956467866898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16215606530507407,
      "backward_entropy": 0.017163816094398498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015185038500931114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632816880941391,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16214560468991598,
      "backward_entropy": 0.009704314917325974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000117942996439524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328379288315773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16213534275690714,
      "backward_entropy": 0.009702202677726746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012501591118052602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026328589767217636,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16212556759516397,
      "backward_entropy": 0.012999175488948822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013435297296382487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328805834054947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16211611032485962,
      "backward_entropy": 0.009698097407817841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001162628541351296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632901817560196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16210679213205972,
      "backward_entropy": 0.009696080535650253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010698104597395286,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026329223066568375,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1620977520942688,
      "backward_entropy": 0.017149919271469118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010850913531612605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026329418644309044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16208899021148682,
      "backward_entropy": 0.00969221442937851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010163245315197855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026329610496759415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620804270108541,
      "backward_entropy": 0.00969039648771286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.995031046448275e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632978931069374,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16207211216290793,
      "backward_entropy": 0.017143586277961732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.891700079198927e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026329968124628067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620642046133677,
      "backward_entropy": 0.009686959534883499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.737791020190343e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026330145075917244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1620566447575887,
      "backward_entropy": 0.009685282409191132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.011100337374955e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026330333203077316,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16204934318860373,
      "backward_entropy": 0.017137411236763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.269631846109405e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026330506429076195,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1620421310265859,
      "backward_entropy": 0.01299881488084793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.449182157870382e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026330653578042984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1620349089304606,
      "backward_entropy": 0.0171337366104126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0844726249342784e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633081190288067,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1620278557141622,
      "backward_entropy": 0.012998971343040466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.787982420064509e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0263309795409441,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16202110052108765,
      "backward_entropy": 0.012998861074447633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0423571994761005e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633114531636238,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1620145042737325,
      "backward_entropy": 0.01299874484539032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.720665987813845e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633132040500641,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16200808684031168,
      "backward_entropy": 0.01712624728679657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.26573310000822e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026331480592489243,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16200174887975058,
      "backward_entropy": 0.017124466598033905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.535582360811532e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633163146674633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16199549039204916,
      "backward_entropy": 0.009671528637409211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.805605931323953e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026331767439842224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1619892418384552,
      "backward_entropy": 0.0096702441573143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3223884858889505e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026331894099712372,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16198323170344034,
      "backward_entropy": 0.017119792103767396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4762557081412524e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633201889693737,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16197752952575684,
      "backward_entropy": 0.017118318378925322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.867394454777241e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026332132518291473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16197197635968527,
      "backward_entropy": 0.017116963863372803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.310010601533577e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633223496377468,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16196656227111816,
      "backward_entropy": 0.009665657579898835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.760332037927583e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026332316920161247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16196107864379883,
      "backward_entropy": 0.009664739668369293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8744470657547936e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633241005241871,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16195579369862875,
      "backward_entropy": 0.009663774073123932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.360095044830814e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633250504732132,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1619506279627482,
      "backward_entropy": 0.00966278687119484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4936954762088135e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026332594454288483,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16194546222686768,
      "backward_entropy": 0.017111214995384216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9705162887694314e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026332687586545944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1619404157002767,
      "backward_entropy": 0.0096608966588974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.238032877561636e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026332778856158257,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1619356075922648,
      "backward_entropy": 0.009659978747367858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.066929639317095e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026332860812544823,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16193091869354248,
      "backward_entropy": 0.013000592589378357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6889680157182738e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026332944631576538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16192631920178732,
      "backward_entropy": 0.01710696965456009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4118609871948138e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026333030313253403,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16192187865575156,
      "backward_entropy": 0.009657414257526397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8286838642088696e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026333119720220566,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16191760698954263,
      "backward_entropy": 0.01300102323293686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.231880534964148e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633320540189743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16191337505976358,
      "backward_entropy": 0.017103850841522217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5601388188079e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026333294808864594,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16190929214159647,
      "backward_entropy": 0.013001194596290589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2511574570671655e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633337676525116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16190524895985922,
      "backward_entropy": 0.00965404063463211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0762934582307935e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026333454996347427,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16190130511919656,
      "backward_entropy": 0.01710086464881897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.723805326037109e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026333533227443695,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16189747055371603,
      "backward_entropy": 0.009652486443519593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6414755009463988e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026333611458539963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618938148021698,
      "backward_entropy": 0.009651746600866318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8306773199583404e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026333697140216827,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16189026832580566,
      "backward_entropy": 0.009650948643684387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7931140973814763e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026333779096603394,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618868112564087,
      "backward_entropy": 0.009650199115276337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6515790775883943e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026333855465054512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618834137916565,
      "backward_entropy": 0.00964946448802948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2816456546715926e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026333928108215332,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16188008586565653,
      "backward_entropy": 0.017095264792442322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2654688362090383e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263340026140213,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16187691688537598,
      "backward_entropy": 0.009648089110851289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3305992979439907e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633407525718212,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16187387704849243,
      "backward_entropy": 0.00964743047952652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3463334653351922e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633415162563324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16187090675036112,
      "backward_entropy": 0.00964675098657608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.468987284169998e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633422240614891,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618679960568746,
      "backward_entropy": 0.009646089375019073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1709176760632545e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026334285736083984,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16186508536338806,
      "backward_entropy": 0.013001653552055358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1541723324626219e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633434720337391,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618622342745463,
      "backward_entropy": 0.01709030419588089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3242779459687881e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026334404945373535,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618594527244568,
      "backward_entropy": 0.01708960235118866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.833458883193089e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026334457099437714,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618566314379374,
      "backward_entropy": 0.017088964581489563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0203890269622207e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633451484143734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618540088335673,
      "backward_entropy": 0.017088279128074646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0279841262672562e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026334572583436966,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16185141603151956,
      "backward_entropy": 0.0096427321434021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.524139047949575e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026334622874855995,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16184883316357931,
      "backward_entropy": 0.009642238914966583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.646585800102912e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026334673166275024,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16184632976849875,
      "backward_entropy": 0.017086365818977357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596539722318994e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026334721595048904,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16184393564860025,
      "backward_entropy": 0.013002249598503112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0778401095594745e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026334773749113083,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16184165080388388,
      "backward_entropy": 0.009640797227621078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.151365712663392e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633482590317726,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1618394354979197,
      "backward_entropy": 0.013002267479896546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.14746340943384e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633487991988659,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16183735926946005,
      "backward_entropy": 0.01708389222621918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.536964858445572e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026334932073950768,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618353525797526,
      "backward_entropy": 0.009639357775449752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0650273806240875e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633497677743435,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16183331608772278,
      "backward_entropy": 0.017082712054252623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.7988941080111545e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633502148091793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16183137893676758,
      "backward_entropy": 0.017082145810127257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.241668415896129e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335064321756363,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16182947158813477,
      "backward_entropy": 0.009638114273548127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.902516477362951e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335101574659348,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618275741736094,
      "backward_entropy": 0.00963771790266037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7836548472114373e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335133239626884,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16182571649551392,
      "backward_entropy": 0.01708071231842041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4410749069356825e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633516676723957,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618239482243856,
      "backward_entropy": 0.01708027422428131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9888227547635324e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335198432207108,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.161822239557902,
      "backward_entropy": 0.00963677316904068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.231736511428608e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335230097174644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16182060043017069,
      "backward_entropy": 0.009636451303958894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7458911517896922e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335259899497032,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16181900103886923,
      "backward_entropy": 0.009636154025793075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3704784527799347e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633529342710972,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16181746125221252,
      "backward_entropy": 0.017078638076782227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.29570002577384e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335325092077255,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618159810702006,
      "backward_entropy": 0.01707819998264313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6838959001906915e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335356757044792,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16181455055872598,
      "backward_entropy": 0.009635243564844131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.839113105641445e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633539028465748,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16181315978368124,
      "backward_entropy": 0.017077362537384032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6501638785703108e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335420086979866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16181174914042154,
      "backward_entropy": 0.009634662419557571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3128819723060587e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335449889302254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1618103881676992,
      "backward_entropy": 0.017076602578163146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.014136154888547e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335475966334343,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618090271949768,
      "backward_entropy": 0.009634125977754593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6851596456035622e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335500180721283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1618076761563619,
      "backward_entropy": 0.009633879363536834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.201742972829379e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335526257753372,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180644432703653,
      "backward_entropy": 0.009633637964725494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4920675514295e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633555233478546,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16180522243181863,
      "backward_entropy": 0.01707526445388794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0811387457797537e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263355765491724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180402040481567,
      "backward_entropy": 0.009633161127567291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4394562387897167e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335598900914192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16180286804835,
      "backward_entropy": 0.017074644565582275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.91853428077593e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335619390010834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180171569188437,
      "backward_entropy": 0.009632731974124908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.340423179703066e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335639879107475,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16180058320363364,
      "backward_entropy": 0.009632524102926254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.48180538417364e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633565664291382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617994507153829,
      "backward_entropy": 0.009632334113121033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.065057062987762e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633567340672016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179836789766947,
      "backward_entropy": 0.009632161259651184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6740939372539287e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335693895816803,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179733475049338,
      "backward_entropy": 0.009631964564323425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5796111938470858e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335712522268295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617963413397471,
      "backward_entropy": 0.017073129117488862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7470911188866012e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633572928607464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617953578631083,
      "backward_entropy": 0.009631606936454772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0838115258593461e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335744187235832,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617943743864695,
      "backward_entropy": 0.009631428867578506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.331452040176373e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335759088397026,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617934505144755,
      "backward_entropy": 0.017072468996047974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2135403721913463e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633577398955822,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617925465106964,
      "backward_entropy": 0.013004273176193237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.221457750943955e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335788890719414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179165244102478,
      "backward_entropy": 0.009630967676639558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0153372613785905e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633580192923546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16179078817367554,
      "backward_entropy": 0.009630829840898514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1814972822321579e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335814967751503,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178995370864868,
      "backward_entropy": 0.017071694135665894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0872635129999253e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263358261436224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178911924362183,
      "backward_entropy": 0.00963055044412613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.827220886407304e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335837319493294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178826491038004,
      "backward_entropy": 0.00963042825460434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.204120606729703e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633585035800934,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16178749004999796,
      "backward_entropy": 0.01300472319126129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.699571824559825e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335863396525383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178677479426065,
      "backward_entropy": 0.009630171954631806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.943728638158063e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335876435041428,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178605953852335,
      "backward_entropy": 0.009630046784877777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.217279645970848e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335889473557472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178536415100098,
      "backward_entropy": 0.009629921615123748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.483813758175529e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633589878678322,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617846687634786,
      "backward_entropy": 0.017070487141609192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.307114972514682e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335906237363815,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617839733759562,
      "backward_entropy": 0.009629712998867035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.523084152831871e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633591555058956,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178331772486368,
      "backward_entropy": 0.009629606455564498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.956926080827543e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633592300117016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178266207377115,
      "backward_entropy": 0.009629511088132859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.976458960001764e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335928589105606,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178202629089355,
      "backward_entropy": 0.017069967091083528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.105208060740551e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335932314395905,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178137063980103,
      "backward_entropy": 0.017069874703884123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.325786105458974e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335936039686203,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16178073485692343,
      "backward_entropy": 0.017069806158542634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.466112042995519e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263359397649765,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16178011894226074,
      "backward_entropy": 0.009629204869270325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9461411915908684e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263359434902668,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177953282992044,
      "backward_entropy": 0.009629154205322265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.936394475407724e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335949078202248,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177896658579508,
      "backward_entropy": 0.00962907075881958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.813326887007861e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335954666137695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617784102757772,
      "backward_entropy": 0.017069435119628905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.08386711114872e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026335960254073143,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16177789370218912,
      "backward_entropy": 0.017069318890571596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9077210089999426e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633596584200859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.161777396996816,
      "backward_entropy": 0.00962885096669197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6755482685512106e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633597142994404,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177691022555032,
      "backward_entropy": 0.009628796577453613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2282588335874607e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335977017879486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177641352017721,
      "backward_entropy": 0.009628719091415406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.635403516000224e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335982605814934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617759664853414,
      "backward_entropy": 0.009628674387931824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8949497732355667e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026335986331105232,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617755095163981,
      "backward_entropy": 0.01300625056028366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.763180475540139e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633599191904068,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16177505254745483,
      "backward_entropy": 0.017068782448768617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.919603557278606e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335997506976128,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617746651172638,
      "backward_entropy": 0.00962848737835884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.683025795453432e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336001232266426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617742379506429,
      "backward_entropy": 0.017068612575531005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0495104397232353e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336003094911575,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177382071812949,
      "backward_entropy": 0.009628385305404663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8922153205712675e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026336004957556725,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617734134197235,
      "backward_entropy": 0.01300661414861679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.922166117969027e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336006820201874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177301605542502,
      "backward_entropy": 0.009628302603960037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0474421091876138e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336008682847023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177262862523398,
      "backward_entropy": 0.009628272801637649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4458964276163897e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336010545492172,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16177223126093546,
      "backward_entropy": 0.017068329453468322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.014957090068492e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633601240813732,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617718736330668,
      "backward_entropy": 0.01706826388835907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9134267859044485e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633601427078247,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177151600519815,
      "backward_entropy": 0.00962817221879959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.462370562421711e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633601613342762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177117824554443,
      "backward_entropy": 0.009628145396709442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9704751252902497e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633601799607277,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16177086035410562,
      "backward_entropy": 0.013007138669490815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3876935983935255e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633601985871792,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16177054246266684,
      "backward_entropy": 0.01706804484128952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.571966805613556e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336021721363068,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177022457122803,
      "backward_entropy": 0.009628041088581086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6485829235080018e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336023584008217,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176992654800415,
      "backward_entropy": 0.017067965865135194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3061300307981583e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336025446653366,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176962852478027,
      "backward_entropy": 0.009627999365329742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3091008099763712e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336027309298515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617693305015564,
      "backward_entropy": 0.017067863047122954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2852767383719765e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336029171943665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617690920829773,
      "backward_entropy": 0.01706780344247818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2911777957924642e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336031034588814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176881392796835,
      "backward_entropy": 0.009627903252840042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3105473328778316e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336032897233963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176855564117432,
      "backward_entropy": 0.009627856314182281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1376499031712228e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336034759879112,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176830728848776,
      "backward_entropy": 0.017067661881446837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3985957991735631e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633603662252426,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176806886990866,
      "backward_entropy": 0.017067603766918182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.260568679612334e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633603848516941,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176782051722208,
      "backward_entropy": 0.017067565023899077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.769037407319047e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633604034781456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617676019668579,
      "backward_entropy": 0.009627778083086014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.573073190769719e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633604221045971,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176738341649374,
      "backward_entropy": 0.00962773859500885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.397679186420646e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633604407310486,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176716486612955,
      "backward_entropy": 0.009627713263034821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.087823744062916e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336047798395157,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176696618398032,
      "backward_entropy": 0.01706734150648117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.878691749534482e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336051523685455,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.161766787370046,
      "backward_entropy": 0.017067301273345947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.386981254991042e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336055248975754,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176660855611166,
      "backward_entropy": 0.017067228257656098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.651560996966509e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026336058974266052,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617664396762848,
      "backward_entropy": 0.013007986545562743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3819739775917697e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633606269955635,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176626086235046,
      "backward_entropy": 0.017067116498947144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.594849111252188e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633606642484665,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176611185073853,
      "backward_entropy": 0.00962754711508751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.230879989743698e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336070150136948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176595290501913,
      "backward_entropy": 0.00962749943137169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4642981694996706e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336073875427246,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176579395929971,
      "backward_entropy": 0.00962747484445572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8562377230609854e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336077600717545,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176564494768778,
      "backward_entropy": 0.017066872119903563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.28325286350173e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336081326007843,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176549593607584,
      "backward_entropy": 0.01706682741641998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.539767317623955e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633608505129814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176536679267883,
      "backward_entropy": 0.009627403318881988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.337141762926876e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633608877658844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176523764928183,
      "backward_entropy": 0.009627379477024078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.9791445633218245e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633609250187874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176509857177734,
      "backward_entropy": 0.009627360850572586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7376725714466374e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336096227169037,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617649793624878,
      "backward_entropy": 0.009627337753772735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.210218662592524e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336099952459335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176486015319824,
      "backward_entropy": 0.017066571116447448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.434237345028123e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336101815104485,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176476081212363,
      "backward_entropy": 0.00962727814912796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.608096577067954e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336105540394783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176464160283408,
      "backward_entropy": 0.009627260267734528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.237729373495313e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336107403039932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176453232765198,
      "backward_entropy": 0.017066442966461183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.232116796425544e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633610926568508,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176444292068481,
      "backward_entropy": 0.009627227485179902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0951238016996285e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633611112833023,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176432371139526,
      "backward_entropy": 0.01706635355949402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.390259723483723e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02633611299097538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176422437032065,
      "backward_entropy": 0.01706630140542984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8114031991322008e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633611485362053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.161764125029246,
      "backward_entropy": 0.009627159684896469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.904854135010737e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633611671626568,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176400581995645,
      "backward_entropy": 0.01300826519727707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.779417762610592e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336118578910828,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176389654477438,
      "backward_entropy": 0.00962713584303856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5694226362938934e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336120441555977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176380713780722,
      "backward_entropy": 0.009627130627632142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.208972205153259e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026336122304201126,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176370779673258,
      "backward_entropy": 0.013008320331573486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6847658318729373e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336124166846275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176360845565796,
      "backward_entropy": 0.017066124081611633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.64093165722079e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026336124166846275,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1617635190486908,
      "backward_entropy": 0.013008373975753783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8095050791089307e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336124166846275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176341970761618,
      "backward_entropy": 0.01706608235836029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4275059356805286e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336124166846275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176334023475647,
      "backward_entropy": 0.00962705835700035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.618946043890901e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336124166846275,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176324089368185,
      "backward_entropy": 0.017066025733947755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3669612997091463e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336124166846275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1617631514867147,
      "backward_entropy": 0.009627043455839156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.82202044749647e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026336124166846275,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176307201385498,
      "backward_entropy": 0.013008467853069305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1948685596507858e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026336126029491425,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176299254099527,
      "backward_entropy": 0.013008476793766021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.143219208188384e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336127892136574,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1617629329363505,
      "backward_entropy": 0.01706593930721283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3554803501847346e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336129754781723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16176286339759827,
      "backward_entropy": 0.0170659214258194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0197041433457343e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336131617426872,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16176278392473856,
      "backward_entropy": 0.009627001732587815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0340023948174348e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633613348007202,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16176273425420126,
      "backward_entropy": 0.013008515536785125,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.8906136209604367e-07,
    "avg_log_Z": 0.026335990224033594,
    "success_rate": 1.0,
    "avg_reward": 45.3,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.12,
      "1": 0.35,
      "2": 0.53
    },
    "avg_forward_entropy": 0.1617740954955419,
    "avg_backward_entropy": 0.012638005964457988,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}