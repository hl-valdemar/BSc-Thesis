{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13852326869964598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13846524953842163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.563276290893555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239831924438477,
      "backward_entropy": 0.13847811222076417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.560395240783691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823988159497579,
      "backward_entropy": 0.1385146975517273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.473649978637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019999967480544,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239919344584146,
      "backward_entropy": 0.13850576877593995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.47101879119873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.000299975392408669,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239994843800864,
      "backward_entropy": 0.13849620819091796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.071093559265137,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00039993954123929143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240086237589517,
      "backward_entropy": 0.13848607540130614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.985797882080078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004997891373932362,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240100145339966,
      "backward_entropy": 0.13847554922103883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.35629415512085,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005995342507958412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240110079447427,
      "backward_entropy": 0.1384190797805786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.130661964416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006990263937041163,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239851792653403,
      "backward_entropy": 0.13845324516296387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.376079559326172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007985472911968827,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239869674046835,
      "backward_entropy": 0.13839688301086425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5004167556762695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008981934515759349,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823994517326355,
      "backward_entropy": 0.13838498592376708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289774894714355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009976410074159503,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239974975585938,
      "backward_entropy": 0.13841588497161866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.347830772399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010972014861181378,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240100145339966,
      "backward_entropy": 0.13832718133926392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.135632514953613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001196557772345841,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239998817443848,
      "backward_entropy": 0.13838844299316405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.344223499298096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012960279127582908,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239843845367432,
      "backward_entropy": 0.13833348751068114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.887630462646484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013953110901638865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823952595392863,
      "backward_entropy": 0.13828060626983643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360846519470215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014946124283596873,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823927362759908,
      "backward_entropy": 0.13834409713745116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.277956008911133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001594110974110663,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239100774129233,
      "backward_entropy": 0.13832809925079345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.114975929260254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001693736296147108,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239025274912515,
      "backward_entropy": 0.13831143379211425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03287410736084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017933899071067572,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18239112695058188,
      "backward_entropy": 0.1382601499557495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.565881252288818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018930279184132814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18239372968673706,
      "backward_entropy": 0.13819172382354736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.134514808654785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0019925138913094997,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823954979578654,
      "backward_entropy": 0.13825721740722657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.187161445617676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0020924690179526806,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18239808082580566,
      "backward_entropy": 0.13823790550231935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.56073522567749,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002192444633692503,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240139881769815,
      "backward_entropy": 0.1381925106048584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.00817346572876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022922097705304623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824038028717041,
      "backward_entropy": 0.13810951709747316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.948456764221191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002391544636338949,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240559101104736,
      "backward_entropy": 0.13817598819732665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.708155155181885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024909195490181446,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240708112716675,
      "backward_entropy": 0.13815393447875976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.540181636810303,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025901994667947292,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240936597188315,
      "backward_entropy": 0.13813107013702391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.174333572387695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026889541186392307,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240869045257568,
      "backward_entropy": 0.13809823989868164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.549856662750244,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027879104018211365,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18240906794865927,
      "backward_entropy": 0.1380778193473816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.937983989715576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002886800328269601,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240884939829508,
      "backward_entropy": 0.13796913623809814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.620422840118408,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0029858022462576628,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18240851163864136,
      "backward_entropy": 0.13803331851959227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32324504852295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030847215093672276,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824093461036682,
      "backward_entropy": 0.1380126357078552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8527069091796875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003183922031894326,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18241057793299356,
      "backward_entropy": 0.13788976669311523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.461401462554932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003283153520897031,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824118693669637,
      "backward_entropy": 0.13796544075012207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.926759243011475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003382239257916808,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824127435684204,
      "backward_entropy": 0.13794081211090087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69851016998291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034814192913472652,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18241341908772787,
      "backward_entropy": 0.13789749145507812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.07852840423584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035809711553156376,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18241669734319052,
      "backward_entropy": 0.13786718845367432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.453236103057861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036806524731218815,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18241886297861734,
      "backward_entropy": 0.13783690929412842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.536179542541504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037801286671310663,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242069085439047,
      "backward_entropy": 0.13780612945556642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.370887756347656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003879908937960863,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242359161376953,
      "backward_entropy": 0.13767242431640625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.911728382110596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003979420755058527,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824263334274292,
      "backward_entropy": 0.13774142265319825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.135463237762451,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004078973084688187,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242867787679037,
      "backward_entropy": 0.13770769834518432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.131014823913574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004178196657449007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242985010147095,
      "backward_entropy": 0.13756494522094725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.517487049102783,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00427706865593791,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18243205547332764,
      "backward_entropy": 0.1376848816871643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4351582527160645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004375877324491739,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824335257212321,
      "backward_entropy": 0.13765270709991456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.971486568450928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004474519751966,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18243670463562012,
      "backward_entropy": 0.13756468296051025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.050396919250488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004572840873152018,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824393073717753,
      "backward_entropy": 0.1375270366668701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.274779319763184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004671845585107803,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18244439363479614,
      "backward_entropy": 0.13748804330825806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.654029369354248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00477062352001667,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18244940042495728,
      "backward_entropy": 0.13744804859161378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.19493579864502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004869326949119568,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18245635430018106,
      "backward_entropy": 0.1374809980392456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420737266540527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004968317225575447,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18246308962504068,
      "backward_entropy": 0.1374441623687744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.339597225189209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0050676483660936356,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18247040112813315,
      "backward_entropy": 0.1373211145401001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.801357746124268,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005166222807019949,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18247715632120767,
      "backward_entropy": 0.13727658987045288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.336460590362549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005264912266284227,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18248331546783447,
      "backward_entropy": 0.1373286247253418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.333614349365234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005363459698855877,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18248877922693887,
      "backward_entropy": 0.13728828430175782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.629731178283691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005461882334202528,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18249372641245523,
      "backward_entropy": 0.13713653087615968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.165191650390625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005560808815062046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250038226445517,
      "backward_entropy": 0.1369637131690979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6291608810424805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0056604743003845215,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250815073649088,
      "backward_entropy": 0.13716087341308594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.635397911071777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005760024301707745,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18251578013102213,
      "backward_entropy": 0.13685967922210693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.397339820861816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005859539844095707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182521382967631,
      "backward_entropy": 0.13680596351623536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.551570415496826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005958311725407839,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18252638975779215,
      "backward_entropy": 0.13702361583709716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.906357765197754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006056529004126787,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18253020445505777,
      "backward_entropy": 0.13697634935379027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.308789253234863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006155416369438171,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825361649195353,
      "backward_entropy": 0.13692786693572997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5414910316467285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006254130508750677,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254154920578003,
      "backward_entropy": 0.13687829971313475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.380666255950928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006352852564305067,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18254590034484863,
      "backward_entropy": 0.1366497755050659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.597941398620605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006451473571360111,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254953622817993,
      "backward_entropy": 0.13677098751068115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.993109226226807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006550650577992201,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18255333105723062,
      "backward_entropy": 0.13671460151672363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.1953706741333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006649473216384649,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18255611260732016,
      "backward_entropy": 0.13646373748779297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5276265144348145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006748559884727001,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825604240099589,
      "backward_entropy": 0.13627088069915771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2186737060546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006847042590379715,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18256362279256186,
      "backward_entropy": 0.13633363246917723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.200806617736816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006945409812033176,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825650135676066,
      "backward_entropy": 0.13613487482070924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6545891761779785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007043600082397461,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256652355194092,
      "backward_entropy": 0.13640791177749634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.636110782623291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007141889072954655,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256821235020956,
      "backward_entropy": 0.13599164485931398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1883625984191895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007240192033350468,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257174889246622,
      "backward_entropy": 0.1360591769218445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.56951904296875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007338322699069977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257518609364828,
      "backward_entropy": 0.13584060668945314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0373215675354,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007435927167534828,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257902065912882,
      "backward_entropy": 0.135911226272583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.434174537658691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0075333998538553715,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18258154392242432,
      "backward_entropy": 0.13568463325500488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.721550941467285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007630457170307636,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18258156379063925,
      "backward_entropy": 0.13575748205184937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3230299949646,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007727873045951128,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257902065912882,
      "backward_entropy": 0.13567620515823364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.303206920623779,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007825326174497604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257629871368408,
      "backward_entropy": 0.13582372665405273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.6673583984375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007922736927866936,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257538477579752,
      "backward_entropy": 0.13574326038360596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.930453300476074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008020891807973385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257617950439453,
      "backward_entropy": 0.13566060066223146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.224463939666748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008118794299662113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825761596361796,
      "backward_entropy": 0.13517944812774657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.454348564147949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008216620422899723,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825760006904602,
      "backward_entropy": 0.13508880138397217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.266926765441895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008314548060297966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257484833399454,
      "backward_entropy": 0.13540077209472656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.040335655212402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008412957191467285,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257478872934976,
      "backward_entropy": 0.1350402355194092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.904251575469971,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008511699736118317,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825748085975647,
      "backward_entropy": 0.1352161169052124,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2886643409729,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008610116317868233,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257407347361246,
      "backward_entropy": 0.13512065410614013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.567286491394043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008708524517714977,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825710336367289,
      "backward_entropy": 0.1345986843109131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.235143661499023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008806997910141945,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256847063700357,
      "backward_entropy": 0.13492214679718018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.489151477813721,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008905884809792042,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18256731828053793,
      "backward_entropy": 0.13451008796691893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.845961093902588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009004797786474228,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18256481488545737,
      "backward_entropy": 0.13439629077911378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.732344627380371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009103864431381226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256340424219766,
      "backward_entropy": 0.13416272401809692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426724433898926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009203515946865082,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825647552808126,
      "backward_entropy": 0.13448693752288818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.932941436767578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009303534403443336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256787459055582,
      "backward_entropy": 0.13392599821090698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.146244525909424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00940311886370182,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825695832570394,
      "backward_entropy": 0.1342545986175537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.412527084350586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009502407163381577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825709342956543,
      "backward_entropy": 0.13413465023040771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.581578731536865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009602165780961514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257220586140951,
      "backward_entropy": 0.13401104211807252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9819111824035645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009701866656541824,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257315953572592,
      "backward_entropy": 0.13342349529266356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.260401248931885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009801208041608334,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257256348927817,
      "backward_entropy": 0.13375506401062012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709923267364502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00990030262619257,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257311979929605,
      "backward_entropy": 0.133248233795166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9203691482543945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009999512694776058,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257278203964233,
      "backward_entropy": 0.1330142855644226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.501093864440918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010098917409777641,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825725237528483,
      "backward_entropy": 0.1329610228538513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.313143730163574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010198795236647129,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825734575589498,
      "backward_entropy": 0.13321006298065186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.598598480224609,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010298480279743671,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257311979929605,
      "backward_entropy": 0.13266063928604127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.252557754516602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010398141108453274,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257220586140951,
      "backward_entropy": 0.13242168426513673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3543500900268555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010498136281967163,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257158994674683,
      "backward_entropy": 0.1327737331390381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.743363380432129,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010597893968224525,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257145086924234,
      "backward_entropy": 0.13218557834625244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.928195953369141,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010698212310671806,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257351716359457,
      "backward_entropy": 0.13246891498565674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.258121967315674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010798623785376549,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257502714792886,
      "backward_entropy": 0.13177430629730225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.173766613006592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010898751206696033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825751264890035,
      "backward_entropy": 0.13160455226898193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.113253593444824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010998561978340149,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257431189219156,
      "backward_entropy": 0.13198385238647461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.615636825561523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01109859999269247,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257415294647217,
      "backward_entropy": 0.13132009506225586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.049189567565918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011199153028428555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18257407347361246,
      "backward_entropy": 0.13108761310577394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.299969673156738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011298693716526031,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825723648071289,
      "backward_entropy": 0.1309114694595337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.500262260437012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011398637667298317,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825702985127767,
      "backward_entropy": 0.13074254989624023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.2011137008667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011498960666358471,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257075548171997,
      "backward_entropy": 0.13054494857788085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.114911079406738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011599532328546047,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257091442743936,
      "backward_entropy": 0.13092515468597413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.378159046173096,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011700262315571308,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257129192352295,
      "backward_entropy": 0.13073574304580687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2934088706970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011800709180533886,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18257129192352295,
      "backward_entropy": 0.1299266815185547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3474297523498535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011900840327143669,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18257107337315878,
      "backward_entropy": 0.13034684658050538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.478707790374756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012000233866274357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18256727854410806,
      "backward_entropy": 0.1294945001602173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.329326629638672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012099002487957478,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18256179491678873,
      "backward_entropy": 0.1293007731437683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.316680431365967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01219766866415739,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825564702351888,
      "backward_entropy": 0.12908658981323243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.021905899047852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012296236120164394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18255130449930826,
      "backward_entropy": 0.1295234441757202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.358927249908447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012395060621201992,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825488011042277,
      "backward_entropy": 0.128643798828125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.702285289764404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012493235059082508,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18254482746124268,
      "backward_entropy": 0.12909257411956787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907963275909424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012590453028678894,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18253886699676514,
      "backward_entropy": 0.12810028791427613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8933610916137695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012688063085079193,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182533860206604,
      "backward_entropy": 0.12864716053009034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.307019233703613,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012785440310835838,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1825287938117981,
      "backward_entropy": 0.12759087085723878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.795638084411621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012882868759334087,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18252344926198324,
      "backward_entropy": 0.12733118534088134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.210419178009033,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012980014085769653,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825185020764669,
      "backward_entropy": 0.12794926166534423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.0499849319458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013076584786176682,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18251270055770874,
      "backward_entropy": 0.1269963264465332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.03261661529541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013173682615160942,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250886599222818,
      "backward_entropy": 0.1267425537109375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.51779842376709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013270729221403599,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825037201245626,
      "backward_entropy": 0.1264821171760559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.210177421569824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013367979787290096,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249889214833578,
      "backward_entropy": 0.12621335983276366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.700444221496582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013465825468301773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249468008677164,
      "backward_entropy": 0.12593560218811034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.408762454986572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013563873246312141,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18249166011810303,
      "backward_entropy": 0.1264406204223633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.473126411437988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013661355711519718,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18248820304870605,
      "backward_entropy": 0.12536251544952393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.786012172698975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013757794164121151,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824830174446106,
      "backward_entropy": 0.1250755786895752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.849720478057861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01385466754436493,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824782888094584,
      "backward_entropy": 0.1256284236907959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.046923637390137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013951393775641918,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824726661046346,
      "backward_entropy": 0.12534756660461427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0969719886779785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014048080891370773,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1824671427408854,
      "backward_entropy": 0.12506186962127686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.157409191131592,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01414477825164795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18246098359425864,
      "backward_entropy": 0.12477290630340576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.059608459472656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014241468161344528,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824564735094706,
      "backward_entropy": 0.12349803447723388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.635593891143799,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014338146895170212,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18245146671930948,
      "backward_entropy": 0.12418273687362671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.729313850402832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014434476383030415,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18244884411493936,
      "backward_entropy": 0.12282459735870362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2811760902404785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014531174674630165,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824482480684916,
      "backward_entropy": 0.12247605323791504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7672247886657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014627985656261444,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824474334716797,
      "backward_entropy": 0.12160000801086426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.037299156188965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01472462434321642,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824447512626648,
      "backward_entropy": 0.12120198011398316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.93751859664917,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014821193180978298,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18244338035583496,
      "backward_entropy": 0.12079496383666992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.127159595489502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01491769403219223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18244123458862305,
      "backward_entropy": 0.12101186513900757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6600141525268555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015014223754405975,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18243942658106485,
      "backward_entropy": 0.11995692253112793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.502012729644775,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01511108223348856,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824390689531962,
      "backward_entropy": 0.1195253610610962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.743190288543701,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015208110213279724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244083722432455,
      "backward_entropy": 0.12121694087982178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.850100517272949,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01530549582093954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182442307472229,
      "backward_entropy": 0.1194197416305542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.88937520980835,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015403296798467636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244266510009766,
      "backward_entropy": 0.12048355340957642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.322064399719238,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015501508489251137,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18244075775146484,
      "backward_entropy": 0.1201035737991333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.294886589050293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015599694103002548,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18243887027104697,
      "backward_entropy": 0.11812478303909302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.120765686035156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015697838738560677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18243702252705893,
      "backward_entropy": 0.11677069664001465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.890545845031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015795180574059486,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18243618806203207,
      "backward_entropy": 0.11628537178039551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.595656394958496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01589168608188629,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824350357055664,
      "backward_entropy": 0.11579353809356689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.518998622894287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01598726585507393,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18243294954299927,
      "backward_entropy": 0.11812553405761719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.958477973937988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01608322560787201,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18243102232615152,
      "backward_entropy": 0.11585596799850464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.256421089172363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016179129481315613,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18243078390757242,
      "backward_entropy": 0.11729576587677001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.699814796447754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01627524569630623,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18242851893107095,
      "backward_entropy": 0.11687023639678955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.263044357299805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016370510682463646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242651224136353,
      "backward_entropy": 0.11441961526870728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.897599697113037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016466643661260605,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824254592259725,
      "backward_entropy": 0.11268800497055054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.608853816986084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016563324257731438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242530028025308,
      "backward_entropy": 0.11341309547424316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.637892246246338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016659678891301155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18242530028025308,
      "backward_entropy": 0.11289808750152588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3307294845581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01675584726035595,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18242196242014566,
      "backward_entropy": 0.11104199886322022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7123589515686035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01685224287211895,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18241800864537558,
      "backward_entropy": 0.11184704303741455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.847320556640625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016948383301496506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18241568406422934,
      "backward_entropy": 0.11130998134613038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.289164066314697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017045078799128532,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182413121064504,
      "backward_entropy": 0.11315374374389649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.802133083343506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01714193820953369,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824092467625936,
      "backward_entropy": 0.10874453783035279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.865950584411621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017238596454262733,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1824052333831787,
      "backward_entropy": 0.10815175771713256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.371189594268799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0173344723880291,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240060408910116,
      "backward_entropy": 0.10907168388366699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.072961330413818,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017430629581212997,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1823958953221639,
      "backward_entropy": 0.10849525928497314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.975090980529785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017526930198073387,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238802750905356,
      "backward_entropy": 0.11057729721069336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.112567901611328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017623208463191986,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238035837809244,
      "backward_entropy": 0.11003950834274293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.509182453155518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01771891862154007,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18237189451853433,
      "backward_entropy": 0.1067234992980957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.668182373046875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017813727259635925,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18236211935679117,
      "backward_entropy": 0.1089470386505127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.011560440063477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017908496782183647,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1823516289393107,
      "backward_entropy": 0.10839257240295411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.399771690368652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018004024401307106,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18234441677729288,
      "backward_entropy": 0.10490448474884033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.91323184967041,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018099907785654068,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18233702580134073,
      "backward_entropy": 0.10426815748214721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2642669677734375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01819644682109356,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18232973416646323,
      "backward_entropy": 0.10362131595611572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.525874137878418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018292436376214027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18232345581054688,
      "backward_entropy": 0.10613541603088379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.976600170135498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018388187512755394,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1823155681292216,
      "backward_entropy": 0.10052233934402466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.443821907043457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018483934924006462,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18230950832366943,
      "backward_entropy": 0.10164977312088012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.733496189117432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01857934147119522,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18230414390563965,
      "backward_entropy": 0.10096611976623535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.254910469055176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018674008548259735,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1822976271311442,
      "backward_entropy": 0.10027854442596436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.651127815246582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018769018352031708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18229146798451742,
      "backward_entropy": 0.0995749592781067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.610730171203613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018863270059227943,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18228419621785483,
      "backward_entropy": 0.1025442361831665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.157454490661621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01895674131810665,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18227851390838623,
      "backward_entropy": 0.10192577838897705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.286229133605957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019049974158406258,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822714408238729,
      "backward_entropy": 0.10129976272583008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4734110832214355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0191437266767025,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18226494391759238,
      "backward_entropy": 0.09672431349754333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.307022571563721,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019237397238612175,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18225791056950888,
      "backward_entropy": 0.09598919749259949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.988861560821533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01933084800839424,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18225177129109701,
      "backward_entropy": 0.09938380718231202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0933661460876465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019423194229602814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.182245671749115,
      "backward_entropy": 0.094510018825531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.216544151306152,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019515354186296463,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822389761606852,
      "backward_entropy": 0.09808679819107055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.882483005523682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019607486203312874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18223007520039877,
      "backward_entropy": 0.0930167019367218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.323485374450684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019699349999427795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822192668914795,
      "backward_entropy": 0.0967603325843811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.556532382965088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01979050040245056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18220921357472739,
      "backward_entropy": 0.09150904417037964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.955055236816406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01988118514418602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1821996569633484,
      "backward_entropy": 0.09074839353561401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.067130088806152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019971799105405807,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18218863010406494,
      "backward_entropy": 0.08998130559921265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.965973854064941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020062407478690147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18217714627583823,
      "backward_entropy": 0.08920650482177735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8842082023620605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02015211619436741,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1821682850519816,
      "backward_entropy": 0.08663727641105652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4672088623046875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020242497324943542,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182159423828125,
      "backward_entropy": 0.08586177825927735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.84885835647583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020332401618361473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1821516752243042,
      "backward_entropy": 0.09199485778808594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.991106986999512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020422223955392838,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182142972946167,
      "backward_entropy": 0.09129879474639893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.730030536651611,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020511312410235405,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18213419119517008,
      "backward_entropy": 0.09060084819793701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6811723709106445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020599551498889923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18212499221165976,
      "backward_entropy": 0.08447449207305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.146573543548584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020687764510512352,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18211495876312256,
      "backward_entropy": 0.08195204734802246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.744426250457764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02077547088265419,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18210665384928384,
      "backward_entropy": 0.08288182020187378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.457926273345947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020862532779574394,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1820961038271586,
      "backward_entropy": 0.0877837896347046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.710482597351074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020949508994817734,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18208531538645426,
      "backward_entropy": 0.08707170486450196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.379993915557861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021036634221673012,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18207349379857382,
      "backward_entropy": 0.07880101203918458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.582238674163818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02112281508743763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18206210931142172,
      "backward_entropy": 0.08563771247863769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.63519811630249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02120831608772278,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1820507844289144,
      "backward_entropy": 0.07722406983375549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.634596347808838,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021293282508850098,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18203838666280112,
      "backward_entropy": 0.07809129357337952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.360691070556641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021377788856625557,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1820243994394938,
      "backward_entropy": 0.07729797959327697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.811229705810547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02146242745220661,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18201011419296265,
      "backward_entropy": 0.07649660110473633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.674521446228027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021546727046370506,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819960872332255,
      "backward_entropy": 0.0820082426071167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.988699913024902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02163144387304783,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18198162317276,
      "backward_entropy": 0.08127250671386718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.965705394744873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02171599119901657,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18196646372477213,
      "backward_entropy": 0.08053442239761352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.904362678527832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02180030383169651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18195251623789468,
      "backward_entropy": 0.07979731559753418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.730008602142334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021884357556700706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18193952242533365,
      "backward_entropy": 0.07906122207641601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.695794582366943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021968891844153404,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18192652861277261,
      "backward_entropy": 0.07010559439659118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.190430164337158,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022053025662899017,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18191295862197876,
      "backward_entropy": 0.07758346796035767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.540376663208008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022136442363262177,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18189716339111328,
      "backward_entropy": 0.07684289813041686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.157501697540283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022219516336917877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1818793217341105,
      "backward_entropy": 0.06911632418632507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9248929023742676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02230190299451351,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18186098337173462,
      "backward_entropy": 0.06692088842391967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.120794773101807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02238348126411438,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18184196949005127,
      "backward_entropy": 0.06613624691963196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.689454078674316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022464444860816002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818238099416097,
      "backward_entropy": 0.07388101816177368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.60727596282959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0225454643368721,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18180362383524576,
      "backward_entropy": 0.06457385420799255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.252776622772217,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022626373916864395,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18178361654281616,
      "backward_entropy": 0.06379632949829102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.661197662353516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022706912830471992,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18176287412643433,
      "backward_entropy": 0.07166362404823304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.037447452545166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022787537425756454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18174028396606445,
      "backward_entropy": 0.06347402334213256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.101179838180542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022867588326334953,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18171807130177817,
      "backward_entropy": 0.07018637657165527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7555654048919678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0229461919516325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1816986600557963,
      "backward_entropy": 0.061884725093841554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9741368293762207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02302417904138565,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1816798448562622,
      "backward_entropy": 0.05996578931808472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.395162343978882,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023100871592760086,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18166261911392212,
      "backward_entropy": 0.06033935546875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.738260269165039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0231767687946558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1816465457280477,
      "backward_entropy": 0.06731135845184326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.543142557144165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023252302780747414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18163055181503296,
      "backward_entropy": 0.06660360097885132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3391973972320557,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023326298221945763,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18161678314208984,
      "backward_entropy": 0.06590611934661865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9428842067718506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02339985780417919,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18160013357798258,
      "backward_entropy": 0.056287771463394164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.058285713195801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023472629487514496,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18158129851023355,
      "backward_entropy": 0.056642717123031615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8067805767059326,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023545805364847183,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18155980110168457,
      "backward_entropy": 0.06381025910377502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7313406467437744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023619085550308228,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18153627713521323,
      "backward_entropy": 0.06310822367668152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4815328121185303,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02369125746190548,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18151402473449707,
      "backward_entropy": 0.053463411331176755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.361752986907959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023763196542859077,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814923882484436,
      "backward_entropy": 0.06172555088996887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.343973159790039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023834863677620888,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18147005637486777,
      "backward_entropy": 0.05207812786102295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3645248413085938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023906296119093895,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18144657214482626,
      "backward_entropy": 0.06035400032997131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6625304222106934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02397759072482586,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18142100175221762,
      "backward_entropy": 0.05071369409561157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.574115514755249,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02404789999127388,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18139630556106567,
      "backward_entropy": 0.05899336338043213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6964128017425537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02411719784140587,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18137294054031372,
      "backward_entropy": 0.04938017725944519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.210570812225342,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024185730144381523,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1813503305117289,
      "backward_entropy": 0.057666671276092527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7056896686553955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024254126474261284,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18132811784744263,
      "backward_entropy": 0.04807190001010895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.673494577407837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02432193234562874,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18130489190419516,
      "backward_entropy": 0.04822922945022583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9474339485168457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024389082565903664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18128236134847006,
      "backward_entropy": 0.047567731142044066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.01678466796875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02445598877966404,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18125905593236288,
      "backward_entropy": 0.046908095479011536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2730329036712646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024522749707102776,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18123581012090048,
      "backward_entropy": 0.04624901115894318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5726797580718994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024588512256741524,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1812124252319336,
      "backward_entropy": 0.05381076335906983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.179354190826416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024653788655996323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18118766943613687,
      "backward_entropy": 0.04496371150016785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9977514743804932,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02471809647977352,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18116319179534912,
      "backward_entropy": 0.04369277656078339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6220403909683228,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02478141151368618,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18113738298416138,
      "backward_entropy": 0.043101686239242556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6349036693573,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024843301624059677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18111189206441244,
      "backward_entropy": 0.042523926496505736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.664468288421631,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024905186146497726,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18108487129211426,
      "backward_entropy": 0.0419500470161438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.019400119781494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024967068806290627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18105703592300415,
      "backward_entropy": 0.04194643497467041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.116382360458374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025028159841895103,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18102872371673584,
      "backward_entropy": 0.04950523376464844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3187661170959473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025088677182793617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18099949757258096,
      "backward_entropy": 0.040786340832710266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4660277366638184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025148950517177582,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18096896012624106,
      "backward_entropy": 0.03971500098705292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8334671258926392,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025209277868270874,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18093591928482056,
      "backward_entropy": 0.03917080760002136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.592309832572937,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02526858076453209,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18090476592381796,
      "backward_entropy": 0.047133469581604005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9846006631851196,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02532677911221981,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18087331453959146,
      "backward_entropy": 0.038111639022827146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6168882846832275,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025384370237588882,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808431347211202,
      "backward_entropy": 0.04599460661411285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7513360977172852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025441035628318787,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18081259727478027,
      "backward_entropy": 0.03708663284778595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.664789080619812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02549699880182743,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18078211943308511,
      "backward_entropy": 0.04488890469074249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4966590404510498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025552276521921158,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18075080712636313,
      "backward_entropy": 0.0364311546087265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1732369661331177,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025606529787182808,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18072096506754556,
      "backward_entropy": 0.04381538927555084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5453310012817383,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025659408420324326,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1806925137837728,
      "backward_entropy": 0.03514560461044312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0674446821212769,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025711579248309135,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18066473801930746,
      "backward_entropy": 0.034683716297149655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9368642568588257,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025762470439076424,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1806360880533854,
      "backward_entropy": 0.03423407077789307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9407063722610474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025813527405261993,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18060539166132608,
      "backward_entropy": 0.03404957950115204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3832142353057861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02586481161415577,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18057233095169067,
      "backward_entropy": 0.041295742988586424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7552646994590759,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02591538429260254,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18053865432739258,
      "backward_entropy": 0.032904553413391116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5320435762405396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025964269414544106,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18050607045491537,
      "backward_entropy": 0.03248273730278015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3686058521270752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026012957096099854,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1804718772570292,
      "backward_entropy": 0.03206584751605988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7330513000488281,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02606114000082016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18043702840805054,
      "backward_entropy": 0.039393109083175656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.258334755897522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02610952965915203,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1804001728693644,
      "backward_entropy": 0.031399494409561156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6532014608383179,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026157332584261894,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18036216497421265,
      "backward_entropy": 0.030976748466491698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1370303630828857,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026205256581306458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18032238880793253,
      "backward_entropy": 0.03055233657360077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2468382120132446,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02625231072306633,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18028277158737183,
      "backward_entropy": 0.037561053037643434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2152518033981323,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026298709213733673,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1802434722582499,
      "backward_entropy": 0.029658281803131105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0142649412155151,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026344455778598785,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18020443121592203,
      "backward_entropy": 0.029279178380966185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2459983825683594,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026389230042696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18016604582468668,
      "backward_entropy": 0.036267143487930295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0922871828079224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026433588936924934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18012730280558267,
      "backward_entropy": 0.028550112247467042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0386897325515747,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026477180421352386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1800891955693563,
      "backward_entropy": 0.03544643521308899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7517611384391785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026520097628235817,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18005075057347616,
      "backward_entropy": 0.027838048338890076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.139693021774292,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026561763137578964,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18001325925191244,
      "backward_entropy": 0.03466155230998993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.110707402229309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026603149250149727,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1799747347831726,
      "backward_entropy": 0.034279316663742065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9330557584762573,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026644226163625717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17993509769439697,
      "backward_entropy": 0.03390160799026489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8683854937553406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02668464370071888,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17989484469095865,
      "backward_entropy": 0.0335306316614151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8964258432388306,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026724420487880707,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17985347906748453,
      "backward_entropy": 0.033165401220321654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0763579607009888,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026763619855046272,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17981133858362833,
      "backward_entropy": 0.02589002251625061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0095610618591309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026802685111761093,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1797680457433065,
      "backward_entropy": 0.02558465600013733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0087332725524902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026841580867767334,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17972310384114584,
      "backward_entropy": 0.025043728947639465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.135669469833374,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026880186051130295,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17967736721038818,
      "backward_entropy": 0.02498590648174286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8632936477661133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026918919757008553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17962988217671713,
      "backward_entropy": 0.024387313425540923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8228498697280884,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026956932619214058,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1795824964841207,
      "backward_entropy": 0.03106144964694977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7693872451782227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026994384825229645,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1795342763264974,
      "backward_entropy": 0.0241196870803833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8771986961364746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027031071484088898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17948593695958456,
      "backward_entropy": 0.02344116270542145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6719938516616821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027067387476563454,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.179436723391215,
      "backward_entropy": 0.023136526346206665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9694428443908691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027102814987301826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17938743034998575,
      "backward_entropy": 0.02284085601568222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4344925284385681,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02713838964700699,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1793361703554789,
      "backward_entropy": 0.023052211105823516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5135368704795837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027172621339559555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17928538719813028,
      "backward_entropy": 0.02226225882768631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42591142654418945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02720576338469982,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17923492193222046,
      "backward_entropy": 0.021990831196308135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6022087931632996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027237549424171448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1791853109995524,
      "backward_entropy": 0.02233406752347946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5713168978691101,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027268819510936737,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1791350245475769,
      "backward_entropy": 0.0214786097407341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6018718481063843,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027299439534544945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1790843407313029,
      "backward_entropy": 0.02189277410507202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6160253286361694,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027329541742801666,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1790330410003662,
      "backward_entropy": 0.02776625156402588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6078906655311584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027359455823898315,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1789806286493937,
      "backward_entropy": 0.02074737846851349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.711470901966095,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02738887071609497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17892752091089884,
      "backward_entropy": 0.027242407202720642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46749788522720337,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027418412268161774,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17887278397878012,
      "backward_entropy": 0.02698344886302948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.563926100730896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027447300031781197,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1788178284962972,
      "backward_entropy": 0.026729953289031983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6476898789405823,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02747570350766182,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17876187960306802,
      "backward_entropy": 0.02648114264011383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5890001058578491,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02750410884618759,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17870396375656128,
      "backward_entropy": 0.020475690066814423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3925292491912842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027532346546649933,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17864485581715903,
      "backward_entropy": 0.020285341143608093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5058119893074036,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027559539303183556,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17858572800954184,
      "backward_entropy": 0.019147083163261414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4169866144657135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027586275711655617,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17852568626403809,
      "backward_entropy": 0.025510457158088685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5102469325065613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02761232480406761,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17846540609995523,
      "backward_entropy": 0.018728810548782348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4279020130634308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027637982740998268,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1784040927886963,
      "backward_entropy": 0.018525663018226623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30695614218711853,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027663078159093857,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17834224303563437,
      "backward_entropy": 0.024841795861721038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36986106634140015,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027687156572937965,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17828071117401123,
      "backward_entropy": 0.024632643163204192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3632378578186035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027710624039173126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17821890115737915,
      "backward_entropy": 0.01795392483472824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24733448028564453,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02773362025618553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17815693219502768,
      "backward_entropy": 0.017774298787117004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36911439895629883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027755508199334145,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17809545993804932,
      "backward_entropy": 0.017603924870491026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26863259077072144,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027776923030614853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1780333916346232,
      "backward_entropy": 0.018704460561275484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32214197516441345,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027797600254416466,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1779716412226359,
      "backward_entropy": 0.023674149811267853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3133039176464081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027817852795124054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17790967226028442,
      "backward_entropy": 0.0171195387840271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24598252773284912,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027837682515382767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17784748474756876,
      "backward_entropy": 0.01696605533361435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3221748471260071,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02785675786435604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17778547604878744,
      "backward_entropy": 0.02316170632839203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2878347337245941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027875326573848724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17772249380747476,
      "backward_entropy": 0.016674748063087462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30695149302482605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027893412858247757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17765909433364868,
      "backward_entropy": 0.022846068441867828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22103647887706757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027911078184843063,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1775948405265808,
      "backward_entropy": 0.01639689952135086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3686958849430084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027928007766604424,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17753074566523233,
      "backward_entropy": 0.01626518666744232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2847568690776825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02794499695301056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17746508121490479,
      "backward_entropy": 0.016132400929927827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20430108904838562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02796163037419319,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17739880084991455,
      "backward_entropy": 0.017605246603488924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27110710740089417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02797764725983143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17733303705851236,
      "backward_entropy": 0.01587713211774826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28629133105278015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02799328602850437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17726647853851318,
      "backward_entropy": 0.01575460135936737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3248693346977234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02800881862640381,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17719934384028116,
      "backward_entropy": 0.01563268303871155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2260075807571411,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028024381026625633,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17713069915771484,
      "backward_entropy": 0.017253170907497405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.328376442193985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028039678931236267,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17706263065338135,
      "backward_entropy": 0.015389879047870637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19529660046100616,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02805517055094242,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1769931117693583,
      "backward_entropy": 0.02147863954305649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26906368136405945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028070081025362015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.176923930644989,
      "backward_entropy": 0.015150949358940125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22177504003047943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028085002675652504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17685421307881674,
      "backward_entropy": 0.015033841133117676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22026579082012177,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028099695220589638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1767848332722982,
      "backward_entropy": 0.014918787777423859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2864375710487366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028113946318626404,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17671491702397665,
      "backward_entropy": 0.01480696201324463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2798207998275757,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028128324076533318,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17664366960525513,
      "backward_entropy": 0.01667880415916443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12358617782592773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028142733499407768,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17657093207041422,
      "backward_entropy": 0.02075972706079483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21401666104793549,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028156539425253868,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17650059858957926,
      "backward_entropy": 0.016525182127952575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16998787224292755,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028170021250844002,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1764294703801473,
      "backward_entropy": 0.020538464188575745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2785661518573761,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02818312868475914,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1763590176900228,
      "backward_entropy": 0.016382405161857606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10513328015804291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028196603059768677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17628687620162964,
      "backward_entropy": 0.016309571266174317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2060694545507431,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02820901945233345,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17621570825576782,
      "backward_entropy": 0.020224694907665253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.183754563331604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02822127752006054,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17614362637201944,
      "backward_entropy": 0.020126621425151824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16415373980998993,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02823331393301487,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17607134580612183,
      "backward_entropy": 0.020030644536018372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18136417865753174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028245028108358383,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1759992241859436,
      "backward_entropy": 0.013777056336402893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2144714742898941,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028256336227059364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17592581113179526,
      "backward_entropy": 0.01368715763092041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18761253356933594,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028267625719308853,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1758506695429484,
      "backward_entropy": 0.01594369262456894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1366882026195526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028278958052396774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.175774614016215,
      "backward_entropy": 0.013506780564785003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13839013874530792,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028289392590522766,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.175697127978007,
      "backward_entropy": 0.01958805024623871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1618492156267166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02829926833510399,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17561904589335123,
      "backward_entropy": 0.013342180848121643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12572906911373138,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028309112414717674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17554086446762085,
      "backward_entropy": 0.019433753192424776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14761735498905182,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02831854484975338,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1754631201426188,
      "backward_entropy": 0.019360196590423585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08261249959468842,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02832772396504879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17538472016652426,
      "backward_entropy": 0.013110001385211945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1253705471754074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028335994109511375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17530715465545654,
      "backward_entropy": 0.015621642768383025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14745531976222992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028344081714749336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1752299666404724,
      "backward_entropy": 0.012973867356777191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10054688155651093,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028352078050374985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17515180508295694,
      "backward_entropy": 0.015552644431591035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19842150807380676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0283596683293581,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17507457733154297,
      "backward_entropy": 0.012843020260334015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.157985657453537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0283680260181427,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17499568065007529,
      "backward_entropy": 0.015483248233795165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13488589227199554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028376342728734016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17491487661997476,
      "backward_entropy": 0.012704277038574218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11304803937673569,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028384432196617126,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17483305931091309,
      "backward_entropy": 0.015410715341567993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13864681124687195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028392130509018898,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.174751083056132,
      "backward_entropy": 0.018792936205863954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09282901138067245,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028399672359228134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17466749747594199,
      "backward_entropy": 0.012506644427776336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11529487371444702,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02840687520802021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17458492517471313,
      "backward_entropy": 0.012444843351840974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08958731591701508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028414001688361168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1745014786720276,
      "backward_entropy": 0.01238371878862381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0973154678940773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02842053398489952,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1744176745414734,
      "backward_entropy": 0.012326578050851822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10807175934314728,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02842678874731064,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1743338704109192,
      "backward_entropy": 0.0185317724943161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08130314201116562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028432976454496384,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17424972852071127,
      "backward_entropy": 0.015216295421123505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07392982393503189,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028438886627554893,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17416679859161377,
      "backward_entropy": 0.01844167411327362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07754592597484589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028444422408938408,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17408502101898193,
      "backward_entropy": 0.012113945186138153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08379972726106644,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02844950556755066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17400328318277994,
      "backward_entropy": 0.01836302876472473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0882444754242897,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028454428538680077,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17392192284266153,
      "backward_entropy": 0.015143094956874848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08085592091083527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028459273278713226,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17384048302968344,
      "backward_entropy": 0.018291087448596956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07151754200458527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02846413664519787,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17376007636388144,
      "backward_entropy": 0.01825554221868515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07142941653728485,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02846875600516796,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1736802856127421,
      "backward_entropy": 0.015096955001354218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1055317372083664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02847311459481716,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17360079288482666,
      "backward_entropy": 0.011845947802066803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0703430250287056,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02847784012556076,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.173520028591156,
      "backward_entropy": 0.01815609633922577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07016368955373764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028482047840952873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1734383503595988,
      "backward_entropy": 0.011761001497507095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08436344563961029,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028486113995313644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1733571688334147,
      "backward_entropy": 0.018096165359020235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06383679062128067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028490260243415833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17327539126078287,
      "backward_entropy": 0.01168079674243927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07731994241476059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028493963181972504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1731931765874227,
      "backward_entropy": 0.018039505183696746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05057762190699577,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028497474268078804,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1731095314025879,
      "backward_entropy": 0.011606785655021667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06495308130979538,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02850079908967018,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17302809158960977,
      "backward_entropy": 0.01799021065235138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05629708990454674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028504131361842155,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17294728755950928,
      "backward_entropy": 0.015004083514213562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06433727592229843,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028507115319371223,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17286646366119385,
      "backward_entropy": 0.017945227026939393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06137995049357414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028510071337223053,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17278563976287842,
      "backward_entropy": 0.01792419105768204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050030533224344254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028513021767139435,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1727051337560018,
      "backward_entropy": 0.014990606904029846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06072116643190384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028515854850411415,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1726257006327311,
      "backward_entropy": 0.01788344979286194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04630204290151596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02851863205432892,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17254541317621866,
      "backward_entropy": 0.014982163906097412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06699071079492569,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028521325439214706,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1724666158358256,
      "backward_entropy": 0.017845290899276733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07201126962900162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028524210676550865,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17238680521647134,
      "backward_entropy": 0.017825189232826232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04317565634846687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028527552261948586,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17230629920959473,
      "backward_entropy": 0.017801856994628905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05553821846842766,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028530439361929893,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17222581307093301,
      "backward_entropy": 0.014957313239574433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028436491265892982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0285333264619112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17214498917261759,
      "backward_entropy": 0.01122015416622162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04978695139288902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028535662218928337,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1720660130182902,
      "backward_entropy": 0.017745546996593475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05043061450123787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028538240119814873,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17198834816614786,
      "backward_entropy": 0.017727944254875182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04121837764978409,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02854098379611969,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17191123962402344,
      "backward_entropy": 0.014937672019004821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050290849059820175,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028543513268232346,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17183438936869302,
      "backward_entropy": 0.014932683110237122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039246831089258194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028546005487442017,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1717564860979716,
      "backward_entropy": 0.011078983545303345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051754292100667953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028548426926136017,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1716796358426412,
      "backward_entropy": 0.014923605322837829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037784673273563385,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028551092371344566,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17160244782765707,
      "backward_entropy": 0.017640092968940736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03758326172828674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028553519397974014,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17152535915374756,
      "backward_entropy": 0.01491236239671707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.035367682576179504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02855570800602436,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17144811153411865,
      "backward_entropy": 0.01490938663482666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03902411088347435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028557466343045235,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17136994997660318,
      "backward_entropy": 0.010946657508611679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0344645157456398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02855920046567917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17129186789194742,
      "backward_entropy": 0.010923656076192856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027148794382810593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028560763224959373,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1712139050165812,
      "backward_entropy": 0.01090179681777954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036506347358226776,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02856210060417652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17113733291625977,
      "backward_entropy": 0.010881524533033371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040297556668519974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02856343239545822,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17106052239735922,
      "backward_entropy": 0.010861349105834962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03180200606584549,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028564972802996635,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1709835728009542,
      "backward_entropy": 0.01083991751074791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031252555549144745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02856655791401863,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17090771595637003,
      "backward_entropy": 0.017533670365810394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03481646627187729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02856805920600891,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17083211739857992,
      "backward_entropy": 0.01079750582575798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029426593333482742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028569689020514488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17075669765472412,
      "backward_entropy": 0.01751211881637573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02969169057905674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028571227565407753,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17068161567052206,
      "backward_entropy": 0.010754945874214172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034528810530900955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028572864830493927,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17060760656992593,
      "backward_entropy": 0.01492125391960144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03271179646253586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02857452630996704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17053250471750894,
      "backward_entropy": 0.01071203052997589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024993296712636948,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028576333075761795,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17045744260152182,
      "backward_entropy": 0.017465999722480773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02373833768069744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028578056022524834,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17038337389628092,
      "backward_entropy": 0.010668233036994934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0222539771348238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028579717501997948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17031051715215048,
      "backward_entropy": 0.010647246241569519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028554607182741165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028581243008375168,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17023861408233643,
      "backward_entropy": 0.010627277195453644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025641974061727524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028582818806171417,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1701661745707194,
      "backward_entropy": 0.010607024282217025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024002598598599434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028584405779838562,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17009385426839194,
      "backward_entropy": 0.014912256598472595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02284417115151882,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028586024418473244,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17002224922180176,
      "backward_entropy": 0.014910426735877991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02116444520652294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02858768403530121,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16995157798131308,
      "backward_entropy": 0.010546331107616425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020032884553074837,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028589220717549324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16988118489583334,
      "backward_entropy": 0.01052694022655487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020103659480810165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02859075367450714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1698120633761088,
      "backward_entropy": 0.010507722944021225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017890509217977524,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02859225496649742,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16974363724390665,
      "backward_entropy": 0.01735750287771225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017637688666582108,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028593603521585464,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16967574755350748,
      "backward_entropy": 0.0173484668135643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018521815538406372,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02859480306506157,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1696082353591919,
      "backward_entropy": 0.01734043061733246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017064087092876434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028596073389053345,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16954187552134195,
      "backward_entropy": 0.014901497960090637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022188549861311913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028597353026270866,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16947662830352783,
      "backward_entropy": 0.010419812053442001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01543969102203846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028598925098776817,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16941179831822714,
      "backward_entropy": 0.017313192784786224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015728069469332695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028600409626960754,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.169347882270813,
      "backward_entropy": 0.010383151471614838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015975771471858025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028601860627532005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1692848006884257,
      "backward_entropy": 0.01036548912525177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011762444861233234,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028603408485651016,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16922303040822348,
      "backward_entropy": 0.017283940315246583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01139547023922205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860487438738346,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16916324694951376,
      "backward_entropy": 0.010330172628164292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013332252390682697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860618755221367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1691047747929891,
      "backward_entropy": 0.01031397134065628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014677518978714943,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02860741689801216,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1690466602643331,
      "backward_entropy": 0.014877334237098694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01141512580215931,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028608644381165504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16898844639460245,
      "backward_entropy": 0.010282811522483826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014361186884343624,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02860983833670616,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1689316431681315,
      "backward_entropy": 0.017244678735733033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010895940475165844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0286110732704401,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16887464125951132,
      "backward_entropy": 0.014869508147239686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011508571915328503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861226163804531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16881879170735678,
      "backward_entropy": 0.01023741066455841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008907800540328026,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028613433241844177,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16876357793807983,
      "backward_entropy": 0.010222715139389039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012931928969919682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028614481911063194,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16870971520741782,
      "backward_entropy": 0.010208968818187714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010427062399685383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028615625575184822,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.168655792872111,
      "backward_entropy": 0.0172104611992836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014251001179218292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02861674875020981,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16860252618789673,
      "backward_entropy": 0.010180629789829254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011338149197399616,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028618106618523598,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1685489614804586,
      "backward_entropy": 0.010165228694677352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008494066074490547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02861952967941761,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16849583387374878,
      "backward_entropy": 0.017186747491359712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008926943875849247,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862081676721573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16844348112742105,
      "backward_entropy": 0.010134755074977875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008089245297014713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028622066602110863,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16839198271433511,
      "backward_entropy": 0.014837507903575898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008623462170362473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862318605184555,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16834098100662231,
      "backward_entropy": 0.010106761753559113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007802143692970276,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028624264523386955,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16829045613606772,
      "backward_entropy": 0.017158502340316774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008558404631912708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02862527221441269,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16824058691660562,
      "backward_entropy": 0.017152702808380126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0074179149232804775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028626274317502975,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16819103558858237,
      "backward_entropy": 0.017146891355514525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007639051415026188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02862720377743244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16814198096593222,
      "backward_entropy": 0.010056189447641372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009814754128456116,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028628095984458923,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16809330383936563,
      "backward_entropy": 0.017136476933956146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008940181694924831,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028629189357161522,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.168044646581014,
      "backward_entropy": 0.014818070828914643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008182341232895851,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02863038331270218,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16799529393513998,
      "backward_entropy": 0.017122459411621094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008381049148738384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02863163687288761,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16794578234354654,
      "backward_entropy": 0.01711462438106537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005702522583305836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028632957488298416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1678959528605143,
      "backward_entropy": 0.009990404546260833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005752569530159235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02863413095474243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1678466796875,
      "backward_entropy": 0.009977350383996964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005888807587325573,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02863520197570324,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16779800256093344,
      "backward_entropy": 0.017092227935791016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005432161968201399,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028636204078793526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16774978240331015,
      "backward_entropy": 0.01708607077598572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005775748752057552,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286371111869812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16770201921463013,
      "backward_entropy": 0.017080560326576233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003894949099048972,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02863798849284649,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16765461365381876,
      "backward_entropy": 0.014787495136260986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031605027616024017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028638677671551704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16760818163553873,
      "backward_entropy": 0.009921051561832428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004738893359899521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02863915264606476,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16756304105122885,
      "backward_entropy": 0.009912604093551635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003788732225075364,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028639663010835648,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16751891374588013,
      "backward_entropy": 0.014786970615386964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005320698022842407,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02864008955657482,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16747577985127768,
      "backward_entropy": 0.017064708471298217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003918468486517668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028640571981668472,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16743254661560059,
      "backward_entropy": 0.009887981414794921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004445614758878946,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286409892141819,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16738990942637125,
      "backward_entropy": 0.017060494422912596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00380468787625432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028641417622566223,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16734755039215088,
      "backward_entropy": 0.009872457385063172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003936729393899441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02864181250333786,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16730580727259317,
      "backward_entropy": 0.017056703567504883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036896136589348316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028642233461141586,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1672647794087728,
      "backward_entropy": 0.009857430309057235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003293671878054738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028642648831009865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1672243277231852,
      "backward_entropy": 0.00985003188252449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037883580662310123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02864300273358822,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16718433300654092,
      "backward_entropy": 0.017051298916339875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028940089978277683,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02864336408674717,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16714443763097128,
      "backward_entropy": 0.014790992438793182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002688327804207802,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028643684461712837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16710543632507324,
      "backward_entropy": 0.009829364717006683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029124452266842127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864394150674343,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16706717014312744,
      "backward_entropy": 0.009823182225227356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003078285837545991,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864418551325798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16702951987584433,
      "backward_entropy": 0.009817147254943847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002750743180513382,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028644463047385216,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16699244578679404,
      "backward_entropy": 0.017045576870441437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024815292563289404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028644755482673645,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1669561266899109,
      "backward_entropy": 0.009804826974868775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029869682621210814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028645042330026627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16692070166269937,
      "backward_entropy": 0.0097988061606884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029093013145029545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02864537015557289,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16688543558120728,
      "backward_entropy": 0.014796891808509826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022787821944803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028645729646086693,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1668502688407898,
      "backward_entropy": 0.009786289930343629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002214648062363267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028646070510149002,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16681577761967978,
      "backward_entropy": 0.009780151396989822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002224372234195471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028646426275372505,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16678224007288614,
      "backward_entropy": 0.009774032235145568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017833352321758866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02864675223827362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1667489210764567,
      "backward_entropy": 0.017035779356956483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020542708225548267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028647027909755707,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1667164166768392,
      "backward_entropy": 0.009762632846832275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020513515919446945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02864728309214115,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16668415069580078,
      "backward_entropy": 0.014797978103160858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002834754064679146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028647543862462044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16665228207906088,
      "backward_entropy": 0.009751985222101212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013582662213593721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028647946193814278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16662033398946127,
      "backward_entropy": 0.017030444741249085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015311554307118058,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028648285195231438,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16658949851989746,
      "backward_entropy": 0.01479763388633728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023440627846866846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864859625697136,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1665594776471456,
      "backward_entropy": 0.009734885394573211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001850668340921402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02864900231361389,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16652941703796387,
      "backward_entropy": 0.009728990495204926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019109903369098902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028649430721998215,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16649969418843588,
      "backward_entropy": 0.009723034501075745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016701536951586604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028649888932704926,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16647009054819742,
      "backward_entropy": 0.009716931730508804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015245332615450025,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02865036576986313,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16644100348154703,
      "backward_entropy": 0.01701745092868805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012999160680919886,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028650842607021332,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16641247272491455,
      "backward_entropy": 0.01479129195213318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011621785815805197,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028651289641857147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16638455788294473,
      "backward_entropy": 0.009698922932147979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016403899062424898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865169569849968,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16635735829671225,
      "backward_entropy": 0.009693437814712524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001235291245393455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028652161359786987,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16633041699727377,
      "backward_entropy": 0.01700727790594101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008267443627119064,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028652606531977654,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1663039227326711,
      "backward_entropy": 0.014785565435886383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012205202365294099,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028652967885136604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1662782629330953,
      "backward_entropy": 0.017002852261066438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001066972385160625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028653351590037346,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16625314950942993,
      "backward_entropy": 0.017000833153724672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001003002980723977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865372598171234,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16622855265935263,
      "backward_entropy": 0.009666836261749268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011768873082473874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02865409292280674,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16620458165804544,
      "backward_entropy": 0.01699700504541397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010406532092019916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865448407828808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16618076960245767,
      "backward_entropy": 0.00965695157647133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009441968286409974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865488827228546,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1661574343840281,
      "backward_entropy": 0.009651914238929749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010250789346173406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028655270114541054,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16613427797953287,
      "backward_entropy": 0.014776532351970673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000849363103043288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865567058324814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16611140966415405,
      "backward_entropy": 0.009642145037651062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008816272020339966,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865605056285858,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16608884930610657,
      "backward_entropy": 0.00963737815618515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007892173016443849,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865643799304962,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16606669624646506,
      "backward_entropy": 0.009632618725299835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007815257413312793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028656823560595512,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16604509949684143,
      "backward_entropy": 0.014770537614822388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007828784873709083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028657197952270508,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1660237709681193,
      "backward_entropy": 0.009623073786497117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000401467812480405,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028657574206590652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16600273052851358,
      "backward_entropy": 0.009618270397186279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005597775452770293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028657859191298485,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16598202784856161,
      "backward_entropy": 0.016976195573806762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000398287083953619,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02865811437368393,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16596152385075888,
      "backward_entropy": 0.01697496175765991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006779646500945091,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02865830436348915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16594147682189941,
      "backward_entropy": 0.014765676856040955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006768581224605441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865852229297161,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16592146952946982,
      "backward_entropy": 0.009602805227041244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005356046021915972,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028658773750066757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16590155164400736,
      "backward_entropy": 0.01697210669517517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005014464841224253,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0286590326577425,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1658820907274882,
      "backward_entropy": 0.016970896720886232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006201041978783906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028659282252192497,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16586293776830038,
      "backward_entropy": 0.016969756782054903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005019553354941308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02865956723690033,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1658438245455424,
      "backward_entropy": 0.009587189555168152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003683747781906277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028659842908382416,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1658247709274292,
      "backward_entropy": 0.016966843605041505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00041873700683936477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028660079464316368,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16580607493718466,
      "backward_entropy": 0.014759571850299835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004157109360676259,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028660306707024574,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1657876968383789,
      "backward_entropy": 0.009576085954904556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039832800393924117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866053394973278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16576963663101196,
      "backward_entropy": 0.016963402926921844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003197662881575525,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028660759329795837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1657518744468689,
      "backward_entropy": 0.00956912487745285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003828534681815654,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028660958632826805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16573448975880942,
      "backward_entropy": 0.009565860033035278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003734299389179796,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866116538643837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16571730375289917,
      "backward_entropy": 0.009562601149082185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003634059976320714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028661387041211128,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16570043563842773,
      "backward_entropy": 0.014755314588546753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035357705201022327,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028661619871854782,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16568374633789062,
      "backward_entropy": 0.016957825422286986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034926930675283074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866186946630478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16566736499468485,
      "backward_entropy": 0.016956430673599244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003338649112265557,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028662139549851418,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1656512220700582,
      "backward_entropy": 0.016954872012138366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027866006712429225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02866242825984955,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16563533743222555,
      "backward_entropy": 0.014750823378562927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022414578415919095,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028662709519267082,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16561967134475708,
      "backward_entropy": 0.016951511800289153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030465933377854526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028662964701652527,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1656043529510498,
      "backward_entropy": 0.016949978470802308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023675714328419417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866324596107006,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16558921337127686,
      "backward_entropy": 0.016948272287845612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002244428760604933,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028663527220487595,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16557449102401733,
      "backward_entropy": 0.009531857073307037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002252814592793584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866380661725998,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1655601461728414,
      "backward_entropy": 0.009528557956218719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013232172932475805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028664086014032364,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1655460794766744,
      "backward_entropy": 0.009525241702795029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017593192751519382,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866431511938572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16553242007891336,
      "backward_entropy": 0.009522304683923722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001565842831041664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866453304886818,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1655190388361613,
      "backward_entropy": 0.00951947197318077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001547384017612785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028664734214544296,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16550598541895548,
      "backward_entropy": 0.009516780078411103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016553033492527902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028664924204349518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16549324989318848,
      "backward_entropy": 0.009514181315898896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013368988584261388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028665119782090187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16548080245653787,
      "backward_entropy": 0.009511569142341613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001297214039368555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028665298596024513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1654685934384664,
      "backward_entropy": 0.016936378180980684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.554562711855397e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028665468096733093,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16545671224594116,
      "backward_entropy": 0.016935443878173827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010980270599247888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028665604069828987,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16544514894485474,
      "backward_entropy": 0.009504573792219162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011456990614533424,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028665730729699135,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16543390353520712,
      "backward_entropy": 0.016934123635292054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.961807907326147e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028665855526924133,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16542289654413858,
      "backward_entropy": 0.01693350225687027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.413014438701794e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866596169769764,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16541218757629395,
      "backward_entropy": 0.009498657286167144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.51742913457565e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028666051104664803,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16540175676345825,
      "backward_entropy": 0.01693262755870819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011077326053055003,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028666142374277115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16539162397384644,
      "backward_entropy": 0.016932250559329988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469533349853009e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866625227034092,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16538159052530924,
      "backward_entropy": 0.009493391960859299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2431005315156654e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028666362166404724,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16537185509999594,
      "backward_entropy": 0.016931140422821046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596037226496264e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028666440397500992,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16536245743433634,
      "backward_entropy": 0.009490056335926056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.816750828875229e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028666498139500618,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16535335779190063,
      "backward_entropy": 0.016930675506591795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.720649253111333e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028666555881500244,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16534449656804404,
      "backward_entropy": 0.014734233915805816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.644176028203219e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866661734879017,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1653358737627665,
      "backward_entropy": 0.00948592573404312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.655151496990584e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866668440401554,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16532742977142334,
      "backward_entropy": 0.016930092871189118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.400386362452991e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866673655807972,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16531931360562643,
      "backward_entropy": 0.009483275562524795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.050861338735558e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028666788712143898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1653114159901937,
      "backward_entropy": 0.00948202908039093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.35684560216032e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028666852042078972,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16530370712280273,
      "backward_entropy": 0.016929656267166138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7402030759258196e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866690792143345,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16529623667399088,
      "backward_entropy": 0.009479540586471557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.271050784154795e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028666967526078224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1652889847755432,
      "backward_entropy": 0.009478330612182617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2108080378966406e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866702526807785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16528191169102988,
      "backward_entropy": 0.00947716236114502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.319002982811071e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028667084872722626,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16527504722277322,
      "backward_entropy": 0.01692904978990555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5619596019387245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866715006530285,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1652683218320211,
      "backward_entropy": 0.009474824368953704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.969248427893035e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028667213395237923,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16526179512341818,
      "backward_entropy": 0.016928589344024657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.853039222827647e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028667284175753593,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16525538762410483,
      "backward_entropy": 0.01692829728126526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8183249014546163e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028667347505688667,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1652491887410482,
      "backward_entropy": 0.016928048431873323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.108616147073917e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028667407110333443,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16524317860603333,
      "backward_entropy": 0.016927841305732726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4035991373239085e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028667468577623367,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1652373472849528,
      "backward_entropy": 0.009469318389892577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0605255485861562e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028667522594332695,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1652317444483439,
      "backward_entropy": 0.016927489638328554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.976616113097407e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028667565435171127,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1652263601620992,
      "backward_entropy": 0.00946742743253708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3885562768555246e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028667602688074112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16522113482157388,
      "backward_entropy": 0.009466592222452164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.562974623288028e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028667643666267395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16521604855855307,
      "backward_entropy": 0.009465744346380233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6692374629201367e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028667692095041275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16521106163660684,
      "backward_entropy": 0.00946488007903099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9225461073801853e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028667733073234558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16520626346270242,
      "backward_entropy": 0.016927191615104677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1047977497801185e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866777591407299,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16520159443219504,
      "backward_entropy": 0.016927115619182587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6722173313610256e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866782620549202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16519700487454733,
      "backward_entropy": 0.0169269859790802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5857338439673185e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866787649691105,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16519255439440408,
      "backward_entropy": 0.009461603313684463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.28556866911822e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02866792492568493,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16518821318944296,
      "backward_entropy": 0.014730075001716613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5126105608942453e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866796776652336,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1651840309302012,
      "backward_entropy": 0.009460036456584931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.317370515607763e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668014332652092,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16517996788024902,
      "backward_entropy": 0.01692642569541931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.76394130702829e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668059036135674,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.165175994237264,
      "backward_entropy": 0.014729416370391846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0110170478583314e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668096289038658,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16517217953999838,
      "backward_entropy": 0.009457847476005555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0114963515661657e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668129816651344,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16516852378845215,
      "backward_entropy": 0.014729101955890656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0625079994497355e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866816148161888,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16516493757565817,
      "backward_entropy": 0.009456589072942733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.07992034626659e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668195009231567,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16516146063804626,
      "backward_entropy": 0.009456006437540054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.818505193630699e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668226674199104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16515807310740152,
      "backward_entropy": 0.016926051676273347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5930925049760845e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866825833916664,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16515480478604636,
      "backward_entropy": 0.016925987601280213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.013865797489416e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866828814148903,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16515161593755087,
      "backward_entropy": 0.00945424884557724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.765825102978852e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668314218521118,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16514853636423746,
      "backward_entropy": 0.009453745931386948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.766721526219044e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668340295553207,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16514557600021362,
      "backward_entropy": 0.009453214704990387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.953681011305889e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668368235230446,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16514267524083456,
      "backward_entropy": 0.016925865411758424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0580501920194365e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668392449617386,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16513985395431519,
      "backward_entropy": 0.01692584604024887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.910002412041649e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668412938714027,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1651371717453003,
      "backward_entropy": 0.016925860941410065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.726107817987213e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668439015746117,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16513450940450033,
      "backward_entropy": 0.014727646112442016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.825935320695862e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668461367487907,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1651319662729899,
      "backward_entropy": 0.016925798356533052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.317067123338347e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668483719229698,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16512949268023172,
      "backward_entropy": 0.016925798356533052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.581740085995989e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02866850420832634,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16512707869211832,
      "backward_entropy": 0.014727318286895752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.772202717300388e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866852656006813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16512474417686462,
      "backward_entropy": 0.00944959968328476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6834223919868236e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668547049164772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1651224891344706,
      "backward_entropy": 0.009449218213558198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.330859271954978e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668565675616264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16512028376261392,
      "backward_entropy": 0.009448830783367158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3024440451990813e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668584302067757,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16511817773183188,
      "backward_entropy": 0.016925744712352753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7708631478162715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286685973405838,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16511614123980203,
      "backward_entropy": 0.009448152035474777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.49130573340517e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668608516454697,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16511417428652445,
      "backward_entropy": 0.009447860717773437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7213366138312267e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866862341761589,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16511225700378418,
      "backward_entropy": 0.009447531402111053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4809432943584397e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668638318777084,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16511040925979614,
      "backward_entropy": 0.014726673066616059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.222889861513977e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668653219938278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16510858138402304,
      "backward_entropy": 0.0169258713722229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4316930193890585e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668666258454323,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16510684291521707,
      "backward_entropy": 0.009446626901626587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7576933259988436e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668681159615517,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16510514418284097,
      "backward_entropy": 0.009446322172880172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1402806851256173e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866869419813156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1651034951210022,
      "backward_entropy": 0.016925890743732453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.028461494774092e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668709099292755,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1651019056638082,
      "backward_entropy": 0.009445762634277344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5230434655677527e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866872400045395,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16510034600893655,
      "backward_entropy": 0.00944550484418869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4226108078219113e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668738901615143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16509881615638733,
      "backward_entropy": 0.014726170897483825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3634859215017059e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668751940131187,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16509735584259033,
      "backward_entropy": 0.009444976598024369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5455983657375327e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668764978647232,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16509594519933066,
      "backward_entropy": 0.009444736689329148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.451169850952283e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668778017163277,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16509457429250082,
      "backward_entropy": 0.016925798356533052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840500870770484e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866879291832447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16509324312210083,
      "backward_entropy": 0.009444227069616317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0729758059824235e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668804094195366,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1650919516881307,
      "backward_entropy": 0.014725850522518158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0020391982834553e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668813407421112,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16509071985880533,
      "backward_entropy": 0.009443816542625428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.043559430210735e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668822720646858,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16508950789769491,
      "backward_entropy": 0.014725756645202637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.546087772425381e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668832033872604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16508835554122925,
      "backward_entropy": 0.016925783455371858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.18763021218183e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286688394844532,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16508724292119345,
      "backward_entropy": 0.009443250298500062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.313617740896007e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668848797678947,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16508615016937256,
      "backward_entropy": 0.014725647866725922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.892551252552948e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668858110904694,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16508508721987405,
      "backward_entropy": 0.016925793886184693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.603301585528243e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866886742413044,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16508406400680542,
      "backward_entropy": 0.009442697465419769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.651808348578925e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668876737356186,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16508307059605917,
      "backward_entropy": 0.009442519396543503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.036205834585417e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668886050581932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16508211692174277,
      "backward_entropy": 0.0169257789850235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.736634420827613e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866889350116253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650812029838562,
      "backward_entropy": 0.009442216157913208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7461031726925285e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668900951743126,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16508029898007712,
      "backward_entropy": 0.009442063421010971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.460718230347993e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668908402323723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16507946451505026,
      "backward_entropy": 0.016925789415836334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.956608788437734e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866891399025917,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16507862011591592,
      "backward_entropy": 0.00944179594516754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.836709308619902e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668921440839767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.165077805519104,
      "backward_entropy": 0.00944163128733635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.498519044522254e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028668930754065514,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.165077010790507,
      "backward_entropy": 0.01692577004432678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.308074099095393e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866894192993641,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650762359301249,
      "backward_entropy": 0.016925744712352753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.189234689671139e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668951243162155,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650755008061727,
      "backward_entropy": 0.009441182762384415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3117029829554667e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286689605563879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16507476568222046,
      "backward_entropy": 0.009441044926643372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8440177857191884e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668969869613647,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1650740603605906,
      "backward_entropy": 0.014725029468536377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4845931534400734e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028668977320194244,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16507341464360556,
      "backward_entropy": 0.009440795332193375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.301512947473384e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866898477077484,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16507275899251303,
      "backward_entropy": 0.016925618052482605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3430156659287604e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668992221355438,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1650721232096354,
      "backward_entropy": 0.01472487598657608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0680064949374355e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028668999671936035,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1650715172290802,
      "backward_entropy": 0.014724841713905335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7287727871462266e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669007122516632,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650709311167399,
      "backward_entropy": 0.009440319985151291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.705184473621557e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866901457309723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16507036487261453,
      "backward_entropy": 0.016925525665283204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.796790201069598e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028669020161032677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1650698184967041,
      "backward_entropy": 0.0147247314453125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.471359780680359e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669025748968124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506929198900858,
      "backward_entropy": 0.009440003335475922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6730525942421082e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669031336903572,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506877541542053,
      "backward_entropy": 0.009439902752637864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.222722971760959e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866903692483902,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506828864415488,
      "backward_entropy": 0.009439808875322342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1829440893507126e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028669040650129318,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16506781180699667,
      "backward_entropy": 0.01692548245191574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4926922631275374e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669044375419617,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506735483805338,
      "backward_entropy": 0.009439658373594284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0311843112731367e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028669048100709915,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16506690780321756,
      "backward_entropy": 0.014724570512771606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0720735588165553e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669051826000214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506648063659668,
      "backward_entropy": 0.009439489245414734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.884424656547708e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669055551290512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650660733381907,
      "backward_entropy": 0.009439433366060257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.887185032335765e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866905927658081,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650656759738922,
      "backward_entropy": 0.016925467550754546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.740187951161715e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866906300187111,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506528854370117,
      "backward_entropy": 0.009439300745725632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.824122943451584e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028669066727161407,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16506491104761759,
      "backward_entropy": 0.014724475145339967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.281843039663727e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669070452451706,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506455341974893,
      "backward_entropy": 0.009439149498939514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.701370836026399e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669074177742004,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506419579188028,
      "backward_entropy": 0.009439095854759216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.732769992050635e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669077903032303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506386796633402,
      "backward_entropy": 0.009439022839069366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.936669822403928e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286690816283226,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506354014078775,
      "backward_entropy": 0.009438975155353546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.697653821494896e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0286690853536129,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506322224934897,
      "backward_entropy": 0.009438909590244293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3528920912194735e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866908721625805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650629242261251,
      "backward_entropy": 0.00943886935710907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0988880673230597e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028669089078903198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16506263613700867,
      "backward_entropy": 0.016925410926342012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.395615960106625e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028669090941548347,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16506236791610718,
      "backward_entropy": 0.014724342525005341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1941202510997755e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028669092804193497,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16506207982699075,
      "backward_entropy": 0.01472431719303131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.400282804795097e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028669094666838646,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650618314743042,
      "backward_entropy": 0.016925419867038726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.294030648248736e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669096529483795,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506157318751016,
      "backward_entropy": 0.009438645839691163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.013021299125285e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669098392128944,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506133476893106,
      "backward_entropy": 0.009438588470220565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6777778217024206e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028669100254774094,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16506109635035196,
      "backward_entropy": 0.016925415396690367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6704883637762578e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028669102117419243,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650608777999878,
      "backward_entropy": 0.00943852886557579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.850031239314376e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028669103980064392,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16506065924962363,
      "backward_entropy": 0.016925419867038726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2524618614738756e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866910584270954,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16506046056747437,
      "backward_entropy": 0.009438452124595643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1147545936628376e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866910770535469,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650602420171102,
      "backward_entropy": 0.016925424337387085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7456216028222116e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866910956799984,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16506006320317587,
      "backward_entropy": 0.01692543029785156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6273702385660727e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1650598645210266,
      "backward_entropy": 0.009438355267047883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4863410058296722e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505970557530722,
      "backward_entropy": 0.00943833366036415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6325515161952353e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650595168272654,
      "backward_entropy": 0.016925467550754546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.341848587799177e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505935788154602,
      "backward_entropy": 0.009438296407461166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4678128934519918e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16505920886993408,
      "backward_entropy": 0.01692548245191574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2459850040613674e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650590499242147,
      "backward_entropy": 0.0169254869222641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0889777968259295e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16505889097849527,
      "backward_entropy": 0.016925497353076933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1603496830048243e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505877176920572,
      "backward_entropy": 0.009438206255435944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.624766678622109e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16505863269170126,
      "backward_entropy": 0.01692550629377365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.534204536976176e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16505849361419678,
      "backward_entropy": 0.01692550629377365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.152255759341642e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505837440490723,
      "backward_entropy": 0.009438135474920274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.208886015381722e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505825519561768,
      "backward_entropy": 0.009438123553991318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9919784689554945e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505813598632812,
      "backward_entropy": 0.009438112378120422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.988283646729542e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505801677703857,
      "backward_entropy": 0.00943809449672699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.472351626347518e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16505791743596396,
      "backward_entropy": 0.014724193513393402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.604768205103028e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1650578180948893,
      "backward_entropy": 0.01692556291818619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.769400956978643e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16505770881970724,
      "backward_entropy": 0.016925568878650665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.838234701765032e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16505761941274008,
      "backward_entropy": 0.009438029676675796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.617675131157739e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02866911143064499,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16505752007166544,
      "backward_entropy": 0.014724189043045044,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 8.986474837691105e-07,
    "avg_log_Z": 0.028668923862278463,
    "success_rate": 1.0,
    "avg_reward": 43.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.17,
      "1": 0.32,
      "2": 0.51
    },
    "avg_forward_entropy": 0.165079564054807,
    "avg_backward_entropy": 0.012734727971255782,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}