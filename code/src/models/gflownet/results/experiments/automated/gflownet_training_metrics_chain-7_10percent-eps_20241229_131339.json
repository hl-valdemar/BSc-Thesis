{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901942525591169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.517385005950928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683104515075684,
      "backward_entropy": 0.09901678562164307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8391265869140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684163987636566,
      "backward_entropy": 0.09902101755142212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.837691307067871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00020004634279757738,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685107231140137,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010419845581055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003001081640832126,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13686007261276245,
      "backward_entropy": 0.09902100903647286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.83506965637207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00040020805317908525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13687001168727875,
      "backward_entropy": 0.0990200298173087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.486332893371582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005002935649827123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.136879563331604,
      "backward_entropy": 0.09902088982718331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.987447738647461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006005392642691731,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688582181930542,
      "backward_entropy": 0.09902075358799525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.485538482666016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0007010105764493346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688898086547852,
      "backward_entropy": 0.09902053219931466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.81167221069336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008015179191716015,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368904709815979,
      "backward_entropy": 0.09902020863124303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.734638214111328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009021430159918964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368895173072815,
      "backward_entropy": 0.09901976585388184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.657337188720703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001002827426418662,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368875503540039,
      "backward_entropy": 0.09900157792227608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73244571685791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001103525864891708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13688544929027557,
      "backward_entropy": 0.09901845455169678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731178283691406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012042628368362784,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13688251376152039,
      "backward_entropy": 0.09902102606637138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.227581977844238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013050278648734093,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368788182735443,
      "backward_entropy": 0.09901651314326695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.798351287841797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014059612294659019,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13687440752983093,
      "backward_entropy": 0.09901530402047294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.222145080566406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0015072048408910632,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1368691325187683,
      "backward_entropy": 0.09901391608374459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.802104949951172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016085200477391481,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13686338067054749,
      "backward_entropy": 0.09902044704982213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.370479583740234,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017097677337005734,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13685673475265503,
      "backward_entropy": 0.09897607564926147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.213228225708008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018111453391611576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684900104999542,
      "backward_entropy": 0.09900849206107003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.797314643859863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0019125606631860137,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368410587310791,
      "backward_entropy": 0.0990189824785505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.374021530151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0020138761028647423,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13683250546455383,
      "backward_entropy": 0.09896023784364973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.43639850616455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0021152780391275883,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13682390749454498,
      "backward_entropy": 0.0990173305783953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.637022972106934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022168077994138002,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13681401312351227,
      "backward_entropy": 0.09899778025490898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.914985656738281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002318131737411022,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136804461479187,
      "backward_entropy": 0.09894115584237236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.31564712524414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002419753698632121,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13679377734661102,
      "backward_entropy": 0.09901365212031774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.346298217773438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025217540096491575,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13678240776062012,
      "backward_entropy": 0.09892643349511283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.86903190612793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0026237417478114367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367703527212143,
      "backward_entropy": 0.09901033129010882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261608123779297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002725514816120267,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367587000131607,
      "backward_entropy": 0.09900837285178048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.148283958435059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002827259711921215,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367466300725937,
      "backward_entropy": 0.09900619302477155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.490072250366211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002928545232862234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13673555850982666,
      "backward_entropy": 0.09896760327475411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.2255220413208,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030299776699393988,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136723130941391,
      "backward_entropy": 0.09900110108511788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.642223358154297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0031310205813497305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13671167194843292,
      "backward_entropy": 0.0989981974874224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24516487121582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0032322874758392572,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13669908046722412,
      "backward_entropy": 0.09894859790802002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.850613594055176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033336086198687553,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13668571412563324,
      "backward_entropy": 0.09899157285690308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.709494590759277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003434803569689393,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13667230308055878,
      "backward_entropy": 0.09898783479418073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.174639701843262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0035362360067665577,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13665783405303955,
      "backward_entropy": 0.09898381573813302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.376784324645996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003638019785284996,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1366426944732666,
      "backward_entropy": 0.09880948066711426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.697707176208496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037394207902252674,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13662828505039215,
      "backward_entropy": 0.09890729188919067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.150440216064453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038410231936722994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13661295175552368,
      "backward_entropy": 0.09897008963993617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.534504890441895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003942574840039015,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365974247455597,
      "backward_entropy": 0.09876493896756854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.598430156707764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00404422078281641,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365813910961151,
      "backward_entropy": 0.09874866689954485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.601154327392578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004145121201872826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13656798005104065,
      "backward_entropy": 0.09886483635221209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.291828155517578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004245785530656576,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13655537366867065,
      "backward_entropy": 0.09885290690830775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.29011344909668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004346134606748819,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13654369115829468,
      "backward_entropy": 0.09869684491838727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.287178039550781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004446627106517553,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13653135299682617,
      "backward_entropy": 0.09882731097085136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.904544353485107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004547244403511286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365184485912323,
      "backward_entropy": 0.09881346566336495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12801456451416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004647394642233849,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1365070790052414,
      "backward_entropy": 0.09879919460841588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.660879135131836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004747624509036541,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13649551570415497,
      "backward_entropy": 0.09861728123256139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.282543182373047,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004848189186304808,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1364825963973999,
      "backward_entropy": 0.09859543187277657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.738452911376953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004948436748236418,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364707052707672,
      "backward_entropy": 0.09875190258026123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.584115028381348,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005048597697168589,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136459082365036,
      "backward_entropy": 0.09854916163853236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.03798770904541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005148594733327627,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364482045173645,
      "backward_entropy": 0.09887339387621198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80704402923584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005248673725873232,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1364368498325348,
      "backward_entropy": 0.09869815622057233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.502246856689453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00534872617572546,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13642549514770508,
      "backward_entropy": 0.09847300393240792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.86314868927002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005448580253869295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13641512393951416,
      "backward_entropy": 0.09884086677006312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.800448417663574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005548911169171333,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13640281558036804,
      "backward_entropy": 0.09841746091842651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.628859519958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0056491512805223465,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363908350467682,
      "backward_entropy": 0.0986148544720241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.171417236328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0057496922090649605,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13637793064117432,
      "backward_entropy": 0.09836031709398542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.393693923950195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005850300192832947,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13636460900306702,
      "backward_entropy": 0.09833104269845146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.788049697875977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0059510646387934685,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13635049760341644,
      "backward_entropy": 0.09830081462860107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.859869956970215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006051679607480764,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13633695244789124,
      "backward_entropy": 0.09826945407049996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03286075592041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006152204237878323,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13632361590862274,
      "backward_entropy": 0.09874681064060756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.001662254333496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006252258084714413,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.136312335729599,
      "backward_entropy": 0.09820338657924108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.597885131835938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006352338008582592,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13630099594593048,
      "backward_entropy": 0.09871527126857213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.144280433654785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00645276065915823,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362878531217575,
      "backward_entropy": 0.0984069790158953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.766864776611328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0065532526932656765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362742930650711,
      "backward_entropy": 0.09837690421513148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.211507797241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006653615273535252,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362614929676056,
      "backward_entropy": 0.09805818114961896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.392525672912598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006754095666110516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13624794781208038,
      "backward_entropy": 0.0983137914112636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.575135231018066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006854288745671511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1362355351448059,
      "backward_entropy": 0.09828082152775355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.682780265808105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006954804994165897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362215131521225,
      "backward_entropy": 0.09793681757790702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.301119804382324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007055171765387058,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13620805740356445,
      "backward_entropy": 0.09821466037205287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41748046875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007155175320804119,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361963152885437,
      "backward_entropy": 0.09856688124792916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261653900146484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0072554657235741615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136182963848114,
      "backward_entropy": 0.0985454831804548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.299246788024902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0073559177108109,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13616864383220673,
      "backward_entropy": 0.09852339540209089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.447279930114746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007456027902662754,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13615593314170837,
      "backward_entropy": 0.09770991121019636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.879189491271973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0075559248216450214,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13614419102668762,
      "backward_entropy": 0.09766049044472831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.259824752807617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007655831053853035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13613232970237732,
      "backward_entropy": 0.09798875876835414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.653867721557617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007754914462566376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13612481951713562,
      "backward_entropy": 0.09794691630772182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.158979415893555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007853995077311993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1361166536808014,
      "backward_entropy": 0.09790364333561488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.954598426818848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007953320629894733,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13610711693763733,
      "backward_entropy": 0.097858726978302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.224729537963867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008053254336118698,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1360943764448166,
      "backward_entropy": 0.09739371708461217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.777593612670898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008153380826115608,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13608045876026154,
      "backward_entropy": 0.09733773980821882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.331404685974121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008253436535596848,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360667198896408,
      "backward_entropy": 0.09829303196498326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.326862335205078,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008353187702596188,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13605454564094543,
      "backward_entropy": 0.09722151926585607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.977145195007324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00845266506075859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1360437572002411,
      "backward_entropy": 0.09761033739362444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.895816802978516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008552239276468754,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13603225350379944,
      "backward_entropy": 0.09709984915597099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.387703895568848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008651850745081902,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13602033257484436,
      "backward_entropy": 0.09703682150159564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.232809066772461,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008751245215535164,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13600949943065643,
      "backward_entropy": 0.0974435806274414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.241365432739258,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00885084643959999,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359972357749939,
      "backward_entropy": 0.09690430334636144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.94666862487793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008950670249760151,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1359839290380478,
      "backward_entropy": 0.09807132823126656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.293522357940674,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009050541557371616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13597071170806885,
      "backward_entropy": 0.09726125853402275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.933426856994629,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009149610064923763,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13596200942993164,
      "backward_entropy": 0.09668304239000593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.703285217285156,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009248805232346058,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.135952427983284,
      "backward_entropy": 0.09660405772072929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.633770942687988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009347467683255672,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359454244375229,
      "backward_entropy": 0.0970693826675415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.913200378417969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00944614876061678,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13593816757202148,
      "backward_entropy": 0.09788622174944196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.569364547729492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009544992819428444,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13592982292175293,
      "backward_entropy": 0.09693296466554914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.39143180847168,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00964383129030466,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13592155277729034,
      "backward_entropy": 0.09780452932630267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.830267906188965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009743059054017067,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1359107941389084,
      "backward_entropy": 0.09678838934217181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314838409423828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00984183605760336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13590267300605774,
      "backward_entropy": 0.09671373026711601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.002824783325195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00994045753031969,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13589529693126678,
      "backward_entropy": 0.09767327989850726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.994118690490723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010039285756647587,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13588634133338928,
      "backward_entropy": 0.09655836650303432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.521745681762695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010138295590877533,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13587595522403717,
      "backward_entropy": 0.09647694655827113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.772723197937012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010236716829240322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358691304922104,
      "backward_entropy": 0.09639476026807513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.508598327636719,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010335259139537811,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13586129248142242,
      "backward_entropy": 0.09630937235695976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2992987632751465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010433257557451725,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13585680723190308,
      "backward_entropy": 0.0954455818448748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.665560722351074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010530667379498482,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13585612177848816,
      "backward_entropy": 0.09737827096666608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02083969116211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010628247633576393,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13585427403450012,
      "backward_entropy": 0.09520527294703893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.642744064331055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01072617992758751,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1358499377965927,
      "backward_entropy": 0.09595186369759696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.120197296142578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010823727585375309,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13584895431995392,
      "backward_entropy": 0.09585613863808769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.557160377502441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010921670123934746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13584548234939575,
      "backward_entropy": 0.0957536016191755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417169570922852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011020218022167683,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13583756983280182,
      "backward_entropy": 0.09708847318376813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.855667114257812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011118697002530098,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13582977652549744,
      "backward_entropy": 0.09553814785821098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.71911096572876,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011217370629310608,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13582061231136322,
      "backward_entropy": 0.09440667288643974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.667293548583984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011315605603158474,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13581448793411255,
      "backward_entropy": 0.09531033039093018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.330548286437988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011413944885134697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13580724596977234,
      "backward_entropy": 0.09519078050340925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.767366409301758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011512716300785542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13579633831977844,
      "backward_entropy": 0.09506707532065255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.082864761352539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011612129397690296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13578078150749207,
      "backward_entropy": 0.0949392489024571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.814148902893066,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011711765080690384,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13576358556747437,
      "backward_entropy": 0.09364470413752965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.359003067016602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011811427772045135,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1357458084821701,
      "backward_entropy": 0.09651721375329154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.852678298950195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01191140990704298,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13572534918785095,
      "backward_entropy": 0.09331484351839338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.370847702026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01201144140213728,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13570456206798553,
      "backward_entropy": 0.09314467225755964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.290325164794922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012111264280974865,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13568535447120667,
      "backward_entropy": 0.09627001626150948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.67762279510498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012210819870233536,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13566726446151733,
      "backward_entropy": 0.09618326595851354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.540160179138184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012310866266489029,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13564498722553253,
      "backward_entropy": 0.09261049543108259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.788678169250488,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01241075899451971,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13562308251857758,
      "backward_entropy": 0.09379128898893084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12661361694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01251067966222763,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13560107350349426,
      "backward_entropy": 0.09223433903285436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.672966003417969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012610848993062973,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13557842373847961,
      "backward_entropy": 0.09204192672457014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.111213684082031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01271094474941492,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13555610179901123,
      "backward_entropy": 0.09184331553322929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.370888710021973,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012810666114091873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355363428592682,
      "backward_entropy": 0.09561892918178014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.356639862060547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01291019655764103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13551756739616394,
      "backward_entropy": 0.0929620691708156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.70850944519043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013009550049901009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13549970090389252,
      "backward_entropy": 0.09278639725276402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.781070709228516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013108921237289906,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13548070192337036,
      "backward_entropy": 0.09260647637503487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.672049522399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01320836041122675,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1354604959487915,
      "backward_entropy": 0.09242231505257743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.024284362792969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01330781914293766,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13544005155563354,
      "backward_entropy": 0.09053705419812884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731608390808105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013406953774392605,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13542278110980988,
      "backward_entropy": 0.0903021012033735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.520014762878418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013506128452718258,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13540343940258026,
      "backward_entropy": 0.09487182753426689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.321319580078125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013605836778879166,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13538037240505219,
      "backward_entropy": 0.091648987361363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.763849258422852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01370589341968298,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1353541612625122,
      "backward_entropy": 0.0914440665926252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10055160522461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013805922120809555,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13532654941082,
      "backward_entropy": 0.09449732303619385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.461431503295898,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013906124979257584,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13529644906520844,
      "backward_entropy": 0.08904738085610527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26147174835205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014006144367158413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13526715338230133,
      "backward_entropy": 0.09080037048884801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51366901397705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014105869457125664,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13523921370506287,
      "backward_entropy": 0.0940952215875898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.957690715789795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014205502346158028,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13521210849285126,
      "backward_entropy": 0.09035032987594604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.200864791870117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014304710552096367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13518719375133514,
      "backward_entropy": 0.0938019071306501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.613306999206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01440367754548788,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13516300916671753,
      "backward_entropy": 0.0876436744417463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.183937072753906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01450265571475029,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13513721525669098,
      "backward_entropy": 0.08964260986873082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.67226791381836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014601467177271843,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13511405885219574,
      "backward_entropy": 0.09331907544817243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.332276344299316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014700381085276604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13508987426757812,
      "backward_entropy": 0.09314886161259242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.481136322021484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01479858998209238,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350702941417694,
      "backward_entropy": 0.09297490119934082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.048665046691895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014897414483129978,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13504478335380554,
      "backward_entropy": 0.08608111313411168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.286521911621094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014995927922427654,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13501931726932526,
      "backward_entropy": 0.09261368002210345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.161534309387207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015093781054019928,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13499966263771057,
      "backward_entropy": 0.09242693015507289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.341835021972656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015192141756415367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13497620820999146,
      "backward_entropy": 0.09223519052777972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.66495132446289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015290454030036926,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1349523961544037,
      "backward_entropy": 0.08469266550881523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.197800636291504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01538892276585102,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13492675125598907,
      "backward_entropy": 0.08433037996292114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.886927127838135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015486684627830982,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13490761816501617,
      "backward_entropy": 0.08396240643092565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.421568870544434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015584160573780537,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1348876655101776,
      "backward_entropy": 0.09142369883401054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.285699844360352,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015681756660342216,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.134866401553154,
      "backward_entropy": 0.08623961039951869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.924489974975586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015778779983520508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13484957814216614,
      "backward_entropy": 0.08592355251312256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.148510932922363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015875663608312607,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13483265042304993,
      "backward_entropy": 0.08243639128548759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.62190055847168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015972554683685303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13481417298316956,
      "backward_entropy": 0.08526428256716047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399581909179688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016069738194346428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13479170203208923,
      "backward_entropy": 0.08491826057434082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.746564865112305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016167033463716507,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1347656548023224,
      "backward_entropy": 0.08456403868538993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.406266212463379,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01626408100128174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13474158942699432,
      "backward_entropy": 0.08420492921556745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.48232889175415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01636132411658764,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1347164809703827,
      "backward_entropy": 0.08038702181407384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.454937934875488,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01645759306848049,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13470205664634705,
      "backward_entropy": 0.07996133395603724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.158656120300293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01655413769185543,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13468313217163086,
      "backward_entropy": 0.08905298369271415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.852878093719482,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01665080152451992,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1346641182899475,
      "backward_entropy": 0.08878772599356514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.965625286102295,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016746748238801956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13465091586112976,
      "backward_entropy": 0.08851824487958636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.87613582611084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01684267446398735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13463330268859863,
      "backward_entropy": 0.08824389321463448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.031996726989746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016938552260398865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1346130073070526,
      "backward_entropy": 0.08155252252306257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5081787109375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01703450456261635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13459008932113647,
      "backward_entropy": 0.08767945425851005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.685060501098633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017130205407738686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13456764817237854,
      "backward_entropy": 0.08073433807918004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.613364219665527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017226358875632286,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13453638553619385,
      "backward_entropy": 0.08709403446742467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.118785858154297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017321676015853882,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13451090455055237,
      "backward_entropy": 0.0798854146684919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.696008682250977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017417196184396744,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1344817578792572,
      "backward_entropy": 0.07534027951104301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.613618850708008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017512649297714233,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13445203006267548,
      "backward_entropy": 0.07901295593806676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.09158992767334,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01760801486670971,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13442286849021912,
      "backward_entropy": 0.07856930153710502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.450453281402588,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0177035853266716,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13438871502876282,
      "backward_entropy": 0.07382660252707345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.493101596832275,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01779833436012268,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1343633383512497,
      "backward_entropy": 0.0733128275190081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.318828105926514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01789233274757862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13434328138828278,
      "backward_entropy": 0.07721492222377233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.749105930328369,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0179862342774868,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343245506286621,
      "backward_entropy": 0.08454224041530065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.812191486358643,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01807965151965618,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13430878520011902,
      "backward_entropy": 0.07173353433609009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.034307956695557,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01817329414188862,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13428673148155212,
      "backward_entropy": 0.08384986434664045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6607985496521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01826666109263897,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13426482677459717,
      "backward_entropy": 0.0753496629851205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.684508800506592,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018359528854489326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13424474000930786,
      "backward_entropy": 0.08313074282237462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.971094131469727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018452001735568047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13422760367393494,
      "backward_entropy": 0.07438489368983678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.056952953338623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01854432187974453,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1342114955186844,
      "backward_entropy": 0.0823890311377389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.398143291473389,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018636556342244148,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13419479131698608,
      "backward_entropy": 0.06841156738145011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.093669414520264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018728312104940414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13418370485305786,
      "backward_entropy": 0.07290370123726982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.272602558135986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018820064142346382,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13416998088359833,
      "backward_entropy": 0.07239958218165807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3228325843811035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01891193725168705,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13415226340293884,
      "backward_entropy": 0.06669420003890991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.802209854125977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01900397054851055,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13413093984127045,
      "backward_entropy": 0.06611371040344238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.708820343017578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019095130264759064,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13411766290664673,
      "backward_entropy": 0.08001787321908134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.097201824188232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019185388460755348,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13410890102386475,
      "backward_entropy": 0.06493822165897914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.144215106964111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019275804981589317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1340939998626709,
      "backward_entropy": 0.0791872228894915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.627728462219238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019366415217518806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13407346606254578,
      "backward_entropy": 0.06925951583044869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.257828235626221,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01945687085390091,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13405251502990723,
      "backward_entropy": 0.06313924704279218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.061546325683594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01954692229628563,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1340329498052597,
      "backward_entropy": 0.0681704112461635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.025557994842529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019637202844023705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13400962948799133,
      "backward_entropy": 0.07742497750691005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.536466598510742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01972764916718006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13398140668869019,
      "backward_entropy": 0.06705773302486964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.382401466369629,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019817905500531197,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13395196199417114,
      "backward_entropy": 0.07649389335087367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.769338607788086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01990787498652935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13392165303230286,
      "backward_entropy": 0.07601984909602574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.747419357299805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019997186958789825,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13389702141284943,
      "backward_entropy": 0.059480518102645874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.313536643981934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02008584886789322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13387441635131836,
      "backward_entropy": 0.07506017174039568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.466366291046143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02017436921596527,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13385024666786194,
      "backward_entropy": 0.0745722736631121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.320193290710449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020262882113456726,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.133822962641716,
      "backward_entropy": 0.0636108432497297,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1902594566345215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02035125344991684,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13379131257534027,
      "backward_entropy": 0.056976641927446635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.080656051635742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02043873444199562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13376881182193756,
      "backward_entropy": 0.06242473636354719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.136499404907227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02052605152130127,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13374458253383636,
      "backward_entropy": 0.06182953715324402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0441365242004395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020613234490156174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13371556997299194,
      "backward_entropy": 0.06122770053999765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1760969161987305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020700333639979362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13368850946426392,
      "backward_entropy": 0.060625242335455756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.040666580200195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020786698907613754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13366976380348206,
      "backward_entropy": 0.0600281868662153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.578652858734131,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020873017609119415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.133647158741951,
      "backward_entropy": 0.07047690238271441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.413130760192871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02095894329249859,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13362427055835724,
      "backward_entropy": 0.058820515871047974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.650228023529053,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02104516513645649,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1335931271314621,
      "backward_entropy": 0.06939999546323504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.202029705047607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02113110013306141,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1335623860359192,
      "backward_entropy": 0.0688522287777492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3327202796936035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02121637761592865,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13353213667869568,
      "backward_entropy": 0.05697442804064069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.308248043060303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021301202476024628,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13350221514701843,
      "backward_entropy": 0.06774873392922538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.729944229125977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021384770050644875,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13347965478897095,
      "backward_entropy": 0.049307750804083686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.429310321807861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02146756649017334,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1334601640701294,
      "backward_entropy": 0.06664161171231951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.177836894989014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02155022881925106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13343504071235657,
      "backward_entropy": 0.05452492407390049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.737421989440918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021632622927427292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13340966403484344,
      "backward_entropy": 0.053910676922116964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.243542194366455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021714387461543083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1333858072757721,
      "backward_entropy": 0.06495767406054906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.797563076019287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021796103566884995,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13336297869682312,
      "backward_entropy": 0.06438756840569633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.738771915435791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02187732234597206,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1333395391702652,
      "backward_entropy": 0.0638154149055481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.032097816467285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02195807918906212,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13331712782382965,
      "backward_entropy": 0.04484535540853228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.138411521911621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022037770599126816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.133299320936203,
      "backward_entropy": 0.05082582575934274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.626338481903076,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02211746945977211,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13327357172966003,
      "backward_entropy": 0.062090788568769185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.392034530639648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02219674549996853,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13324566185474396,
      "backward_entropy": 0.06151287044797625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.853937149047852,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022275468334555626,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13321912288665771,
      "backward_entropy": 0.04233973366873605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.274842739105225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0223541222512722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1331886351108551,
      "backward_entropy": 0.04835025327546256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.968757152557373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022432221099734306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13316138088703156,
      "backward_entropy": 0.04773564849581037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.987401962280273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022510433569550514,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1331268548965454,
      "backward_entropy": 0.04049440792628697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.913646221160889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02258879505097866,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1330859363079071,
      "backward_entropy": 0.05858538831983294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5834574699401855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022667238488793373,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13303899765014648,
      "backward_entropy": 0.045869141817092896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.002580642700195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022744476795196533,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13299846649169922,
      "backward_entropy": 0.045254026140485494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.056138515472412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02282101847231388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13295677304267883,
      "backward_entropy": 0.05680824177605765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.273196697235107,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022897066548466682,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1329176127910614,
      "backward_entropy": 0.056217619350978305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.068187713623047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02297297492623329,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1328827142715454,
      "backward_entropy": 0.0556229863848005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.00039529800415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023048460483551025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1328461468219757,
      "backward_entropy": 0.04283195734024048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.310166358947754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02312351204454899,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13280807435512543,
      "backward_entropy": 0.042231351137161255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.019316673278809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023197470232844353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13277535140514374,
      "backward_entropy": 0.041639889989580424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6650402545928955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023271195590496063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13273900747299194,
      "backward_entropy": 0.04104881201471601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2154293060302734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023344382643699646,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1327044516801834,
      "backward_entropy": 0.0404631325176784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.110157489776611,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02341659739613533,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13267481327056885,
      "backward_entropy": 0.03354252449103764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3648900985717773,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023488905280828476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13263791799545288,
      "backward_entropy": 0.05149026853697641,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6572446823120117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02356058917939663,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13260804116725922,
      "backward_entropy": 0.03873845509120396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6906356811523438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023631924763321877,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1325722634792328,
      "backward_entropy": 0.03816963519368853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2992491722106934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02370304986834526,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13253304362297058,
      "backward_entropy": 0.03141040674277714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.899829149246216,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023773489519953728,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13249024748802185,
      "backward_entropy": 0.04914047036852155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8957860469818115,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023842990398406982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13245634734630585,
      "backward_entropy": 0.0364879880632673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1843998432159424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023911520838737488,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1324215680360794,
      "backward_entropy": 0.03594363587243216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.365572929382324,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02397955022752285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13238276541233063,
      "backward_entropy": 0.03540213618959699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5689337253570557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024047331884503365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13233551383018494,
      "backward_entropy": 0.034860031945364814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9275190830230713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02411527931690216,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1322842836380005,
      "backward_entropy": 0.046273687056132724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4847612380981445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02418261393904686,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1322377473115921,
      "backward_entropy": 0.033786503332001824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.658811330795288,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024248847737908363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13220000267028809,
      "backward_entropy": 0.03326792802129473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.101576566696167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024314291775226593,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1321650892496109,
      "backward_entropy": 0.032755294016429355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.813978910446167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024379534646868706,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13212120532989502,
      "backward_entropy": 0.032241831932749064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.296076774597168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024444270879030228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1320740282535553,
      "backward_entropy": 0.03173239742006574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9728708267211914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024507898837327957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13203182816505432,
      "backward_entropy": 0.03123085413660322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4645097255706787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02457142435014248,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13198131322860718,
      "backward_entropy": 0.030728693519319807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.83920955657959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024634292349219322,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13193659484386444,
      "backward_entropy": 0.041857123374938965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5525293350219727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024697085842490196,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.131889209151268,
      "backward_entropy": 0.029746149267469133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7540063858032227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024759333580732346,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13183704018592834,
      "backward_entropy": 0.02390937720026289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5390818119049072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024821484461426735,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13178125023841858,
      "backward_entropy": 0.040250050170081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3287134170532227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024883270263671875,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13172520697116852,
      "backward_entropy": 0.03971905793462481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9176455736160278,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024944359436631203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13166667520999908,
      "backward_entropy": 0.03919460092272077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1337528228759766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025004124268889427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13160651922225952,
      "backward_entropy": 0.027365518467766897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4143624305725098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02506316639482975,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13154740631580353,
      "backward_entropy": 0.02191028211797987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8911798000335693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025122016668319702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13148345053195953,
      "backward_entropy": 0.03767289859907968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4409760236740112,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025179894641041756,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13142384588718414,
      "backward_entropy": 0.026023255927222117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9925779104232788,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025236111134290695,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13137206435203552,
      "backward_entropy": 0.02080056071281433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8014518022537231,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025291772559285164,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1313171237707138,
      "backward_entropy": 0.03621560335159302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.218641757965088,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025346696376800537,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13126584887504578,
      "backward_entropy": 0.02010126624788557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0115249156951904,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0254017673432827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1312129646539688,
      "backward_entropy": 0.02436129535947527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.669999599456787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025456510484218597,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13115420937538147,
      "backward_entropy": 0.01941914643560137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9234188795089722,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02551036886870861,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13109558820724487,
      "backward_entropy": 0.02355863792555673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.80999755859375,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025563957169651985,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13103359937667847,
      "backward_entropy": 0.02316524727003915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.688732624053955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025616995990276337,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13096296787261963,
      "backward_entropy": 0.018438492502485002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5825233459472656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02566942758858204,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13089099526405334,
      "backward_entropy": 0.0329833094562803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5640740394592285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025721166282892227,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13082082569599152,
      "backward_entropy": 0.017813892236777713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4794392585754395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025772249326109886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13075074553489685,
      "backward_entropy": 0.021648355892726352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3756084442138672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025822507217526436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13067711889743805,
      "backward_entropy": 0.031686714717320034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3909542560577393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025871923193335533,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.130606546998024,
      "backward_entropy": 0.016928161893572127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4526591300964355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025920536369085312,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1305321305990219,
      "backward_entropy": 0.01664669918162482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6279758214950562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025968683883547783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13045689463615417,
      "backward_entropy": 0.02024427694933755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.08769953250885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260168444365263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13037614524364471,
      "backward_entropy": 0.019903893981661116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3038569688796997,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026063788682222366,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13030120730400085,
      "backward_entropy": 0.015834292130810872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0021133422851562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02611013501882553,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1302236169576645,
      "backward_entropy": 0.02927141104425703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0860551595687866,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026155222207307816,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1301494687795639,
      "backward_entropy": 0.015326832021985735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1246768236160278,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02619941532611847,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13007666170597076,
      "backward_entropy": 0.02852657437324524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.159993052482605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026242980733513832,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13000574707984924,
      "backward_entropy": 0.028163539511816844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0375112295150757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026286158710718155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12993726134300232,
      "backward_entropy": 0.018045359424182346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9032586216926575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328586041927338,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12986811995506287,
      "backward_entropy": 0.017759295446532115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0702571868896484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02636990323662758,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12979696691036224,
      "backward_entropy": 0.02710892472948347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.064873218536377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026410825550556183,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12972339987754822,
      "backward_entropy": 0.026771143078804016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.85976243019104,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026451509445905685,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1296514868736267,
      "backward_entropy": 0.026435422045843943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8336803913116455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02649133838713169,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12958337366580963,
      "backward_entropy": 0.01353841062102999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7326379418373108,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026530202478170395,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12951204180717468,
      "backward_entropy": 0.013340045298848833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8743643164634705,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02656792663037777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12944145500659943,
      "backward_entropy": 0.025470571858542308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.805662989616394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02660522609949112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1293712854385376,
      "backward_entropy": 0.015932456723281314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8416498303413391,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026641862466931343,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12929902970790863,
      "backward_entropy": 0.012778869697025843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8500444889068604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02667817659676075,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12922784686088562,
      "backward_entropy": 0.02456138389451163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6656396389007568,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026714283972978592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12915684282779694,
      "backward_entropy": 0.015232826982225691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6894033551216125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026749387383461,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12908390164375305,
      "backward_entropy": 0.015010003532682146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5526719689369202,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026783697307109833,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1290070116519928,
      "backward_entropy": 0.023696933473859514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7055779099464417,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02681683748960495,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.128933385014534,
      "backward_entropy": 0.023426666855812073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4462968409061432,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026849618181586266,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12885768711566925,
      "backward_entropy": 0.014379045792988368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6971150636672974,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026880808174610138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12878106534481049,
      "backward_entropy": 0.022907365645681108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47397077083587646,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02691188082098961,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12870071828365326,
      "backward_entropy": 0.011490891022341592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.575630247592926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026941783726215363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12862154841423035,
      "backward_entropy": 0.013805830052920751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5286474823951721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026971248909831047,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12854278087615967,
      "backward_entropy": 0.022177985736301968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48545366525650024,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027000198140740395,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12846815586090088,
      "backward_entropy": 0.011093746338571821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4604339599609375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027028486132621765,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1283978521823883,
      "backward_entropy": 0.021710921611104692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5016977787017822,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027056105434894562,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12833261489868164,
      "backward_entropy": 0.013113003756318773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4766632318496704,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027083218097686768,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12826327979564667,
      "backward_entropy": 0.021262756415775845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5229366421699524,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027109801769256592,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12819145619869232,
      "backward_entropy": 0.021046427743775502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.391798734664917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027136271819472313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12811611592769623,
      "backward_entropy": 0.012635221438748496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4028065800666809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02716177888214588,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12803904712200165,
      "backward_entropy": 0.012483643633978707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45013201236724854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027186602354049683,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12796175479888916,
      "backward_entropy": 0.01029532722064427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3930857181549072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02721119113266468,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12788179516792297,
      "backward_entropy": 0.020226453031812395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35306593775749207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027235226705670357,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12780170142650604,
      "backward_entropy": 0.012049436569213867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3199863135814667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027258465066552162,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12772083282470703,
      "backward_entropy": 0.01191267158303942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3627830445766449,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027280787006020546,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1276407241821289,
      "backward_entropy": 0.019666850566864014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30015552043914795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027302753180265427,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12756091356277466,
      "backward_entropy": 0.011653912918908256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35919564962387085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02732384391129017,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1274816393852234,
      "backward_entropy": 0.011531552033764976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3094111979007721,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027344856411218643,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12740300595760345,
      "backward_entropy": 0.019152109112058367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30139291286468506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0273651871830225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12732122838497162,
      "backward_entropy": 0.011292532086372375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3153807818889618,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027384957298636436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12723839282989502,
      "backward_entropy": 0.011178358324936457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30111873149871826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027404535561800003,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1271558254957199,
      "backward_entropy": 0.011065717254366194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2877562642097473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027423705905675888,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12707002460956573,
      "backward_entropy": 0.010955195341791426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.25015559792518616,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02744254656136036,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12698407471179962,
      "backward_entropy": 0.018373376556805203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2375476360321045,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027460673823952675,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1268986463546753,
      "backward_entropy": 0.018229867730821882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22534751892089844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027478011325001717,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12681308388710022,
      "backward_entropy": 0.010644263454845973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2396627813577652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0274944007396698,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12672482430934906,
      "backward_entropy": 0.009111584297248296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23509065806865692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027510538697242737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12663961946964264,
      "backward_entropy": 0.010459039892469133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22067825496196747,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027526430785655975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12655626237392426,
      "backward_entropy": 0.017707239304270064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21357034146785736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02754194475710392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12647473812103271,
      "backward_entropy": 0.010282366403511592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2153586745262146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02755708619952202,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1263948678970337,
      "backward_entropy": 0.01746262184211186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19476105272769928,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027571991086006165,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12631545960903168,
      "backward_entropy": 0.008850160986185074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17237114906311035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027586402371525764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12623757123947144,
      "backward_entropy": 0.010035211486475808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20194397866725922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027599796652793884,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1261589229106903,
      "backward_entropy": 0.009961234671728951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18082860112190247,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027613533660769463,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12608602643013,
      "backward_entropy": 0.01701031838144575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1871667206287384,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027626730501651764,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1260114312171936,
      "backward_entropy": 0.008677287293331963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1691047102212906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02763975039124489,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12593522667884827,
      "backward_entropy": 0.016799950173922946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.163070946931839,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02765214629471302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12585686147212982,
      "backward_entropy": 0.016700776559965953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1583361178636551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02766404300928116,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1257781684398651,
      "backward_entropy": 0.016605477247919356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1550746113061905,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027675466611981392,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1256992071866989,
      "backward_entropy": 0.009546467236110143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14830344915390015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02768663689494133,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12562163174152374,
      "backward_entropy": 0.009485428886754172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1586945354938507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027697544544935226,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12554609775543213,
      "backward_entropy": 0.00942615738936833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14882786571979523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02770865149796009,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12547020614147186,
      "backward_entropy": 0.009365675704819816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14219960570335388,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02771960198879242,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12539316713809967,
      "backward_entropy": 0.009305882666792189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13120922446250916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027730470523238182,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12531667947769165,
      "backward_entropy": 0.009246611169406347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12731535732746124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027740731835365295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12523970007896423,
      "backward_entropy": 0.009190716913768224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13197970390319824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027750518172979355,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12516307830810547,
      "backward_entropy": 0.015912064484187534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12221325933933258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027759812772274017,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12508244812488556,
      "backward_entropy": 0.0158376544713974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1198807805776596,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027768893167376518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12500271201133728,
      "backward_entropy": 0.009036647421973092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11489200592041016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027777299284934998,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12492060661315918,
      "backward_entropy": 0.015697999724320004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11086110770702362,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027785541489720345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12483981251716614,
      "backward_entropy": 0.01563197374343872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1105276420712471,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027793334797024727,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1247592568397522,
      "backward_entropy": 0.008221782743930817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10796807706356049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0278005450963974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12467668205499649,
      "backward_entropy": 0.008859852594988686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1032053753733635,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780759148299694,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12459346652030945,
      "backward_entropy": 0.00881951195853097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10178417712450027,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02781437523663044,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12451033294200897,
      "backward_entropy": 0.008780448564461299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09534690529108047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027821103110909462,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12442676723003387,
      "backward_entropy": 0.015341146716049739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08963951468467712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027828192338347435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12434608489274979,
      "backward_entropy": 0.008700792278562273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09155629575252533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027835210785269737,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12426885962486267,
      "backward_entropy": 0.008660848651613508,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08409702777862549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027842367067933083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12419189512729645,
      "backward_entropy": 0.015168400747435433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07974504679441452,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027849413454532623,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12411807477474213,
      "backward_entropy": 0.008580302553517478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07759169489145279,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027856333181262016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12404830753803253,
      "backward_entropy": 0.00854169683797019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0831746757030487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02786356583237648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12398181855678558,
      "backward_entropy": 0.008501693606376648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07522029429674149,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02787051722407341,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12391246855258942,
      "backward_entropy": 0.014938578009605408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07705239206552505,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027877502143383026,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12384417653083801,
      "backward_entropy": 0.008423832378217153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06689204275608063,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027884362265467644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12377369403839111,
      "backward_entropy": 0.014826554272856032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07292711734771729,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027891462668776512,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12370616942644119,
      "backward_entropy": 0.01476990750857762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06905880570411682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027897873893380165,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12363830953836441,
      "backward_entropy": 0.007994815175022398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06495000422000885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027904072776436806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12356947362422943,
      "backward_entropy": 0.00827469942825181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0633229911327362,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027910133823752403,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12350109219551086,
      "backward_entropy": 0.008240495409284319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0602668859064579,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027916060760617256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12343248724937439,
      "backward_entropy": 0.00820696194257055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06109201908111572,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027921929955482483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12336388230323792,
      "backward_entropy": 0.014521970280579157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05500619113445282,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027927415445446968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12329544126987457,
      "backward_entropy": 0.0144770975623812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05995960906147957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02793275937438011,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12322942912578583,
      "backward_entropy": 0.014433125300066811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05109773576259613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027937695384025574,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12316126376390457,
      "backward_entropy": 0.008084207773208618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04756845533847809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027942603453993797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12309486418962479,
      "backward_entropy": 0.008056301091398512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0495791956782341,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027947621420025826,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12303012609481812,
      "backward_entropy": 0.008027950035674232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049886852502822876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027952518314123154,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12296529114246368,
      "backward_entropy": 0.008000177996499198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05289922654628754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027957068756222725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1229015439748764,
      "backward_entropy": 0.00797435109104429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04340599477291107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02796119451522827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12283432483673096,
      "backward_entropy": 0.007950344255992345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.043998025357723236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027965404093265533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12276627868413925,
      "backward_entropy": 0.014163151383399963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04308844730257988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027969466522336006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12269865721464157,
      "backward_entropy": 0.007901826607329505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04019079729914665,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027973314747214317,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12263211607933044,
      "backward_entropy": 0.007879141718149185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03364865481853485,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027977025136351585,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12256775796413422,
      "backward_entropy": 0.007904894649982452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03353215008974075,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027980921790003777,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12250669300556183,
      "backward_entropy": 0.014032042452267237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037497855722904205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027984915301203728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12244786322116852,
      "backward_entropy": 0.007812191333089556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036474451422691345,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027988677844405174,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12238944321870804,
      "backward_entropy": 0.0077906666057450434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032087478786706924,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02799222804605961,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1223306804895401,
      "backward_entropy": 0.013936725045953478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.036062583327293396,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02799575962126255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12227271497249603,
      "backward_entropy": 0.007900706359318324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03378666937351227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027998976409435272,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12221349030733109,
      "backward_entropy": 0.013887874782085419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02552482858300209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02800196409225464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12215394526720047,
      "backward_entropy": 0.007713198661804199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02271634340286255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02800513058900833,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12209868431091309,
      "backward_entropy": 0.0076949138726506916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032256413251161575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028008559718728065,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12204824388027191,
      "backward_entropy": 0.007675698293106896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025715649127960205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028011616319417953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12199714779853821,
      "backward_entropy": 0.007658349084002631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02482720836997032,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028014658018946648,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12194778025150299,
      "backward_entropy": 0.007903389100517546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02403898723423481,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0280176792293787,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12190002202987671,
      "backward_entropy": 0.013750870312963213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02142544835805893,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028020676225423813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12185271829366684,
      "backward_entropy": 0.013728105596133642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022316014394164085,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028023747727274895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12180715799331665,
      "backward_entropy": 0.01370432334286826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020692255347967148,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028026774525642395,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12176378071308136,
      "backward_entropy": 0.007897984768663133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027563391253352165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028029803186655045,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12172295898199081,
      "backward_entropy": 0.007895431880440031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019263098016381264,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02803238295018673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12167979776859283,
      "backward_entropy": 0.007542839007718223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01857707090675831,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02803499437868595,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12163814902305603,
      "backward_entropy": 0.00789559313229152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01631884276866913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028037628158926964,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12159821391105652,
      "backward_entropy": 0.007513896695205143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01806262880563736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028040368109941483,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12155973166227341,
      "backward_entropy": 0.007498973714453834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018184829503297806,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028043055906891823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1215224415063858,
      "backward_entropy": 0.01354687980243138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016005832701921463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028045643121004105,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12148387730121613,
      "backward_entropy": 0.0074701809457370216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014709034003317356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02804822474718094,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12144416570663452,
      "backward_entropy": 0.0074557991964476445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016414953395724297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02805083803832531,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12140572816133499,
      "backward_entropy": 0.013483674398490362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014327224344015121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028053341433405876,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12136773765087128,
      "backward_entropy": 0.0074274832648890355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014572045765817165,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0280558243393898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12132987380027771,
      "backward_entropy": 0.013443423168999808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015557368285953999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028058240190148354,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12129251658916473,
      "backward_entropy": 0.007400212011166981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017821921035647392,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028060507029294968,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12125569581985474,
      "backward_entropy": 0.013405323028564453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015085484832525253,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028062468394637108,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.121217280626297,
      "backward_entropy": 0.007879566933427538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014602810144424438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028064275160431862,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1211777850985527,
      "backward_entropy": 0.007365668990782329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012213047593832016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028065940365195274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12113787233829498,
      "backward_entropy": 0.00735569851739066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011745480820536613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02806759625673294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12109936773777008,
      "backward_entropy": 0.013347445854118891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01066518947482109,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02806924097239971,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12106190621852875,
      "backward_entropy": 0.013333941144602639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010309543460607529,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028070908039808273,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12102547287940979,
      "backward_entropy": 0.013320206531456538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011083807796239853,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028072591871023178,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12099023163318634,
      "backward_entropy": 0.007316653217588153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011153574101626873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02807421237230301,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12095539271831512,
      "backward_entropy": 0.007307217589446476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012954454869031906,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02807573415338993,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12092004716396332,
      "backward_entropy": 0.007298214094979423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008385548368096352,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0280770231038332,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12088320404291153,
      "backward_entropy": 0.013270056673458644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010614937171339989,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028078386560082436,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12084829807281494,
      "backward_entropy": 0.013258785009384155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009632575325667858,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028079641982913017,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12081357091665268,
      "backward_entropy": 0.007906737072127206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010335496626794338,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028080828487873077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1207788735628128,
      "backward_entropy": 0.007910543254443578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008160975761711597,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02808189205825329,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12074416875839233,
      "backward_entropy": 0.007915099816662925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00821707397699356,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02808297425508499,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12071086466312408,
      "backward_entropy": 0.01322024209158761,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007719205692410469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02808403968811035,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12067820876836777,
      "backward_entropy": 0.013211203472954887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006730105262249708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028085079044103622,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1206454187631607,
      "backward_entropy": 0.013202502259186335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007580113131552935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028086161240935326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12061362713575363,
      "backward_entropy": 0.007233461099011558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008256692439317703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028087187558412552,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12058176845312119,
      "backward_entropy": 0.013184947626931327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007571343798190355,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02808811143040657,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12055021524429321,
      "backward_entropy": 0.013177154319626945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006573140621185303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028088971972465515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1205192282795906,
      "backward_entropy": 0.0072157228631632665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006170871201902628,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02808983251452446,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12048928439617157,
      "backward_entropy": 0.007947833410331182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0048598130233585835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028090687468647957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12045974284410477,
      "backward_entropy": 0.007204991366182055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005752909928560257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028091611340641975,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1204308345913887,
      "backward_entropy": 0.013147224273000444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005635934881865978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02809252217411995,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12040248513221741,
      "backward_entropy": 0.00719366329056876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006075169891119003,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028093425557017326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12037505209445953,
      "backward_entropy": 0.013131842017173767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006104462314397097,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02809423767030239,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12034723162651062,
      "backward_entropy": 0.007183001509734562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004548170603811741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0280949417501688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12031896412372589,
      "backward_entropy": 0.007178379488842828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004471926484256983,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0280956719070673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12029130756855011,
      "backward_entropy": 0.013113042073590415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003797557670623064,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028096430003643036,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12026454508304596,
      "backward_entropy": 0.007978108844586782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0040806052275002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02809729054570198,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12023983895778656,
      "backward_entropy": 0.007163515580551965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004130963701754808,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02809816040098667,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12021567672491074,
      "backward_entropy": 0.013091670615332467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034978266339749098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028099047020077705,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12019265443086624,
      "backward_entropy": 0.01308400503226689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003880643518641591,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028100021183490753,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12017163634300232,
      "backward_entropy": 0.00714743829199246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004478991497308016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02810096926987171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1201508641242981,
      "backward_entropy": 0.013067097536155156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033047518227249384,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028101835399866104,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12013034522533417,
      "backward_entropy": 0.013059320194380624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030886500608175993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028102729469537735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12011073529720306,
      "backward_entropy": 0.00713198578783444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034997984766960144,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028103670105338097,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12009238451719284,
      "backward_entropy": 0.0071267666561262944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003412383608520031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028104562312364578,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12007400393486023,
      "backward_entropy": 0.007121782749891281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0032374931033700705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02810540981590748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12005580961704254,
      "backward_entropy": 0.0071170202323368615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00302512152120471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028106214478611946,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12003766000270844,
      "backward_entropy": 0.0071124737816197535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028061536140739918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028106974437832832,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12001930177211761,
      "backward_entropy": 0.013012807284082686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002614770084619522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028107741847634315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12000179290771484,
      "backward_entropy": 0.007103749151740756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002431475091725588,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0281085092574358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11998482793569565,
      "backward_entropy": 0.007099400673593793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002335520228371024,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028109271079301834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11996810138225555,
      "backward_entropy": 0.0070950984954833984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0025929613038897514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028110025450587273,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11995157599449158,
      "backward_entropy": 0.007090820265667779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002904362976551056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028110742568969727,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11993527412414551,
      "backward_entropy": 0.007086730429104396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001727137016132474,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028111349791288376,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11991825699806213,
      "backward_entropy": 0.012972896652562278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002094313967972994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028112011030316353,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1199021115899086,
      "backward_entropy": 0.012966942574296678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001941680908203125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028112677857279778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1198866069316864,
      "backward_entropy": 0.007075484309877668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019346179906278849,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028113340958952904,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11987170577049255,
      "backward_entropy": 0.008010014359440123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017916435608640313,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02811400406062603,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11985735595226288,
      "backward_entropy": 0.012948781251907349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016881281044334173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02811466157436371,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11984334886074066,
      "backward_entropy": 0.007064236061913627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013798126019537449,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02811530977487564,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11982953548431396,
      "backward_entropy": 0.008013076015881129,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015316018834710121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028115997090935707,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11981649696826935,
      "backward_entropy": 0.01293068379163742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019199308007955551,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02811664342880249,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11980310082435608,
      "backward_entropy": 0.008014278752463204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014375258469954133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02811717987060547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1197887435555458,
      "backward_entropy": 0.007049892629895892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013805567286908627,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028117714449763298,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11977474391460419,
      "backward_entropy": 0.012915533568177904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014120087726041675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028118286281824112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11976191401481628,
      "backward_entropy": 0.007043437766177314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012735669733956456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028118835762143135,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11974920332431793,
      "backward_entropy": 0.007040264351027352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001380647998303175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028119375929236412,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11973674595355988,
      "backward_entropy": 0.007037130849702018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014884959673509002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02811986207962036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11972394585609436,
      "backward_entropy": 0.007034242153167725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010863133938983083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028120314702391624,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11971138417720795,
      "backward_entropy": 0.007031539721148354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012848441256210208,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028120800852775574,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11969970166683197,
      "backward_entropy": 0.008024090634925025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001168990507721901,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028121281415224075,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11968857049942017,
      "backward_entropy": 0.007026015647820064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012289020232856274,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028121711686253548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1196770966053009,
      "backward_entropy": 0.012879197086606706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011317457538098097,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028122128918766975,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11966605484485626,
      "backward_entropy": 0.007021057286432811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010725189931690693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02812252566218376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11965523660182953,
      "backward_entropy": 0.007018740688051496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011119800619781017,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028122922405600548,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1196448877453804,
      "backward_entropy": 0.012867559279714311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009311167523264885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028123274445533752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11963438987731934,
      "backward_entropy": 0.007014398596116475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009698341018520296,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028123605996370316,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11962388455867767,
      "backward_entropy": 0.01286084737096514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009753872873261571,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028123943135142326,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11961396038532257,
      "backward_entropy": 0.007010434887238911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008573686936870217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028124244883656502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11960393190383911,
      "backward_entropy": 0.00700862067086356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007495733443647623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028124535456299782,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11959408223628998,
      "backward_entropy": 0.00700687404189791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006789937033317983,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028124837204813957,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11958463490009308,
      "backward_entropy": 0.01284837509904589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00064455735264346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02812514454126358,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11957547813653946,
      "backward_entropy": 0.007003289780446461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006208703271113336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02812548354268074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11956700682640076,
      "backward_entropy": 0.007001381899629321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000727102451492101,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028125835582613945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11955894529819489,
      "backward_entropy": 0.006999430911881583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005156437400728464,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028126176446676254,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11955109238624573,
      "backward_entropy": 0.008046238017933709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006182023789733648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0281265489757061,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11954382061958313,
      "backward_entropy": 0.008046932518482208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004420617187861353,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028126899152994156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11953651905059814,
      "backward_entropy": 0.012827777436801366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046995774027891457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028127258643507957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11952945590019226,
      "backward_entropy": 0.006991687097719738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004055049503222108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028127646073698997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11952294409275055,
      "backward_entropy": 0.006989640316792897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004932273295708001,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028128037229180336,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11951662600040436,
      "backward_entropy": 0.006987575973783221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004711946239694953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028128422796726227,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11951050162315369,
      "backward_entropy": 0.0069855621882847375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004709891218226403,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02812882512807846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.119504913687706,
      "backward_entropy": 0.012809038162231445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005735184531658888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028129195794463158,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11949915438890457,
      "backward_entropy": 0.006981569741453443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043255320633761585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028129534795880318,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11949340999126434,
      "backward_entropy": 0.006979776812451226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003734149504452944,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028129858896136284,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11948775500059128,
      "backward_entropy": 0.012798759554113661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00048515587695874274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028130196034908295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11948248744010925,
      "backward_entropy": 0.006976336240768433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033138474100269377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813049964606762,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11947709321975708,
      "backward_entropy": 0.006974747138363975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034068760578520596,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02813081443309784,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11947203427553177,
      "backward_entropy": 0.008051046303340368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002810537116602063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813113108277321,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11946722865104675,
      "backward_entropy": 0.006971497088670731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033953203819692135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028131460770964622,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1194627657532692,
      "backward_entropy": 0.012782507709094457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002501642156857997,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028131762519478798,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1194581463932991,
      "backward_entropy": 0.012779463614736284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002407952124485746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028132064267992973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11945365369319916,
      "backward_entropy": 0.006966746811355863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020341732306405902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028132395818829536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11944979429244995,
      "backward_entropy": 0.006965095443384988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003764512075576931,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813274785876274,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11944635212421417,
      "backward_entropy": 0.006963379148926053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030762708047404885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028133075684309006,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11944292485713959,
      "backward_entropy": 0.008051001067672457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022376285050995648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028133388608694077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11943955719470978,
      "backward_entropy": 0.012763057436261858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020003662211820483,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028133699670433998,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11943639814853668,
      "backward_entropy": 0.012759849429130554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018491875380277634,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028134005144238472,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11943328380584717,
      "backward_entropy": 0.012756694640432085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016088839038275182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02813430316746235,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11943020671606064,
      "backward_entropy": 0.008050295923437392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016409807722084224,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028134606778621674,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11942736804485321,
      "backward_entropy": 0.008049975016287394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002651470131240785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028134899213910103,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11942452192306519,
      "backward_entropy": 0.006952907357897077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002282851201016456,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813515067100525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1194213256239891,
      "backward_entropy": 0.012745112180709839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019280875858385116,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028135376051068306,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11941801011562347,
      "backward_entropy": 0.012742773762771062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00025756616378203034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813558839261532,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11941468715667725,
      "backward_entropy": 0.006949450288500104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002701123885344714,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028135772794485092,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11941124498844147,
      "backward_entropy": 0.008050598204135895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021279652719385922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813590131700039,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11940722167491913,
      "backward_entropy": 0.012737144316945757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018176125013269484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02813602052628994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11940331757068634,
      "backward_entropy": 0.008052427853856767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011604974861256778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028136124834418297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11939935386180878,
      "backward_entropy": 0.006946499858583722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013262193533591926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028136249631643295,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11939580738544464,
      "backward_entropy": 0.00694583569254194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011497157538542524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028136372566223145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11939237266778946,
      "backward_entropy": 0.006945147578205381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012550297833513469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028136499226093292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11938908696174622,
      "backward_entropy": 0.00694447649376733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011643654579529539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813662588596344,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11938591301441193,
      "backward_entropy": 0.012728640011378698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010500226926524192,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028136758133769035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11938293278217316,
      "backward_entropy": 0.0069431109087807795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.376606612931937e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028136884793639183,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11937998980283737,
      "backward_entropy": 0.006942429712840489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015585457731503993,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813701145350933,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11937713623046875,
      "backward_entropy": 0.012724318674632482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001335266715614125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028137117624282837,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11937414109706879,
      "backward_entropy": 0.012723102101257868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.649214967386797e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028137212619185448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11937114596366882,
      "backward_entropy": 0.006940661264317376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010773885151138529,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028137315064668655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11936832964420319,
      "backward_entropy": 0.006940105663878577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.251468873117119e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028137430548667908,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11936581879854202,
      "backward_entropy": 0.006939518664564405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.726452556904405e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813754603266716,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11936341226100922,
      "backward_entropy": 0.012718095311096736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50822325446643e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813766524195671,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11936114728450775,
      "backward_entropy": 0.012716759528432573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001145760907093063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028137782588601112,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11935892701148987,
      "backward_entropy": 0.00693772839648383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.809606854105368e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028137879446148872,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11935655772686005,
      "backward_entropy": 0.012714285935674394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.357692761113867e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813795767724514,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11935404688119888,
      "backward_entropy": 0.006936802395752498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.629646279383451e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813802659511566,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11935151368379593,
      "backward_entropy": 0.0069364192230360845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.262506212806329e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138093650341034,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11934905499219894,
      "backward_entropy": 0.0069360339215823585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.385868957499042e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138160705566406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11934664845466614,
      "backward_entropy": 0.006935657135077885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.291542715393007e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02813822776079178,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11934433877468109,
      "backward_entropy": 0.008065351418086461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.771552580175921e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138278052210808,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11934187263250351,
      "backward_entropy": 0.006934987115008491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.650365685345605e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813832461833954,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11933942139148712,
      "backward_entropy": 0.012708457452910287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.869782424066216e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813836745917797,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11933700740337372,
      "backward_entropy": 0.006934420338698796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.610320658888668e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138417750597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11933474242687225,
      "backward_entropy": 0.006934128701686859,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4313495638780296e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813846804201603,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11933252960443497,
      "backward_entropy": 0.006933825356619698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.314224058063701e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138529509305954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11933055520057678,
      "backward_entropy": 0.0069335028529167175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3934134484734386e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138581663370132,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11932854354381561,
      "backward_entropy": 0.006933221859591348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.545849878923036e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028138620778918266,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11932642757892609,
      "backward_entropy": 0.012704378792217799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8879108362598345e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813866175711155,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11932434141635895,
      "backward_entropy": 0.006932738636221204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.296807699371129e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138691559433937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11932218074798584,
      "backward_entropy": 0.0069325316165174755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.961231777793728e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813873440027237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11932025849819183,
      "backward_entropy": 0.006932282022067479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6615390854422e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0281387772411108,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11931838095188141,
      "backward_entropy": 0.006932031895433154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.860967990476638e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028138810768723488,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11931640654802322,
      "backward_entropy": 0.008073863174234117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9709590307902545e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138848021626472,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11931454390287399,
      "backward_entropy": 0.006931589650256293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.889854476961773e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028138894587755203,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1193128377199173,
      "backward_entropy": 0.006931335266147341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1311417842516676e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028138944879174232,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11931122839450836,
      "backward_entropy": 0.012699873319693975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.034726589452475e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02813899889588356,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11930972337722778,
      "backward_entropy": 0.008075708789484841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.796428270812612e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139039874076843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11930809915065765,
      "backward_entropy": 0.006930535393101829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.379743818892166e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028139080852270126,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11930649727582932,
      "backward_entropy": 0.012698109660829817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.142995774396695e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813911810517311,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11930489540100098,
      "backward_entropy": 0.012697623244353704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.773738767951727e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139157220721245,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11930334568023682,
      "backward_entropy": 0.006929871227060046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.613957076391671e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813919633626938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11930184066295624,
      "backward_entropy": 0.006929640259061541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.40770896198228e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028139233589172363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11930035054683685,
      "backward_entropy": 0.012696119291441781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3942389816511422e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028139272704720497,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11929892748594284,
      "backward_entropy": 0.008078710309096746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8044222088065e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028139308094978333,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11929750442504883,
      "backward_entropy": 0.00807912221976689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.33999417105224e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139350935816765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11929617822170258,
      "backward_entropy": 0.006928768541131701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7313777789240703e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0281393900513649,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11929488182067871,
      "backward_entropy": 0.006928609950201852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9308485207147896e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02813943289220333,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11929367482662201,
      "backward_entropy": 0.012693607381411962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1740028387284838e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028139473870396614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192924827337265,
      "backward_entropy": 0.012693083712032862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7659833247307688e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0281395073980093,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11929122358560562,
      "backward_entropy": 0.01269261964729854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6764932297519408e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028139539062976837,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11928997933864594,
      "backward_entropy": 0.008081035954611642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7517209926154464e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028139567002654076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11928872764110565,
      "backward_entropy": 0.012691763894898551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3273993317852728e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028139598667621613,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11928754299879074,
      "backward_entropy": 0.012691314731325423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7334406948066317e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0281396321952343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11928640305995941,
      "backward_entropy": 0.0069274625607899255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2138450074417051e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028139661997556686,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11928528547286987,
      "backward_entropy": 0.008082233369350433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5792023987160064e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028139693662524223,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11928419768810272,
      "backward_entropy": 0.008082500525883265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.526870983070694e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02813972905278206,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11928319931030273,
      "backward_entropy": 0.006926934101751873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.750994852045551e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028139764443039894,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11928223073482513,
      "backward_entropy": 0.01268894225358963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1951164196943864e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139788657426834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11928118020296097,
      "backward_entropy": 0.006926610001495906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1980565432168078e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139811009168625,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11928011476993561,
      "backward_entropy": 0.006926494517496654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.2157114371075295e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139838948845863,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927914619445801,
      "backward_entropy": 0.006926331669092178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.8629534477368e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0281398706138134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927825212478638,
      "backward_entropy": 0.0069261400827339715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.199295163853094e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028139902278780937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927740275859833,
      "backward_entropy": 0.006925957543509347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.787677870714106e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028139937669038773,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11927659809589386,
      "backward_entropy": 0.01268633667911802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149701327260118e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028139974921941757,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11927584558725357,
      "backward_entropy": 0.008084434483732496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.459323337068781e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02814001403748989,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11927514523267746,
      "backward_entropy": 0.008084526019436973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.408894932974363e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140056878328323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927451938390732,
      "backward_entropy": 0.006925080503736224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.790156476199627e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140099719166756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11927393823862076,
      "backward_entropy": 0.012684190911906106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399750186072197e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814014069736004,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11927333474159241,
      "backward_entropy": 0.012683662985052382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.779441042046528e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140177950263023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927275359630585,
      "backward_entropy": 0.006924392389399665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.748828698415309e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140217065811157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927217990159988,
      "backward_entropy": 0.006924208785806384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.869199867447605e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814025618135929,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927162855863571,
      "backward_entropy": 0.0069240289075034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598210918833502e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028140295296907425,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11927111446857452,
      "backward_entropy": 0.00808487513235637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.484215191449039e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140336275100708,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927065998315811,
      "backward_entropy": 0.006923639880759376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.275427949731238e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140373528003693,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11927017569541931,
      "backward_entropy": 0.006923464792115348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.756351361516863e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140408918261528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11926969885826111,
      "backward_entropy": 0.01268025061913899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.582996098179137e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140444308519363,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192692369222641,
      "backward_entropy": 0.012679819549833025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.426567102200352e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814047783613205,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926878243684769,
      "backward_entropy": 0.006922974118164608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.439887445390923e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140513226389885,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926837265491486,
      "backward_entropy": 0.006922789982386998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.055961198901059e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814054675400257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11926797032356262,
      "backward_entropy": 0.01267855507986886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.912918368267128e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140582144260406,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926762759685516,
      "backward_entropy": 0.006922470139605659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.733069545181934e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140611946582794,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926722526550293,
      "backward_entropy": 0.006922346140657153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.019419409611146e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140639886260033,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192668229341507,
      "backward_entropy": 0.00692220830491611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7495400445332052e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140665963292122,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11926640570163727,
      "backward_entropy": 0.012677046869482313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.816516138816951e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814069204032421,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11926603317260742,
      "backward_entropy": 0.012676713722092765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.413307013033773e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814071625471115,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926563084125519,
      "backward_entropy": 0.006921837904623577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.135387032671133e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814074046909809,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926524341106415,
      "backward_entropy": 0.006921735725232533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.952325187128736e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140762820839882,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192648857831955,
      "backward_entropy": 0.01267579197883606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.925751121234498e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140783309936523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926449835300446,
      "backward_entropy": 0.006921540413584028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0568860438506817e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140805661678314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192641407251358,
      "backward_entropy": 0.006921423865216119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7065009362559067e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028140824288129807,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11926378309726715,
      "backward_entropy": 0.008085858608995165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.887548705781228e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814084105193615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192634105682373,
      "backward_entropy": 0.012674743575709206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.495914602855919e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140855953097343,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926303803920746,
      "backward_entropy": 0.0069211795926094055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.052497620752547e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140872716903687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192627102136612,
      "backward_entropy": 0.012674309313297272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7192988934766618e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814089134335518,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926239728927612,
      "backward_entropy": 0.00692100716488702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.868989784270525e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814090996980667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926211416721344,
      "backward_entropy": 0.006920923611947468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7196621229231823e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028140930458903313,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11926185339689255,
      "backward_entropy": 0.01267357702766146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4598828076705104e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140950947999954,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926161497831345,
      "backward_entropy": 0.006920744265828814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7239685803360771e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140967711806297,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926133930683136,
      "backward_entropy": 0.006920667099101203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8775244825519621e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814098447561264,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926106363534927,
      "backward_entropy": 0.0069205909967422485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9367771528777666e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028140999376773834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11926078796386719,
      "backward_entropy": 0.0069205207484109065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5420521322084824e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02814101241528988,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1192605197429657,
      "backward_entropy": 0.008086619632584708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1002642850144184e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141025453805923,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192602664232254,
      "backward_entropy": 0.006920387702328818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.241885340481531e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141040354967117,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192600429058075,
      "backward_entropy": 0.006920333951711655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3554564475271036e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141051530838013,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925976723432541,
      "backward_entropy": 0.012671994311468942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0162480066355783e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141062706708908,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925952136516571,
      "backward_entropy": 0.012671816561903273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.331072874374513e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141075745224953,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192592978477478,
      "backward_entropy": 0.006920155669961657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1946644917770755e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028141090646386147,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925911158323288,
      "backward_entropy": 0.008087012384619032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.803032980926218e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814110368490219,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925892531871796,
      "backward_entropy": 0.006920039653778076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2659497770073358e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028141116723418236,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925874650478363,
      "backward_entropy": 0.008087099662848882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.489427270636952e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814112976193428,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192585676908493,
      "backward_entropy": 0.012670940586498805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.506622179993428e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028141140937805176,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925837397575378,
      "backward_entropy": 0.008087197584765298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1686264542731806e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814115211367607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925819516181946,
      "backward_entropy": 0.006919824119125094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.794443715487432e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141163289546967,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925801634788513,
      "backward_entropy": 0.01267048077923911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.685365173732862e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141172602772713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925783008337021,
      "backward_entropy": 0.012670321123940604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.729943263257155e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814118191599846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925764381885529,
      "backward_entropy": 0.0069196995879922596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.159571732197946e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141189366579056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925746500492096,
      "backward_entropy": 0.012670089091573442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.588329822283413e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141196817159653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925727128982544,
      "backward_entropy": 0.006919628807476589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.130779972110759e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814120426774025,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925707757472992,
      "backward_entropy": 0.01266985067299434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.828243049814773e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141209855675697,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192568689584732,
      "backward_entropy": 0.006919566009725843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.520709234791866e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141217306256294,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925669014453888,
      "backward_entropy": 0.006919542061431068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.042247034405591e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141222894191742,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925652623176575,
      "backward_entropy": 0.006919501615422112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.72403735077387e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814122848212719,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925636231899261,
      "backward_entropy": 0.00691947979586465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.122778361510427e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141234070062637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925618350505829,
      "backward_entropy": 0.006919460637228829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.552503807848552e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141239657998085,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925601959228516,
      "backward_entropy": 0.012669286557606288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4499498130790016e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141245245933533,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925585567951202,
      "backward_entropy": 0.012669197150639125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.204767603572691e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814124897122383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192556843161583,
      "backward_entropy": 0.00691938613142286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.959697434969712e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814125269651413,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925552040338516,
      "backward_entropy": 0.006919354200363159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.533967168958043e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141256421804428,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925536394119263,
      "backward_entropy": 0.006919339299201965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6849698403784714e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028141260147094727,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1192551851272583,
      "backward_entropy": 0.008088369454656328,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.138744375519309e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141263872385025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925502121448517,
      "backward_entropy": 0.006919313754354205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8075512520663324e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141267597675323,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925486475229263,
      "backward_entropy": 0.006919300981930324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3073411032091826e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141271322965622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192547157406807,
      "backward_entropy": 0.006919269050870623,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.575921994070086e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814127504825592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925455927848816,
      "backward_entropy": 0.006919254149709429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5917690865971963e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814127877354622,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925441026687622,
      "backward_entropy": 0.012668625584670476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1772663078299956e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141282498836517,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925426870584488,
      "backward_entropy": 0.012668567044394357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0422295910502726e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141286224126816,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925412714481354,
      "backward_entropy": 0.006919219557728086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4351095362362685e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141288086771965,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192539781332016,
      "backward_entropy": 0.006919194545064654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8816148756050097e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141289949417114,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925382912158966,
      "backward_entropy": 0.0069191860301154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.909260956585058e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141291812062263,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925369501113892,
      "backward_entropy": 0.012668362685612269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7247747880210227e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141293674707413,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925353854894638,
      "backward_entropy": 0.012668316917760032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1057444143934845e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141295537352562,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925339698791504,
      "backward_entropy": 0.01266827221427645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.845634696768684e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02814129739999771,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1192532479763031,
      "backward_entropy": 0.008089166666780199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2663542154077732e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814129739999771,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925311386585236,
      "backward_entropy": 0.006919149309396744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2812618283296615e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02814129739999771,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925296485424042,
      "backward_entropy": 0.008089302373783929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.489168539592356e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814129739999771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925281584262848,
      "backward_entropy": 0.012668141296931676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8404030299734586e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814129926264286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925268173217773,
      "backward_entropy": 0.006919115781784058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6229257937538932e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814130112528801,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925254762172699,
      "backward_entropy": 0.012668090207236153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6528566959550517e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814130298793316,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925242841243744,
      "backward_entropy": 0.006919100880622864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4618530030929833e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141304850578308,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925230920314789,
      "backward_entropy": 0.012668005057743617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0395754657110956e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141306713223457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925218999385834,
      "backward_entropy": 0.01266797206231526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2413846661729622e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141308575868607,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925209313631058,
      "backward_entropy": 0.006919084915093013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3026810563587787e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141312301158905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925198137760162,
      "backward_entropy": 0.00691907640014376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.093966375265154e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141316026449203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925189942121506,
      "backward_entropy": 0.012667833694389887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1263698951324841e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141319751739502,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192518025636673,
      "backward_entropy": 0.006919032228844506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289953257190064e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0281413234770298,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925172805786133,
      "backward_entropy": 0.008089756859200341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1171731273407204e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0281413272023201,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925163865089417,
      "backward_entropy": 0.008089778678757804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.105319924477044e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141330927610397,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192515641450882,
      "backward_entropy": 0.012667636786188399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.537804857018273e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141334652900696,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925148218870163,
      "backward_entropy": 0.006918980606964656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.200300610245904e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141338378190994,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925140768289566,
      "backward_entropy": 0.012667521834373474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99525787190214e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141342103481293,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925134062767029,
      "backward_entropy": 0.012667469680309296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.239731386083804e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814134582877159,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925128847360611,
      "backward_entropy": 0.012667411140033178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6434657835779944e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814134955406189,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925122141838074,
      "backward_entropy": 0.006918874170098986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.188499585528916e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141353279352188,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925116181373596,
      "backward_entropy": 0.0069188544792788366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.183065520166565e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141357004642487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925111711025238,
      "backward_entropy": 0.0069188401103019714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9452645473356824e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141360729932785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192510724067688,
      "backward_entropy": 0.006918824676956449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.311022187650451e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141364455223083,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925101280212402,
      "backward_entropy": 0.012667132275445121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9257015294633675e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028141368180513382,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925095319747925,
      "backward_entropy": 0.008089903209890639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.214437592826471e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814137190580368,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925089359283447,
      "backward_entropy": 0.0069187719907079425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.4308415542436705e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814137563109398,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192508339881897,
      "backward_entropy": 0.006918758153915405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.945653131471772e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141379356384277,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925078928470612,
      "backward_entropy": 0.006918745381491525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.499072403518767e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141383081674576,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925073713064194,
      "backward_entropy": 0.012666921530451094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.500573342307689e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141386806964874,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925068497657776,
      "backward_entropy": 0.006918707064219883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.222545951255597e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141388669610023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925064027309418,
      "backward_entropy": 0.006918699081454959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.445519152795896e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141390532255173,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192505806684494,
      "backward_entropy": 0.006918686309031078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3458524012198723e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141392394900322,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925053596496582,
      "backward_entropy": 0.006918677794081824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7101862915278616e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814139425754547,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925048381090164,
      "backward_entropy": 0.006918669279132571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7734074592444813e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814139612019062,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925044655799866,
      "backward_entropy": 0.00691865969981466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.834536954627765e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02814139798283577,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925040185451508,
      "backward_entropy": 0.006918635751519885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7878756131703994e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02814139984548092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192503571510315,
      "backward_entropy": 0.012666661824498857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3820680539188288e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141401708126068,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925031244754791,
      "backward_entropy": 0.006918622446911675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3615170324499104e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028141403570771217,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925027519464493,
      "backward_entropy": 0.00809005435023989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4442493301867216e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141405433416367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925023794174194,
      "backward_entropy": 0.012666575610637665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.320487624274392e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028141407296061516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11925019323825836,
      "backward_entropy": 0.006918591580220631,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9266248091630587e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028141409158706665,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11925016343593597,
      "backward_entropy": 0.01266651600599289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.993200709511257e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028141411021351814,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11925014108419418,
      "backward_entropy": 0.008090077234166009,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 6.667272080296271e-07,
    "avg_log_Z": 0.028141217827796935,
    "success_rate": 1.0,
    "avg_reward": 46.2,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.13,
      "1": 0.32,
      "2": 0.55
    },
    "avg_forward_entropy": 0.11925523959100247,
    "avg_backward_entropy": 0.008911425577742714,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}