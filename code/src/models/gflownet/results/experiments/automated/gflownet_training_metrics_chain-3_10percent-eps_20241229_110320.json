{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103193442026773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.23103143771489462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84408187866211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450937032699585,
      "backward_entropy": 0.2310487429300944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84164047241211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745160162448883,
      "backward_entropy": 0.23102744420369467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.468101501464844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00019999989308416843,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745223641395569,
      "backward_entropy": 0.23102239767710367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.836793899536133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00029991776682436466,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745283246040344,
      "backward_entropy": 0.23104894161224365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.481576919555664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00039988785283640027,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27453407645225525,
      "backward_entropy": 0.23104852437973022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.739178657531738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005000321543775499,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274539589881897,
      "backward_entropy": 0.2310035228729248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.906332492828369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0006000983994454145,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27454501390457153,
      "backward_entropy": 0.2309959332148234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.470914840698242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0006998477620072663,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27455049753189087,
      "backward_entropy": 0.23104528586069742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.649372100830078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.000799845380242914,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745557427406311,
      "backward_entropy": 0.23104339838027954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.370843887329102,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009000624995678663,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27456074953079224,
      "backward_entropy": 0.23096861441930136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.72685432434082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010003740899264812,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27456551790237427,
      "backward_entropy": 0.23097455501556396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.636417388916016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011005669366568327,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27456989884376526,
      "backward_entropy": 0.23096513748168945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.721741676330566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00120093475561589,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745741009712219,
      "backward_entropy": 0.23093460003534952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.542200088500977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0013011652044951916,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27457788586616516,
      "backward_entropy": 0.23094463348388672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89451789855957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0014015613123774529,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27458110451698303,
      "backward_entropy": 0.2309075395266215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.079703330993652,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015018511330708861,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27458423376083374,
      "backward_entropy": 0.23092234134674072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981412887573242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016017905436456203,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27458685636520386,
      "backward_entropy": 0.2310108741124471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.522199630737305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017017428763210773,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745892405509949,
      "backward_entropy": 0.23089629411697388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.337342262268066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018015316454693675,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745916247367859,
      "backward_entropy": 0.23088173071543375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2572174072265625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0019014887511730194,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274593710899353,
      "backward_entropy": 0.23082216580708823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.631153106689453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020008108112961054,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459561824798584,
      "backward_entropy": 0.23084946473439535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.525744438171387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0020997796673327684,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274596631526947,
      "backward_entropy": 0.23083134492238364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.696953773498535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00219877902418375,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459728717803955,
      "backward_entropy": 0.2308123509089152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.708410739898682,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002297854283824563,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459776401519775,
      "backward_entropy": 0.23079230388005575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.880023956298828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023966128937900066,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745981812477112,
      "backward_entropy": 0.23093515634536743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.408705711364746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024955824483186007,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745979428291321,
      "backward_entropy": 0.2309217850367228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704045295715332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002594925696030259,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745974361896515,
      "backward_entropy": 0.23090747992197672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.966569900512695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026943539269268513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745962142944336,
      "backward_entropy": 0.23089226086934408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66328239440918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00279395398683846,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745945453643799,
      "backward_entropy": 0.23087604840596518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.131546020507812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0028939442709088326,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745928168296814,
      "backward_entropy": 0.2306468884150187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.584308624267578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029940796084702015,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27459073066711426,
      "backward_entropy": 0.23061863581339517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.464428901672363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030940936412662268,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27458879351615906,
      "backward_entropy": 0.23058871428171793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.121919631958008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00319434842094779,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27458682656288147,
      "backward_entropy": 0.23055771986643472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.762996673583984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0032947128638625145,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27458447217941284,
      "backward_entropy": 0.23077897230784097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.376791000366211,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0033950209617614746,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745819091796875,
      "backward_entropy": 0.23037660121917725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.63393497467041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034955302253365517,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745789587497711,
      "backward_entropy": 0.23033597071965536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73462963104248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035963139962404966,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27457568049430847,
      "backward_entropy": 0.230293869972229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.397504806518555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036969289649277925,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27457255125045776,
      "backward_entropy": 0.2306804656982422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.9727201461792,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037972908467054367,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745693027973175,
      "backward_entropy": 0.2303402622540792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.542657852172852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0038980955723673105,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745654582977295,
      "backward_entropy": 0.2306234041849772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.482881546020508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003999134059995413,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27456092834472656,
      "backward_entropy": 0.23010329405466715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.644720077514648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004099908284842968,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27455613017082214,
      "backward_entropy": 0.23021324475606283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.775956630706787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004200499504804611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27455127239227295,
      "backward_entropy": 0.23053415616353354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73154067993164,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004300555679947138,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27454662322998047,
      "backward_entropy": 0.22993423541386923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.26447868347168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004400565288960934,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27454179525375366,
      "backward_entropy": 0.23046871026357016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.330329895019531,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0045007988810539246,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2745363712310791,
      "backward_entropy": 0.23043354352315268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.767953872680664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00460122711956501,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27453097701072693,
      "backward_entropy": 0.22996008396148682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.114578247070312,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004702036269009113,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2745249271392822,
      "backward_entropy": 0.22967918713887533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.459813117980957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004802430979907513,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27451908588409424,
      "backward_entropy": 0.22984488805135092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.761961936950684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004902619868516922,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27451321482658386,
      "backward_entropy": 0.22978361447652182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.453550338745117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005002297461032867,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2745078206062317,
      "backward_entropy": 0.22971896330515543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61135482788086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005101850721985102,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27450239658355713,
      "backward_entropy": 0.23018360137939453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.300230026245117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005201347172260284,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27449697256088257,
      "backward_entropy": 0.22958107789357504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.974775314331055,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005301120691001415,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744911015033722,
      "backward_entropy": 0.22950843969980875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.1309232711792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005401031579822302,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27448466420173645,
      "backward_entropy": 0.230029026667277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84912109375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005501116160303354,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744778096675873,
      "backward_entropy": 0.22935537497202554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9287238121032715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005601185839623213,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27447089552879333,
      "backward_entropy": 0.2289725144704183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.34433364868164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005700855515897274,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744644284248352,
      "backward_entropy": 0.22985597451527914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.26617431640625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005800775717943907,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744576632976532,
      "backward_entropy": 0.2297938664754232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.108070373535156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005900476593524218,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744509279727936,
      "backward_entropy": 0.22972965240478516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.760366439819336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006000370718538761,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744435966014862,
      "backward_entropy": 0.22891302903493246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4111480712890625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006100267171859741,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2744360566139221,
      "backward_entropy": 0.22849194208780924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.65956974029541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006199547555297613,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744292616844177,
      "backward_entropy": 0.22871124744415283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.746565818786621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006298841442912817,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.274422287940979,
      "backward_entropy": 0.22860477368036905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.174269676208496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006398203317075968,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2744143009185791,
      "backward_entropy": 0.2293640375137329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.804269790649414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006497849710285664,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27440565824508667,
      "backward_entropy": 0.22805037101109824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890096664428711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006597519852221012,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743968367576599,
      "backward_entropy": 0.2291959524154663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.723095893859863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006697266362607479,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2743872404098511,
      "backward_entropy": 0.22910650571187338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.240946769714355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006797471083700657,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27437645196914673,
      "backward_entropy": 0.22768310705820718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.550536155700684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006897913292050362,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743645906448364,
      "backward_entropy": 0.22755420207977295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.227214813232422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006998674012720585,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27435171604156494,
      "backward_entropy": 0.22742184003194174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8474016189575195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007099602371454239,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27433788776397705,
      "backward_entropy": 0.22871522108713785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.112451553344727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007199938874691725,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743253707885742,
      "backward_entropy": 0.22714571158091226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.115917205810547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00730087561532855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27431124448776245,
      "backward_entropy": 0.2284994920094808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.422686576843262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00740189291536808,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742964029312134,
      "backward_entropy": 0.22719407081604004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9172210693359375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007503089029341936,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2742807865142822,
      "backward_entropy": 0.22704337040583292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51336669921875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007603704463690519,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742666006088257,
      "backward_entropy": 0.22814840078353882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.749983787536621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007704141549766064,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27425265312194824,
      "backward_entropy": 0.22672625382741293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.07822322845459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007804017048329115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274240106344223,
      "backward_entropy": 0.22789718707402548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.403313636779785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007904073223471642,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27422648668289185,
      "backward_entropy": 0.22600024938583374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.573766708374023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008004455827176571,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27421146631240845,
      "backward_entropy": 0.22763137022654215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.458643913269043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008104728534817696,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2741963267326355,
      "backward_entropy": 0.22563199202219644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.714290618896484,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008204787038266659,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.274181604385376,
      "backward_entropy": 0.22544004519780478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.036985397338867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008304820396006107,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741665244102478,
      "backward_entropy": 0.22719955444335938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.78500747680664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008404999040067196,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274150550365448,
      "backward_entropy": 0.22704700628916422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.030333518981934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008505187928676605,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27413409948349,
      "backward_entropy": 0.22689024607340494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.980839729309082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008604983799159527,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274119108915329,
      "backward_entropy": 0.226729154586792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.81395149230957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008705394342541695,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27410203218460083,
      "backward_entropy": 0.2248158852259318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.474958419799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008806287311017513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2740829586982727,
      "backward_entropy": 0.22638837496439615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.620054244995117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008907435461878777,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740624248981476,
      "backward_entropy": 0.2243725856145223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729768753051758,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00900886207818985,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740405201911926,
      "backward_entropy": 0.2241444190343221,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.271438598632812,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009110131300985813,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27401918172836304,
      "backward_entropy": 0.22583397229512533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.130277633666992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009211485274136066,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739964723587036,
      "backward_entropy": 0.2256385882695516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.051239967346191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009312340058386326,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27397555112838745,
      "backward_entropy": 0.22543787956237793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.716100692749023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009412741288542747,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27395617961883545,
      "backward_entropy": 0.22523224353790283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.156004905700684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009513533674180508,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739345133304596,
      "backward_entropy": 0.22249281406402588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.855690002441406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009614437818527222,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27391213178634644,
      "backward_entropy": 0.2222264806429545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.404050827026367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009714754298329353,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27389195561408997,
      "backward_entropy": 0.22195271650950113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15782642364502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00981584470719099,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27386796474456787,
      "backward_entropy": 0.22167416413625082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.510881423950195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009916486218571663,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27384525537490845,
      "backward_entropy": 0.22409343719482422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.635171890258789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01001745369285345,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27382102608680725,
      "backward_entropy": 0.22145978609720865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.831496238708496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010118710808455944,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27379462122917175,
      "backward_entropy": 0.22115735212961832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.032008171081543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010219823569059372,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376800775527954,
      "backward_entropy": 0.22084871927897134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.054166793823242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01032040361315012,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737433910369873,
      "backward_entropy": 0.2205318013827006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.190457344055176,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01042106468230486,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27371764183044434,
      "backward_entropy": 0.21986504395802817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.927297592163086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010521849617362022,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27369046211242676,
      "backward_entropy": 0.21953962246576944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.713549613952637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010622571222484112,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27366259694099426,
      "backward_entropy": 0.22215537230173746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.122058868408203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010723221115767956,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27363476157188416,
      "backward_entropy": 0.21886559327443442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.964607238769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010823412798345089,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736087441444397,
      "backward_entropy": 0.2185155153274536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.178327560424805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010923638939857483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2735815644264221,
      "backward_entropy": 0.22119716803232828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.880577087402344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01102400105446577,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27355265617370605,
      "backward_entropy": 0.21779046456019083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.541669845581055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011125416494905949,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27351754903793335,
      "backward_entropy": 0.21741978327433267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.289031982421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011226538568735123,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2734830677509308,
      "backward_entropy": 0.21704010168711343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7496209144592285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011327780783176422,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27344486117362976,
      "backward_entropy": 0.2197871208190918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.555329322814941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011428339406847954,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27340900897979736,
      "backward_entropy": 0.2164461612701416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.333919525146484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011528672650456429,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733730971813202,
      "backward_entropy": 0.21903189023335776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.45981216430664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011628738604485989,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733384370803833,
      "backward_entropy": 0.21542616685231528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13831901550293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011728613637387753,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733039855957031,
      "backward_entropy": 0.2182398239771525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.980354309082031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011828143149614334,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732708752155304,
      "backward_entropy": 0.21464010079701742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.294607162475586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011927299201488495,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27323976159095764,
      "backward_entropy": 0.21741159756978354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.750779151916504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012026781216263771,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27320489287376404,
      "backward_entropy": 0.2136541207631429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.968308925628662,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012126266956329346,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27316856384277344,
      "backward_entropy": 0.2131877342859904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.853636741638184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01222530473023653,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731342315673828,
      "backward_entropy": 0.21610267957051596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.28868293762207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012323986738920212,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731022238731384,
      "backward_entropy": 0.2156611680984497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.53152084350586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012423061765730381,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730654776096344,
      "backward_entropy": 0.21167592207590738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.323034286499023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012522091157734394,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27302759885787964,
      "backward_entropy": 0.2147441307703654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.648850440979004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012621510773897171,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729851007461548,
      "backward_entropy": 0.21056624253590903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6042327880859375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012720937840640545,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2729414701461792,
      "backward_entropy": 0.2101041873296102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.32947826385498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012819809839129448,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2729020118713379,
      "backward_entropy": 0.20955955982208252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.853296279907227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012919110246002674,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27285751700401306,
      "backward_entropy": 0.21277948220570883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.738041877746582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013018508441746235,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2728102207183838,
      "backward_entropy": 0.20843327045440674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76884937286377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013117378577589989,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727659344673157,
      "backward_entropy": 0.20762952168782553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.120614051818848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013216422870755196,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727198004722595,
      "backward_entropy": 0.20699886480967203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.640337944030762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013315173797309399,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726740837097168,
      "backward_entropy": 0.210645854473114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.516331672668457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013414032757282257,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2726263999938965,
      "backward_entropy": 0.21007810036341348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9159650802612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013512867502868176,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2725762724876404,
      "backward_entropy": 0.20539170503616333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528749942779541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013611340895295143,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27252742648124695,
      "backward_entropy": 0.2089086373647054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8111443519592285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01370926108211279,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2724817991256714,
      "backward_entropy": 0.20831122001012167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.76544713973999,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01380689162760973,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27243804931640625,
      "backward_entropy": 0.2077029546101888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.251509666442871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01390419714152813,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723953127861023,
      "backward_entropy": 0.2070847749710083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.996511936187744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01400152500718832,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723507881164551,
      "backward_entropy": 0.2015827496846517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.044784545898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01409869734197855,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2723054885864258,
      "backward_entropy": 0.20124071836471558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.477571964263916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01419577095657587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722591161727905,
      "backward_entropy": 0.2051537831624349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.880212783813477,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014292472042143345,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.272216260433197,
      "backward_entropy": 0.20448789993921915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.371074676513672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014389583840966225,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27216583490371704,
      "backward_entropy": 0.20380528767903647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6741180419921875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014486291445791721,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2721194922924042,
      "backward_entropy": 0.20311311880747476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.729121208190918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014582784846425056,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27207452058792114,
      "backward_entropy": 0.19742723306020102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720850467681885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014679666608572006,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2720222473144531,
      "backward_entropy": 0.19618316491444907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.03833293914795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014776286669075489,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2719695568084717,
      "backward_entropy": 0.2009547750155131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.658833980560303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014872872270643711,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27191412448883057,
      "backward_entropy": 0.19452246030171713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.377127170562744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014969196170568466,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2718585133552551,
      "backward_entropy": 0.193677286307017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15912914276123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015065161511301994,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2718072235584259,
      "backward_entropy": 0.1928181250890096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.501599311828613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015161274932324886,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2717529535293579,
      "backward_entropy": 0.1919421156247457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.819571495056152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015258250758051872,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2716830372810364,
      "backward_entropy": 0.1916365623474121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.833316802978516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015355072915554047,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2716079354286194,
      "backward_entropy": 0.19015634059906006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4097161293029785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015451736748218536,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2715306282043457,
      "backward_entropy": 0.1898792584737142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.119914054870605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01554802805185318,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27145519852638245,
      "backward_entropy": 0.1945363481839498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.175426483154297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01564444974064827,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713766098022461,
      "backward_entropy": 0.19366437196731567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.566538333892822,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01574096456170082,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27129191160202026,
      "backward_entropy": 0.18632535139719644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.958315849304199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015836698934435844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2712218761444092,
      "backward_entropy": 0.19188302755355835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.264694213867188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015931924805045128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2711581289768219,
      "backward_entropy": 0.19098136822382608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.033929824829102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01602746732532978,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.271085649728775,
      "backward_entropy": 0.19005938371022543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.712150573730469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016123168170452118,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2710072994232178,
      "backward_entropy": 0.18911929925282797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1821794509887695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016218775883316994,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27092456817626953,
      "backward_entropy": 0.18115214506785074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.635256290435791,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01631401665508747,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27084410190582275,
      "backward_entropy": 0.18140214681625366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.109920501708984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016408592462539673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2707712948322296,
      "backward_entropy": 0.18622851371765137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.812248229980469,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01650349609553814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2706892788410187,
      "backward_entropy": 0.18523667256037393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.900145530700684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01659851148724556,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27060145139694214,
      "backward_entropy": 0.17677334944407144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6326494216918945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016693707555532455,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2705081105232239,
      "backward_entropy": 0.17731332778930664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.523011207580566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016788309440016747,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27042555809020996,
      "backward_entropy": 0.17447954416275024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.718714237213135,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016883499920368195,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27032920718193054,
      "backward_entropy": 0.1752087672551473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39408016204834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01697867549955845,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27022504806518555,
      "backward_entropy": 0.17213710149129233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634599208831787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017073705792427063,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.270119309425354,
      "backward_entropy": 0.1730495492617289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7041473388671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017168734222650528,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2700076401233673,
      "backward_entropy": 0.17784897486368814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.818312644958496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017263216897845268,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26990336179733276,
      "backward_entropy": 0.17674225568771362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.660012722015381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017356619238853455,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26981598138809204,
      "backward_entropy": 0.17563925186793009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.255845069885254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017449593171477318,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26973170042037964,
      "backward_entropy": 0.17452786366144815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.315340518951416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01754256896674633,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26964128017425537,
      "backward_entropy": 0.16746709744135538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.10262393951416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017635570839047432,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26954299211502075,
      "backward_entropy": 0.1722570856412252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9294023513793945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01772850938141346,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26944172382354736,
      "backward_entropy": 0.16516712307929993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.648436546325684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017821263521909714,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2693384289741516,
      "backward_entropy": 0.16400285561879477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.261023998260498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01791367121040821,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2692360579967499,
      "backward_entropy": 0.1628284454345703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.329873085021973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018005533143877983,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2691405117511749,
      "backward_entropy": 0.16755841175715128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.994419097900391,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018097590655088425,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26903316378593445,
      "backward_entropy": 0.16045457124710083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.548013210296631,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018188975751399994,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2689364552497864,
      "backward_entropy": 0.1558834115664164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.001473426818848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018280090764164925,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26883751153945923,
      "backward_entropy": 0.15804027517636618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.401491165161133,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018370622768998146,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.268746018409729,
      "backward_entropy": 0.1568180521329244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.007748126983643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01846020482480526,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26866960525512695,
      "backward_entropy": 0.1614376107851664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.060859680175781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018549395725131035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26859793066978455,
      "backward_entropy": 0.16019795338312784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.793302536010742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01863821968436241,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2685255706310272,
      "backward_entropy": 0.15894953409830728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.221352577209473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0187265332788229,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2684563398361206,
      "backward_entropy": 0.1478252410888672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.634214878082275,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01881466433405876,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26838013529777527,
      "backward_entropy": 0.15643096963564554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.26505184173584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018902281299233437,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26830974221229553,
      "backward_entropy": 0.14511958758036295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.467041969299316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018990561366081238,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26821377873420715,
      "backward_entropy": 0.14801414807637533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.870112419128418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019078895449638367,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26810765266418457,
      "backward_entropy": 0.1467208464940389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1336469650268555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019167585298419,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2679849863052368,
      "backward_entropy": 0.15121683478355408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.667508602142334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019256100058555603,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.267860472202301,
      "backward_entropy": 0.14412079254786173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.913012981414795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019344089552760124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2677392363548279,
      "backward_entropy": 0.1485270063082377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598578929901123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01943177543580532,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26761394739151,
      "backward_entropy": 0.1471710205078125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.382584571838379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01951899193227291,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.267486035823822,
      "backward_entropy": 0.1353384256362915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2814178466796875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019606348127126694,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2673396170139313,
      "backward_entropy": 0.14442205429077148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.800817966461182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0196930430829525,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2672008275985718,
      "backward_entropy": 0.1430413325627645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.158939361572266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01977957971394062,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2670600116252899,
      "backward_entropy": 0.13111003239949545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.91734504699707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019865496084094048,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26693010330200195,
      "backward_entropy": 0.13485823074976602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.570144176483154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01995060034096241,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26680776476860046,
      "backward_entropy": 0.13888947168986002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.45395565032959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02003476954996586,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2667042911052704,
      "backward_entropy": 0.1375235120455424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.80533504486084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020118750631809235,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2665911912918091,
      "backward_entropy": 0.13614904880523682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.875245571136475,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02020285651087761,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26646143198013306,
      "backward_entropy": 0.12950637936592102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.166094779968262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020287130028009415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2663128077983856,
      "backward_entropy": 0.13337348898251852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.280550003051758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020371023565530777,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2661628723144531,
      "backward_entropy": 0.1319796840349833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.680273056030273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02045467495918274,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26600730419158936,
      "backward_entropy": 0.12545719742774963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.369673728942871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020537633448839188,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26586025953292847,
      "backward_entropy": 0.11840490500132243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.425000190734863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02062050811946392,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26569926738739014,
      "backward_entropy": 0.12275225917498271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.625235557556152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020702581852674484,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26555192470550537,
      "backward_entropy": 0.12639981508255005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.520939826965332,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020784087479114532,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2654080092906952,
      "backward_entropy": 0.11416364709536235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7484822273254395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020864995196461678,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26526764035224915,
      "backward_entropy": 0.11276491483052571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8098416328430176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0209455918520689,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2651260495185852,
      "backward_entropy": 0.12225520610809326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.62294864654541,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02102510817348957,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2650097608566284,
      "backward_entropy": 0.10998019576072693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.551422595977783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021104328334331512,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2648853659629822,
      "backward_entropy": 0.1195324460665385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.691957473754883,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02118326537311077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26475799083709717,
      "backward_entropy": 0.1181684136390686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.464033603668213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02126205340027809,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2646181583404541,
      "backward_entropy": 0.11680007974306743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.646333694458008,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021340517327189445,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2644716799259186,
      "backward_entropy": 0.11543196439743042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.755833625793457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021417979151010513,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26434439420700073,
      "backward_entropy": 0.10937253634134929,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.999568462371826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021495560184121132,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2641989290714264,
      "backward_entropy": 0.11272314190864563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.807814836502075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021572520956397057,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2640528678894043,
      "backward_entropy": 0.11137219270070393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.992281198501587,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021648839116096497,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26392024755477905,
      "backward_entropy": 0.10543744762738545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8050663471221924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021723829209804535,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26382672786712646,
      "backward_entropy": 0.10872216025988261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.960980176925659,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02179833874106407,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2637324631214142,
      "backward_entropy": 0.10286433498064677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.819472551345825,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021872591227293015,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2636319696903229,
      "backward_entropy": 0.10611267884572347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.417977333068848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021946504712104797,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2635307312011719,
      "backward_entropy": 0.09381973743438721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.918307065963745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022020641714334488,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2633991241455078,
      "backward_entropy": 0.09251272678375244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5276923179626465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02209450863301754,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2632550895214081,
      "backward_entropy": 0.10218363006909688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.40049409866333,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022167788818478584,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26311445236206055,
      "backward_entropy": 0.09654261668523152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6776206493377686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022240402176976204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26297682523727417,
      "backward_entropy": 0.09959081808725993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7474989891052246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022312721237540245,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26283127069473267,
      "backward_entropy": 0.09406377871831258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2682793140411377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02238485962152481,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26267334818840027,
      "backward_entropy": 0.09283689657847087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.953552484512329,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022456392645835876,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26252466440200806,
      "backward_entropy": 0.0848893125851949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5879390239715576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022527022287249565,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26238998770713806,
      "backward_entropy": 0.09042182564735413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9962096214294434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022597484290599823,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2622367739677429,
      "backward_entropy": 0.08922593792279561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.92112135887146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022667216137051582,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2620924115180969,
      "backward_entropy": 0.08123191197713216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.809898853302002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022736167535185814,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.261951744556427,
      "backward_entropy": 0.08004692196846008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9988794326782227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022804372012615204,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26182419061660767,
      "backward_entropy": 0.08956492940584819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.573115587234497,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022872118279337883,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2616977095603943,
      "backward_entropy": 0.08836742242177327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.157646656036377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022940026596188545,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2615363895893097,
      "backward_entropy": 0.08716206749280293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7801053524017334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023007676005363464,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2613633871078491,
      "backward_entropy": 0.07539730270703633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.631049633026123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023074643686413765,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2611902356147766,
      "backward_entropy": 0.07426568865776062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7782254219055176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023140842095017433,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2610222101211548,
      "backward_entropy": 0.07315263152122498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5823283195495605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023206518962979317,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26084786653518677,
      "backward_entropy": 0.07205536961555481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5597355365753174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02327149361371994,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2606731653213501,
      "backward_entropy": 0.07782501975695293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.091073513031006,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023335879668593407,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26050323247909546,
      "backward_entropy": 0.06991009910901387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5847299098968506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02339917980134487,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26036009192466736,
      "backward_entropy": 0.07568550109863281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6566550731658936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023462025448679924,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26020312309265137,
      "backward_entropy": 0.07799697915712993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0189995765686035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0235245730727911,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2600281834602356,
      "backward_entropy": 0.07690999905268352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2194693088531494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02358607016503811,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2598688006401062,
      "backward_entropy": 0.07256077726682027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3261353969573975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02364690788090229,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2597125172615051,
      "backward_entropy": 0.07479885717233022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2160956859588623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023707278072834015,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25954824686050415,
      "backward_entropy": 0.0638656069835027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7071969509124756,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02376711182296276,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25938257575035095,
      "backward_entropy": 0.06955297787984212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9686050415039062,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023827118799090385,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25918352603912354,
      "backward_entropy": 0.06195840239524841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8185341358184814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023886384442448616,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25900185108184814,
      "backward_entropy": 0.07068560520807902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1953563690185547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02394472248852253,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25883567333221436,
      "backward_entropy": 0.06009133656819662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0377039909362793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024002743884921074,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25865671038627625,
      "backward_entropy": 0.06870719293753307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.835831642150879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024060312658548355,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.258475661277771,
      "backward_entropy": 0.06480698784192403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.037855863571167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02411709912121296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2582913041114807,
      "backward_entropy": 0.06677079200744629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6248241662979126,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024173535406589508,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25809478759765625,
      "backward_entropy": 0.06581755479176839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8203318119049072,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024229032918810844,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25790899991989136,
      "backward_entropy": 0.06211500863234202,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8040597438812256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024284038692712784,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2577221393585205,
      "backward_entropy": 0.05480746924877167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7900995016098022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024338552728295326,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2575283646583557,
      "backward_entropy": 0.06305532654126485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.821908950805664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024392638355493546,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2573283314704895,
      "backward_entropy": 0.05314783255259196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.617224097251892,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024446401745080948,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25711748003959656,
      "backward_entropy": 0.05233039458592733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4654202461242676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02449955604970455,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25690749287605286,
      "backward_entropy": 0.05152516563733419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4388630390167236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024551894515752792,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25670287013053894,
      "backward_entropy": 0.05073763430118561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.340186357498169,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024603473022580147,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25650352239608765,
      "backward_entropy": 0.0563062330087026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.716135025024414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02465415745973587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25630801916122437,
      "backward_entropy": 0.05785252650578817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0785667896270752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02470475248992443,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2560906410217285,
      "backward_entropy": 0.057025025288263954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4035224914550781,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024754179641604424,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25590085983276367,
      "backward_entropy": 0.05622126658757528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4716883897781372,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024803100153803825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25570380687713623,
      "backward_entropy": 0.055427188674608864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.372422695159912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024851679801940918,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25548943877220154,
      "backward_entropy": 0.04632064700126648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2833377122879028,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024899855256080627,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.255270779132843,
      "backward_entropy": 0.04562349617481232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1655480861663818,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024947458878159523,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25504541397094727,
      "backward_entropy": 0.051124244928359985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1454031467437744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02499437890946865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2548266053199768,
      "backward_entropy": 0.05233994126319885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9521231651306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025040602311491966,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2546073794364929,
      "backward_entropy": 0.049757430950800575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.889825165271759,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02508583851158619,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2544041872024536,
      "backward_entropy": 0.050884375969568886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0150561332702637,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025130022317171097,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25421416759490967,
      "backward_entropy": 0.048450201749801636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1765552759170532,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025173576548695564,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2540268898010254,
      "backward_entropy": 0.04173662761847178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8048046827316284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025216884911060333,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2538210451602936,
      "backward_entropy": 0.04882698257764181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7428356409072876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02525915391743183,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.253627747297287,
      "backward_entropy": 0.048169309894243874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6571005582809448,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025300374254584312,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25345146656036377,
      "backward_entropy": 0.045990834633509316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9301246404647827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02534051612019539,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25330230593681335,
      "backward_entropy": 0.0469182034333547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7349759340286255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02538023330271244,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25314009189605713,
      "backward_entropy": 0.038893831272919975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8400329351425171,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025419164448976517,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25298672914505005,
      "backward_entropy": 0.044295743107795715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8278209567070007,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02545762062072754,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25282591581344604,
      "backward_entropy": 0.04375313719113668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7013550996780396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025495652109384537,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.252658873796463,
      "backward_entropy": 0.037336928149064384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8825162053108215,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025532977655529976,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2524949908256531,
      "backward_entropy": 0.04270085692405701,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8608771562576294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02557010017335415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25230950117111206,
      "backward_entropy": 0.0434398353099823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6857574582099915,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025607014074921608,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25210487842559814,
      "backward_entropy": 0.04168189068635305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8113532066345215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025643240660429,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2518949806690216,
      "backward_entropy": 0.03539042919874191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7143741846084595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02567925862967968,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2516685724258423,
      "backward_entropy": 0.04180208841959635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7464643120765686,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02571485936641693,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25143659114837646,
      "backward_entropy": 0.04021286964416504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.549976110458374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025750136002898216,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25118935108184814,
      "backward_entropy": 0.03401603798071543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5470249652862549,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025784611701965332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2509513795375824,
      "backward_entropy": 0.040235184133052826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5995722413063049,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02581830881536007,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2507156431674957,
      "backward_entropy": 0.03973888357480367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.758266806602478,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025851473212242126,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2504734694957733,
      "backward_entropy": 0.0383894219994545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4975040853023529,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025884687900543213,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2502055764198303,
      "backward_entropy": 0.03876006603240967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47462424635887146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025917142629623413,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2499426156282425,
      "backward_entropy": 0.038282821575800575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5372284650802612,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02594882994890213,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24968357384204865,
      "backward_entropy": 0.03781892110904058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4740471839904785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025979992002248764,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24941445887088776,
      "backward_entropy": 0.03736360867818197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5001460313796997,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0260105449706316,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2491460144519806,
      "backward_entropy": 0.036316280563672386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4611023962497711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026040710508823395,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24887630343437195,
      "backward_entropy": 0.03648140529791514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3123658299446106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02607031539082527,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2486024796962738,
      "backward_entropy": 0.03605332225561142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4300488829612732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026098910719156265,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2483452558517456,
      "backward_entropy": 0.03564306596914927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3666815161705017,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02612702175974846,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.248084157705307,
      "backward_entropy": 0.029382973909378052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30139294266700745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02615448832511902,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24782735109329224,
      "backward_entropy": 0.02905719478925069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4130575656890869,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026181118562817574,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24758082628250122,
      "backward_entropy": 0.02874258408943812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27550840377807617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026207461953163147,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24732592701911926,
      "backward_entropy": 0.03409761687119802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44978588819503784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026232963427901268,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24708007276058197,
      "backward_entropy": 0.03373834242423376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30486953258514404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026258472353219986,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2468152642250061,
      "backward_entropy": 0.03337874015172323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33009153604507446,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026283403858542442,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24655503034591675,
      "backward_entropy": 0.033028741677602134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33810001611709595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02630789950489998,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24629053473472595,
      "backward_entropy": 0.027265066901842754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3802426755428314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026332052424550056,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24601879715919495,
      "backward_entropy": 0.03234804918368658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2908119559288025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026356076821684837,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2457297146320343,
      "backward_entropy": 0.032016322016716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14946317672729492,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026379592716693878,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2454383671283722,
      "backward_entropy": 0.026447579264640808,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21257886290550232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026401955634355545,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24516689777374268,
      "backward_entropy": 0.03147067377964655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17563673853874207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026423577219247818,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24489986896514893,
      "backward_entropy": 0.031076471010843914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27926209568977356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026444410905241966,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.244645357131958,
      "backward_entropy": 0.030790540079275768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26864975690841675,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026465024799108505,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24437852203845978,
      "backward_entropy": 0.02548927317063014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.259258896112442,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026485400274395943,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24410071969032288,
      "backward_entropy": 0.03022771080334981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2782430350780487,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026505541056394577,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.243813619017601,
      "backward_entropy": 0.025042419632275898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21164433658123016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0265255905687809,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2435123771429062,
      "backward_entropy": 0.02967612197001775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24392476677894592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026545213535428047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24321061372756958,
      "backward_entropy": 0.029407404363155365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1542380452156067,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02656465955078602,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24290025234222412,
      "backward_entropy": 0.029141326745351154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1483840048313141,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026583395898342133,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2425978183746338,
      "backward_entropy": 0.028885977963606518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17752240598201752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026601476594805717,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24230307340621948,
      "backward_entropy": 0.028640389442443848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17081616818904877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026619134470820427,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24200685322284698,
      "backward_entropy": 0.02381320297718048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.161959707736969,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0266363937407732,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24170997738838196,
      "backward_entropy": 0.02877659598986308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12467435747385025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026653187349438667,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24140962958335876,
      "backward_entropy": 0.027939721941947937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1623419225215912,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026669368147850037,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24111582338809967,
      "backward_entropy": 0.023279738922913868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1259937882423401,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026685329154133797,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2408202886581421,
      "backward_entropy": 0.0231114203731219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12099076807498932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02670084685087204,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.240530863404274,
      "backward_entropy": 0.022948001821835835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1421358287334442,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026715951040387154,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24024754762649536,
      "backward_entropy": 0.027095024784406025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14548924565315247,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026730773970484734,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23995964229106903,
      "backward_entropy": 0.02774537354707718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13041576743125916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02674540877342224,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23966628313064575,
      "backward_entropy": 0.02758832524220149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08503575623035431,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026759713888168335,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23936831951141357,
      "backward_entropy": 0.026508512596289318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08923079818487167,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026773419231176376,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23907984793186188,
      "backward_entropy": 0.022191467384497326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10018066316843033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026786616072058678,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23879744112491608,
      "backward_entropy": 0.026149143775304157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11812667548656464,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026799390092492104,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2385135293006897,
      "backward_entropy": 0.021923832595348358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0854484811425209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02681203931570053,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23822593688964844,
      "backward_entropy": 0.02580951650937398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10200512409210205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02682419680058956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23793962597846985,
      "backward_entropy": 0.025646939873695374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08512456715106964,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026836134493350983,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23765024542808533,
      "backward_entropy": 0.021549309293429058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07559023052453995,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026847733184695244,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2373625934123993,
      "backward_entropy": 0.025332185129324596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10178594291210175,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026858918368816376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23707766830921173,
      "backward_entropy": 0.025182594855626423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10327345132827759,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026870042085647583,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2367871105670929,
      "backward_entropy": 0.025033767024676006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05053179711103439,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026881126686930656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23648913204669952,
      "backward_entropy": 0.024885351459185284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07441471517086029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026891609653830528,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2362005114555359,
      "backward_entropy": 0.024745007356007893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07567505538463593,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02690180018544197,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23591068387031555,
      "backward_entropy": 0.025972711543242138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07285110652446747,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02691185660660267,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23562213778495789,
      "backward_entropy": 0.020794446269671123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05618681758642197,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026921723037958145,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2353328913450241,
      "backward_entropy": 0.02069762349128723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06700088828802109,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02693122997879982,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23504869639873505,
      "backward_entropy": 0.024214754501978557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05988863855600357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026940546929836273,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23476390540599823,
      "backward_entropy": 0.02408982316652934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.061392150819301605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026949632912874222,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23448102176189423,
      "backward_entropy": 0.023968137800693512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06239313632249832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026958540081977844,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2341979742050171,
      "backward_entropy": 0.020338868101437885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05614472180604935,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02696733921766281,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2339143306016922,
      "backward_entropy": 0.02373095601797104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05006396770477295,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026975959539413452,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23363152146339417,
      "backward_entropy": 0.023615509271621704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0415596105158329,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026984361931681633,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23335175216197968,
      "backward_entropy": 0.023503015438715618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0328318253159523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026992427185177803,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23307658731937408,
      "backward_entropy": 0.02339496711889903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03480413928627968,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027000118046998978,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23281055688858032,
      "backward_entropy": 0.025012701749801636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03419246897101402,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027007484808564186,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2325504571199417,
      "backward_entropy": 0.023193287352720898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05166167765855789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027014490216970444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23229321837425232,
      "backward_entropy": 0.02309902509053548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04177691787481308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027021531015634537,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2320321500301361,
      "backward_entropy": 0.023004355529944103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025183748453855515,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02702842839062214,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23177066445350647,
      "backward_entropy": 0.019671107331911724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03797701746225357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027034880593419075,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2315148264169693,
      "backward_entropy": 0.022824063897132874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029418205842375755,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027041243389248848,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23125988245010376,
      "backward_entropy": 0.024628080427646637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02821306884288788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027047378942370415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23100963234901428,
      "backward_entropy": 0.02265491584936778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039960093796253204,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02705329656600952,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2307637631893158,
      "backward_entropy": 0.01943790912628174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032281868159770966,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02705925889313221,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23051553964614868,
      "backward_entropy": 0.022493702669938404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030788008123636246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027065109461545944,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2302677184343338,
      "backward_entropy": 0.02241431673367818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02780965343117714,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02707085572183132,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2300209403038025,
      "backward_entropy": 0.022336319088935852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028428608551621437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027076441794633865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22977575659751892,
      "backward_entropy": 0.022260348002115887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027197515591979027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027081910520792007,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2295311689376831,
      "backward_entropy": 0.02425754815340042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026009421795606613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0270872600376606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22928744554519653,
      "backward_entropy": 0.022112836440404255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024757321923971176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02709249220788479,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22904479503631592,
      "backward_entropy": 0.02204137047131856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023761559277772903,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027097614482045174,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.228803813457489,
      "backward_entropy": 0.02197133998076121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021272746846079826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027102619409561157,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22856423258781433,
      "backward_entropy": 0.02190294365088145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02440910041332245,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027107473462820053,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2283274531364441,
      "backward_entropy": 0.01893930385510127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020697474479675293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027112282812595367,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22809088230133057,
      "backward_entropy": 0.018895591298739117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02185465767979622,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02711697481572628,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22785654664039612,
      "backward_entropy": 0.02170568456252416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01757025718688965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027121638879179955,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22762374579906464,
      "backward_entropy": 0.023906382421652477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01803985796868801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02712615393102169,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22739431262016296,
      "backward_entropy": 0.021579707662264507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01433707494288683,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027130546048283577,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2271668016910553,
      "backward_entropy": 0.0238288218776385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015312960371375084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02713470347225666,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2269425243139267,
      "backward_entropy": 0.02146168053150177,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01733863726258278,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02713872864842415,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2267213761806488,
      "backward_entropy": 0.023759459455808003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016305770725011826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027142727747559547,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22650158405303955,
      "backward_entropy": 0.021350296835104626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01245491299778223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027146708220243454,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2262842357158661,
      "backward_entropy": 0.021295353770256042,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010218512266874313,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02715051732957363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22607064247131348,
      "backward_entropy": 0.021242524186770122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010469498112797737,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027154110372066498,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22586201131343842,
      "backward_entropy": 0.018520043541987736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009299411438405514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027157533913850784,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22565798461437225,
      "backward_entropy": 0.01848982771237691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010844910517334938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027160769328475,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22545868158340454,
      "backward_entropy": 0.018461361527442932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00857654307037592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027163922786712646,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22526289522647858,
      "backward_entropy": 0.02105453610420227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009830459952354431,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027166899293661118,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22507116198539734,
      "backward_entropy": 0.02101217458645503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010232377797365189,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027169810608029366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22488296031951904,
      "backward_entropy": 0.02097084124883016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009542870335280895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027172666043043137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22469641268253326,
      "backward_entropy": 0.020930248002211254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008748466148972511,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027175482362508774,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22451260685920715,
      "backward_entropy": 0.023455289502938587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010731992311775684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027178218588232994,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22433117032051086,
      "backward_entropy": 0.020851343870162964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009314932860434055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02718101628124714,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2241508662700653,
      "backward_entropy": 0.020811863243579865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007314518094062805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027183806523680687,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2239723801612854,
      "backward_entropy": 0.020772598683834076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008430465124547482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027186524122953415,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22379785776138306,
      "backward_entropy": 0.020734425634145737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004696113057434559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0271892286837101,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22362519800662994,
      "backward_entropy": 0.020696538190046947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006034262478351593,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027191728353500366,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22345750033855438,
      "backward_entropy": 0.018198173493146896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007232720963656902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027194134891033173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22329318523406982,
      "backward_entropy": 0.020626944800217945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0069573670625686646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027196543291211128,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22313082218170166,
      "backward_entropy": 0.02059292917450269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0055725849233567715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02719894051551819,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22297030687332153,
      "backward_entropy": 0.023263245820999146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005226530600339174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02720125950872898,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22281280159950256,
      "backward_entropy": 0.020526307324568432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005670415237545967,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0272035114467144,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22265878319740295,
      "backward_entropy": 0.0204943244655927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004778195638209581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027205731719732285,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22250691056251526,
      "backward_entropy": 0.020462920268376667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004211694933474064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027207879349589348,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22235792875289917,
      "backward_entropy": 0.02043244242668152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003506879787892103,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027209945023059845,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22221237421035767,
      "backward_entropy": 0.020403067270914715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003608100116252899,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02721189334988594,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.222070574760437,
      "backward_entropy": 0.0203751598795255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003397804917767644,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027213748544454575,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22193190455436707,
      "backward_entropy": 0.020348443339268368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043642763048410416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027215521782636642,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22179657220840454,
      "backward_entropy": 0.020322781056165695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0041476059705019,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027217306196689606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22166311740875244,
      "backward_entropy": 0.020297081520160038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027115934062749147,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027219098061323166,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22153156995773315,
      "backward_entropy": 0.020271497468153637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003730630036443472,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027220789343118668,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22140361368656158,
      "backward_entropy": 0.0230892871816953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002826348412781954,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027222489938139915,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22127768397331238,
      "backward_entropy": 0.02307582398255666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002874374622479081,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02722412720322609,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2211546152830124,
      "backward_entropy": 0.02019938329855601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022068193648010492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027225719764828682,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22103409469127655,
      "backward_entropy": 0.020176522433757782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023991670459508896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02722722478210926,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2209170162677765,
      "backward_entropy": 0.020154766738414764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023008789867162704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02722868323326111,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2208028882741928,
      "backward_entropy": 0.020133646825949352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002455133479088545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027230093255639076,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22069144248962402,
      "backward_entropy": 0.020113130410512287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002479810267686844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027231490239501,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22058239579200745,
      "backward_entropy": 0.02009295920530955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022240036632865667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027232883498072624,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22047525644302368,
      "backward_entropy": 0.02007289230823517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002350136637687683,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027234258130192757,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22037029266357422,
      "backward_entropy": 0.020053210357824963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020918205846101046,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027235640212893486,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22026711702346802,
      "backward_entropy": 0.020033476253350575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017849871655926108,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02723701484501362,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22016629576683044,
      "backward_entropy": 0.020014002919197083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001251610228791833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027238352224230766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22006769478321075,
      "backward_entropy": 0.01999504615863164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020053102634847164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027239607647061348,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2199724018573761,
      "backward_entropy": 0.01782757043838501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017016710480675101,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027240879833698273,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21987847983837128,
      "backward_entropy": 0.017818206300338108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017911510076373816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02724214270710945,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21978649497032166,
      "backward_entropy": 0.01994132250547409,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012587166856974363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027243414893746376,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21969611942768097,
      "backward_entropy": 0.017799484233061474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015969015657901764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02724464237689972,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2196083962917328,
      "backward_entropy": 0.02291063219308853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013525162357836962,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02724587731063366,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2195223867893219,
      "backward_entropy": 0.017781339585781097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013542328961193562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027247097343206406,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2194385528564453,
      "backward_entropy": 0.017772326866785686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012043777387589216,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027248309925198555,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21935658156871796,
      "backward_entropy": 0.019855377574761707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001007274491712451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027249503880739212,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21927660703659058,
      "backward_entropy": 0.017754536122083664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011379747884348035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027250660583376884,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21919888257980347,
      "backward_entropy": 0.019823018461465836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008924811845645308,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02725180611014366,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2191227674484253,
      "backward_entropy": 0.01980731636285782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007308914791792631,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027252914384007454,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21904891729354858,
      "backward_entropy": 0.017729386687278748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007415955769829452,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027253970503807068,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21897760033607483,
      "backward_entropy": 0.019777571161588032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007963624666444957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0272549856454134,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21890845894813538,
      "backward_entropy": 0.022833431760470074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006111750844866037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027255980297923088,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21884119510650635,
      "backward_entropy": 0.01974994440873464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006204657256603241,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027256930246949196,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21877622604370117,
      "backward_entropy": 0.01770028347770373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006685318076051772,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027257846668362617,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21871331334114075,
      "backward_entropy": 0.01972426598270734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007487203693017364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027258744463324547,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21865214407444,
      "backward_entropy": 0.01768738031387329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008168360218405724,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027259645983576775,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21859222650527954,
      "backward_entropy": 0.022798707087834675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005243798368610442,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027260567992925644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21853318810462952,
      "backward_entropy": 0.019687111179033916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000591483258176595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027261460199952126,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21847599744796753,
      "backward_entropy": 0.01766759653886159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005559457349590957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02726234309375286,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2184201180934906,
      "backward_entropy": 0.01966312030951182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005223309271968901,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0272632148116827,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21836556494235992,
      "backward_entropy": 0.02277068297068278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038065778790041804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027264075353741646,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21831239759922028,
      "backward_entropy": 0.019639845937490463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033204624196514487,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027264898642897606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21826106309890747,
      "backward_entropy": 0.019628769407669704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004085032851435244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027265682816505432,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2182115614414215,
      "backward_entropy": 0.019618230561415356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003156945458613336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027266452088952065,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.218163400888443,
      "backward_entropy": 0.01960790529847145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031800282886251807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02726718969643116,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2181168794631958,
      "backward_entropy": 0.017625528077284496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002594892866909504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027267903089523315,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21807178854942322,
      "backward_entropy": 0.019588403403759003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003740672837011516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027268582955002785,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21802836656570435,
      "backward_entropy": 0.01761542136470477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042333739111199975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027269266545772552,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2179858684539795,
      "backward_entropy": 0.017610435684521992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026476127095520496,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027269970625638962,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21794384717941284,
      "backward_entropy": 0.019560806453227997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020070366736035794,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02727065235376358,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21790313720703125,
      "backward_entropy": 0.01760014146566391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015769709716551006,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027271298691630363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21786394715309143,
      "backward_entropy": 0.01954319328069687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001639262482058257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027271905913949013,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2178264707326889,
      "backward_entropy": 0.01759096359213193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019278531544841826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027272479608654976,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21779045462608337,
      "backward_entropy": 0.01952738066514333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001563991972943768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027273034676909447,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2177554816007614,
      "backward_entropy": 0.019519959886868794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013661339471582323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727356366813183,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21772179007530212,
      "backward_entropy": 0.01951289673646291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013877863239031285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727406471967697,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21768930554389954,
      "backward_entropy": 0.019506140301624935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019062864885199815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027274543419480324,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21765798330307007,
      "backward_entropy": 0.019499731560548145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016067337128333747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027275023981928825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21762731671333313,
      "backward_entropy": 0.01949326569835345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015078885189723223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727549709379673,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21759739518165588,
      "backward_entropy": 0.019486981133619945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001422734494553879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027275962755084038,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21756824851036072,
      "backward_entropy": 0.019480712711811066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001327837526332587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727642096579075,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21753987669944763,
      "backward_entropy": 0.019474659115076065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010984497203025967,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027276871725916862,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2175123244524002,
      "backward_entropy": 0.017555868873993557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011019783414667472,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027277307584881783,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2174856960773468,
      "backward_entropy": 0.01946289340655009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011699252354446799,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027277734130620956,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21745993196964264,
      "backward_entropy": 0.019457233448823292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012195367889944464,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027278155088424683,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21743476390838623,
      "backward_entropy": 0.017546705901622772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00608065421693e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727857418358326,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2174101173877716,
      "backward_entropy": 0.019446176787217457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.385734013747424e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02727898396551609,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21738627552986145,
      "backward_entropy": 0.017540644854307175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.041362161748111e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02727936953306198,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2173634171485901,
      "backward_entropy": 0.019435716172059376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.485039921244606e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027279743924736977,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21734115481376648,
      "backward_entropy": 0.02263626456260681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.736821913160384e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027280105277895927,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2173197865486145,
      "backward_entropy": 0.019426004340251286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.416399603243917e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027280448004603386,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21729916334152222,
      "backward_entropy": 0.01942146196961403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.240338552743196e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027280787006020546,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21727900207042694,
      "backward_entropy": 0.017527736723423004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.184115798329003e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02728111669421196,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21725940704345703,
      "backward_entropy": 0.017525404691696167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.436974217649549e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728142961859703,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2172403782606125,
      "backward_entropy": 0.019408526519934338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.626323738601059e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027281740680336952,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21722179651260376,
      "backward_entropy": 0.017521031200885773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.956416862318292e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027282055467367172,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21720361709594727,
      "backward_entropy": 0.017518748839696247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.363347347360104e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027282368391752243,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2171858251094818,
      "backward_entropy": 0.0175165260831515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.697143958765082e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027282683178782463,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21716824173927307,
      "backward_entropy": 0.019392138967911404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5252400013851e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027282990515232086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21715113520622253,
      "backward_entropy": 0.019388174017270405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.02327386836987e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728329226374626,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2171345353126526,
      "backward_entropy": 0.019384267429510754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7657646569423378e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728358656167984,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21711842715740204,
      "backward_entropy": 0.019380434105793636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9289865778991953e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027283862233161926,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21710290014743805,
      "backward_entropy": 0.019376859068870544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.121828558505513e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027284126728773117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21708790957927704,
      "backward_entropy": 0.019373442977666855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8271326300455257e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728438191115856,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21707332134246826,
      "backward_entropy": 0.019370120018720627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4819251848384738e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728462964296341,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21705922484397888,
      "backward_entropy": 0.019366839279731114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4435430532321334e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728486806154251,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2170456200838089,
      "backward_entropy": 0.01936376343170802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5447207008255646e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027285099029541016,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21703247725963593,
      "backward_entropy": 0.022588680187861126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7524293070891872e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027285326272249222,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2170197069644928,
      "backward_entropy": 0.01935778682430585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5156452466035262e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027285542339086533,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21700739860534668,
      "backward_entropy": 0.01749364783366521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.610839899512939e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027285758405923843,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21699540317058563,
      "backward_entropy": 0.02258264273405075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2837086615036242e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027285965159535408,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2169838845729828,
      "backward_entropy": 0.017490603029727936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.838070784287993e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027286160737276077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21697290241718292,
      "backward_entropy": 0.019346988449494045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6954532839008607e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027286352589726448,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21696223318576813,
      "backward_entropy": 0.022577228645483654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4281380572356284e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02728654257953167,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21695184707641602,
      "backward_entropy": 0.01748645305633545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3412098269327544e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027286726981401443,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21694180369377136,
      "backward_entropy": 0.019339698056379955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.155993049906101e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02728690393269062,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2169319987297058,
      "backward_entropy": 0.0174838329354922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715430911048315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728707529604435,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2169225513935089,
      "backward_entropy": 0.01933520535628001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0086497240990866e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027287235483527184,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21691352128982544,
      "backward_entropy": 0.01933310677607854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0434692740091123e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728739008307457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21690477430820465,
      "backward_entropy": 0.01933112492163976,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.560534529853612e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027287539094686508,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21689622104167938,
      "backward_entropy": 0.019329165418942768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.727571755822282e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0272876787930727,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21688798069953918,
      "backward_entropy": 0.019327341268459957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.674056516611017e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027287811040878296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2168799638748169,
      "backward_entropy": 0.01932563508550326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.729310487367911e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027287941426038742,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21687215566635132,
      "backward_entropy": 0.02256256341934204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.835877684352454e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02728806436061859,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2168646603822708,
      "backward_entropy": 0.02256145824988683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.097064670029795e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027288183569908142,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21685734391212463,
      "backward_entropy": 0.01932074377934138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.884865342726698e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027288299053907394,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2168503850698471,
      "backward_entropy": 0.02255930503209432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3408967940195e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027288414537906647,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21684348583221436,
      "backward_entropy": 0.019317726294199627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.393469225760782e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027288522571325302,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21683689951896667,
      "backward_entropy": 0.02255726357301076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.074527168995701e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728862501680851,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2168305367231369,
      "backward_entropy": 0.019314926117658615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.990289769717492e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728872187435627,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21682435274124146,
      "backward_entropy": 0.019313670694828033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.897982878697803e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728881500661373,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2168184071779251,
      "backward_entropy": 0.019312426447868347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.155085662205238e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027288906276226044,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2168126106262207,
      "backward_entropy": 0.019311209519704182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.527297738197376e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027288997545838356,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2168070524930954,
      "backward_entropy": 0.019310057163238525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.751561623881571e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728908322751522,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.216801717877388,
      "backward_entropy": 0.019308912257353466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.546222503951867e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027289165183901787,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21679659187793732,
      "backward_entropy": 0.017468792696793873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.180116664225352e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027289243414998055,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21679165959358215,
      "backward_entropy": 0.017468334486087162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.365845375607023e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027289319783449173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21678684651851654,
      "backward_entropy": 0.01930582771698634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.493864030839177e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027289392426609993,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21678215265274048,
      "backward_entropy": 0.022549194594224293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7328138710581698e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027289465069770813,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21677765250205994,
      "backward_entropy": 0.019303888082504272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8202848650616943e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027289535850286484,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2167733609676361,
      "backward_entropy": 0.019302986562252045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6576926782363444e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027289604768157005,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.216769278049469,
      "backward_entropy": 0.017466063300768535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3686768625120749e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02728966809809208,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21676528453826904,
      "backward_entropy": 0.022546616693337757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7197987745021237e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027289727702736855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21676146984100342,
      "backward_entropy": 0.019300465782483418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.331818793914863e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02728978730738163,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21675774455070496,
      "backward_entropy": 0.019299672295649845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3110319514453295e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027289843186736107,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21675410866737366,
      "backward_entropy": 0.017464653899272282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.96279140963452e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027289897203445435,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2167506217956543,
      "backward_entropy": 0.019298211981852848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1441336482675979e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027289949357509613,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21674731373786926,
      "backward_entropy": 0.022543939451376598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.521189218095969e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027289999648928642,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2167440950870514,
      "backward_entropy": 0.02254346013069153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.803707487459178e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290046215057373,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21674105525016785,
      "backward_entropy": 0.01929626738031705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.459954526391812e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290090918540955,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21673810482025146,
      "backward_entropy": 0.019295640289783478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.00026987487945e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290135622024536,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21673527359962463,
      "backward_entropy": 0.019295071562131245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.6066269255316e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729017846286297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21673254668712616,
      "backward_entropy": 0.019294515252113342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.271804409152537e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290217578411102,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21672992408275604,
      "backward_entropy": 0.019293983777364094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.913015795362298e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290254831314087,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2167273759841919,
      "backward_entropy": 0.019293492039044697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.115128030614869e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290290221571922,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21672490239143372,
      "backward_entropy": 0.017462049921353657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.149100275048113e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290325611829758,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21672245860099792,
      "backward_entropy": 0.017461868623892467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.59388707238395e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290359139442444,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21672014892101288,
      "backward_entropy": 0.019292081395785015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.644510624984832e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729039080440998,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21671797335147858,
      "backward_entropy": 0.019291676580905914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.428613979394868e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290422469377518,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21671588718891144,
      "backward_entropy": 0.019291281700134277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.793197151935601e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027290452271699905,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21671387553215027,
      "backward_entropy": 0.022539051870505016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5025610145567043e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290480211377144,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21671190857887268,
      "backward_entropy": 0.019290541609128315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9578251314887893e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290506288409233,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21671006083488464,
      "backward_entropy": 0.019290136794249218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.268782708370054e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290530502796173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2167082130908966,
      "backward_entropy": 0.019289844979842503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7361221555111115e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290552854537964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2167065143585205,
      "backward_entropy": 0.019289528330167133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.165898393968746e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290575206279755,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2167048454284668,
      "backward_entropy": 0.017460691432158153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9801680650743947e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290597558021545,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21670329570770264,
      "backward_entropy": 0.017460578431685764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.10117647725383e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290618047118187,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21670180559158325,
      "backward_entropy": 0.017460502684116364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9180940569185623e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729063853621483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21670040488243103,
      "backward_entropy": 0.01928844799598058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6972576588614174e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02729065716266632,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166990339756012,
      "backward_entropy": 0.022537007927894592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7650867789598124e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027290675789117813,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21669772267341614,
      "backward_entropy": 0.022536809245745342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5632792838005116e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027290694415569305,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21669650077819824,
      "backward_entropy": 0.022536608080069225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5653854745778517e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729071117937565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21669530868530273,
      "backward_entropy": 0.019287437200546265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1953083856042213e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729072794318199,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21669411659240723,
      "backward_entropy": 0.01928722858428955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1477079908672749e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290742844343185,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166929841041565,
      "backward_entropy": 0.019287018726269405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1098984487034613e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729075774550438,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21669191122055054,
      "backward_entropy": 0.019286816318829853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.763504411035683e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290770784020424,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21669086813926697,
      "backward_entropy": 0.01745983709891637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.596698191671749e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729078382253647,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166898548603058,
      "backward_entropy": 0.019286468625068665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.650420113553992e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290796861052513,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668894588947296,
      "backward_entropy": 0.01928629477818807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.802481232805803e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290809899568558,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21668800711631775,
      "backward_entropy": 0.017459674427906673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39104066838081e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290821075439453,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166871428489685,
      "backward_entropy": 0.0192859781285127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.61748771335624e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729083225131035,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21668627858161926,
      "backward_entropy": 0.017459625999132793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.01020246904227e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027290843427181244,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166854739189148,
      "backward_entropy": 0.022534961501757305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.54851631306974e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729085460305214,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166847288608551,
      "backward_entropy": 0.019285517434279125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2219196078340246e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290863916277885,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166839987039566,
      "backward_entropy": 0.01745954528450966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.655950647247664e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729087322950363,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166832983493805,
      "backward_entropy": 0.019285279015700024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7291486282574624e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290882542729378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668267250061035,
      "backward_entropy": 0.01928514117995898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.471621650736779e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290891855955124,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166820466518402,
      "backward_entropy": 0.019285046805938084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8557782744419455e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729090116918087,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21668145060539246,
      "backward_entropy": 0.017459403723478317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.666109904543191e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027290908619761467,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166808843612671,
      "backward_entropy": 0.017459376404682796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5461845016016014e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290916070342064,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668031811714172,
      "backward_entropy": 0.019284730156262715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1497933150603785e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729092352092266,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667978167533875,
      "backward_entropy": 0.019284615914026897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.869418835871329e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290930971503258,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667928993701935,
      "backward_entropy": 0.01928455134232839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5191758012965693e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290938422083855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667878329753876,
      "backward_entropy": 0.0192844420671463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5209814680238196e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729094587266445,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667832136154175,
      "backward_entropy": 0.019284377495447796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3907887225504965e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0272909514605999,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667787432670593,
      "backward_entropy": 0.022533732155958813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.179066171947852e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290957048535347,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667742729187012,
      "backward_entropy": 0.01928422103325526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0759301833095378e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290962636470795,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166769802570343,
      "backward_entropy": 0.0192841241757075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7857395562259626e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027290968224406242,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667659282684326,
      "backward_entropy": 0.022533483803272247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.648143665988755e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02729097381234169,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667620539665222,
      "backward_entropy": 0.022533441583315533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6005728298296162e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290979400277138,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667587757110596,
      "backward_entropy": 0.01928393418590228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.531269333554519e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027290984988212585,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667557954788208,
      "backward_entropy": 0.022533295055230457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.229814472480939e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290988713502884,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667525172233582,
      "backward_entropy": 0.01928383857011795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2774670210546901e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027290992438793182,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667495369911194,
      "backward_entropy": 0.019283761580785114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1374183372936386e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729099616408348,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667468547821045,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1005404587649537e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729099988937378,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667441725730896,
      "backward_entropy": 0.019283678382635117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0122334970219526e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291003614664078,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667416393756866,
      "backward_entropy": 0.017459134260813396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731888101465302e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291007339954376,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667394042015076,
      "backward_entropy": 0.01928356910745303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.071186468645465e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291011065244675,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667368710041046,
      "backward_entropy": 0.019283533096313477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.121958217088832e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291014790534973,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667346358299255,
      "backward_entropy": 0.017459118117888767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.965024113014806e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729101851582527,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667326986789703,
      "backward_entropy": 0.017459118117888767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1862124312028755e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729102224111557,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166731059551239,
      "backward_entropy": 0.019283400227626164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.1961494541028515e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729102596640587,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667291224002838,
      "backward_entropy": 0.017459101974964142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.57837517792359e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291029691696167,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667273342609406,
      "backward_entropy": 0.01928333689769109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596916707872879e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291031554341316,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667256951332092,
      "backward_entropy": 0.01745909700791041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.319428453276487e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291033416986465,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667242050170898,
      "backward_entropy": 0.01928328350186348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.864119773628772e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291035279631615,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667227149009705,
      "backward_entropy": 0.017459085832039516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.446633283805568e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291037142276764,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166721522808075,
      "backward_entropy": 0.01745907465616862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.720327240193001e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291039004921913,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667200326919556,
      "backward_entropy": 0.01745907465616862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.149505627992767e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291040867567062,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.216671884059906,
      "backward_entropy": 0.022532430787881214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.672653292596806e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729104273021221,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667173504829407,
      "backward_entropy": 0.019283140699068706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4779645829985384e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729104459285736,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667161583900452,
      "backward_entropy": 0.01928312083085378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3090685747083626e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02729104645550251,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667149662971497,
      "backward_entropy": 0.02253231902917226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.733749226990767e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729104831814766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166714072227478,
      "backward_entropy": 0.019283055017391842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3075514832271438e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02729105018079281,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667131781578064,
      "backward_entropy": 0.017459080864985783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.509295882191509e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291052043437958,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166711986064911,
      "backward_entropy": 0.01928303266565005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.963265106041945e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291053906083107,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667110919952393,
      "backward_entropy": 0.01928301403919856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9398029849071463e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291055768728256,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667098999023438,
      "backward_entropy": 0.019283001621564228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.216829386725294e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291057631373405,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166709005832672,
      "backward_entropy": 0.01928298423687617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8277290791957057e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291059494018555,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667082607746124,
      "backward_entropy": 0.019282979269822437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.924796322327893e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291061356663704,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667072176933289,
      "backward_entropy": 0.017459101974964142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9486492419673596e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291063219308853,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166706621646881,
      "backward_entropy": 0.01928296188513438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7250982864425168e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291065081954002,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667060256004333,
      "backward_entropy": 0.019282954434553783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5539711739620543e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729106694459915,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667052805423737,
      "backward_entropy": 0.01928294946750005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3847483160134288e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0272910688072443,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667048335075378,
      "backward_entropy": 0.019282943258682888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.523453363461158e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729107066988945,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166704535484314,
      "backward_entropy": 0.019282925873994827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2048744224557595e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0272910725325346,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667039394378662,
      "backward_entropy": 0.019282920906941097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.185825433632999e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02729107439517975,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667036414146423,
      "backward_entropy": 0.01928287371993065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.826575026432693e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291076257824898,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667033433914185,
      "backward_entropy": 0.019282862544059753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.813909519427398e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291078120470047,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667030453681946,
      "backward_entropy": 0.022531961401303608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.270983815033105e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291079983115196,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667027473449707,
      "backward_entropy": 0.019282856335242588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.392167044097732e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291081845760345,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667024493217468,
      "backward_entropy": 0.022531936566034954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.125855626734847e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291083708405495,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166702151298523,
      "backward_entropy": 0.019282850126425426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.665885621259804e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166702002286911,
      "backward_entropy": 0.019282845159371693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.893490305832529e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166701704263687,
      "backward_entropy": 0.019282837708791096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.201474889167002e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667015552520752,
      "backward_entropy": 0.019282827774683636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.701270649500657e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667012572288513,
      "backward_entropy": 0.019282827774683636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.838316496920015e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667009592056274,
      "backward_entropy": 0.01928282156586647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4420289668778423e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667008101940155,
      "backward_entropy": 0.019282815357049305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.735074637414073e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667006611824036,
      "backward_entropy": 0.022531817356745403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.036113748246862e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21667003631591797,
      "backward_entropy": 0.022531809906164806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.524309815678862e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667003631591797,
      "backward_entropy": 0.019282809148232143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.560831712296931e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667000651359558,
      "backward_entropy": 0.019282809148232143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2522430021563196e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166699469089508,
      "backward_entropy": 0.022531782587369282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.915108320346917e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166699320077896,
      "backward_entropy": 0.01928280418117841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.127898023398302e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666991710662842,
      "backward_entropy": 0.01928280418117841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.162501454629819e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666991710662842,
      "backward_entropy": 0.01928280418117841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2818547879287507e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666991710662842,
      "backward_entropy": 0.02253175526857376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.730828896346793e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666988730430603,
      "backward_entropy": 0.019282791763544083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3518964553659316e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666988730430603,
      "backward_entropy": 0.019282791763544083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.546798327784927e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666985750198364,
      "backward_entropy": 0.019282791763544083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5144686333078425e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666985750198364,
      "backward_entropy": 0.017459134260813396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.851123781510978e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666985750198364,
      "backward_entropy": 0.019282786796490353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.629434447953827e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666985750198364,
      "backward_entropy": 0.019282786796490353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.566409307291906e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666982769966125,
      "backward_entropy": 0.019282791763544083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.028954781962966e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666981279850006,
      "backward_entropy": 0.019282791763544083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8212631403002888e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666979789733887,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4551915228366852e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666979789733887,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6416379367001355e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666978299617767,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5700152289355174e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666979789733887,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4949819160392508e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666979789733887,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.589413045621768e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666978299617767,
      "backward_entropy": 0.022531650960445404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0162182206840953e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666976809501648,
      "backward_entropy": 0.017459178964296978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2880718713859096e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666976809501648,
      "backward_entropy": 0.017459178964296978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2113332559238188e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666975319385529,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1004885891452432e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166697382926941,
      "backward_entropy": 0.017459183931350708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1238654451517505e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166697382926941,
      "backward_entropy": 0.017459183931350708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0619061185934697e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166697233915329,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0812328810061445e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166697233915329,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.752731789878453e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166697084903717,
      "backward_entropy": 0.019282779345909756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0606271416691015e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166697084903717,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0230394309473922e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166697084903717,
      "backward_entropy": 0.022531628608703613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.247091732802801e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166697084903717,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.064660050877137e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.148326292532147e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166696935892105,
      "backward_entropy": 0.022531616191069286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.469225238310173e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.474909580196254e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166696935892105,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.343725544866174e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166696935892105,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.178879630169831e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.596945129582309e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.719336281297728e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.022531603773434956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.839950745212263e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.022531603773434956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.473577064345591e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.01928276817003886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.470912694567232e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.022531603773434956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.675371201301459e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282761961221695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.709033080667723e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282761961221695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.283595783112105e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4788172342814505e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3722358239174355e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0806469314702554e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3288927170360694e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7132963370822836e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.759037442956469e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.304023721284466e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3445246572227916e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.944489096989855e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2147617073642323e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.83648660115432e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.984990032928181e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2509993868879974e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.495426087989472e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.017459183931350708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1543655748246238e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.022531569004058838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.120259523508139e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666967868804932,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.219024963778793e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666966378688812,
      "backward_entropy": 0.022531569004058838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1444179765239824e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9895196601282805e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2680524125462398e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.086153472191654e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.660538373471354e-11,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.02253156155347824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6072476682893466e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7848833522293717e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7564616427989677e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8133050616597757e-11,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.019282756994167965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3585577107733116e-11,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027291085571050644,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666964888572693,
      "backward_entropy": 0.017459188898404438,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 4.267655384637692e-10,
    "avg_log_Z": 0.02729108203202486,
    "success_rate": 1.0,
    "avg_reward": 53.5,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.15,
      "1": 0.15,
      "2": 0.7
    },
    "avg_forward_entropy": 0.2166699357330799,
    "avg_backward_entropy": 0.019496599659323693,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}