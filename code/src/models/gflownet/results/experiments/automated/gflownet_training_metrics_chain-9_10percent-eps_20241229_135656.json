{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 0.47368421052631576
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 0.7368421052631579
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07701230049133301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07701230049133301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07701230049133301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07701230049133301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.0770092142952813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.404695510864258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10976378917694092,
      "backward_entropy": 0.07693801985846625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.058171272277832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1097597599029541,
      "backward_entropy": 0.07701132032606336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.396230697631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00019994757894892246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10975567102432252,
      "backward_entropy": 0.07700610160827637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.302523612976074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00029994489159435034,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10975148677825927,
      "backward_entropy": 0.07692331075668335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.04679012298584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0003999417822342366,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974733829498291,
      "backward_entropy": 0.077007704310947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.954151153564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004998829681426287,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10974314212799072,
      "backward_entropy": 0.07700626717673408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.290925025939941,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0005997593980282545,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973892211914063,
      "backward_entropy": 0.07690727710723877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.123942375183105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006996813463047147,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10973461866378784,
      "backward_entropy": 0.07690162128872341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.441094398498535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007996039930731058,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10973023176193238,
      "backward_entropy": 0.07700129350026448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.513550758361816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000899330188985914,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10972583293914795,
      "backward_entropy": 0.07688977983262804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.096118927001953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009989093523472548,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1097214698791504,
      "backward_entropy": 0.07698803477817112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.020833969116211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0010982652893289924,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10971711874008179,
      "backward_entropy": 0.07687730259365505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.51536750793457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0011977292597293854,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10971266031265259,
      "backward_entropy": 0.07699273692237006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.589362144470215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012971381656825542,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10970813035964966,
      "backward_entropy": 0.07686404387156169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.920571327209473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013965070247650146,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10970357656478882,
      "backward_entropy": 0.07698750495910645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.755572319030762,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.001495651202276349,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10969903469085693,
      "backward_entropy": 0.07685001691182454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99344539642334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015948782674968243,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10969438552856445,
      "backward_entropy": 0.07698160409927368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.577469825744629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0016939094057306647,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10968979597091674,
      "backward_entropy": 0.07696447107526991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.82497501373291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017929745372384787,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10968515872955323,
      "backward_entropy": 0.07697506745656331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.565596580505371,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018921494483947754,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10968044996261597,
      "backward_entropy": 0.07681951257917616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.318291664123535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001990976743400097,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967590808868408,
      "backward_entropy": 0.07696783542633057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.149612426757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0020897937938570976,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10967131853103637,
      "backward_entropy": 0.07696392801072863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.309757232666016,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002188559388741851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966664552688599,
      "backward_entropy": 0.07679483625623915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.225935935974121,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002286951057612896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10966217517852783,
      "backward_entropy": 0.07678619358274671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05594253540039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002385365078225732,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10965766906738281,
      "backward_entropy": 0.07693276802698772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.137648582458496,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024833660572767258,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10965337753295898,
      "backward_entropy": 0.07694653007719252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.551316261291504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0025814117398113012,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964909791946412,
      "backward_entropy": 0.07675896750556098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.298713684082031,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002679312601685524,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10964480638504029,
      "backward_entropy": 0.07691646284527248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79581069946289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027773622423410416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10964039564132691,
      "backward_entropy": 0.07673964235517713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79295539855957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0028753632213920355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10963592529296876,
      "backward_entropy": 0.07690449555714925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.040146827697754,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002973324852064252,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10963141918182373,
      "backward_entropy": 0.07671917809380426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.124256134033203,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0030713484156876802,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10962681770324707,
      "backward_entropy": 0.07691454887390137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.20268440246582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0031694392673671246,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10962221622467042,
      "backward_entropy": 0.07688483926984999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.038731575012207,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0032672546803951263,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961771011352539,
      "backward_entropy": 0.07690203852123684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69772720336914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003365129930898547,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10961327552795411,
      "backward_entropy": 0.07689542240566677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034697532653809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0034629537258297205,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1096088171005249,
      "backward_entropy": 0.07666429546144274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.282022476196289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035608443431556225,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960441827774048,
      "backward_entropy": 0.07685538132985432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.350170135498047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003658503061160445,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10960017442703247,
      "backward_entropy": 0.07684740755293104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.028460502624512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037564276717603207,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095956802368164,
      "backward_entropy": 0.07683916886647542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.264445304870605,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00385441817343235,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10959122180938721,
      "backward_entropy": 0.07661518123414782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.352787017822266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003952598199248314,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958662033081054,
      "backward_entropy": 0.07685026857588026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.85061264038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004050561226904392,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10958212614059448,
      "backward_entropy": 0.07684177822536892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.491477012634277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004148537293076515,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10957763195037842,
      "backward_entropy": 0.07657483551237318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.345709800720215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004246843978762627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10957272052764892,
      "backward_entropy": 0.07679387595918444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092998504638672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004345329012721777,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956777334213257,
      "backward_entropy": 0.07654603322347005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.24614143371582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004443461541086435,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10956299304962158,
      "backward_entropy": 0.0765311320622762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.665242195129395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004541783593595028,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10955801010131835,
      "backward_entropy": 0.07651582691404554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.025877952575684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004640435799956322,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10955288410186767,
      "backward_entropy": 0.07678464386198255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.063908576965332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004738643299788237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10954823493957519,
      "backward_entropy": 0.07674160930845472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.599050521850586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004836976993829012,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1095433235168457,
      "backward_entropy": 0.07673030429416233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.750418663024902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004935160279273987,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953872203826905,
      "backward_entropy": 0.07675162288877699,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.248796463012695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005033300258219242,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10953419208526612,
      "backward_entropy": 0.07674018541971843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.093900680541992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005131192039698362,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10952982902526856,
      "backward_entropy": 0.07641726069980198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.798016548156738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005228776019066572,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952577590942383,
      "backward_entropy": 0.07671627733442518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.467167854309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005326464306563139,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10952155590057373,
      "backward_entropy": 0.07670379347271389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.188512802124023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005424522329121828,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10951703786849976,
      "backward_entropy": 0.0766909122467041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.813589096069336,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005521840415894985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10951321125030518,
      "backward_entropy": 0.07634549670749241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.057877540588379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005618838593363762,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950947999954223,
      "backward_entropy": 0.07666424910227458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.982391357421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005716100800782442,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950559377670288,
      "backward_entropy": 0.07665034135182698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.052460670471191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005813117604702711,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10950183868408203,
      "backward_entropy": 0.07663606272803412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.252387046813965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005910403095185757,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949794054031373,
      "backward_entropy": 0.07659541236029731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547889709472656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006007530726492405,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10949442386627198,
      "backward_entropy": 0.07660644584231907,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.942889213562012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006104700732976198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10949078798294068,
      "backward_entropy": 0.0765670273039076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366568565368652,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006202110555022955,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10948681831359863,
      "backward_entropy": 0.07657504081726074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.391552925109863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0062994686886668205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10948270559310913,
      "backward_entropy": 0.0765369865629408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.711994171142578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006396759767085314,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109478759765625,
      "backward_entropy": 0.07652143637339275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.063450813293457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006494150497019291,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947481393814087,
      "backward_entropy": 0.07613105244106716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.850573539733887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006591316778212786,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10947117805480958,
      "backward_entropy": 0.0761066542731391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.275087356567383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006689137313514948,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946704149246216,
      "backward_entropy": 0.0760823753145006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700118064880371,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006787272170186043,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10946242809295655,
      "backward_entropy": 0.07605757978227404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.444695472717285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006885418202728033,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10945776700973511,
      "backward_entropy": 0.07645034790039062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.476457595825195,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0069839125499129295,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10945298671722412,
      "backward_entropy": 0.07600640588336521,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.730568885803223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007082244846969843,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10944874286651611,
      "backward_entropy": 0.0764100816514757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51034164428711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0071806334890425205,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10944392681121826,
      "backward_entropy": 0.07638021310170491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.434931755065918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007278938312083483,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943901538848877,
      "backward_entropy": 0.07592554887135823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.431571006774902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007377123925834894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10943412780761719,
      "backward_entropy": 0.07589718368318346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.859780788421631,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007475204300135374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10942926406860351,
      "backward_entropy": 0.07631791300243801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.496054649353027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007572916802018881,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10942471027374268,
      "backward_entropy": 0.07583844661712646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.704360008239746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007670622784644365,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10942000150680542,
      "backward_entropy": 0.07627602418263753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.169468879699707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007768374867737293,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10941568613052369,
      "backward_entropy": 0.07577695449193318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.520586967468262,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007865956984460354,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10941139459609986,
      "backward_entropy": 0.07622669140497844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870331764221191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007963530719280243,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940735340118408,
      "backward_entropy": 0.07620110114415486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.220854759216309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008061321452260017,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10940271615982056,
      "backward_entropy": 0.07617483536402385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.21645450592041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008159447461366653,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093977451324463,
      "backward_entropy": 0.0756461222966512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941072463989258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008257871493697166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10939245223999024,
      "backward_entropy": 0.07561146550708348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.02983283996582,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008355919271707535,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938780307769776,
      "backward_entropy": 0.07610403166876899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.95540714263916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00845420267432928,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10938268899917603,
      "backward_entropy": 0.07607732216517131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.733727931976318,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008552651852369308,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10937731266021729,
      "backward_entropy": 0.07603437370724148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.749945163726807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008650115691125393,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10937345027923584,
      "backward_entropy": 0.07546615600585938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.43006706237793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008747234009206295,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10936996936798096,
      "backward_entropy": 0.07599482933680217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.127782821655273,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008843882009387016,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936713218688965,
      "backward_entropy": 0.07538978258768718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.382870674133301,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008940481580793858,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10936417579650878,
      "backward_entropy": 0.07591085963779026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54442024230957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009036684408783913,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10936129093170166,
      "backward_entropy": 0.07530973354975383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.567703247070312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009133081883192062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935821533203124,
      "backward_entropy": 0.07587875260247125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.178722381591797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009229714050889015,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10935441255569459,
      "backward_entropy": 0.07584783766004774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.105650901794434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009326348081231117,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10935037136077881,
      "backward_entropy": 0.07577527231640285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.595137596130371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009422940202057362,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10934629440307617,
      "backward_entropy": 0.07573923799726698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.972851753234863,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009519733488559723,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10934203863143921,
      "backward_entropy": 0.07570232285393609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.641637802124023,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00961691327393055,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1093371868133545,
      "backward_entropy": 0.07504476441277398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.647651672363281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009713740088045597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10933302640914917,
      "backward_entropy": 0.07568144798278809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.194304466247559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009810787625610828,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10932848453521729,
      "backward_entropy": 0.07494881418016222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.5702543258667,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009907780215144157,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10932427644729614,
      "backward_entropy": 0.07560953166749743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.82337760925293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010004932060837746,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10931988954544067,
      "backward_entropy": 0.07484928766886394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.360860824584961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0101018650457263,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10931556224822998,
      "backward_entropy": 0.07553450266520183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.059866905212402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010198833420872688,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10931166410446166,
      "backward_entropy": 0.07541887627707587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.356156349182129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01029572170227766,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10930767059326171,
      "backward_entropy": 0.07469260692596436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4232587814331055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010393185541033745,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10930297374725342,
      "backward_entropy": 0.07532936996883816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.912191390991211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010490184649825096,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10929884910583496,
      "backward_entropy": 0.0753733581966824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.037359237670898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010587012395262718,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1092950701713562,
      "backward_entropy": 0.07452670733133952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.771216869354248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010683773085474968,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1092911720275879,
      "backward_entropy": 0.07446911599900988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.2725830078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010780299082398415,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10928807258605958,
      "backward_entropy": 0.07513833045959473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.748592376708984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0108769116923213,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10928471088409424,
      "backward_entropy": 0.0743514166937934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.000996589660645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010974329896271229,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10928068161010743,
      "backward_entropy": 0.07515414555867513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.878488540649414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011072101071476936,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10927627086639405,
      "backward_entropy": 0.07422930664486355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.376174926757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011169612407684326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092722773551941,
      "backward_entropy": 0.07492891947428386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.994636535644531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01126718521118164,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1092677116394043,
      "backward_entropy": 0.0748741692966885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.101157188415527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011364602483808994,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10926306247711182,
      "backward_entropy": 0.07403576374053955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.148581504821777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011462454684078693,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1092576265335083,
      "backward_entropy": 0.07491128974490696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.173083305358887,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011560685932636261,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10925211906433105,
      "backward_entropy": 0.0738992624812656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.967663764953613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01165827363729477,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10924706459045411,
      "backward_entropy": 0.07382904158698188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.63475227355957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011755695566534996,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10924196243286133,
      "backward_entropy": 0.07475484742058648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.255837440490723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011853293515741825,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10923683643341064,
      "backward_entropy": 0.07470003763834636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.071645736694336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011950839310884476,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10923223495483399,
      "backward_entropy": 0.0744572016927931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16542911529541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01204830314964056,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10922707319259643,
      "backward_entropy": 0.07458719942304823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.930953502655029,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012146220542490482,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10922150611877442,
      "backward_entropy": 0.07432638936572605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.475374221801758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012243925593793392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10921590328216553,
      "backward_entropy": 0.07446900341245863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.219066619873047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012341727502644062,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920989513397217,
      "backward_entropy": 0.07440797487894694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092242240905762,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012439443729817867,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10920453071594238,
      "backward_entropy": 0.07434637016720241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.44806957244873,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012537087313830853,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10919840335845947,
      "backward_entropy": 0.07404748598734538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.317861557006836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012634781189262867,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091928243637085,
      "backward_entropy": 0.07397421863343981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.248038291931152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012732477858662605,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1091873288154602,
      "backward_entropy": 0.07415179411570232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.324285984039307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012830175459384918,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10918121337890625,
      "backward_entropy": 0.0738230546315511,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6803083419799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012927329167723656,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.109176504611969,
      "backward_entropy": 0.07401369677649604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7336931228637695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013024244457483292,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10917150974273682,
      "backward_entropy": 0.07266468471950954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092263221740723,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013120942749083042,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10916695594787598,
      "backward_entropy": 0.0735855499903361,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870896339416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01321761030703783,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10916312932968139,
      "backward_entropy": 0.0735031631257799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.731663227081299,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013314703479409218,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10915852785110473,
      "backward_entropy": 0.0737173424826728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.875542163848877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013411050662398338,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1091546893119812,
      "backward_entropy": 0.07226684358384874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.417708396911621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013507352210581303,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10915038585662842,
      "backward_entropy": 0.0732390350765652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.130887031555176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013603860512375832,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1091462254524231,
      "backward_entropy": 0.07347883118523492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.969236373901367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013699882663786411,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1091428518295288,
      "backward_entropy": 0.07305347257190281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.630104064941406,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013795925304293633,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10913941860198975,
      "backward_entropy": 0.07183267672856648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.519726753234863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01389231812208891,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10913592576980591,
      "backward_entropy": 0.0717197126812405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.576812744140625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013988474383950233,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10913227796554566,
      "backward_entropy": 0.07313778665330675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.586176872253418,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01408441737294197,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10912920236587524,
      "backward_entropy": 0.07265870438681708,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.779289722442627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014180747792124748,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10912501811981201,
      "backward_entropy": 0.07295634349187215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.988178730010986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014276380650699139,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10912301540374755,
      "backward_entropy": 0.07124365700615777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.005642890930176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014371584169566631,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10912085771560669,
      "backward_entropy": 0.07277029752731323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.034834384918213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014466947875916958,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10911796092987061,
      "backward_entropy": 0.07267419497172038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.537992477416992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014561906456947327,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.109115731716156,
      "backward_entropy": 0.07086145877838135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.295999526977539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01465730182826519,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10911328792572021,
      "backward_entropy": 0.0724769565794203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.512398719787598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014753538183867931,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10910913944244385,
      "backward_entropy": 0.07059481408860949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.080321311950684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014850066974759102,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10910495519638061,
      "backward_entropy": 0.07045245170593262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.086031913757324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014947217889130116,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10909906625747681,
      "backward_entropy": 0.07030491696463691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.936450004577637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015043827705085278,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10909353494644165,
      "backward_entropy": 0.07204341888427734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.816302299499512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015140959061682224,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10908693075180054,
      "backward_entropy": 0.0699997345606486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09109878540039,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015237409621477127,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10908082723617554,
      "backward_entropy": 0.07126720084084405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.07546329498291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015334472991526127,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10907387733459473,
      "backward_entropy": 0.07169299655490452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.552722454071045,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01543265301734209,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10906472206115722,
      "backward_entropy": 0.07099388705359565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.424102783203125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01553044281899929,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10905581712722778,
      "backward_entropy": 0.07144408755832249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.431090354919434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015628375113010406,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10904603004455567,
      "backward_entropy": 0.06917714410358006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092687606811523,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015726398676633835,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10903640985488891,
      "backward_entropy": 0.06900248924891154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.330704689025879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01582435518503189,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10902628898620606,
      "backward_entropy": 0.07040882110595703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.228416919708252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015922920778393745,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10901505947113037,
      "backward_entropy": 0.06864131821526422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.515941619873047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0160208810120821,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10900425910949707,
      "backward_entropy": 0.06845510005950928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.056621074676514,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016119007021188736,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10899286270141602,
      "backward_entropy": 0.07059710555606419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.224838733673096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016216501593589783,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10898147821426392,
      "backward_entropy": 0.07044483555687799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.27396011352539,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01631351001560688,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10897027254104615,
      "backward_entropy": 0.06784800026151869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.982199192047119,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01641121320426464,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10895768404006959,
      "backward_entropy": 0.06763631767696804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.963520526885986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01650823839008808,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10894654989242554,
      "backward_entropy": 0.06742193301518758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.865510940551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016604647040367126,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1089367389678955,
      "backward_entropy": 0.0690793858634101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.076873779296875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016701579093933105,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10892602205276489,
      "backward_entropy": 0.06698348787095812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.913215637207031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01679854653775692,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10891498327255249,
      "backward_entropy": 0.06871343983544244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.979722499847412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0168954748660326,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10890318155288696,
      "backward_entropy": 0.06929563151465522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.531585216522217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0169912651181221,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10889291763305664,
      "backward_entropy": 0.06629259718788995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.126294136047363,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01708691567182541,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.108882474899292,
      "backward_entropy": 0.06894061300489637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.769101142883301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017181675881147385,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10887222290039063,
      "backward_entropy": 0.06875979900360107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.698105335235596,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017276544123888016,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10886135101318359,
      "backward_entropy": 0.06555882427427503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5823588371276855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017371462658047676,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10885022878646851,
      "backward_entropy": 0.06838595867156982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.365002632141113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017466343939304352,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10883948802947999,
      "backward_entropy": 0.0650490125020345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.578018665313721,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017561081796884537,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10882887840270997,
      "backward_entropy": 0.06708869669172499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.02830696105957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017655810341238976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1088182806968689,
      "backward_entropy": 0.06779832972420587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.769105911254883,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017750782892107964,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10880749225616455,
      "backward_entropy": 0.0666307806968689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.895416259765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017845263704657555,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10879737138748169,
      "backward_entropy": 0.06639554765489367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.192472457885742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017939355224370956,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10878846645355225,
      "backward_entropy": 0.06717878580093384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.361257553100586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018033284693956375,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10877984762191772,
      "backward_entropy": 0.0659127566549513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.77878999710083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018127156421542168,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1087717056274414,
      "backward_entropy": 0.06315516763263279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5430684089660645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018221255391836166,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10876215696334839,
      "backward_entropy": 0.06286858850055271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3301849365234375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018315382301807404,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10875306129455567,
      "backward_entropy": 0.06257919470469157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.619246006011963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018408847972750664,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10874496698379517,
      "backward_entropy": 0.06604714526070489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.574989318847656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018501900136470795,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10873696804046631,
      "backward_entropy": 0.06462759441799587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.189326763153076,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01859513856470585,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10872822999954224,
      "backward_entropy": 0.0655644800927904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.630597114562988,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018688298761844635,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10871998071670533,
      "backward_entropy": 0.06138726075490316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6374969482421875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018781643360853195,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10871188640594483,
      "backward_entropy": 0.06380164623260498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.031292915344238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01887516863644123,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10870360136032105,
      "backward_entropy": 0.06480512354109022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.101780414581299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01896912232041359,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10869314670562744,
      "backward_entropy": 0.06322774622175428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.019288539886475,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019062886014580727,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10868287086486816,
      "backward_entropy": 0.06014182832505968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.773364543914795,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019155822694301605,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10867458581924438,
      "backward_entropy": 0.06263691849178737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314469337463379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019249076023697853,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10866549015045165,
      "backward_entropy": 0.05949632989035712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.16561222076416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019342953339219093,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10865437984466553,
      "backward_entropy": 0.06202788485421075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.698529243469238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019437281414866447,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1086424708366394,
      "backward_entropy": 0.06315558486514622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.392360210418701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019531749188899994,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10862973928451539,
      "backward_entropy": 0.06286178694831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.318287372589111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019626155495643616,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10861674547195435,
      "backward_entropy": 0.058154437277052135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.79069185256958,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01972045749425888,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10860382318496704,
      "backward_entropy": 0.06076693534851074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.392892360687256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019815009087324142,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10858807563781739,
      "backward_entropy": 0.0574568510055542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.777515888214111,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019908905029296875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10857255458831787,
      "backward_entropy": 0.05709879265891181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9997711181640625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020002437755465508,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10855727195739746,
      "backward_entropy": 0.061327960756089955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.15232515335083,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020095784217119217,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10854169130325317,
      "backward_entropy": 0.05943753321965536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.879117965698242,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02018905058503151,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10852600336074829,
      "backward_entropy": 0.06068719095653958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.649073600769043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02028145082294941,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10851223468780517,
      "backward_entropy": 0.06036183569166395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.800034046173096,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020373573526740074,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10849814414978028,
      "backward_entropy": 0.05838569667604235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.083905220031738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020465532317757607,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10848398208618164,
      "backward_entropy": 0.05802610847685072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.714052200317383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02055690437555313,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1084702730178833,
      "backward_entropy": 0.05449205305841234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4471049308776855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020648138597607613,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1084564208984375,
      "backward_entropy": 0.0590214729309082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.446078300476074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020739085972309113,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10844259262084961,
      "backward_entropy": 0.05692280001110501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3589091300964355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020830433815717697,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10842621326446533,
      "backward_entropy": 0.05832501252492269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.78564453125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020921427756547928,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10841007232666015,
      "backward_entropy": 0.056166761451297335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.548962593078613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021012380719184875,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10839337110519409,
      "backward_entropy": 0.052516685591803655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.009276866912842,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02110249735414982,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10837841033935547,
      "backward_entropy": 0.055395043558544584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.413394451141357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02119150385260582,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1083662748336792,
      "backward_entropy": 0.05500485830836826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.594366073608398,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021281106397509575,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10835093259811401,
      "backward_entropy": 0.05461082193586561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.027563571929932,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021370695903897285,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10833489894866943,
      "backward_entropy": 0.05421292781829834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.332208633422852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02145989052951336,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10831980705261231,
      "backward_entropy": 0.05577645036909315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.201833724975586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021548964083194733,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10830340385437012,
      "backward_entropy": 0.05004792743259006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.538753509521484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021637823432683945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10828694105148315,
      "backward_entropy": 0.05500136481391059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.192098617553711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021726012229919434,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10827369689941406,
      "backward_entropy": 0.054611113336351186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.597838401794434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02181340381503105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10826188325881958,
      "backward_entropy": 0.05422047773996989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.949324131011963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021900352090597153,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10825046300888061,
      "backward_entropy": 0.053827246030171715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.657318115234375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021987130865454674,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10823928117752075,
      "backward_entropy": 0.05133628182941013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.942453384399414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0220742616802454,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10822561979293824,
      "backward_entropy": 0.04746054940753513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.887986660003662,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022161228582262993,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10821077823638917,
      "backward_entropy": 0.047012514538235135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.461594104766846,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022248011082410812,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10819488763809204,
      "backward_entropy": 0.052203744649887085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3368682861328125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02233501896262169,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10817687511444092,
      "backward_entropy": 0.046105543772379555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.75588846206665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0224214568734169,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10815869569778443,
      "backward_entropy": 0.0456477337413364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.58653450012207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0225069522857666,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10814354419708253,
      "backward_entropy": 0.045191175407833524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.762570381164551,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02259150706231594,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10812950134277344,
      "backward_entropy": 0.050527592500050865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.857661247253418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022675340995192528,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10811572074890137,
      "backward_entropy": 0.04427069425582886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6784257888793945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022759269922971725,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1081021785736084,
      "backward_entropy": 0.04968464374542236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.660181045532227,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02284318394958973,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10808734893798828,
      "backward_entropy": 0.04700209034813775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.528741836547852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022927086800336838,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10807045698165893,
      "backward_entropy": 0.04288338290320502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.764004230499268,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02301015518605709,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10805453062057495,
      "backward_entropy": 0.042416284481684365,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.261096954345703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02309260331094265,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10804145336151123,
      "backward_entropy": 0.041953861713409424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.6199212074279785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02317490242421627,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10802687406539917,
      "backward_entropy": 0.047524087958865695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.762242317199707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023257333785295486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.108009934425354,
      "backward_entropy": 0.047083642747667104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2284674644470215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02333925850689411,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10799201726913452,
      "backward_entropy": 0.04664232995775011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.792300701141357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023421049118041992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10797402858734131,
      "backward_entropy": 0.046198215749528676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.307925701141357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023503152653574944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1079542875289917,
      "backward_entropy": 0.045748250352011785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.65650749206543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023584410548210144,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10793628692626953,
      "backward_entropy": 0.04529861609141032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.047682762145996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023665176704525948,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10791877508163453,
      "backward_entropy": 0.04249159826172723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.997265815734863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023745045065879822,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10790183544158935,
      "backward_entropy": 0.0382116072707706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.462253570556641,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023824850097298622,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10788249969482422,
      "backward_entropy": 0.043931530581580266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.620747089385986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023904945701360703,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10786130428314208,
      "backward_entropy": 0.037273406982421875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.165238857269287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023984644562005997,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10784003734588624,
      "backward_entropy": 0.036806209219826594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.535033702850342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024064432829618454,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10781650543212891,
      "backward_entropy": 0.04253515932295057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.431695938110352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024143803864717484,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1077918291091919,
      "backward_entropy": 0.0397239261203342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.011756896972656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024222703650593758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10776733160018921,
      "backward_entropy": 0.04159739282396105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.962827205657959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024300847202539444,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1077432632446289,
      "backward_entropy": 0.03494119644165039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8783750534057617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024378271773457527,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1077191710472107,
      "backward_entropy": 0.040667593479156494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.168086051940918,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02445496991276741,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10769590139389038,
      "backward_entropy": 0.037893457545174494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2525222301483154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024531250819563866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10767306089401245,
      "backward_entropy": 0.03974680105845133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.321946620941162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024606402963399887,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10765187740325928,
      "backward_entropy": 0.03310773770014445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.053949356079102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024680571630597115,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10763332843780518,
      "backward_entropy": 0.03265763653649224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9588990211486816,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024755341932177544,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10761208534240722,
      "backward_entropy": 0.036095105939441256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.712099552154541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02482972852885723,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10758943557739258,
      "backward_entropy": 0.037941283649868436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7886404991149902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02490355260670185,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10756633281707764,
      "backward_entropy": 0.035205301311280995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.102619171142578,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02497691847383976,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10754406452178955,
      "backward_entropy": 0.03703516059451633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2218852043151855,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025050168856978416,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10752002000808716,
      "backward_entropy": 0.030436442957984075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.793612003326416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025123434141278267,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10749318599700927,
      "backward_entropy": 0.03387848867310418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8815665245056152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025196317583322525,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10746575593948364,
      "backward_entropy": 0.03343918588426378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.505236864089966,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025268932804465294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10743817090988159,
      "backward_entropy": 0.03521288103527493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.586315870285034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0253409706056118,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10740997791290283,
      "backward_entropy": 0.03475805123647054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7001352310180664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025412555783987045,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10738203525543213,
      "backward_entropy": 0.028278380632400513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3334662914276123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025482889264822006,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10735739469528198,
      "backward_entropy": 0.027860773934258357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.44339656829834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025552721694111824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10733065605163575,
      "backward_entropy": 0.02744336426258087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5120604038238525,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025621220469474792,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10730676651000977,
      "backward_entropy": 0.030866344769795735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7536771297454834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02568957209587097,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10728060007095337,
      "backward_entropy": 0.026621975832515292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.073601722717285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025758033618330956,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10725204944610596,
      "backward_entropy": 0.026214910878075495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.077179193496704,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025825919583439827,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10722408294677735,
      "backward_entropy": 0.0316583878464169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.337096929550171,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025892257690429688,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10720040798187255,
      "backward_entropy": 0.02541456785466936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.430579900741577,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025957463309168816,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10717864036560058,
      "backward_entropy": 0.03081215090221829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1230878829956055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026021739467978477,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1071584701538086,
      "backward_entropy": 0.028438736995061237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.333991765975952,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026085907593369484,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10713627338409423,
      "backward_entropy": 0.024257664879163105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1464579105377197,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026149138808250427,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10711444616317749,
      "backward_entropy": 0.023880902263853285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.361902952194214,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026212399825453758,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10708990097045898,
      "backward_entropy": 0.02727662358019087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5998587608337402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026274826377630234,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1070670247077942,
      "backward_entropy": 0.026896576086680096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5514872074127197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026337886229157448,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10703805685043336,
      "backward_entropy": 0.026517538560761347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7888340950012207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02640034817159176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10700691938400268,
      "backward_entropy": 0.022411682539516024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.015825033187866,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02646138332784176,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10697991847991943,
      "backward_entropy": 0.02205704152584076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0989625453948975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026521386578679085,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10695559978485107,
      "backward_entropy": 0.021710084544287786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.454632520675659,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026580549776554108,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1069342851638794,
      "backward_entropy": 0.026792037818166945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.66927170753479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026639379560947418,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10691211223602295,
      "backward_entropy": 0.024700323740641277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6065292358398438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026698175817728043,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10688552856445313,
      "backward_entropy": 0.020701491170459323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5502641201019287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02675686590373516,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1068570852279663,
      "backward_entropy": 0.02565947837299771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7338001728057861,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026815395802259445,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1068258285522461,
      "backward_entropy": 0.02364090581734975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9373809099197388,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026872754096984863,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10679656267166138,
      "backward_entropy": 0.019725425375832453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.643669843673706,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026929311454296112,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10676727294921876,
      "backward_entropy": 0.019411020808749728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5995482206344604,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02698476053774357,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10673869848251342,
      "backward_entropy": 0.019102229012383357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6763050556182861,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027039142325520515,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10671145915985107,
      "backward_entropy": 0.01879979173342387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8670775890350342,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02709265798330307,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10668586492538452,
      "backward_entropy": 0.021980315446853638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5886833667755127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02714564837515354,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10665992498397828,
      "backward_entropy": 0.01821327871746487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3188265562057495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02719777636229992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10663442611694336,
      "backward_entropy": 0.02283012866973877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9549567699432373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027248738333582878,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10661075115203858,
      "backward_entropy": 0.022504010134273104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6854976415634155,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0272995512932539,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10658528804779052,
      "backward_entropy": 0.02074709865781996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2044095993041992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027349840849637985,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1065589427947998,
      "backward_entropy": 0.017104422052701313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3836508989334106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027398938313126564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10653311014175415,
      "backward_entropy": 0.021543537576993305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.767359972000122,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02744722180068493,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10650688409805298,
      "backward_entropy": 0.019877306289143033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8228164911270142,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02749534882605076,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10647795200347901,
      "backward_entropy": 0.02092928025457594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4739086627960205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02754341997206211,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10644488334655762,
      "backward_entropy": 0.016068493326505024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2309069633483887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027590898796916008,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1064107894897461,
      "backward_entropy": 0.019047912624147203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.690740942955017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02763744629919529,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10637649297714233,
      "backward_entropy": 0.020023831062846713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6451263427734375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027683906257152557,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1063399076461792,
      "backward_entropy": 0.01533148189385732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2200218439102173,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027730215340852737,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1063008427619934,
      "backward_entropy": 0.015093088150024414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2822703123092651,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02777566947042942,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10626146793365479,
      "backward_entropy": 0.014859941270616319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1594916582107544,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027820466086268425,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10622223615646362,
      "backward_entropy": 0.01886310676733653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.29519784450531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02786446176469326,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10618466138839722,
      "backward_entropy": 0.017507826288541157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3487399816513062,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027907956391572952,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10614563226699829,
      "backward_entropy": 0.01831437150637309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1386021375656128,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027951104566454887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10610514879226685,
      "backward_entropy": 0.018044781353738572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4375981092453003,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027993550524115562,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10606439113616943,
      "backward_entropy": 0.017780595355563693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.987676203250885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028035923838615417,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10602040290832519,
      "backward_entropy": 0.0175172703133689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9598388671875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028077371418476105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10597670078277588,
      "backward_entropy": 0.017260923981666565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.928905725479126,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028117932379245758,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10593364238739014,
      "backward_entropy": 0.013172907961739434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9748290777206421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02815762162208557,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10589088201522827,
      "backward_entropy": 0.0167680647638109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2474254369735718,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028196608647704124,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10584737062454223,
      "backward_entropy": 0.016529993878470525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.991351842880249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028235536068677902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10580084323883057,
      "backward_entropy": 0.016292525662316218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8195229172706604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028273873031139374,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1057533860206604,
      "backward_entropy": 0.016058385372161865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9344379901885986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028311310335993767,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10570657253265381,
      "backward_entropy": 0.015830604566468134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8310388326644897,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02834819257259369,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1056591272354126,
      "backward_entropy": 0.01209556394153171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9429261684417725,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028384309262037277,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10561071634292603,
      "backward_entropy": 0.015388253662321303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5237094759941101,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028420016169548035,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1055607795715332,
      "backward_entropy": 0.011768551336394416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8892540335655212,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028454359620809555,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10551321506500244,
      "backward_entropy": 0.014343589544296265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9215620160102844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028488360345363617,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10546425580978394,
      "backward_entropy": 0.01416856712765164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6506245732307434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028522122651338577,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10541291236877441,
      "backward_entropy": 0.011311370465490553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5696995258331299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028554977849125862,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10536165237426758,
      "backward_entropy": 0.013828968836201562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6130368709564209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028586789965629578,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10531086921691894,
      "backward_entropy": 0.014176727996932136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48315656185150146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028617801144719124,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10526041984558106,
      "backward_entropy": 0.013511743810441759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.683047354221344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028647741302847862,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10521171092987061,
      "backward_entropy": 0.013817452722125582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5022321343421936,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028677232563495636,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10516148805618286,
      "backward_entropy": 0.010632711152235666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5919440984725952,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028705798089504242,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10511161088943481,
      "backward_entropy": 0.01347713503572676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5221452116966248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028733795508742332,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10506092309951783,
      "backward_entropy": 0.010387281576792399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6077260971069336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02876105159521103,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1050098180770874,
      "backward_entropy": 0.01279804358879725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3975815773010254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028787925839424133,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10495744943618775,
      "backward_entropy": 0.012998406257894304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5724907517433167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02881380170583725,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10490627288818359,
      "backward_entropy": 0.012539549006356133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5102754235267639,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028839318081736565,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10485364198684692,
      "backward_entropy": 0.012700663672553169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6287670135498047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028864305466413498,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1048001766204834,
      "backward_entropy": 0.012556213471624587,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5243549942970276,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028889212757349014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10474412441253662,
      "backward_entropy": 0.00972782572110494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5508158206939697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028913702815771103,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1046868920326233,
      "backward_entropy": 0.009626439876026578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5756290555000305,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02893790602684021,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10462788343429566,
      "backward_entropy": 0.00952698869837655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40049248933792114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028961950913071632,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10456666946411133,
      "backward_entropy": 0.011993033190568289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.42732563614845276,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02898525260388851,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10450586080551147,
      "backward_entropy": 0.009334734744495816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48934632539749146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02900799736380577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10444486141204834,
      "backward_entropy": 0.011729170050885942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32926714420318604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029030466452240944,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10438241958618164,
      "backward_entropy": 0.011600789924462637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3905584216117859,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029052020981907845,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10432066917419433,
      "backward_entropy": 0.009068884783320956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4478664696216583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029073040932416916,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10425856113433837,
      "backward_entropy": 0.0089865666296747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3687254786491394,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02909381501376629,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10419493913650513,
      "backward_entropy": 0.008905798196792603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35840967297554016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02911399118602276,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10413082838058471,
      "backward_entropy": 0.011106221212281121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4105880856513977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02913358248770237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10406622886657715,
      "backward_entropy": 0.01101490275727378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3993662893772125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029152924194931984,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1040001630783081,
      "backward_entropy": 0.010905370116233826,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3584422767162323,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02917197160422802,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1039326548576355,
      "backward_entropy": 0.010797578427526686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37641650438308716,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029190579429268837,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10386433601379394,
      "backward_entropy": 0.010692383680078719,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36717110872268677,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02920890785753727,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10379472970962525,
      "backward_entropy": 0.010588872763845656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48974609375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029226887971162796,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10372385978698731,
      "backward_entropy": 0.010591978828112284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29372116923332214,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029245220124721527,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10364935398101807,
      "backward_entropy": 0.01051024595896403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.36083322763442993,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029262879863381386,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10357496738433838,
      "backward_entropy": 0.008274866474999322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27791428565979004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0292802881449461,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1034991979598999,
      "backward_entropy": 0.00821248193581899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29273906350135803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02929702401161194,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10342357158660889,
      "backward_entropy": 0.010092488593525357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10553204268217087,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02931327000260353,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10334758758544922,
      "backward_entropy": 0.01021158778005176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3202482759952545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02932795137166977,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10327513217926025,
      "backward_entropy": 0.008045825693342421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2280956208705902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029342548921704292,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10320100784301758,
      "backward_entropy": 0.010085912214385139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26510366797447205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029356494545936584,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10312725305557251,
      "backward_entropy": 0.009758054382271238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2747929096221924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02937004715204239,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10305286645889282,
      "backward_entropy": 0.009681643711196052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24866017699241638,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029383409768342972,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10297737121582032,
      "backward_entropy": 0.007859217623869577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1685304194688797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029396435245871544,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10290131568908692,
      "backward_entropy": 0.00953276620970832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.182461678981781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029408613219857216,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1028265118598938,
      "backward_entropy": 0.009808604088094499,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.179286390542984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02942013368010521,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10275236368179322,
      "backward_entropy": 0.007739775710635715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1570599228143692,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029431024566292763,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10267879962921142,
      "backward_entropy": 0.009336291087998284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20662470161914825,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0294412262737751,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10260612964630127,
      "backward_entropy": 0.007674023509025574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.29543861746788025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029451100155711174,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10253304243087769,
      "backward_entropy": 0.009637214243412018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22668680548667908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02946142852306366,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10245692729949951,
      "backward_entropy": 0.009595917330847846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2182166576385498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029471643269062042,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10237971544265748,
      "backward_entropy": 0.009555228882365756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2589801847934723,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029481777921319008,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10230053663253784,
      "backward_entropy": 0.007549535897043016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15796935558319092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029492132365703583,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10221894979476928,
      "backward_entropy": 0.00898544407553143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2140667885541916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029501769691705704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.1021382212638855,
      "backward_entropy": 0.008929807278845046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16192960739135742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029511451721191406,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10205597877502441,
      "backward_entropy": 0.00939825177192688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11301262676715851,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02952059917151928,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10197417736053467,
      "backward_entropy": 0.007432167728741963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19045042991638184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02952899970114231,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1018937349319458,
      "backward_entropy": 0.007407795223924849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13351264595985413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029537320137023926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10181239843368531,
      "backward_entropy": 0.007383771240711212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13389764726161957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02954516001045704,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10173200368881226,
      "backward_entropy": 0.008676729268497892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21192115545272827,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029552504420280457,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10165218114852906,
      "backward_entropy": 0.007341075274679396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11790180951356888,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029560143128037453,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10157029628753662,
      "backward_entropy": 0.008587702280945249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14576055109500885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029567161574959755,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.1014894962310791,
      "backward_entropy": 0.00918940951426824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14700692892074585,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029573962092399597,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10140851736068726,
      "backward_entropy": 0.007282355593310462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16388742625713348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029580488801002502,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10132746696472168,
      "backward_entropy": 0.008464967211087545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10980570316314697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029586970806121826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10124565362930298,
      "backward_entropy": 0.008425578474998474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1810334324836731,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029592888429760933,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10116487741470337,
      "backward_entropy": 0.00838900109132131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1593557745218277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02959916554391384,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10108215808868408,
      "backward_entropy": 0.009074541429678598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10436481982469559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029605524614453316,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.1009984016418457,
      "backward_entropy": 0.007202082210116916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1103219985961914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029611289501190186,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10091588497161866,
      "backward_entropy": 0.009031177394919924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14944374561309814,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029616620391607285,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10083410739898682,
      "backward_entropy": 0.008242613739437528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12851132452487946,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029622070491313934,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10075129270553589,
      "backward_entropy": 0.008993608256181082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10123448818922043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029627427458763123,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10066816806793213,
      "backward_entropy": 0.007151217924224006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1353582739830017,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02963239885866642,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10058578252792358,
      "backward_entropy": 0.00895788437790341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10819461941719055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029637333005666733,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.10050289630889893,
      "backward_entropy": 0.008111576239267984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08695212006568909,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029641954228281975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10042047500610352,
      "backward_entropy": 0.008924980958302816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1047658696770668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02964615263044834,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10033904314041138,
      "backward_entropy": 0.007112945119539897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13852769136428833,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029650278389453888,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10025752782821655,
      "backward_entropy": 0.00889764643377728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10318978130817413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029654785990715027,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10017439126968383,
      "backward_entropy": 0.0070958104398515486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10788443684577942,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029659131541848183,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.10009143352508545,
      "backward_entropy": 0.0070869773626327515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07625701278448105,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029663408175110817,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.10000832080841064,
      "backward_entropy": 0.008853648271825578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12307119369506836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029667112976312637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09992671608924866,
      "backward_entropy": 0.007072245081265767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10564085841178894,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02967105060815811,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09984399080276489,
      "backward_entropy": 0.007888836165269216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08318079262971878,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029674863442778587,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09976128339767457,
      "backward_entropy": 0.008815700809160868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07123282551765442,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02967832423746586,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09967943429946899,
      "backward_entropy": 0.0070539166529973345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09381178021430969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968144603073597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09959861040115356,
      "backward_entropy": 0.007816769182682037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08577636629343033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029684582725167274,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09951757192611695,
      "backward_entropy": 0.007794400884045495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09923021495342255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02968764677643776,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09943665266036987,
      "backward_entropy": 0.007772402630911933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06869310140609741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690910130739212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09935499429702759,
      "backward_entropy": 0.007749525209267934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06994064897298813,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029693787917494774,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09927446842193603,
      "backward_entropy": 0.008754862679375542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06747844815254211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02969644032418728,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0991946816444397,
      "backward_entropy": 0.007708609104156494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07377124577760696,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029698900878429413,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0991155743598938,
      "backward_entropy": 0.00702689422501458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07806970924139023,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029701221734285355,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09903687238693237,
      "backward_entropy": 0.007671394281917148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0713438019156456,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029703477397561073,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09895826578140259,
      "backward_entropy": 0.0070238204465972055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06643594056367874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029705757275223732,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09887976050376893,
      "backward_entropy": 0.007022128336959415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07449235022068024,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029707957059144974,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09880165457725525,
      "backward_entropy": 0.007020578616195255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04780121147632599,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029710227623581886,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09872339367866516,
      "backward_entropy": 0.00760020481215583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07115114480257034,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029712073504924774,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09864671230316162,
      "backward_entropy": 0.007018401390976376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0747641995549202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02971402369439602,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09856981039047241,
      "backward_entropy": 0.00756826251745224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08108893036842346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029716121032834053,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09849247932434083,
      "backward_entropy": 0.007551441589991252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060571227222681046,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02971850149333477,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0984142541885376,
      "backward_entropy": 0.007013705041673448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05634649842977524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02972073294222355,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09833554029464722,
      "backward_entropy": 0.008674281338850657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060430362820625305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02972288429737091,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09825708270072937,
      "backward_entropy": 0.007499092155032688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0649707019329071,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029725003987550735,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0981786608695984,
      "backward_entropy": 0.00866058717171351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056233927607536316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029727265238761902,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09809982776641846,
      "backward_entropy": 0.007465130752987332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.038373395800590515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029729507863521576,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09802123308181762,
      "backward_entropy": 0.007448023392094506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06282104551792145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029731353744864464,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09794425964355469,
      "backward_entropy": 0.008639952374829186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04676535353064537,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029733307659626007,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09786689281463623,
      "backward_entropy": 0.008633572194311354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04977161064743996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029735103249549866,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09779033660888672,
      "backward_entropy": 0.007402343054612477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03811683878302574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029736945405602455,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09771402478218079,
      "backward_entropy": 0.006999654902352227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.048509564250707626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02973850630223751,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09763903617858886,
      "backward_entropy": 0.0073737651109695435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.047399260103702545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029740111902356148,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09756425619125367,
      "backward_entropy": 0.007360037830140855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041347529739141464,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029741892591118813,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0974895179271698,
      "backward_entropy": 0.008606001734733582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.060938477516174316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029743671417236328,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09741538763046265,
      "backward_entropy": 0.006996280617184109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04703008010983467,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029745766893029213,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0973402202129364,
      "backward_entropy": 0.007315502398543888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04281793534755707,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02974790893495083,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09726521968841553,
      "backward_entropy": 0.007299623555607266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050547897815704346,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029750032350420952,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09719070196151733,
      "backward_entropy": 0.007283893724282582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04730469360947609,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029752308502793312,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09711586236953736,
      "backward_entropy": 0.008569279478655921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030738867819309235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0297547634691,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09704086780548096,
      "backward_entropy": 0.0072504546907212995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.037219882011413574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029757006093859673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09696729183197021,
      "backward_entropy": 0.0072344210412767194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03753654286265373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0297591183334589,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09689443111419678,
      "backward_entropy": 0.0072190769844585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0318690650165081,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02976120077073574,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09682209491729736,
      "backward_entropy": 0.006967282129658593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03680725023150444,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02976313605904579,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09675074815750122,
      "backward_entropy": 0.0069643739196989275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03713228553533554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029765143990516663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09667970538139344,
      "backward_entropy": 0.007174944712056054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03378311172127724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029767179861664772,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0966089129447937,
      "backward_entropy": 0.007160285280810462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028270157054066658,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029769184067845345,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09653865098953247,
      "backward_entropy": 0.006954266793198056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03451216593384743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02977105788886547,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09646940231323242,
      "backward_entropy": 0.007132047580348121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03577393665909767,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02977307327091694,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09640029668807984,
      "backward_entropy": 0.007117724253071679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03540370240807533,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029775260016322136,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09633114337921142,
      "backward_entropy": 0.006943138937155406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03444366157054901,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029777467250823975,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09626200199127197,
      "backward_entropy": 0.008477669623163011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03110499307513237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029779687523841858,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09619295597076416,
      "backward_entropy": 0.007072547243701087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0291192214936018,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029781879857182503,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09612429141998291,
      "backward_entropy": 0.006929453876283433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022198261693120003,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029784077778458595,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09605612754821777,
      "backward_entropy": 0.008452433678838942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030825041234493256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029786046594381332,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09598926305770875,
      "backward_entropy": 0.007029038336541917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030654024332761765,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02978813834488392,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0959224283695221,
      "backward_entropy": 0.007014791998598311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023531878367066383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02979031205177307,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09585559964179993,
      "backward_entropy": 0.007000225285689036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023536890745162964,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029792457818984985,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.095789635181427,
      "backward_entropy": 0.008420280284351774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028758924454450607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02979455143213272,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09572440385818481,
      "backward_entropy": 0.00841224855846829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03007769025862217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029796689748764038,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09565913081169128,
      "backward_entropy": 0.006898113836844762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.027095038443803787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029798980802297592,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09559351205825806,
      "backward_entropy": 0.006942859954304165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02005428820848465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02980128675699234,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0955267071723938,
      "backward_entropy": 0.006887289798922009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01945784129202366,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029803447425365448,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09546054601669311,
      "backward_entropy": 0.008377182814810012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01856774277985096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02980547398328781,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09539511203765869,
      "backward_entropy": 0.006900477740499709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01749485544860363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02980738878250122,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09533047676086426,
      "backward_entropy": 0.008361726999282837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01519452128559351,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029809044674038887,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0952667236328125,
      "backward_entropy": 0.00687590738137563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01823604479432106,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029810534790158272,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0952041506767273,
      "backward_entropy": 0.006869041257434421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01648211106657982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029812000691890717,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09514211416244507,
      "backward_entropy": 0.006854286210404502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01887020654976368,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029813405126333237,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09508086442947387,
      "backward_entropy": 0.0068647058473693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016351399943232536,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02981472760438919,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09501988887786865,
      "backward_entropy": 0.008333130015267266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015343534760177135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029815969988703728,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09495956301689149,
      "backward_entropy": 0.00686174010237058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02126534841954708,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029817162081599236,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09490001201629639,
      "backward_entropy": 0.006860539731052186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011822646483778954,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02981860749423504,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09484008550643921,
      "backward_entropy": 0.006804557724131478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01662346161901951,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02981993556022644,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09478101134300232,
      "backward_entropy": 0.006794780906703737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015357383526861668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029821326956152916,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09472112655639649,
      "backward_entropy": 0.006784787608517541,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011975279077887535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029822729527950287,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09466121196746827,
      "backward_entropy": 0.008301599986023374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012550384737551212,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029824042692780495,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09460209012031555,
      "backward_entropy": 0.00676527288224962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01765516772866249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029825305566191673,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09454358220100403,
      "backward_entropy": 0.006756027953492271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00957975909113884,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02982671558856964,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09448454380035401,
      "backward_entropy": 0.0067461902896563215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01333340909332037,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02982802502810955,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0944268524646759,
      "backward_entropy": 0.00828063405222363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015437412075698376,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02982926368713379,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09436941146850586,
      "backward_entropy": 0.006727926019165251,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009900717064738274,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029830601066350937,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09431173801422119,
      "backward_entropy": 0.006838166051440769,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011540754698216915,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02983185462653637,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09425517916679382,
      "backward_entropy": 0.006836082372400496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010987263172864914,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029833072796463966,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09419916868209839,
      "backward_entropy": 0.006700885792573293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012110349722206593,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029834266752004623,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09414383172988891,
      "backward_entropy": 0.006832260224554274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012613222002983093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029835496097803116,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09408873915672303,
      "backward_entropy": 0.006683614518907335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010989955626428127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02983683906495571,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09403379559516907,
      "backward_entropy": 0.006674485488070382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009469478391110897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029838217422366142,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09397938251495361,
      "backward_entropy": 0.006665260427527958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013808094896376133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029839495196938515,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09392571449279785,
      "backward_entropy": 0.00682255004843076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010053129866719246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02984098717570305,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09387160539627075,
      "backward_entropy": 0.006646863288349575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00927986204624176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029842546209692955,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09381818771362305,
      "backward_entropy": 0.006636999961402681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009111005812883377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029844064265489578,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.0937654733657837,
      "backward_entropy": 0.00821392403708564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00875148270279169,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029845532029867172,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09371336102485657,
      "backward_entropy": 0.00820763326353497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010575137101113796,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02984701469540596,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09366199970245362,
      "backward_entropy": 0.006805419921875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008926935493946075,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029848603531718254,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09361066818237304,
      "backward_entropy": 0.006598888999885983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006694611627608538,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029850192368030548,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09355981349945068,
      "backward_entropy": 0.00658917302886645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005106172990053892,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029851626604795456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0935099959373474,
      "backward_entropy": 0.0065801483061578535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006434641778469086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02985290251672268,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09346174001693726,
      "backward_entropy": 0.006571885612275865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006964413449168205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029854092746973038,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09341438412666321,
      "backward_entropy": 0.006564036011695862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006722138728946447,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029855258762836456,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09336762428283692,
      "backward_entropy": 0.006556332111358643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007141739595681429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029856400564312935,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09332146644592285,
      "backward_entropy": 0.006548788812425401,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006852617487311363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029857521876692772,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09327560663223267,
      "backward_entropy": 0.008155846761332618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006300484761595726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029858576133847237,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09322999119758606,
      "backward_entropy": 0.006534178637795978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005674772430211306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029859641566872597,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09318498373031617,
      "backward_entropy": 0.006527039325899548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004764553625136614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986064925789833,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0931406557559967,
      "backward_entropy": 0.006520160370402866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005381477996706963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029861565679311752,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09309734106063842,
      "backward_entropy": 0.006513739625612895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005117873195558786,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029862429946660995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09305456280708313,
      "backward_entropy": 0.006507563922140334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004617249593138695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029863299801945686,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09301252365112304,
      "backward_entropy": 0.006501418020990159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004853812977671623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029864154756069183,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0929713487625122,
      "backward_entropy": 0.006495391329129537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003313615918159485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029865005984902382,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09293079972267151,
      "backward_entropy": 0.006489434176021152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004491642117500305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029865799471735954,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09289158582687378,
      "backward_entropy": 0.006483794086509281,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005302635952830315,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029866551980376244,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09285285472869872,
      "backward_entropy": 0.0064783551626735264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004016955848783255,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029867392033338547,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0928142249584198,
      "backward_entropy": 0.006768619020779927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0030453139916062355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029868202283978462,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09277624487876893,
      "backward_entropy": 0.006466934664381875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003985894378274679,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986898459494114,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09273951053619385,
      "backward_entropy": 0.006461513953076469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003796321339905262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02986975759267807,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09270324110984803,
      "backward_entropy": 0.006456172714630763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003405983792617917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029870567843317986,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09266756772994995,
      "backward_entropy": 0.00676388003759914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024993291590362787,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987135760486126,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09263255596160888,
      "backward_entropy": 0.006445378892951542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035172230564057827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987213432788849,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09259884357452393,
      "backward_entropy": 0.0064401837686697645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003078746609389782,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029872892424464226,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09256544709205627,
      "backward_entropy": 0.006760098040103912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035556142684072256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029873669147491455,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09253275394439697,
      "backward_entropy": 0.006430000894599491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0033860697876662016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029874468222260475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09250022768974304,
      "backward_entropy": 0.006424784246418212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029868423007428646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987532690167427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09246808886528016,
      "backward_entropy": 0.006419353187084198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003181454027071595,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029876163229346275,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09243636131286621,
      "backward_entropy": 0.006414049201541477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028367014601826668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029877008870244026,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09240484237670898,
      "backward_entropy": 0.0067521317137612235,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0035158267710357904,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029877856373786926,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0923737645149231,
      "backward_entropy": 0.006750371307134628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022432703990489244,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029878808185458183,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09234265089035035,
      "backward_entropy": 0.008058461050192514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021070241928100586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02987966313958168,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09231215715408325,
      "backward_entropy": 0.006392457418971592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026763612404465675,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029880406334996223,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.092282235622406,
      "backward_entropy": 0.0063876691791746355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022379213478416204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02988121472299099,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09225268363952636,
      "backward_entropy": 0.006382637553744846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017924648709595203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029881970956921577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09222357273101807,
      "backward_entropy": 0.006377852625317044,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022462396882474422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029882606118917465,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09219502210617066,
      "backward_entropy": 0.008040478660000695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002367872279137373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02988327108323574,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09216688871383667,
      "backward_entropy": 0.006369224852985806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00131738290656358,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029883958399295807,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09213892221450806,
      "backward_entropy": 0.006364806244770686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022273750510066748,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02988460659980774,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09211214184761048,
      "backward_entropy": 0.006360602047708299,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018448173068463802,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029885299503803253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09208551049232483,
      "backward_entropy": 0.006356235179636214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019834262784570456,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029886020347476006,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09205940961837769,
      "backward_entropy": 0.006351788424783283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019963362719863653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02988678589463234,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09203362464904785,
      "backward_entropy": 0.006347194314002991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001696040970273316,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02988765388727188,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09200822710990905,
      "backward_entropy": 0.006730908321009742,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014327045064419508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029888514429330826,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09198325872421265,
      "backward_entropy": 0.0063373032543394305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013490525307133794,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02988937310874462,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09195901155471801,
      "backward_entropy": 0.006726497163375218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001022985321469605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029890207573771477,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09193539023399352,
      "backward_entropy": 0.006327686624394523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018324158154428005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02989097125828266,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09191260933876037,
      "backward_entropy": 0.00632328126165602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011916488874703646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02989177219569683,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09188963174819946,
      "backward_entropy": 0.006720417075686985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014617263805121183,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02989250421524048,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09186707735061646,
      "backward_entropy": 0.006718658738666111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012824888108298182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029893245548009872,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09184468388557435,
      "backward_entropy": 0.0063101839688089155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013024879153817892,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029894014820456505,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09182268977165223,
      "backward_entropy": 0.006305824965238571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011282700579613447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029894771054387093,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09180089235305786,
      "backward_entropy": 0.006712947454717424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011706202058121562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029895514249801636,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09177949428558349,
      "backward_entropy": 0.006297319299644894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000921686936635524,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029896266758441925,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09175840616226197,
      "backward_entropy": 0.006293077435758378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001094019622541964,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02989700622856617,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09173792004585266,
      "backward_entropy": 0.006288938224315643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010724165476858616,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029897743836045265,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09171764850616455,
      "backward_entropy": 0.007968568139606051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009333526249974966,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029898453503847122,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09169749021530152,
      "backward_entropy": 0.007965185576015048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007916800095699728,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029899105429649353,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09167759418487549,
      "backward_entropy": 0.006277061171001858,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00084093795157969,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02989974245429039,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09165825843811035,
      "backward_entropy": 0.006700252493222554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008469169843010604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029900314286351204,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09163916110992432,
      "backward_entropy": 0.006269995537069108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006918289000168443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029900893568992615,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09162037372589112,
      "backward_entropy": 0.006266603039370643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000795097672380507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02990145981311798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09160208702087402,
      "backward_entropy": 0.0062633003625604845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006763918790966272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029902024194598198,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09158403277397156,
      "backward_entropy": 0.006259990235169728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000714041874743998,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029902564361691475,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0915663480758667,
      "backward_entropy": 0.006256825808021758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000640638405457139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029903091490268707,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09154891967773438,
      "backward_entropy": 0.006253718501991696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006923169130459428,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029903588816523552,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09153177738189697,
      "backward_entropy": 0.006250744064648946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006041991873644292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029904091730713844,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09151482582092285,
      "backward_entropy": 0.006247768385542763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005262321210466325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02990458533167839,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09149817824363708,
      "backward_entropy": 0.006244845688343048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006015807157382369,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02990509197115898,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09148201942443848,
      "backward_entropy": 0.0079329295290841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005982191651128232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029905563220381737,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0914659857749939,
      "backward_entropy": 0.006239111224810283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005521839484572411,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02990603819489479,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09145008325576783,
      "backward_entropy": 0.006236312290032704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004035880556330085,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029906518757343292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09143439531326295,
      "backward_entropy": 0.006233501351541943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047754685510881245,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029906943440437317,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09141919612884522,
      "backward_entropy": 0.006684013952811559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036986396298743784,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029907362535595894,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09140421748161316,
      "backward_entropy": 0.0066831376817491316,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003610336862038821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02990778721868992,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09138976335525513,
      "backward_entropy": 0.006225886030329598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00039594879490323365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029908176511526108,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.091375732421875,
      "backward_entropy": 0.007917697230974833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042908918112516403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02990853786468506,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09136193990707397,
      "backward_entropy": 0.006221302267577913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004078947240486741,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029908902943134308,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09134825468063354,
      "backward_entropy": 0.006679976152049171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003909970400854945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029909219592809677,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09133468866348267,
      "backward_entropy": 0.00667946082022455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003043102042283863,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029909510165452957,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09132122993469238,
      "backward_entropy": 0.0062151286337110735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036917024408467114,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029909787699580193,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09130817651748657,
      "backward_entropy": 0.006213277992275026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032941592507995665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029910067096352577,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09129523038864136,
      "backward_entropy": 0.007907900545332167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027903506997972727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02991032414138317,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09128248691558838,
      "backward_entropy": 0.007906505631075965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026443813112564385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029910558834671974,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09127005338668823,
      "backward_entropy": 0.007905205090840658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021995701536070555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991078794002533,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09125795364379882,
      "backward_entropy": 0.006206423044204712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026817742036655545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991100773215294,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09124629497528076,
      "backward_entropy": 0.006204881601863437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002664512721821666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991124428808689,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09123482704162597,
      "backward_entropy": 0.006677117612626817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002732067951001227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991149201989174,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09122350215911865,
      "backward_entropy": 0.006201657156149547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024454400409013033,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029911711812019348,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09121225476264953,
      "backward_entropy": 0.0062001463439729475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019676169904414564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02991189993917942,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09120116829872131,
      "backward_entropy": 0.007897756165928312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002253468701383099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991209551692009,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09119041562080384,
      "backward_entropy": 0.006197379281123479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001685019669821486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029912283644080162,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09117980599403382,
      "backward_entropy": 0.006196034865246879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018108365475200117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991246059536934,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09116957187652588,
      "backward_entropy": 0.006194743017355601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018538669974077493,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029912635684013367,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09115960597991943,
      "backward_entropy": 0.006676043073336284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017117361130658537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029912792146205902,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09114980697631836,
      "backward_entropy": 0.006676012857092751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015994015848264098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029912929981946945,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09114024639129639,
      "backward_entropy": 0.006191210614310371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015628288383595645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991304360330105,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09113091230392456,
      "backward_entropy": 0.006190237071779039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016855873400345445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029913144186139107,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09112179875373841,
      "backward_entropy": 0.006676406082179811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001528203283669427,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029913228005170822,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09111278653144836,
      "backward_entropy": 0.0061884671449661255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013752457743976265,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029913287609815598,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09110392332077026,
      "backward_entropy": 0.006187722086906433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013818562729284167,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991333417594433,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09109529852867126,
      "backward_entropy": 0.0061870333221223615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012759306991938502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029913395643234253,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09108681082725525,
      "backward_entropy": 0.006186303993066152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.331686305813491e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029913468286395073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09107850193977356,
      "backward_entropy": 0.006185541964239544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012517311552073807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029913537204265594,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09107059240341187,
      "backward_entropy": 0.006678300599257152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010348099021939561,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991359867155552,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09106278419494629,
      "backward_entropy": 0.006678615179326799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011615298717515543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991366758942604,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09105519652366638,
      "backward_entropy": 0.006678860634565353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.75673649716191e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029913736507296562,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09104768037796021,
      "backward_entropy": 0.006679106089803908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.905231854645535e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029913807287812233,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09104045033454895,
      "backward_entropy": 0.006182044330570433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.97698157839477e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991386130452156,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09103336334228515,
      "backward_entropy": 0.006181425932380889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.988552533788607e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029913919046521187,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09102654457092285,
      "backward_entropy": 0.0066798776388168335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.409930160269141e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029913978651165962,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09101995229721069,
      "backward_entropy": 0.007882271375921037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.439434895990416e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991403080523014,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09101349115371704,
      "backward_entropy": 0.006680401662985484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.809248588979244e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029914097860455513,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09100710153579712,
      "backward_entropy": 0.006179004493686888,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.92589019308798e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991417422890663,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0910009503364563,
      "backward_entropy": 0.006178358362780677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.132959192153066e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991424687206745,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0909949779510498,
      "backward_entropy": 0.006177720096376207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.723783008055761e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029914313927292824,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09098896980285645,
      "backward_entropy": 0.006681033306651645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8890942707657814e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029914380982518196,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09098310470581054,
      "backward_entropy": 0.006176520552900102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.865668936166912e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991444803774357,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09097754955291748,
      "backward_entropy": 0.006175946444272995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.267302185529843e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991451695561409,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09097213745117187,
      "backward_entropy": 0.006175369024276733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.287382711889222e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029914597049355507,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09096689820289612,
      "backward_entropy": 0.006174756420983208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.245284046395682e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029914677143096924,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0909616470336914,
      "backward_entropy": 0.0061741318139765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7327353968285024e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991475909948349,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09095650911331177,
      "backward_entropy": 0.006681655844052632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.437138730078004e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029914837330579758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0909515380859375,
      "backward_entropy": 0.0061729297869735295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.127676584175788e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991493046283722,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0909468650817871,
      "backward_entropy": 0.006172308905257119,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5319458877202123e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029915031045675278,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09094233512878418,
      "backward_entropy": 0.006681615279780494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0391969378106296e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029915133491158485,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09093784093856812,
      "backward_entropy": 0.006681516352627013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.846051393134985e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029915230348706245,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09093345999717713,
      "backward_entropy": 0.006170350644323561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.82980470021721e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029915321618318558,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0909293532371521,
      "backward_entropy": 0.006169755011796951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.208541602361947e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029915405437350273,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09092530012130737,
      "backward_entropy": 0.006169201599227058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.773141568468418e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991548925638199,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09092140197753906,
      "backward_entropy": 0.006168653153710895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.462344466242939e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029915569350123405,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09091765880584717,
      "backward_entropy": 0.006681329260269801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1322764698415995e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991565316915512,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09091392755508423,
      "backward_entropy": 0.006167579856183793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7455849703983404e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029915733262896538,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09091025590896606,
      "backward_entropy": 0.006167050864961412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.493436295480933e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029915805906057358,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09090667963027954,
      "backward_entropy": 0.0061665574709574384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5524723241687752e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029915889725089073,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09090321063995362,
      "backward_entropy": 0.006166037172079086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5253702915506437e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02991597168147564,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09089981317520142,
      "backward_entropy": 0.007865800625748105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3786555175320245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916048049926758,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09089649319648743,
      "backward_entropy": 0.006165025962723626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5564748284523375e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916124418377876,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09089322090148926,
      "backward_entropy": 0.006164548711644279,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2554066163138486e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0299161896109581,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09088996052742004,
      "backward_entropy": 0.007864048911465539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.042227606580127e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029916252940893173,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09088674783706666,
      "backward_entropy": 0.00786351909240087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8507649656385183e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916314408183098,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09088360071182251,
      "backward_entropy": 0.006163246929645538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8542838006396778e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916375875473022,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09088056087493897,
      "backward_entropy": 0.0061628321806589765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.806522959668655e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916435480117798,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0908775806427002,
      "backward_entropy": 0.006162431091070175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7692213077680208e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029916493222117424,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09087464809417725,
      "backward_entropy": 0.006680986533562343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4018899491929915e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916539788246155,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09087180495262145,
      "backward_entropy": 0.006161686033010483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6751613657106645e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029916588217020035,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09086906909942627,
      "backward_entropy": 0.00786061253812578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3775086699752137e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029916631057858467,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09086637496948242,
      "backward_entropy": 0.007860199444823794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.362230977974832e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0299166738986969,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09086375832557678,
      "backward_entropy": 0.007859795457786985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2415081982908305e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029916711151599884,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09086121916770935,
      "backward_entropy": 0.006681238197618061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1604116480157245e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916750267148018,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09085875749588013,
      "backward_entropy": 0.006160121825006273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.245192288479302e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991678938269615,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09085637331008911,
      "backward_entropy": 0.006681330502033234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0280710739607457e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029916826635599136,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09085402488708497,
      "backward_entropy": 0.007858246564865112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.216394048242364e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991686388850212,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09085177183151245,
      "backward_entropy": 0.006159278667635388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1109374099760316e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916897416114807,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09084951877593994,
      "backward_entropy": 0.0061590249339739484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.606622031948064e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029916923493146896,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09084731936454774,
      "backward_entropy": 0.006681590444511837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.138581845036242e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029916953295469284,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09084520339965821,
      "backward_entropy": 0.0066816479795508915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.534489436191507e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029916983097791672,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09084312915802002,
      "backward_entropy": 0.006158329132530425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.864581443252973e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917007312178612,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09084111452102661,
      "backward_entropy": 0.006158128380775452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.54776499181753e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917025938630104,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.0908390998840332,
      "backward_entropy": 0.006681893434789445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.9474031079153065e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029917040839791298,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09083713293075561,
      "backward_entropy": 0.00785572412941191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.559229066420812e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991705760359764,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09083523750305175,
      "backward_entropy": 0.006157594836420483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.005757081264164e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917079955339432,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09083344936370849,
      "backward_entropy": 0.006682193941540188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4130612119915895e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917094856500626,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0908316969871521,
      "backward_entropy": 0.00615724590089586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.405329258996062e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991710603237152,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09082995653152466,
      "backward_entropy": 0.006157117171419991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.647273610520642e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029917115345597267,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.090828275680542,
      "backward_entropy": 0.007854488160875108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.168867912492715e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917128384113312,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09082661867141724,
      "backward_entropy": 0.006156836532884174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.021891294949455e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917141422629356,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09082496166229248,
      "backward_entropy": 0.006156696213616265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4153889575682115e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917152598500252,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09082331657409667,
      "backward_entropy": 0.006156548029846615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7685857680335175e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917165637016296,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09082176685333251,
      "backward_entropy": 0.006156409780184428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5810611482011154e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02991717867553234,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09082027673721313,
      "backward_entropy": 0.007853381335735321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.03848150401609e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917191714048386,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09081882238388062,
      "backward_entropy": 0.006156145698494381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9338297028734814e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917199164628983,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09081740379333496,
      "backward_entropy": 0.006156028972731696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8148036765051074e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029917210340499878,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09081599712371827,
      "backward_entropy": 0.007852769560284086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5566301903600106e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917221516370773,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09081467390060424,
      "backward_entropy": 0.006683381067381965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.448106326686684e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991723269224167,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0908133864402771,
      "backward_entropy": 0.006155671758784188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.975543222622946e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917243868112564,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09081215858459472,
      "backward_entropy": 0.0061555612418386675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1188885714072967e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991725318133831,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09081091284751892,
      "backward_entropy": 0.0066836414237817126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5241121167928213e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917264357209206,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09080970287322998,
      "backward_entropy": 0.006155338552263048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.599542540338007e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917273670434952,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09080849885940552,
      "backward_entropy": 0.006155232588450114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.442966660964885e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917284846305847,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09080735445022584,
      "backward_entropy": 0.006155136558744643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6125615022465354e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029917296022176743,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09080626964569091,
      "backward_entropy": 0.007851265370845795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7470973691379186e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917309060692787,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09080521464347839,
      "backward_entropy": 0.0066839853922526045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2272013211477315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917320236563683,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09080415964126587,
      "backward_entropy": 0.006154810388882955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.957604808922042e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917331412434578,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09080314636230469,
      "backward_entropy": 0.006154716842704349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9338126548973378e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917344450950623,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09080219268798828,
      "backward_entropy": 0.006154608395364549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.092125214403495e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029917357489466667,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09080127477645875,
      "backward_entropy": 0.007850358055697547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0755769583047368e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917370527982712,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09080038666725158,
      "backward_entropy": 0.006154408057530721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.904902433125244e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917381703853607,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079949855804444,
      "backward_entropy": 0.006154304991165797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.207529405495734e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029917392879724503,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09079862833023071,
      "backward_entropy": 0.007849829064475166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4913658787918394e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991739846765995,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.090797758102417,
      "backward_entropy": 0.006154134455654357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5464156604139134e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917407780885696,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079689979553222,
      "backward_entropy": 0.00615405829416381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.39251687869546e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917417094111443,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079607129096985,
      "backward_entropy": 0.00615396723151207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6249272221102729e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917428269982338,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079527854919434,
      "backward_entropy": 0.0061538877586523695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2648521305891336e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917435720562935,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079447984695435,
      "backward_entropy": 0.0061538004212909276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2784910268237581e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991744503378868,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079371690750122,
      "backward_entropy": 0.0061537255015638136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4220569255485316e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917454347014427,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.090792977809906,
      "backward_entropy": 0.006153649753994412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0524973959036288e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029917461797595024,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09079222679138184,
      "backward_entropy": 0.007848694920539856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1772613106586505e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991747111082077,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09079150557518005,
      "backward_entropy": 0.006153494947486454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1965156545556965e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917480424046516,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09079079031944275,
      "backward_entropy": 0.00668475694126553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.972183079298702e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917487874627113,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09079008102416992,
      "backward_entropy": 0.0066848016447491115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.387460409016057e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02991749532520771,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09078937768936157,
      "backward_entropy": 0.006684830205308067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.957594334584428e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917502775788307,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09078871011734009,
      "backward_entropy": 0.006684880289766524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.448248536296887e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917510226368904,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09078807830810547,
      "backward_entropy": 0.006684918370511796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.797644343554566e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0299175176769495,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09078744649887086,
      "backward_entropy": 0.00784786625040902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.278318321368715e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917525127530098,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0907868504524231,
      "backward_entropy": 0.006153019352091683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.874279847579601e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917532578110695,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078627824783325,
      "backward_entropy": 0.006152974234686958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.448573230954935e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917540028691292,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078574180603027,
      "backward_entropy": 0.0061529117325941724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.727549930474197e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991754747927189,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.0907852053642273,
      "backward_entropy": 0.006152857508924272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.178568128234474e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917554929852486,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078468084335327,
      "backward_entropy": 0.00615279624859492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.964937711018138e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029917562380433083,
      "trajectory_length": 11,
      "branch_chosen": 1,
      "forward_entropy": 0.09078415632247924,
      "backward_entropy": 0.006685121191872491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.680431627297367e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02991756796836853,
      "trajectory_length": 11,
      "branch_chosen": 0,
      "forward_entropy": 0.09078363180160523,
      "backward_entropy": 0.00784712036450704,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.11427458604885e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917573556303978,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078311920166016,
      "backward_entropy": 0.006152629852294922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.325618985807523e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917579144239426,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078261852264405,
      "backward_entropy": 0.006152583493126763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.133882154950697e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917584732174873,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078211784362793,
      "backward_entropy": 0.006152527199851142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.430194167071022e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991759032011032,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078162908554077,
      "backward_entropy": 0.006152480840682983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2830407664951053e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02991759590804577,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078114628791809,
      "backward_entropy": 0.006152439448568556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.873849721003353e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029917599633336067,
      "trajectory_length": 11,
      "branch_chosen": 2,
      "forward_entropy": 0.09078068137168885,
      "backward_entropy": 0.006152392261558109,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 1.2164339567277694e-05,
    "avg_log_Z": 0.029916784074157477,
    "success_rate": 1.0,
    "avg_reward": 49.8,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.17,
      "1": 0.2,
      "2": 0.63
    },
    "avg_forward_entropy": 0.09084211361408233,
    "avg_backward_entropy": 0.0065523705921239316,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}