{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 0.42857142857142855
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 0.7142857142857143
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.2309040625890096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.2309040625890096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.2309040625890096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.2309040625890096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.2309040625890096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23026448488235474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.32528018951416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27442097663879395,
      "backward_entropy": 0.23083577553431192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.03720760345459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2744064927101135,
      "backward_entropy": 0.2302231788635254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.318624973297119,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0001999529922613874,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743915617465973,
      "backward_entropy": 0.2307924429575602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2284369468688965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00029995033401064575,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2743763029575348,
      "backward_entropy": 0.23076887925465903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.312068939208984,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00039993959944695234,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743613123893738,
      "backward_entropy": 0.23009729385375977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.222817420959473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004999542725272477,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.274345725774765,
      "backward_entropy": 0.2308322787284851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39105749130249,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005999513668939471,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27433016896247864,
      "backward_entropy": 0.23081549008687338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.675745487213135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007000025361776352,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2743138372898102,
      "backward_entropy": 0.22996278603871664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.672537326812744,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0008001705864444375,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27429717779159546,
      "backward_entropy": 0.2307800849278768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41671085357666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009004235034808517,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27428025007247925,
      "backward_entropy": 0.23060071468353271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.208786964416504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0010009667603299022,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2742639183998108,
      "backward_entropy": 0.23056976000467935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.870321750640869,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0011013338807970285,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2742474675178528,
      "backward_entropy": 0.23071986436843872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.116100311279297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012017778353765607,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27423182129859924,
      "backward_entropy": 0.22971534729003906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8658037185668945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0013023893116042018,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27421557903289795,
      "backward_entropy": 0.2304698626200358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.90625524520874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0014030231395736337,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27420008182525635,
      "backward_entropy": 0.2306506633758545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.689642906188965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015033389208838344,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741837799549103,
      "backward_entropy": 0.22955322265625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.273612022399902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016040275804698467,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27416834235191345,
      "backward_entropy": 0.2294965386390686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.069194793701172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017045172862708569,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27415212988853455,
      "backward_entropy": 0.2294381062189738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.520833015441895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0018051021033897996,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2741382420063019,
      "backward_entropy": 0.2293779452641805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.851810455322266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019059418700635433,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2741260826587677,
      "backward_entropy": 0.23052151997884116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.578777313232422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00200675125233829,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27411431074142456,
      "backward_entropy": 0.23049269119898477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3376145362854,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002107482636347413,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27409985661506653,
      "backward_entropy": 0.23015371958414713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.17722225189209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002208019606769085,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27408406138420105,
      "backward_entropy": 0.2301081418991089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.957606315612793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023083023261278868,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2740681767463684,
      "backward_entropy": 0.22904839118321738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.108923435211182,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0024082930758595467,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740510404109955,
      "backward_entropy": 0.2300109068552653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9908294677734375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0025081150233745575,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2740318775177002,
      "backward_entropy": 0.22995962699254355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.579304695129395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0026081313844770193,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27401259541511536,
      "backward_entropy": 0.2302955985069275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.983664512634277,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0027085391338914633,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739947438240051,
      "backward_entropy": 0.22985470294952393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.235024452209473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0028090558480471373,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2739766240119934,
      "backward_entropy": 0.22980046272277832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.825627326965332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0029093443881720304,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2739580273628235,
      "backward_entropy": 0.23018038272857666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.970301151275635,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0030096699483692646,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2739405035972595,
      "backward_entropy": 0.22850990295410156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.852453708648682,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00311005930416286,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27392715215682983,
      "backward_entropy": 0.22962562243143717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.072654724121094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032100582029670477,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27391317486763,
      "backward_entropy": 0.2283379634221395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.484541893005371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0033097933046519756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27389994263648987,
      "backward_entropy": 0.2300036350886027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.663629055023193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0034099200274795294,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27388840913772583,
      "backward_entropy": 0.22943113247553507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.215386390686035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035100108943879604,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738790810108185,
      "backward_entropy": 0.2299051284790039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.842681884765625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0036098535638302565,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738725543022156,
      "backward_entropy": 0.22929064432779947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.472742080688477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0037102915812283754,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738637626171112,
      "backward_entropy": 0.22785147031148276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.097498893737793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0038110315799713135,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27385637164115906,
      "backward_entropy": 0.22914481163024902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.538633346557617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003911863546818495,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738502621650696,
      "backward_entropy": 0.22763963540395102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.864190578460693,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004012987948954105,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27384474873542786,
      "backward_entropy": 0.22752992312113443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715945243835449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004114065784960985,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27383866906166077,
      "backward_entropy": 0.2295701503753662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.042383670806885,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004215009976178408,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27383363246917725,
      "backward_entropy": 0.22882938385009766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.080107688903809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004315524362027645,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27382853627204895,
      "backward_entropy": 0.2271822690963745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.777291774749756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004416142590343952,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738245725631714,
      "backward_entropy": 0.22937808434168497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.443324089050293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004516717977821827,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273820698261261,
      "backward_entropy": 0.22856481870015463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.510591506958008,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004617562051862478,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27381783723831177,
      "backward_entropy": 0.22680715719858804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.876368522644043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004718683660030365,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738151252269745,
      "backward_entropy": 0.22916813691457114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.060403823852539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0048202225007116795,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27381253242492676,
      "backward_entropy": 0.22827579577763876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.899008750915527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004921724554151297,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27381086349487305,
      "backward_entropy": 0.22901841004689535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.226281642913818,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0050231460481882095,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27380770444869995,
      "backward_entropy": 0.226265549659729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.188146591186523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005124174058437347,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738018333911896,
      "backward_entropy": 0.22796106338500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.744111061096191,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005225304048508406,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737954258918762,
      "backward_entropy": 0.22597225507100424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.510865688323975,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005326292477548122,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737893760204315,
      "backward_entropy": 0.22869396209716797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.242703437805176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005427060183137655,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737816572189331,
      "backward_entropy": 0.22860745588938394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.751141548156738,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005527995061129332,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27377206087112427,
      "backward_entropy": 0.22851904233296713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.023999214172363,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005628754384815693,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737685441970825,
      "backward_entropy": 0.2273623545964559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.547107696533203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005729537922888994,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27376604080200195,
      "backward_entropy": 0.22833436727523804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.450374603271484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005830570589751005,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376750111579895,
      "backward_entropy": 0.2250429391860962,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.251810550689697,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005931817926466465,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376848459243774,
      "backward_entropy": 0.22487801313400269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.576444625854492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006032691337168217,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27376505732536316,
      "backward_entropy": 0.22804047664006552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.388670921325684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006133881397545338,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737598419189453,
      "backward_entropy": 0.2279385725657145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.588215827941895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006235166918486357,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737605571746826,
      "backward_entropy": 0.22783386707305908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.191617965698242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006336670368909836,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376359701156616,
      "backward_entropy": 0.2241894801457723,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3860368728637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006438218057155609,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27376413345336914,
      "backward_entropy": 0.2262170910835266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.110898971557617,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006539377849549055,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376341819763184,
      "backward_entropy": 0.22381226221720377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.58993911743164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0066405655816197395,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27376145124435425,
      "backward_entropy": 0.22739032904307047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8529691696167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006742476020008326,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273762583732605,
      "backward_entropy": 0.22572008768717447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.387680053710938,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006844649091362953,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376630902290344,
      "backward_entropy": 0.2232140302658081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.014020919799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0069468580186367035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27376899123191833,
      "backward_entropy": 0.22703019777933756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.713848114013672,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0070494613610208035,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27376699447631836,
      "backward_entropy": 0.22517933448155722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.526906967163086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007151706609874964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737637460231781,
      "backward_entropy": 0.22677860657374063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.586119651794434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00725400960072875,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737630307674408,
      "backward_entropy": 0.22478723526000977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.921226501464844,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007356402464210987,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737635672092438,
      "backward_entropy": 0.22211980819702148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9803924560546875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007458536885678768,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737645208835602,
      "backward_entropy": 0.22437214851379395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.267180442810059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007560481317341328,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376484870910645,
      "backward_entropy": 0.22164642810821533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.634575843811035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00766239408403635,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273765504360199,
      "backward_entropy": 0.22608991463979086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890439510345459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007764978334307671,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27376672625541687,
      "backward_entropy": 0.22115184863408408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469169616699219,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007867254316806793,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27376824617385864,
      "backward_entropy": 0.2257669766743978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.687155723571777,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007969536818563938,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737717032432556,
      "backward_entropy": 0.22063565254211426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.874760627746582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008071916177868843,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27377843856811523,
      "backward_entropy": 0.22037150462468466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.288146018981934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00817450974136591,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27378517389297485,
      "backward_entropy": 0.22523601849873862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.919443130493164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00827751960605383,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737906277179718,
      "backward_entropy": 0.2250461975733439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.547139644622803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008380702696740627,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737951874732971,
      "backward_entropy": 0.21954758961995444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.991372108459473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00848331768065691,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27379876375198364,
      "backward_entropy": 0.22200999657313028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.240399360656738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008586138486862183,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738049626350403,
      "backward_entropy": 0.21896878878275552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.070852279663086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008688795380294323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273809552192688,
      "backward_entropy": 0.22423468033472696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.377898216247559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008791767992079258,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2738105058670044,
      "backward_entropy": 0.22402522961298624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.500736236572266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008894594386219978,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738128900527954,
      "backward_entropy": 0.22092060248057047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.420625686645508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00899684801697731,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738145589828491,
      "backward_entropy": 0.22062993049621582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.31590461730957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009099063463509083,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27381670475006104,
      "backward_entropy": 0.22336596250534058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.878974914550781,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009201230481266975,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27381595969200134,
      "backward_entropy": 0.21701860427856445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.801298141479492,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009303633123636246,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738151252269745,
      "backward_entropy": 0.2197192112604777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0334320068359375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009406191296875477,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738143801689148,
      "backward_entropy": 0.2163021763165792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.646403312683105,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009507923386991024,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2738145589828491,
      "backward_entropy": 0.21593594551086426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.69718074798584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009609775617718697,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273816853761673,
      "backward_entropy": 0.21874173482259116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654297828674316,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00971177127212286,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2738206386566162,
      "backward_entropy": 0.21839964389801025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.384648323059082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009813925251364708,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27381980419158936,
      "backward_entropy": 0.2180528243382772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.23415470123291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009916026145219803,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27381929755210876,
      "backward_entropy": 0.21769789854685465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.767984390258789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010017490945756435,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27381566166877747,
      "backward_entropy": 0.21398691336313883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.996298789978027,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010119196958839893,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27381107211112976,
      "backward_entropy": 0.21696341037750244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.328681945800781,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010220680385828018,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27380722761154175,
      "backward_entropy": 0.21658289432525635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3401336669921875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010322147980332375,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27380403876304626,
      "backward_entropy": 0.2201997439066569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142022132873535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010423063300549984,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27380096912384033,
      "backward_entropy": 0.21989639600118002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.690659523010254,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010523952543735504,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2737952470779419,
      "backward_entropy": 0.21538647015889487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.705074310302734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010625098831951618,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737886905670166,
      "backward_entropy": 0.21927030881245932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.968181610107422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010725936852395535,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27378150820732117,
      "backward_entropy": 0.21894737084706625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.050821781158447,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010827731341123581,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27377358078956604,
      "backward_entropy": 0.21039982636769614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.438414573669434,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010928787291049957,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737637162208557,
      "backward_entropy": 0.21827727556228638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.019041061401367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011029905639588833,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27375665307044983,
      "backward_entropy": 0.21793107191721597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.625288963317871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011130832135677338,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27375349402427673,
      "backward_entropy": 0.20886160929997763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.389813423156738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011231420561671257,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27374953031539917,
      "backward_entropy": 0.2083305517832438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.410447597503662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011331594549119473,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2737424075603485,
      "backward_entropy": 0.21687289079030356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.410468101501465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011431354098021984,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27373772859573364,
      "backward_entropy": 0.2072364091873169,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.631452560424805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01153131015598774,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737339437007904,
      "backward_entropy": 0.2066762646039327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.141066551208496,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011631608009338379,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27372652292251587,
      "backward_entropy": 0.20610390106836954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.194438934326172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01173134334385395,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737206518650055,
      "backward_entropy": 0.20552186171213785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.660581111907959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011831186711788177,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737133502960205,
      "backward_entropy": 0.20492849747339884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.347080230712891,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011930788867175579,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27370840311050415,
      "backward_entropy": 0.20860175291697183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.022417068481445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012029942125082016,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737117111682892,
      "backward_entropy": 0.2037168343861898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.116893768310547,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012129717506468296,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27371278405189514,
      "backward_entropy": 0.20748114585876465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7982378005981445,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012230122461915016,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27370962500572205,
      "backward_entropy": 0.20690850416819254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.010091781616211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012330281548202038,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273709774017334,
      "backward_entropy": 0.21276007095972696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538726806640625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012430384755134583,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27370837330818176,
      "backward_entropy": 0.20111697912216187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.68639087677002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012530144304037094,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2737082839012146,
      "backward_entropy": 0.2004424532254537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.668229579925537,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01263029221445322,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273704469203949,
      "backward_entropy": 0.1997539202372233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.462347030639648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012730197980999947,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736988663673401,
      "backward_entropy": 0.21078900496164957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.007709503173828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01283031515777111,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27369335293769836,
      "backward_entropy": 0.21026329199473062,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.52471923828125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012930400669574738,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27368438243865967,
      "backward_entropy": 0.1976110339164734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.558199405670166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013030736707150936,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2736734449863434,
      "backward_entropy": 0.2091766595840454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.469803810119629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013130677863955498,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273667573928833,
      "backward_entropy": 0.20861756801605225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.002843856811523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013230853714048862,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27365928888320923,
      "backward_entropy": 0.20804649591445923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.7064104080200195,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013330944813787937,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2736515402793884,
      "backward_entropy": 0.19985240697860718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4666008949279785,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013430795632302761,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27364373207092285,
      "backward_entropy": 0.19914142290751138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.888123512268066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013530311174690723,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736342251300812,
      "backward_entropy": 0.19286672274271646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.254391670227051,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013630333356559277,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27362343668937683,
      "backward_entropy": 0.19202331701914468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.907894134521484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013729906640946865,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2736084461212158,
      "backward_entropy": 0.19116288423538208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.135785102844238,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013829349540174007,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.273599237203598,
      "backward_entropy": 0.19618713855743408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.216123104095459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013928256928920746,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27359288930892944,
      "backward_entropy": 0.2037423849105835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.985941410064697,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014026754535734653,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27358686923980713,
      "backward_entropy": 0.1946335236231486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.899941921234131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014125380665063858,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.273576557636261,
      "backward_entropy": 0.20241705576578775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4944939613342285,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014224059879779816,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2735634446144104,
      "backward_entropy": 0.19303826491038004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.415280342102051,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014321914874017239,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27355286478996277,
      "backward_entropy": 0.18578739960988364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.696145534515381,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014419035986065865,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27353987097740173,
      "backward_entropy": 0.20034917195638022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.297054290771484,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014516228809952736,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2735264301300049,
      "backward_entropy": 0.1996388832728068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.003605842590332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014613231644034386,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27351441979408264,
      "backward_entropy": 0.18970014651616415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.670981407165527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01470989640802145,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2735033631324768,
      "backward_entropy": 0.19818409283955893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.990312099456787,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014805424027144909,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2734977602958679,
      "backward_entropy": 0.18795454502105713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256815910339355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014900771901011467,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27349141240119934,
      "backward_entropy": 0.19669665892918906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.492620944976807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01499668974429369,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27348580956459045,
      "backward_entropy": 0.17895042896270752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.579434394836426,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015092689543962479,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27347901463508606,
      "backward_entropy": 0.19515172640482584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3369364738464355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015188205055892467,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27347248792648315,
      "backward_entropy": 0.1842147707939148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.025834560394287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015283157117664814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27346473932266235,
      "backward_entropy": 0.19356022278467813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2467851638793945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015377994626760483,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27345767617225647,
      "backward_entropy": 0.1927481691042582,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.383996963500977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015472859144210815,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27345144748687744,
      "backward_entropy": 0.17371773719787598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.914649963378906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015568455681204796,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27344346046447754,
      "backward_entropy": 0.18020335833231607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.229235649108887,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01566380262374878,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27343592047691345,
      "backward_entropy": 0.1791681448618571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.728338718414307,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015759138390421867,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2734268307685852,
      "backward_entropy": 0.17812112967173258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.926377296447754,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015854177996516228,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2734149396419525,
      "backward_entropy": 0.18847246964772543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.996598243713379,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015948468819260597,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273400217294693,
      "backward_entropy": 0.1681277553240458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.021803855895996,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016042757779359818,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27338171005249023,
      "backward_entropy": 0.17491241296132407,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.134125709533691,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01613633893430233,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733684778213501,
      "backward_entropy": 0.17381707827250162,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.74655294418335,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01622999832034111,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733571529388428,
      "backward_entropy": 0.18484652042388916,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6893181800842285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01632346771657467,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27334946393966675,
      "backward_entropy": 0.16338448723157248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.280087947845459,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016417406499385834,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2733399569988251,
      "backward_entropy": 0.1704519788424174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.050015449523926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016511553898453712,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27332577109336853,
      "backward_entropy": 0.18198049068450928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.257805347442627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016605697572231293,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2733112573623657,
      "backward_entropy": 0.18098763624827066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.213496208190918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016699347645044327,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27329620718955994,
      "backward_entropy": 0.1584987243016561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.70737361907959,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016792524605989456,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2732805609703064,
      "backward_entropy": 0.1572495996952057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.531614780426025,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016885599121451378,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27326342463493347,
      "backward_entropy": 0.1559899946053823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.901022911071777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016979139298200607,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2732420563697815,
      "backward_entropy": 0.17690769831339517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3185625076293945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01707267388701439,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2732188403606415,
      "backward_entropy": 0.16224327683448792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.983473777770996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01716582290828228,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27319490909576416,
      "backward_entropy": 0.17478060722351074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.577353000640869,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017258398234844208,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.273171067237854,
      "backward_entropy": 0.15084370970726013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.369693756103516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0173508133739233,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731488347053528,
      "backward_entropy": 0.1725417971611023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.753504753112793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01744297705590725,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27312570810317993,
      "backward_entropy": 0.1482300559679667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.266524314880371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017534490674734116,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2731042504310608,
      "backward_entropy": 0.17023372650146484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.172772407531738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017625780776143074,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27308186888694763,
      "backward_entropy": 0.1548159122467041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.801043510437012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017716795206069946,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2730594873428345,
      "backward_entropy": 0.15353665749231973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.318662166595459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017807291820645332,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2730391025543213,
      "backward_entropy": 0.14293622970581055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.309526443481445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017897017300128937,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2730202078819275,
      "backward_entropy": 0.1654857595761617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.379716873168945,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017986053600907326,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27300184965133667,
      "backward_entropy": 0.14964807033538818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.248420715332031,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018074559047818184,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2729812264442444,
      "backward_entropy": 0.13891772429148355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.468089580535889,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018162470310926437,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27296048402786255,
      "backward_entropy": 0.1375641425450643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.028461933135986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018250009045004845,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2729382812976837,
      "backward_entropy": 0.14571471015612283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.744305610656738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018336856737732887,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27291882038116455,
      "backward_entropy": 0.13484567403793335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.697545051574707,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018423601984977722,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2728988826274872,
      "backward_entropy": 0.13348535696665445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.558852195739746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018509503453969955,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2728819251060486,
      "backward_entropy": 0.14173054695129395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.541280269622803,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018595244735479355,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2728656232357025,
      "backward_entropy": 0.13077068328857422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.108005523681641,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018680842593312263,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27284878492355347,
      "backward_entropy": 0.1294146478176117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.130953311920166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01876603625714779,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27283063530921936,
      "backward_entropy": 0.1531111796696981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.188654899597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018850823864340782,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2728140950202942,
      "backward_entropy": 0.13634546597798666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.645510673522949,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01893608644604683,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727915644645691,
      "backward_entropy": 0.12533729275067648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.513278007507324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019021373242139816,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27276530861854553,
      "backward_entropy": 0.12397100528081258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.524052143096924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019106561318039894,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27273720502853394,
      "backward_entropy": 0.1478747526804606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3566765785217285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019191697239875793,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2727055251598358,
      "backward_entropy": 0.12124686439832051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8923542499542236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01927662454545498,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2726728916168213,
      "backward_entropy": 0.11988794803619385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4101057052612305,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019360236823558807,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27264606952667236,
      "backward_entropy": 0.12817196051279703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9624123573303223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019443105906248093,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27261966466903687,
      "backward_entropy": 0.11719209949175517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.478011608123779,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019524982199072838,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2725946009159088,
      "backward_entropy": 0.11582754055658977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.024324417114258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019606323912739754,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27257028222084045,
      "backward_entropy": 0.11446371674537659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.708191871643066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01968693919479847,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2725435495376587,
      "backward_entropy": 0.11309052507082622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.935668468475342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019767379388213158,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27251356840133667,
      "backward_entropy": 0.13722674051920572,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.187943458557129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019847778603434563,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27248185873031616,
      "backward_entropy": 0.1358884871006012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.909170627593994,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019927529618144035,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27245256304740906,
      "backward_entropy": 0.11873738964398702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.821229934692383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020006561651825905,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2724226713180542,
      "backward_entropy": 0.13318894306818643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.58099889755249,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020084859803318977,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27239304780960083,
      "backward_entropy": 0.1062702735265096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.083849906921387,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020163102075457573,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2723599374294281,
      "backward_entropy": 0.10491519172986348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7059874534606934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02024087868630886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2723260819911957,
      "backward_entropy": 0.12910103797912598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.36776876449585,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020317865535616875,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2722955346107483,
      "backward_entropy": 0.1277411381403605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.107654094696045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020394742488861084,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27226197719573975,
      "backward_entropy": 0.1263741354147593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.119457244873047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020471304655075073,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2722269296646118,
      "backward_entropy": 0.09956514835357666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7825217247009277,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020548472180962563,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2721834182739258,
      "backward_entropy": 0.09823111693064372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3690948486328125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020624155178666115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27214574813842773,
      "backward_entropy": 0.12223061919212341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.086548805236816,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020699024200439453,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27210885286331177,
      "backward_entropy": 0.09559529026349385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8069088459014893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02077377401292324,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27206847071647644,
      "backward_entropy": 0.104335884253184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.531236171722412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02084815874695778,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2720264792442322,
      "backward_entropy": 0.1181258757909139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4978652000427246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02092195674777031,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.271984726190567,
      "backward_entropy": 0.09168724219004314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.43971586227417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020995208993554115,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2719423770904541,
      "backward_entropy": 0.11540140708287557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4050681591033936,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021067913621664047,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2718997895717621,
      "backward_entropy": 0.08913259704907735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9769833087921143,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02114010602235794,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27185678482055664,
      "backward_entropy": 0.08786938587824504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7222893238067627,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021211441606283188,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2718147933483124,
      "backward_entropy": 0.11136174201965332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6848721504211426,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021282732486724854,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2717667818069458,
      "backward_entropy": 0.0853693683942159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1736273765563965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021352969110012054,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27171963453292847,
      "backward_entropy": 0.09439054131507874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.275452136993408,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02142271213233471,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27167099714279175,
      "backward_entropy": 0.08291049798329671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.256767749786377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021492088213562965,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2716202437877655,
      "backward_entropy": 0.09199938178062439,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1406702995300293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021561142057180405,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2715662121772766,
      "backward_entropy": 0.10475839177767436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2951557636260986,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02162974886596203,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27151161432266235,
      "backward_entropy": 0.07927748064200084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6628670692443848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021698130294680595,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27145326137542725,
      "backward_entropy": 0.08846933643023173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.799093246459961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021765634417533875,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2713973820209503,
      "backward_entropy": 0.10085733731587727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0843634605407715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02183249406516552,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27134156227111816,
      "backward_entropy": 0.07576669255892436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2439932823181152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021899061277508736,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27128303050994873,
      "backward_entropy": 0.09830443064371745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.835017681121826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021965570747852325,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2712186872959137,
      "backward_entropy": 0.07349411646525066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.434570789337158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02203158661723137,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2711520791053772,
      "backward_entropy": 0.08277274171511333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0336616039276123,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022096717730164528,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2710866928100586,
      "backward_entropy": 0.08166744311650594,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.857598304748535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022161688655614853,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2710168659687042,
      "backward_entropy": 0.09326131145159404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4399561882019043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0222263652831316,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2709422707557678,
      "backward_entropy": 0.09201778968175252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2443535327911377,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02229027822613716,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2708682715892792,
      "backward_entropy": 0.0784100741147995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6340737342834473,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022353291511535645,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27079516649246216,
      "backward_entropy": 0.06698533892631531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.477104663848877,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022415902465581894,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.27071958780288696,
      "backward_entropy": 0.07630757490793864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.890178918838501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022478021681308746,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27064064145088196,
      "backward_entropy": 0.08718728025754292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.070728302001953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02254018932580948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2705537676811218,
      "backward_entropy": 0.08599355816841125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.124032974243164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022601425647735596,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2704673409461975,
      "backward_entropy": 0.06291442612806956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5349316596984863,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022661827504634857,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27038154006004333,
      "backward_entropy": 0.06193368136882782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2136175632476807,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022721994668245316,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.27029088139533997,
      "backward_entropy": 0.06096505622069041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9803524017333984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022781584411859512,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.27019810676574707,
      "backward_entropy": 0.0813754399617513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6731338500976562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022840308025479317,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2701064646244049,
      "backward_entropy": 0.059073095520337425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4599852561950684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022897880524396896,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2700181305408478,
      "backward_entropy": 0.05815643072128296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.74275803565979,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02295541577041149,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2699228823184967,
      "backward_entropy": 0.06728531420230865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6561434268951416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023012010380625725,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26982831954956055,
      "backward_entropy": 0.07699676354726155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0293128490448,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023067573085427284,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26973679661750793,
      "backward_entropy": 0.05549055337905884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.782464027404785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023122722283005714,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2696417570114136,
      "backward_entropy": 0.0749064286549886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4430396556854248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023178543895483017,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26953309774398804,
      "backward_entropy": 0.0738521118958791,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0087108612060547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02323314920067787,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2694275975227356,
      "backward_entropy": 0.05294909576574961,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9614813327789307,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023287393152713776,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26931869983673096,
      "backward_entropy": 0.052129591504732765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.206637144088745,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023341244086623192,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2692057490348816,
      "backward_entropy": 0.051324223478635154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6264816522598267,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023395180702209473,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2690827250480652,
      "backward_entropy": 0.06978822251160939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3656139373779297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023448266088962555,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26895976066589355,
      "backward_entropy": 0.04974155128002167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7892675399780273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0235002264380455,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2688392102718353,
      "backward_entropy": 0.05851943294207255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.750314474105835,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02355179376900196,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26871389150619507,
      "backward_entropy": 0.05771528681119283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.475409746170044,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023602960631251335,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26858359575271606,
      "backward_entropy": 0.06593327720959981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9884842038154602,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02365332655608654,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.268452525138855,
      "backward_entropy": 0.05614644785722097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8534419536590576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023702174425125122,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2683287560939789,
      "backward_entropy": 0.06411327918370564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6822607517242432,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02375110052525997,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26819565892219543,
      "backward_entropy": 0.0546487420797348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7616888284683228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023799778893589973,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2680559754371643,
      "backward_entropy": 0.06232968966166178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3992016315460205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023848414421081543,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26790714263916016,
      "backward_entropy": 0.06144419809182485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2289292812347412,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02389637939631939,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2677557170391083,
      "backward_entropy": 0.05246957143147787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3969995975494385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023943355306982994,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2676060199737549,
      "backward_entropy": 0.05177081127961477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.079471230506897,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023989742621779442,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26745346188545227,
      "backward_entropy": 0.051082998514175415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6194013357162476,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02403506077826023,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2673029601573944,
      "backward_entropy": 0.041455539564291634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2270212173461914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02408040128648281,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2671426832675934,
      "backward_entropy": 0.04085203508536021,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0830228328704834,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02412511594593525,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2669801414012909,
      "backward_entropy": 0.04909798502922058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3259609937667847,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02416892535984516,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2668188810348511,
      "backward_entropy": 0.03968127320210139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8471165895462036,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024212408810853958,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2666512131690979,
      "backward_entropy": 0.039112781484921776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9955158233642578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024254634976387024,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2664879262447357,
      "backward_entropy": 0.04723511139551798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0486221313476562,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024296026676893234,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26632410287857056,
      "backward_entropy": 0.03802734365065893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.10373854637146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024336760863661766,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2661578357219696,
      "backward_entropy": 0.037503970166047416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5048099160194397,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02437702752649784,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2659876346588135,
      "backward_entropy": 0.03699057797590891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.963821291923523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02441556379199028,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2658282518386841,
      "backward_entropy": 0.05138878027598063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6296342611312866,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02445354126393795,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2656654119491577,
      "backward_entropy": 0.05073492228984833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9894682765007019,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024490270763635635,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26550784707069397,
      "backward_entropy": 0.035558849573135376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8154478073120117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02452668733894825,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2653440833091736,
      "backward_entropy": 0.04948286712169647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7881779670715332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024562422186136246,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2651786506175995,
      "backward_entropy": 0.048873489101727806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6310579776763916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024597443640232086,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2650117874145508,
      "backward_entropy": 0.048278038700421654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9559950828552246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024631481617689133,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26484736800193787,
      "backward_entropy": 0.04770159721374512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6614334583282471,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02466539666056633,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26467445492744446,
      "backward_entropy": 0.0333974634607633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8436586260795593,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02469848282635212,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.26450198888778687,
      "backward_entropy": 0.04107240835825602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5578059554100037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02473129890859127,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2643231451511383,
      "backward_entropy": 0.04601821303367615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7959905862808228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024763092398643494,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26414766907691956,
      "backward_entropy": 0.045485079288482666,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46647292375564575,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024794593453407288,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26396656036376953,
      "backward_entropy": 0.0449565052986145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8140439987182617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0248249564319849,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26379019021987915,
      "backward_entropy": 0.04445031781991323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7918832898139954,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024855216965079308,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2636050581932068,
      "backward_entropy": 0.03113137682278951,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7714390158653259,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02488531917333603,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26341167092323303,
      "backward_entropy": 0.030781179666519165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6960588693618774,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024915236979722977,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2632104754447937,
      "backward_entropy": 0.0304361234108607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4559374451637268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024944806471467018,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26300397515296936,
      "backward_entropy": 0.04245725770791372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6041430234909058,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02497333101928234,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26280105113983154,
      "backward_entropy": 0.04198610285917918,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5870797634124756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025001367554068565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26259469985961914,
      "backward_entropy": 0.04152404268582662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5717586874961853,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025028901174664497,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26238566637039185,
      "backward_entropy": 0.041071188946564995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5549642443656921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025055956095457077,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2621733546257019,
      "backward_entropy": 0.04062722623348236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5894166231155396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02508249692618847,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26195773482322693,
      "backward_entropy": 0.04019259909788767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.47867685556411743,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025108730420470238,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26173698902130127,
      "backward_entropy": 0.028255855043729145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6034279465675354,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025134317576885223,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26151615381240845,
      "backward_entropy": 0.02797439197699229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.406303733587265,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02515975385904312,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26128822565078735,
      "backward_entropy": 0.02769644558429718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4831750988960266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025184301659464836,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.261061429977417,
      "backward_entropy": 0.03853388627370199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38485056161880493,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02520836889743805,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.26083171367645264,
      "backward_entropy": 0.027170076966285706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5403857827186584,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025231637060642242,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.26060372591018677,
      "backward_entropy": 0.03776754935582479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5255729556083679,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025254804641008377,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2603687047958374,
      "backward_entropy": 0.037393314143021904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43261757493019104,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02527780830860138,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2601267695426941,
      "backward_entropy": 0.026428987582524616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30626314878463745,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025300346314907074,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2598828375339508,
      "backward_entropy": 0.03346952050924301,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.44645875692367554,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02532191574573517,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2596430480480194,
      "backward_entropy": 0.03321690857410431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5065720677375793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02534322254359722,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2593993842601776,
      "backward_entropy": 0.03296870489915212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38792723417282104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02536456286907196,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25914737582206726,
      "backward_entropy": 0.03272139529387156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5136938095092773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02538536675274372,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25889265537261963,
      "backward_entropy": 0.035296306014060974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2998755872249603,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02540627494454384,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2586279809474945,
      "backward_entropy": 0.03496209035317103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2594746947288513,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0254263523966074,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25836610794067383,
      "backward_entropy": 0.03464146455128988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2213408499956131,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025445496663451195,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25810864567756653,
      "backward_entropy": 0.031799192229906716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49013084173202515,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025463616475462914,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25785714387893677,
      "backward_entropy": 0.03404805064201355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26883623003959656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02548210322856903,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25759363174438477,
      "backward_entropy": 0.033752769231796265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17614474892616272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02549988217651844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2573325037956238,
      "backward_entropy": 0.03347080200910568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2284618318080902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025516532361507416,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25707924365997314,
      "backward_entropy": 0.033206673959891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2769036293029785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02553240954875946,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25682884454727173,
      "backward_entropy": 0.03295427064100901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2972239553928375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025547871366143227,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25657764077186584,
      "backward_entropy": 0.030667404333750408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26341482996940613,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025563059374690056,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.25632336735725403,
      "backward_entropy": 0.023531983296076458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28321853280067444,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02557784877717495,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2560679614543915,
      "backward_entropy": 0.02338913083076477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27737823128700256,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025592364370822906,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2558087706565857,
      "backward_entropy": 0.03199871381123861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1749255359172821,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025606580078601837,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25554540753364563,
      "backward_entropy": 0.03003871689240138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2635575234889984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025619955733418465,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25528591871261597,
      "backward_entropy": 0.03155741095542908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.166524738073349,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025633111596107483,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2550225257873535,
      "backward_entropy": 0.022860375543435413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1637280285358429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025645507499575615,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25476324558258057,
      "backward_entropy": 0.031147005657354992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.203464537858963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025657180696725845,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2545069754123688,
      "backward_entropy": 0.03095845381418864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19805514812469482,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025668449699878693,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25424957275390625,
      "backward_entropy": 0.030775720874468487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2346070557832718,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02567935921251774,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2539917528629303,
      "backward_entropy": 0.029296199480692547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12868812680244446,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025690192356705666,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25372982025146484,
      "backward_entropy": 0.029188841581344604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2050902396440506,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025700300931930542,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2534743547439575,
      "backward_entropy": 0.029089219868183136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20073041319847107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025710243731737137,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2532169222831726,
      "backward_entropy": 0.030095979571342468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21492218971252441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0257200188934803,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.252957820892334,
      "backward_entropy": 0.029934967557589214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15705284476280212,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02572975680232048,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2526954710483551,
      "backward_entropy": 0.029773672421773274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20493324100971222,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02573903650045395,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.25243422389030457,
      "backward_entropy": 0.02871246635913849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20138898491859436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02574830688536167,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2521693706512451,
      "backward_entropy": 0.029466688632965088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1634325087070465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02575753442943096,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25190046429634094,
      "backward_entropy": 0.029314006368319195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2250170260667801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02576645463705063,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2516312599182129,
      "backward_entropy": 0.029165854056676228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17250630259513855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025775589048862457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2513551414012909,
      "backward_entropy": 0.029014478127161663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24439795315265656,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02578451670706272,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2510773837566376,
      "backward_entropy": 0.021479328473409016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16464732587337494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02579389698803425,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2507912516593933,
      "backward_entropy": 0.028711567322413128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15971210598945618,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025803014636039734,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2505042552947998,
      "backward_entropy": 0.028560824692249298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12842297554016113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025811903178691864,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.25021737813949585,
      "backward_entropy": 0.028413782517115276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1949342042207718,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025820305570960045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24993300437927246,
      "backward_entropy": 0.028273920218149822,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17624472081661224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025828862562775612,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24964387714862823,
      "backward_entropy": 0.02813182274500529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10586999356746674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025837430730462074,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24935229122638702,
      "backward_entropy": 0.021014392375946045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14295707643032074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02584540843963623,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24906614422798157,
      "backward_entropy": 0.027706121404965717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2010992020368576,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025853173807263374,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2487790882587433,
      "backward_entropy": 0.027635350823402405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14799082279205322,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025861332193017006,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24848425388336182,
      "backward_entropy": 0.027589567005634308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14450953900814056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025869358330965042,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.248187854886055,
      "backward_entropy": 0.027455784380435944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15203095972537994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025877246633172035,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24789002537727356,
      "backward_entropy": 0.027323998510837555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1476615071296692,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025885118171572685,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24758967757225037,
      "backward_entropy": 0.027342466016610462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15485167503356934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025892969220876694,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24728843569755554,
      "backward_entropy": 0.020536104838053387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15123599767684937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025900892913341522,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24698485434055328,
      "backward_entropy": 0.026930764317512512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1976245790719986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025908855721354485,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24667894840240479,
      "backward_entropy": 0.02679867794116338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13328763842582703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02591738849878311,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24636335670948029,
      "backward_entropy": 0.026659175753593445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11045636981725693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025925757363438606,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24604684114456177,
      "backward_entropy": 0.026966874798138935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09793888032436371,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025933749973773956,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24573232233524323,
      "backward_entropy": 0.02018454298377037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14900469779968262,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025941291823983192,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24542129039764404,
      "backward_entropy": 0.026265740394592285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07572649419307709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025949038565158844,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24510547518730164,
      "backward_entropy": 0.02613825599352519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10697207599878311,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025956125929951668,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24479568004608154,
      "backward_entropy": 0.02669295420249303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1285756379365921,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02596302330493927,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24448682367801666,
      "backward_entropy": 0.025905003150304157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13268139958381653,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025970038026571274,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24417561292648315,
      "backward_entropy": 0.025788490970929463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10605071485042572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02597724460065365,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24386131763458252,
      "backward_entropy": 0.025669224560260773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10319880396127701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02598430961370468,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24354702234268188,
      "backward_entropy": 0.02555246651172638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11443940550088882,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025991231203079224,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2432326078414917,
      "backward_entropy": 0.02543789893388748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08314946293830872,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025998201221227646,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2429160177707672,
      "backward_entropy": 0.026320166885852814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08743832260370255,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02600482665002346,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24260321259498596,
      "backward_entropy": 0.0262620747089386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07889348268508911,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026011226698756218,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2422928512096405,
      "backward_entropy": 0.02510594328244527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07644072920084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026017310097813606,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24198462069034576,
      "backward_entropy": 0.025003701448440552,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07455786317586899,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026023106649518013,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.24167880415916443,
      "backward_entropy": 0.024905559917291004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08965496718883514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026028629392385483,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24137479066848755,
      "backward_entropy": 0.019387169430653255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09824807941913605,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026034174486994743,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.24106991291046143,
      "backward_entropy": 0.02602266271909078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0734008401632309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039907708764076,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.240763321518898,
      "backward_entropy": 0.01929487536350886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06113957241177559,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02604544907808304,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.24045971035957336,
      "backward_entropy": 0.01925007502237956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059261538088321686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02605062536895275,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.240159273147583,
      "backward_entropy": 0.024437929193178814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07228321582078934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02605547197163105,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23986202478408813,
      "backward_entropy": 0.019169470916191738,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06539247930049896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02606027200818062,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23956534266471863,
      "backward_entropy": 0.019131240745385487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09603802859783173,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02606494165956974,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23927044868469238,
      "backward_entropy": 0.01909442866841952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06617332994937897,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026070063933730125,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23897165060043335,
      "backward_entropy": 0.024102523922920227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07712087780237198,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02607508935034275,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23867425322532654,
      "backward_entropy": 0.025702856481075287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05796898156404495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026080261915922165,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2383754849433899,
      "backward_entropy": 0.02393019696076711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06832806766033173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02608523517847061,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23807884752750397,
      "backward_entropy": 0.023846134543418884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.062199871987104416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026090256869792938,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23778200149536133,
      "backward_entropy": 0.023761625091234844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05644787475466728,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026095235720276833,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2374861240386963,
      "backward_entropy": 0.018851295113563538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04373016208410263,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02610008977353573,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23719224333763123,
      "backward_entropy": 0.025501340627670288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059982407838106155,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026104597374796867,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23690290749073029,
      "backward_entropy": 0.023519687354564667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05464945361018181,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026109158992767334,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2366146445274353,
      "backward_entropy": 0.025430301825205486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04961642995476723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026113687083125114,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23632758855819702,
      "backward_entropy": 0.0233653982480367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05433201789855957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02611810527741909,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23604251444339752,
      "backward_entropy": 0.02329046030839284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052550334483385086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0261225588619709,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23575758934020996,
      "backward_entropy": 0.02321527401606242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02727285958826542,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026127034798264503,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.235473170876503,
      "backward_entropy": 0.023140110075473785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04344646632671356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02613096870481968,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23519587516784668,
      "backward_entropy": 0.023072292407353718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04753870517015457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026134822517633438,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2349204421043396,
      "backward_entropy": 0.025229570766290028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.045972585678100586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026138735935091972,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23464597761631012,
      "backward_entropy": 0.022938554485638935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02653748355805874,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02614269219338894,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23437286913394928,
      "backward_entropy": 0.018476555744806927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030632922425866127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02614622376859188,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23410576581954956,
      "backward_entropy": 0.022808656096458435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04169369488954544,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026149502024054527,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23384258151054382,
      "backward_entropy": 0.022750166555245716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0402994342148304,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02615286409854889,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2335798144340515,
      "backward_entropy": 0.018398864815632503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04122292250394821,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026156296953558922,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23331761360168457,
      "backward_entropy": 0.01837253322203954,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03987458720803261,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026159849017858505,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23305556178092957,
      "backward_entropy": 0.018344997117916744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04675888270139694,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02616349793970585,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.23279449343681335,
      "backward_entropy": 0.025014683604240417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04504329711198807,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02616746723651886,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2325318455696106,
      "backward_entropy": 0.022442248960336048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028002142906188965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026171712204813957,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23226848244667053,
      "backward_entropy": 0.018250685185194016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025158515200018883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0261757280677557,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.23200905323028564,
      "backward_entropy": 0.018218512336413067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02599659189581871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026179473847150803,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23175391554832458,
      "backward_entropy": 0.02224510908126831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02174406312406063,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026183031499385834,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2315022200345993,
      "backward_entropy": 0.022185616195201874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02572842873632908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026186300441622734,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23125514388084412,
      "backward_entropy": 0.022129957874615986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023388540372252464,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026189474388957024,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23101097345352173,
      "backward_entropy": 0.022075677911440533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016412755474448204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026192501187324524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23077033460140228,
      "backward_entropy": 0.022023479143778484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029086660593748093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026195185258984566,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23053501546382904,
      "backward_entropy": 0.021975800395011902,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020883534103631973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026198023930191994,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.23030024766921997,
      "backward_entropy": 0.021926316122214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024401677772402763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02620074525475502,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2300688624382019,
      "backward_entropy": 0.018026469896237057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01546020619571209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02620350383222103,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.229839488863945,
      "backward_entropy": 0.024699124197165172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020065326243638992,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02620600163936615,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22961503267288208,
      "backward_entropy": 0.021789051592350006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024372432380914688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026208456605672836,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22939354181289673,
      "backward_entropy": 0.021745771169662476,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02123587764799595,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026211056858301163,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22917279601097107,
      "backward_entropy": 0.024643319348494213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015875253826379776,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026213685050606728,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22895392775535583,
      "backward_entropy": 0.01792815700173378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020668046548962593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02621614933013916,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22873902320861816,
      "backward_entropy": 0.02161205808321635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015751639381051064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026218697428703308,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22852620482444763,
      "backward_entropy": 0.02156771222750346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.016168255358934402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026221133768558502,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22831670939922333,
      "backward_entropy": 0.017871839304765064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012564587406814098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02622351236641407,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22811023890972137,
      "backward_entropy": 0.021483113368352253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012188694439828396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026225708425045013,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2279077172279358,
      "backward_entropy": 0.017837442457675934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00992688350379467,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026227736845612526,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22770896553993225,
      "backward_entropy": 0.01782256488998731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013984461314976215,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026229530572891235,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22751472890377045,
      "backward_entropy": 0.017809880276521046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015279782935976982,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026231320574879646,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22732320427894592,
      "backward_entropy": 0.021338388323783875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015498329885303974,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026233183220028877,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22713369131088257,
      "backward_entropy": 0.02446820338567098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010970872826874256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026235152035951614,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2269451916217804,
      "backward_entropy": 0.01776919886469841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014430324546992779,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026237014681100845,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2267601042985916,
      "backward_entropy": 0.02123337984085083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01465210784226656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026238974183797836,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22657647728919983,
      "backward_entropy": 0.021198369562625885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011260655708611012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026241054758429527,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22639398276805878,
      "backward_entropy": 0.024403626720110577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014354114420711994,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026243088766932487,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22621381282806396,
      "backward_entropy": 0.017709811528523762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01101025752723217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624525874853134,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2260342687368393,
      "backward_entropy": 0.021090403199195862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008709863759577274,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026247408241033554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22585716843605042,
      "backward_entropy": 0.021054151157538097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009715329855680466,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02624942734837532,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22568339109420776,
      "backward_entropy": 0.021019667387008667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009825115092098713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02625139057636261,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22551199793815613,
      "backward_entropy": 0.017646367351214092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007107504643499851,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026253340765833855,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22534307837486267,
      "backward_entropy": 0.02095295488834381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009138422086834908,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026255149394273758,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22517803311347961,
      "backward_entropy": 0.02092161277929942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01033446192741394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026256950572133064,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22501501441001892,
      "backward_entropy": 0.020890528957049053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0073549784719944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026258843019604683,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22485315799713135,
      "backward_entropy": 0.020858516295750935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007082768715918064,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026260657235980034,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22469419240951538,
      "backward_entropy": 0.020827628672122955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006852839142084122,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026262398809194565,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2245381474494934,
      "backward_entropy": 0.01756272464990616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008865534327924252,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026264069601893425,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22438493371009827,
      "backward_entropy": 0.020768956591685612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005419542081654072,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626582235097885,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2242327332496643,
      "backward_entropy": 0.02073957771062851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004347502253949642,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02626744471490383,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22408410906791687,
      "backward_entropy": 0.020712029188871384,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007483270019292831,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026268893852829933,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22393959760665894,
      "backward_entropy": 0.020686693489551544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007557117845863104,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02627040632069111,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22379693388938904,
      "backward_entropy": 0.02066054691871007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00690059969201684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026272002607584,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2236555814743042,
      "backward_entropy": 0.02063344419002533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0073488252237439156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026273643597960472,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2235158085823059,
      "backward_entropy": 0.020605935404698055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006678218953311443,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02627537213265896,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22337709367275238,
      "backward_entropy": 0.024116535981496174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034224125556647778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026277150958776474,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22324001789093018,
      "backward_entropy": 0.02054838587840398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005160264205187559,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026278739795088768,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22310684621334076,
      "backward_entropy": 0.020521814624468487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00469115050509572,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02628031186759472,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22297582030296326,
      "backward_entropy": 0.020495833208163578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005063650663942099,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02628183551132679,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.222847118973732,
      "backward_entropy": 0.020470523585875828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0042730942368507385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02628336288034916,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22272028028964996,
      "backward_entropy": 0.020445358008146286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004916850943118334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026284845545887947,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2225956916809082,
      "backward_entropy": 0.024031718571980793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004457201808691025,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026286354288458824,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2224726378917694,
      "backward_entropy": 0.02039620776971181,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037756047677248716,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026287859305739403,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2223512977361679,
      "backward_entropy": 0.01736743375658989,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004548728931695223,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026289314031600952,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22223210334777832,
      "backward_entropy": 0.01735614736874898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004554848186671734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026290807873010635,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22211411595344543,
      "backward_entropy": 0.020323889950911205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0039637889713048935,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026292355731129646,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2219972461462021,
      "backward_entropy": 0.017332114279270172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004178919829428196,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026293901726603508,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22188207507133484,
      "backward_entropy": 0.020275137076775234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002804605523124337,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026295484974980354,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2217685878276825,
      "backward_entropy": 0.020250370105107624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0034183685202151537,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026296980679035187,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2216578871011734,
      "backward_entropy": 0.020226689676443737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003283499972894788,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629847079515457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22154918313026428,
      "backward_entropy": 0.020203091204166412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0024493145756423473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02629995159804821,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22144220769405365,
      "backward_entropy": 0.02017989257971446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002361075486987829,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026301346719264984,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22133749723434448,
      "backward_entropy": 0.01726026212175687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002572363708168268,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026302658021450043,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22123488783836365,
      "backward_entropy": 0.02013688286145528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028645936399698257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026303928345441818,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2211340367794037,
      "backward_entropy": 0.017239974190791447,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027254719752818346,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026305213570594788,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22103454172611237,
      "backward_entropy": 0.017229899764060974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023244156036525965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026306509971618652,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2209363877773285,
      "backward_entropy": 0.020075682550668716,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001372376224026084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026307780295610428,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22084012627601624,
      "backward_entropy": 0.020055646697680157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023614661768078804,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026308907195925713,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22074651718139648,
      "backward_entropy": 0.020037366698185604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021194126456975937,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02631005086004734,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22065415978431702,
      "backward_entropy": 0.02380284418662389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016170054441317916,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02631119266152382,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22056353092193604,
      "backward_entropy": 0.01718280091881752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014389652060344815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026312265545129776,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22047507762908936,
      "backward_entropy": 0.019983676572640736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001467716647312045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026313260197639465,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.22038878500461578,
      "backward_entropy": 0.019967347383499146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015175743028521538,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026314198970794678,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22030453383922577,
      "backward_entropy": 0.017159319172302883,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013381720054894686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026315098628401756,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2202218770980835,
      "backward_entropy": 0.01993674288193385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014511644840240479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026315949857234955,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.22014105319976807,
      "backward_entropy": 0.02375111977259318,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001298276474699378,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02631678245961666,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.22006180882453918,
      "backward_entropy": 0.01713964839776357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014820881187915802,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631758712232113,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21998412907123566,
      "backward_entropy": 0.019894535342852276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011701310286298394,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026318401098251343,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2199077308177948,
      "backward_entropy": 0.019880856076876324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013886918313801289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026319187134504318,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21983307600021362,
      "backward_entropy": 0.019867591559886932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001232642913237214,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026320001110434532,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21975961327552795,
      "backward_entropy": 0.02371642490228017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014143077423796058,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632080391049385,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21968728303909302,
      "backward_entropy": 0.019840877503156662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011748531833291054,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026321645826101303,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21961601078510284,
      "backward_entropy": 0.023702154556910198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012297274079173803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026322484016418457,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21954600512981415,
      "backward_entropy": 0.019813672949870426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010110697476193309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026323338970541954,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2194768786430359,
      "backward_entropy": 0.01980007067322731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006971432594582438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632417343556881,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21940898895263672,
      "backward_entropy": 0.01978675276041031,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007077004993334413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026324933394789696,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2193428874015808,
      "backward_entropy": 0.017076238989830017,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008684074273332953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026325637474656105,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21927857398986816,
      "backward_entropy": 0.017070854703585308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007344786426983774,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632633037865162,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21921546757221222,
      "backward_entropy": 0.019751518964767456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006681231316179037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026326993480324745,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21915394067764282,
      "backward_entropy": 0.019740494589010876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008281084010377526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02632761560380459,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21909382939338684,
      "backward_entropy": 0.01705596347649892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006683006649836898,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026328250765800476,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21903479099273682,
      "backward_entropy": 0.01971941441297531,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000606310204602778,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02632886916399002,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21897712349891663,
      "backward_entropy": 0.019709143787622452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007091760635375977,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026329461485147476,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21892064809799194,
      "backward_entropy": 0.023632079362869263,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006721247918903828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026330066844820976,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21886509656906128,
      "backward_entropy": 0.02362668514251709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005500238621607423,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026330681517720222,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21881060302257538,
      "backward_entropy": 0.023621176679929096,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004294038808438927,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026331277564167976,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21875733137130737,
      "backward_entropy": 0.02361578494310379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005225975764915347,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026331830769777298,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2187054455280304,
      "backward_entropy": 0.019660353660583496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044267874909564853,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026332376524806023,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21865466237068176,
      "backward_entropy": 0.02360624074935913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004767596838064492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026332899928092957,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21860511600971222,
      "backward_entropy": 0.019642601410547893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00038063013926148415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026333417743444443,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21855664253234863,
      "backward_entropy": 0.01963404690225919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00047813905985094607,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026333903893828392,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21850937604904175,
      "backward_entropy": 0.01700822760661443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033509384957142174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026334401220083237,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21846315264701843,
      "backward_entropy": 0.0235883891582489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00036620424361899495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026334872469305992,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2184181660413742,
      "backward_entropy": 0.019609774152437847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003817548858933151,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026335330680012703,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21837417781352997,
      "backward_entropy": 0.019602087636788685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003342021373100579,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633579447865486,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21833109855651855,
      "backward_entropy": 0.019594386219978333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002638593432493508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026336245238780975,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21828895807266235,
      "backward_entropy": 0.01699031765262286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032020261278375983,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026336662471294403,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21824784576892853,
      "backward_entropy": 0.019579933335383732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032170210033655167,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026337074115872383,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21820753812789917,
      "backward_entropy": 0.023565255105495453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001951086160261184,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026337487623095512,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21816810965538025,
      "backward_entropy": 0.023561611771583557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002438992087263614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633785828948021,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21812984347343445,
      "backward_entropy": 0.019559822976589203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027159290038980544,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02633821591734886,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21809247136116028,
      "backward_entropy": 0.023555301129817963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026069756131619215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633857913315296,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21805593371391296,
      "backward_entropy": 0.019547523309787113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000289473042357713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02633894793689251,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21802011132240295,
      "backward_entropy": 0.019541393965482712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001999044034164399,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263393335044384,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2179848700761795,
      "backward_entropy": 0.019535069664319355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00024643499637022614,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026339702308177948,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2179504930973053,
      "backward_entropy": 0.01952896888057391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019998157222289592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634008228778839,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21791675686836243,
      "backward_entropy": 0.01952284201979637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001995571656152606,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026340456679463387,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2178838551044464,
      "backward_entropy": 0.01951677103837331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015886969049461186,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026340829208493233,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2178516536951065,
      "backward_entropy": 0.02353164553642273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001630808983463794,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026341184973716736,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21782031655311584,
      "backward_entropy": 0.023528399566809338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011306675150990486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026341527700424194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21778970956802368,
      "backward_entropy": 0.019499475757280987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013457154273055494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026341844350099564,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2177601456642151,
      "backward_entropy": 0.023522434135278065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020778292673639953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026342147961258888,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21773138642311096,
      "backward_entropy": 0.019489275912443798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.933389810612425e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263424851000309,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21770304441452026,
      "backward_entropy": 0.019483891626199085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001529889996163547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026342792436480522,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21767550706863403,
      "backward_entropy": 0.019478902220726013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013560398656409234,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026343107223510742,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2176484763622284,
      "backward_entropy": 0.019473838309446972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013028545072302222,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634342387318611,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21762201189994812,
      "backward_entropy": 0.01946880171696345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010808704246301204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634374052286148,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2175961136817932,
      "backward_entropy": 0.019463816036780674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.516586967743933e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026344044134020805,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21757075190544128,
      "backward_entropy": 0.02350233495235443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010834804561454803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026344329118728638,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21754616498947144,
      "backward_entropy": 0.01945449908574422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.679140253458172e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634461596608162,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21752220392227173,
      "backward_entropy": 0.01944991946220398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010694959200918674,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026344886049628258,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2174990177154541,
      "backward_entropy": 0.016924177606900532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.63577879499644e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026345163583755493,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2174762785434723,
      "backward_entropy": 0.01944119731585185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.708457658533007e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026345431804656982,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2174539566040039,
      "backward_entropy": 0.02348954975605011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.99021911714226e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02634568139910698,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21743229031562805,
      "backward_entropy": 0.02348722517490387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.255938205868006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634592168033123,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21741122007369995,
      "backward_entropy": 0.019429051627715428,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.204576493473724e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026346150785684586,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21739065647125244,
      "backward_entropy": 0.023482923706372578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.253391959238797e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026346366852521896,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21737055480480194,
      "backward_entropy": 0.019421793520450592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.984743959037587e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026346588507294655,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21735087037086487,
      "backward_entropy": 0.01941824456055959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7187240852508694e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026346812024712563,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21733158826828003,
      "backward_entropy": 0.019414694358905155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.68069119961001e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026347020640969276,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21731282770633698,
      "backward_entropy": 0.01941133787234624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.486216468852945e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026347219944000244,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21729469299316406,
      "backward_entropy": 0.019408125430345535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.057928890688345e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02634742110967636,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21727699041366577,
      "backward_entropy": 0.02347129335006078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.252442861092277e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026347607374191284,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21725979447364807,
      "backward_entropy": 0.016903288662433624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1443712941836566e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026347797363996506,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21724295616149902,
      "backward_entropy": 0.01939869796236356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6864894102327526e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026347968727350235,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21722665429115295,
      "backward_entropy": 0.016900554299354553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5389857657719404e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026348143815994263,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21721065044403076,
      "backward_entropy": 0.019393014411131542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7747355236206204e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026348313316702843,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21719509363174438,
      "backward_entropy": 0.019390292465686798,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8293748982832767e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026348480954766273,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21717987954616547,
      "backward_entropy": 0.016896693656841915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.126350177102722e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634863741695881,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21716511249542236,
      "backward_entropy": 0.019384998828172684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6119243557332084e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02634880319237709,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21715064346790314,
      "backward_entropy": 0.01938234269618988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9409105991362594e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026348961517214775,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21713659167289734,
      "backward_entropy": 0.023457037905852,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3664693799219094e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02634911797940731,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21712294220924377,
      "backward_entropy": 0.02345561484495799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2601199816563167e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263492614030838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21710962057113647,
      "backward_entropy": 0.019374939302603405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9994304238935e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026349397376179695,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21709665656089783,
      "backward_entropy": 0.019372740139563877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.034783028648235e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026349524036049843,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21708407998085022,
      "backward_entropy": 0.023451924324035645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3012344172457233e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026349645107984543,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21707184612751007,
      "backward_entropy": 0.019368577748537064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6625113858026452e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026349764317274094,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21705986559391022,
      "backward_entropy": 0.01936658223470052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7125799786299467e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026349876075983047,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2170482873916626,
      "backward_entropy": 0.019364687303702038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.088445944536943e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026349982246756554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21703703701496124,
      "backward_entropy": 0.019362864394982655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6704227164154872e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635009214282036,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21702603995800018,
      "backward_entropy": 0.019361050178607304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7975833543459885e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026350196450948715,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2170153260231018,
      "backward_entropy": 0.019359273215134937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3274344382807612e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635030448436737,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21700483560562134,
      "backward_entropy": 0.01935746520757675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2936817256559152e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635040692985058,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2169947326183319,
      "backward_entropy": 0.016882364948590595,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1706531950039789e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635050378739834,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2169848382472992,
      "backward_entropy": 0.01688163975874583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2692586096818559e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635059505701065,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21697521209716797,
      "backward_entropy": 0.019352587560812633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1293007446511183e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026350684463977814,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21696579456329346,
      "backward_entropy": 0.019351063917080562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1716760127455927e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635077014565468,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21695667505264282,
      "backward_entropy": 0.019349607328573864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1549919690878596e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026350855827331543,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2169477939605713,
      "backward_entropy": 0.01934817060828209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2023152521578595e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026350943371653557,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21693909168243408,
      "backward_entropy": 0.023438771565755207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.355883099080529e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635103464126587,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21693065762519836,
      "backward_entropy": 0.019345209002494812,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.30996066017542e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026351120322942734,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21692252159118652,
      "backward_entropy": 0.01934380332628886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0735407158790622e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263512060046196,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21691462397575378,
      "backward_entropy": 0.01934245104591052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.15652310848236e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635129727423191,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21690687537193298,
      "backward_entropy": 0.019340967138608296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.1354285207926296e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026351386681199074,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21689936518669128,
      "backward_entropy": 0.023434596757094067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.450306384271244e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635147050023079,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2168920934200287,
      "backward_entropy": 0.016874620070060093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.240090442588553e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026351554319262505,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.216885045170784,
      "backward_entropy": 0.019336951275666554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.079356353438925e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635163441300392,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21687814593315125,
      "backward_entropy": 0.016873373339573543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.36194454273209e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635171078145504,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2168714702129364,
      "backward_entropy": 0.016872794677813847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.358720954973251e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02635178714990616,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2168649584054947,
      "backward_entropy": 0.02343078205982844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.785842404293362e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635185979306698,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2168586552143097,
      "backward_entropy": 0.016871678332487743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.818966433755122e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0263519324362278,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21685244143009186,
      "backward_entropy": 0.016871134440104168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.746257556893397e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635199762880802,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21684646606445312,
      "backward_entropy": 0.019329880674680073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.864396487391787e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026352064684033394,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21684056520462036,
      "backward_entropy": 0.016870177040497463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.091770279046614e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352131739258766,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21683481335639954,
      "backward_entropy": 0.019327712555726368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.489437858661404e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635219879448414,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21682928502559662,
      "backward_entropy": 0.016869152585665386,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0812448130745906e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352262124419212,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21682387590408325,
      "backward_entropy": 0.01932566985487938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.120759629382519e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352321729063988,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2168186604976654,
      "backward_entropy": 0.019324736048777897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.50501022694516e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352379471063614,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2168135941028595,
      "backward_entropy": 0.019323783616224926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8519611987576354e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635243721306324,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21680864691734314,
      "backward_entropy": 0.016867394248644512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2171860766538884e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026352493092417717,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21680384874343872,
      "backward_entropy": 0.01686694969733556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.568369154687389e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352548971772194,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21679916977882385,
      "backward_entropy": 0.019321137418349583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9850508579111192e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026352601125836372,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21679461002349854,
      "backward_entropy": 0.023422859609127045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1907876543991733e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263526514172554,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21679021418094635,
      "backward_entropy": 0.01931953305999438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7376148662151536e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026352697983384132,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21678593754768372,
      "backward_entropy": 0.02342191090186437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5815705864952179e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026352742686867714,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2167818546295166,
      "backward_entropy": 0.01686517521739006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4391919194167713e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352783665060997,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21677786111831665,
      "backward_entropy": 0.019317368666330974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.842094206949696e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635282091796398,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21677401661872864,
      "backward_entropy": 0.019316765169302624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6777272549006739e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352858170866966,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21677029132843018,
      "backward_entropy": 0.019316115727027256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4694483070343267e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635289542376995,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21676665544509888,
      "backward_entropy": 0.01931547001004219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1427192703195033e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026352930814027786,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21676316857337952,
      "backward_entropy": 0.016863804310560226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3711335213884013e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026352962478995323,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21675972640514374,
      "backward_entropy": 0.019314376016457874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5628386336175026e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02635299414396286,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2167564034461975,
      "backward_entropy": 0.023419047395388286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4768000937692705e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353025808930397,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21675315499305725,
      "backward_entropy": 0.019313298165798187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.14023600872315e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353059336543083,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21674995124340057,
      "backward_entropy": 0.019312746822834015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1221978866160498e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635309286415577,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21674686670303345,
      "backward_entropy": 0.01931220789750417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0463375019753585e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353126391768456,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2167438566684723,
      "backward_entropy": 0.023417726159095764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.603354106322513e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353158056735992,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2167409211397171,
      "backward_entropy": 0.016862161457538605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.941157148001366e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635318785905838,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21673810482025146,
      "backward_entropy": 0.019310640792051952,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.642847089708084e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353217661380768,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21673539280891418,
      "backward_entropy": 0.01931016892194748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.893242243677378e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353249326348305,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21673272550106049,
      "backward_entropy": 0.019309704502423603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.632676902678213e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353279128670692,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21673014760017395,
      "backward_entropy": 0.019309225181738537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.184453695823322e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635330706834793,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21672767400741577,
      "backward_entropy": 0.01930879553159078,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.466962420541677e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635333314538002,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21672528982162476,
      "backward_entropy": 0.01930833359559377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.40131793513865e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635335922241211,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21672296524047852,
      "backward_entropy": 0.016860733429590862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5901146588912525e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635338343679905,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21672073006629944,
      "backward_entropy": 0.01930755500992139,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.58234091840859e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635340578854084,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21671855449676514,
      "backward_entropy": 0.01930719738205274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0378790799877606e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635342814028263,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2167164385318756,
      "backward_entropy": 0.016860246658325195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.157754460720753e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353448629379272,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21671441197395325,
      "backward_entropy": 0.019306490818659466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.683300917600718e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353469118475914,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21671244502067566,
      "backward_entropy": 0.016859959810972214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4980621421709657e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353489607572556,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21671056747436523,
      "backward_entropy": 0.016859838118155796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0812171303296054e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353508234024048,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2167086899280548,
      "backward_entropy": 0.01685971145828565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.73559544186719e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635352499783039,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21670691668987274,
      "backward_entropy": 0.01930525278051694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.734279291871644e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353541761636734,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21670517325401306,
      "backward_entropy": 0.019304946064949036,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.341935640970405e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353558525443077,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21670347452163696,
      "backward_entropy": 0.01685935879747073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.423735168122221e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02635357342660427,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21670186519622803,
      "backward_entropy": 0.023413337767124176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.937983569177959e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353586465120316,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21670027077198029,
      "backward_entropy": 0.019304193556308746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.121136475352614e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635359950363636,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21669873595237732,
      "backward_entropy": 0.01930392285188039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9625522895694303e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353612542152405,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21669727563858032,
      "backward_entropy": 0.019303726653258007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8768609777453094e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0263536237180233,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21669583022594452,
      "backward_entropy": 0.019303523004055023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.84718061291278e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353634893894196,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166944146156311,
      "backward_entropy": 0.016858894377946854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7230578919225081e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635364606976509,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21669310331344604,
      "backward_entropy": 0.01685879131158193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.445104800268382e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353657245635986,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21669180691242218,
      "backward_entropy": 0.019302893429994583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4407530102289456e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635366842150688,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166905701160431,
      "backward_entropy": 0.016858629882335663,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.307382433424209e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353679597377777,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166893631219864,
      "backward_entropy": 0.019302505999803543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1850427483750536e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353690773248672,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21668821573257446,
      "backward_entropy": 0.016858482112487156,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1612883099587634e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635370008647442,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668705344200134,
      "backward_entropy": 0.019302159547805786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.760231023392407e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353709399700165,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21668599545955658,
      "backward_entropy": 0.023411994179089863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823096209198411e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635371871292591,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668490767478943,
      "backward_entropy": 0.019301842898130417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860663314180783e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353728026151657,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668395400047302,
      "backward_entropy": 0.019301723688840866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.461759565785542e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353735476732254,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668294072151184,
      "backward_entropy": 0.019301580886046093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.20687375835405e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635374292731285,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668198704719543,
      "backward_entropy": 0.019301429390907288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89731808229044e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353750377893448,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668106317520142,
      "backward_entropy": 0.01930130397280057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.080929975700201e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353757828474045,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21668018400669098,
      "backward_entropy": 0.01930118476351102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.221307558007538e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635376527905464,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667933464050293,
      "backward_entropy": 0.019301036993662517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.175454814183468e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635377272963524,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667851507663727,
      "backward_entropy": 0.01930089791615804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.756925164883796e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353780180215836,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166777402162552,
      "backward_entropy": 0.019300753871599834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.909706063926933e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353787630796432,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166769802570343,
      "backward_entropy": 0.0234111746152242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.519277124221844e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635379508137703,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166762351989746,
      "backward_entropy": 0.019300520420074463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.447249324357472e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353802531957626,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166755050420761,
      "backward_entropy": 0.01685779169201851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8139666596871393e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353809982538223,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166748344898224,
      "backward_entropy": 0.019300299386183422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.359809852554463e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635381557047367,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667416393756866,
      "backward_entropy": 0.01930018017689387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5292867295311225e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635382115840912,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667355298995972,
      "backward_entropy": 0.019300058484077454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.030305606444017e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353826746344566,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667295694351196,
      "backward_entropy": 0.019299976527690887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8592609169209027e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353832334280014,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166723608970642,
      "backward_entropy": 0.0192998672525088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6809146902451175e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635383792221546,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21667177975177765,
      "backward_entropy": 0.016857522229353588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5152052884891418e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635384351015091,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21667122840881348,
      "backward_entropy": 0.019299689680337906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5873333697745693e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353849098086357,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166706919670105,
      "backward_entropy": 0.023410528898239136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2970993995841127e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353852823376656,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166701853275299,
      "backward_entropy": 0.01929953321814537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8161692594276246e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353856548666954,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166696935892105,
      "backward_entropy": 0.01929946740468343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8160449144488666e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353860273957253,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166692018508911,
      "backward_entropy": 0.023410384853680927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.512628244881853e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635386399924755,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166687548160553,
      "backward_entropy": 0.019299323360125225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8934230183731415e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635386772453785,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166682779788971,
      "backward_entropy": 0.016857342173655827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.499456203646332e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353871449828148,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666787564754486,
      "backward_entropy": 0.01929922153552373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.406777982992935e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353875175118446,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666744351387024,
      "backward_entropy": 0.019299133370320003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.297912888276187e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353878900408745,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166670262813568,
      "backward_entropy": 0.019299078732728958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2543488026039995e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353882625699043,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666663885116577,
      "backward_entropy": 0.016857267667849857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0669559458165168e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353886350989342,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666628122329712,
      "backward_entropy": 0.019298953314622242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0847116982404259e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635389007627964,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666593849658966,
      "backward_entropy": 0.019298911094665527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.366953352378914e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635389380156994,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166655957698822,
      "backward_entropy": 0.019298821687698364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.239709359258995e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353897526860237,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21666526794433594,
      "backward_entropy": 0.02341001232465108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.748066994077817e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353901252150536,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666495501995087,
      "backward_entropy": 0.019298744698365528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.023590515269461e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353904977440834,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166646420955658,
      "backward_entropy": 0.019298697511355083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.598359109626472e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353908702731133,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166643738746643,
      "backward_entropy": 0.019298623005549114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.120188800196047e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635391242802143,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666409075260162,
      "backward_entropy": 0.01929858699440956,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.109324601766275e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635391429066658,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666382253170013,
      "backward_entropy": 0.019298552225033443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.595591462930315e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635391615331173,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666356921195984,
      "backward_entropy": 0.019298518697420757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.640572453557979e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635391801595688,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666333079338074,
      "backward_entropy": 0.016857067743937176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0034998366754735e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353919878602028,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666309237480164,
      "backward_entropy": 0.019298430532217026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.41458070099543e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353921741247177,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666286885738373,
      "backward_entropy": 0.019298403213421505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.958859906560974e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353923603892326,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666264533996582,
      "backward_entropy": 0.019298372169335682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.064887093591096e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353925466537476,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666240692138672,
      "backward_entropy": 0.01929834857583046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9667930334653647e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353927329182625,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666219830513,
      "backward_entropy": 0.019298336158196133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.038820750589366e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353929191827774,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666201949119568,
      "backward_entropy": 0.019298276553551357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.513374397494772e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353931054472923,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666178107261658,
      "backward_entropy": 0.01929825296004613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.729869663653517e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353932917118073,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666163206100464,
      "backward_entropy": 0.01929823060830434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.153505818114354e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353934779763222,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666143834590912,
      "backward_entropy": 0.016856978336970013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8474679563951213e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635393664240837,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166612595319748,
      "backward_entropy": 0.019298189630111057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.655394044064451e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635393850505352,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666109561920166,
      "backward_entropy": 0.019298172245423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.007801924719388e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635394036769867,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666094660758972,
      "backward_entropy": 0.019298164794842403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3743033377977554e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02635394223034382,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666079759597778,
      "backward_entropy": 0.01685696840286255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.244274017153657e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353944092988968,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21666066348552704,
      "backward_entropy": 0.01685696840286255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4918910551386944e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353945955634117,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166605293750763,
      "backward_entropy": 0.0192980853219827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0899228186644905e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353947818279266,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666041016578674,
      "backward_entropy": 0.01929807538787524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2583569741764222e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353949680924416,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166602909564972,
      "backward_entropy": 0.016856955985228222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2684893135883613e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21666017174720764,
      "backward_entropy": 0.019298056761423748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1878000805154443e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.2166600376367569,
      "backward_entropy": 0.019298038134972256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0493081958884432e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21665993332862854,
      "backward_entropy": 0.019298025717337925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.350955565423646e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.216659814119339,
      "backward_entropy": 0.016856946051120758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.761116194160422e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21665972471237183,
      "backward_entropy": 0.016856946051120758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.562448445241898e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21665963530540466,
      "backward_entropy": 0.016856946051120758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.812612696194265e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.2166595160961151,
      "backward_entropy": 0.016856946051120758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.21996684660553e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21665944159030914,
      "backward_entropy": 0.019297979772090912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.384350743042887e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21665936708450317,
      "backward_entropy": 0.019297928859790165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.040110633875884e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21665926277637482,
      "backward_entropy": 0.016856946051120758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.793481250293553e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21665921807289124,
      "backward_entropy": 0.019297916442155838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5767478695779573e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21665912866592407,
      "backward_entropy": 0.019297911475102108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.327844749241194e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166590541601181,
      "backward_entropy": 0.023409406344095867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7923086892988067e-10,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 2,
      "forward_entropy": 0.21665899455547333,
      "backward_entropy": 0.019297899057467777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4155789307988016e-10,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 1,
      "forward_entropy": 0.21665892004966736,
      "backward_entropy": 0.016856946051120758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4717828611974255e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.21665886044502258,
      "backward_entropy": 0.023409391442934673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.473914489404706e-10,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026353951543569565,
      "trajectory_length": 5,
      "branch_chosen": 0,
      "forward_entropy": 0.2166588008403778,
      "backward_entropy": 0.023409391442934673,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 8.818813116207025e-08,
    "avg_log_Z": 0.02635379733517766,
    "success_rate": 1.0,
    "avg_reward": 52.1,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.09,
      "1": 0.25,
      "2": 0.66
    },
    "avg_forward_entropy": 0.21667631670832635,
    "avg_backward_entropy": 0.019059759105245273,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}