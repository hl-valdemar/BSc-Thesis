{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06293681534853848,
      "exploration_ratio": 0.4782608695652174
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06293681534853848,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 0.7391304347826086
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06293681534853848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06293681534853848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06293681534853848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06293681534853848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06288632479580966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06293681534853848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.745905876159668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145564834276836,
      "backward_entropy": 0.06291444193233144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.386564254760742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145528078079224,
      "backward_entropy": 0.0629341873255643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.088603019714355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0001999465748667717,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145483374595642,
      "backward_entropy": 0.06288012591275302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.646864891052246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0003000014985445887,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145429730415344,
      "backward_entropy": 0.06287696144797585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.993910789489746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0004000159678980708,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09145370125770569,
      "backward_entropy": 0.06287376989017833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.988028526306152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0005000854143872857,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09145303567250569,
      "backward_entropy": 0.06292290037328546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.362324714660645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006001887959428132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145227074623108,
      "backward_entropy": 0.06289731372486461,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.274677276611328,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007001612102612853,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145142634709676,
      "backward_entropy": 0.06289432265541771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.817781448364258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008000098750926554,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09145053227742513,
      "backward_entropy": 0.0628912936557423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.430856704711914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008996551623567939,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144950906435649,
      "backward_entropy": 0.06288821047002618,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.543846130371094,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0009993198327720165,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0914484163125356,
      "backward_entropy": 0.062885197726163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.889480590820312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010987480636686087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144717454910278,
      "backward_entropy": 0.06285003098574551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.930792808532715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011980991112068295,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144578377405803,
      "backward_entropy": 0.06287928061051802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.534363746643066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0012977052247151732,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09144424398740132,
      "backward_entropy": 0.06287633830850775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.308480262756348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001397086656652391,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09144260485967,
      "backward_entropy": 0.0628389607776295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.667994499206543,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001496541895903647,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09144080678621928,
      "backward_entropy": 0.06289088184183295,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.788862228393555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015961461467668414,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143899877866109,
      "backward_entropy": 0.06288740309801968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.830070495605469,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0016956041799858212,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143712123235066,
      "backward_entropy": 0.06288385391235352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.864190101623535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017946170410141349,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09143523375193278,
      "backward_entropy": 0.06286100907759233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.632843971252441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0018936172127723694,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09143325686454773,
      "backward_entropy": 0.06287653879685835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.266179084777832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001992878969758749,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09143110116322835,
      "backward_entropy": 0.06281570954756303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.033504486083984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020918583031743765,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142905473709106,
      "backward_entropy": 0.06281165643171831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.552703857421875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021908809430897236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142696857452393,
      "backward_entropy": 0.06280753829262474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.257613182067871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022901121992617846,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142484267552693,
      "backward_entropy": 0.06280336596749046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.446518898010254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002389064058661461,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09142281611760457,
      "backward_entropy": 0.0628411119634455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.018045425415039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002488229423761368,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09142065048217773,
      "backward_entropy": 0.06279499964280562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.355818748474121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002587417373433709,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141844511032104,
      "backward_entropy": 0.06279073520140215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.351388931274414,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026867524720728397,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09141614039738973,
      "backward_entropy": 0.06284564191644842,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.265134811401367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0027862158603966236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09141373634338379,
      "backward_entropy": 0.06278206543488936,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.247431755065918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002885752124711871,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09141126275062561,
      "backward_entropy": 0.06282339854673906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.740118026733398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.002985379658639431,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140859047571818,
      "backward_entropy": 0.06281969764015892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.981514930725098,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003084876574575901,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140586853027344,
      "backward_entropy": 0.06281592629172585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.394258499145508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003184380242601037,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09140294790267944,
      "backward_entropy": 0.06281208992004395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.472759246826172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0032836345490068197,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09140001734097798,
      "backward_entropy": 0.06275937773964622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.888960838317871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0033827119041234255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913969874382019,
      "backward_entropy": 0.06280425461855801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.629315376281738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003481811610981822,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09139378865559895,
      "backward_entropy": 0.06280023401433771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.637959480285645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0035808372776955366,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09139045079549153,
      "backward_entropy": 0.06280544671145352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.643924713134766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036797691136598587,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09138712286949158,
      "backward_entropy": 0.0627400279045105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.129277229309082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0037790292408317327,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09138368566830952,
      "backward_entropy": 0.06279549815438011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.789670944213867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003878388088196516,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09138011932373047,
      "backward_entropy": 0.06278355555100874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.959208488464355,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0039776964113116264,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09137645363807678,
      "backward_entropy": 0.06272468241778287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.874391555786133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00407701451331377,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09137280782063802,
      "backward_entropy": 0.06277486411007968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.365894317626953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004176299087703228,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09136921167373657,
      "backward_entropy": 0.06271404027938843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.774950981140137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004275778774172068,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136545658111572,
      "backward_entropy": 0.06276595050638373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.599501609802246,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004375193268060684,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09136159221331279,
      "backward_entropy": 0.06276133927431973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.679207801818848,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004474494606256485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913575291633606,
      "backward_entropy": 0.06275661967017433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.180352210998535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0045733097940683365,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913534164428711,
      "backward_entropy": 0.0627521276473999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.931441307067871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00467189634218812,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09134926398595174,
      "backward_entropy": 0.06268596649169922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42580509185791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004770582541823387,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913451115290324,
      "backward_entropy": 0.0627419189973311,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.593255996704102,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004869157448410988,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09134092926979065,
      "backward_entropy": 0.06273687427694147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.570143699645996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00496769230812788,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133679668108623,
      "backward_entropy": 0.06273177537051114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.65548038482666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00506665650755167,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09133227666219075,
      "backward_entropy": 0.0627265680919994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.400856971740723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005166012793779373,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132754802703857,
      "backward_entropy": 0.06265567649494518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.728339195251465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005265615414828062,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09132259090741475,
      "backward_entropy": 0.06264927170493385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.968178749084473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005365177057683468,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.091317484776179,
      "backward_entropy": 0.06270211935043335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.803635597229004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005465204361826181,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09131214022636414,
      "backward_entropy": 0.0627048828385093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.320547103881836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0055655548349022865,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0913066565990448,
      "backward_entropy": 0.06269928542050449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.069735527038574,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005665550474077463,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0913012723128001,
      "backward_entropy": 0.06268191879445856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.292119026184082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00576512748375535,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09129597743352254,
      "backward_entropy": 0.0626754869114269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.859241485595703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005864875391125679,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09129043420155843,
      "backward_entropy": 0.06260844794186679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.37631893157959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005965020507574081,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09128457307815552,
      "backward_entropy": 0.06260124119845303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.864205360412598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0060649048537015915,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09127852320671082,
      "backward_entropy": 0.06265621293674815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.036176681518555,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00616476172581315,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09127227465311687,
      "backward_entropy": 0.06266405365683815,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.532275199890137,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006264619063585997,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09126605590184529,
      "backward_entropy": 0.06265785477378151,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.717081069946289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00636430224403739,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09125972787539165,
      "backward_entropy": 0.06265151500701904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.100555419921875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006463474128395319,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09125349919001262,
      "backward_entropy": 0.06256350603970615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.131074905395508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006562768016010523,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124720096588135,
      "backward_entropy": 0.06263840198516846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.196435928344727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006661723833531141,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09124115109443665,
      "backward_entropy": 0.06263178586959839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.601243019104004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006760456599295139,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09123506148656209,
      "backward_entropy": 0.06260806863958185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.199817657470703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006859154906123877,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122894207636516,
      "backward_entropy": 0.06253297220576894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.680777549743652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006957628298550844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09122295180956523,
      "backward_entropy": 0.06252521818334406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.426034927368164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007056111004203558,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121699134508769,
      "backward_entropy": 0.0625173503702337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.509027481079102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007154530379921198,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09121092160542806,
      "backward_entropy": 0.06250935792922974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.860517501831055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007252908311784267,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09120483199755351,
      "backward_entropy": 0.06250123544172807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.261512756347656,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007350980769842863,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09119883179664612,
      "backward_entropy": 0.06256307255138051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.575504302978516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00744894752278924,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09119285146395366,
      "backward_entropy": 0.06257538361982866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.494854927062988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00754697248339653,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09118675192197163,
      "backward_entropy": 0.0625470822507685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.77388858795166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00764500442892313,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09118060270945232,
      "backward_entropy": 0.06246961246837269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.803510665893555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007742728106677532,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09117461244265239,
      "backward_entropy": 0.06246166879480535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.314887046813965,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007840645499527454,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09116840362548828,
      "backward_entropy": 0.06252208623019131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.920262336730957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007938559167087078,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09116197625796,
      "backward_entropy": 0.06244546716863459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.021453857421875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008036273531615734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09115558862686157,
      "backward_entropy": 0.06243717670440674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.101609230041504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008134324103593826,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09114877382914226,
      "backward_entropy": 0.0625185641375455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.699284553527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008232688531279564,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09114164113998413,
      "backward_entropy": 0.062486870722337204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.847484588623047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00833116751164198,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09113425016403198,
      "backward_entropy": 0.06250078569759022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.851374626159668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00842984113842249,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09112651149431865,
      "backward_entropy": 0.062402188777923584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.827434539794922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008528655394911766,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09111833572387695,
      "backward_entropy": 0.06245843930677934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.775897979736328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008627128787338734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09111016988754272,
      "backward_entropy": 0.06238373843106357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.86233139038086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008726214990019798,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09110129872957866,
      "backward_entropy": 0.06237422878091985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447330474853516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008825828321278095,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09109191099802653,
      "backward_entropy": 0.06236455657265403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.66878604888916,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008925282396376133,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09108253320058186,
      "backward_entropy": 0.0624181790785356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.20511531829834,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009024729020893574,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0910729169845581,
      "backward_entropy": 0.06243441863493486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.892440795898438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009123927913606167,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09106342991193135,
      "backward_entropy": 0.06239692731337114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.890012741088867,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009223250672221184,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09105358521143596,
      "backward_entropy": 0.0623195388100364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.338494300842285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00932218786329031,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910440981388092,
      "backward_entropy": 0.06230726025321267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.421100616455078,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009421516209840775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09103388587633769,
      "backward_entropy": 0.06229455904527144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.334959030151367,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009520712308585644,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09102372328440349,
      "backward_entropy": 0.06235195289958607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.401326179504395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009619775228202343,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0910135308901469,
      "backward_entropy": 0.06234017285433682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.954712867736816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009719226509332657,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0910029908021291,
      "backward_entropy": 0.06225488402626731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.468935012817383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009818289428949356,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090992937485377,
      "backward_entropy": 0.06234868006272749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.701299667358398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00991775281727314,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09098222851753235,
      "backward_entropy": 0.062226544726978646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.621590614318848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010017214342951775,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09097136060396831,
      "backward_entropy": 0.06228805672038685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.314455032348633,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010116628371179104,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09096040328343709,
      "backward_entropy": 0.062312104485251686,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.457883834838867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010215848684310913,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09094955523808797,
      "backward_entropy": 0.06225830316543579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.926543235778809,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010314987041056156,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09093863765398662,
      "backward_entropy": 0.06228692965074019,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.198965072631836,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01041379850357771,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0909280776977539,
      "backward_entropy": 0.06214840845628218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.144220352172852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010512925684452057,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09091687202453613,
      "backward_entropy": 0.062261592258106575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.961007118225098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010611830279231071,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09090585509936015,
      "backward_entropy": 0.06219345873052424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.582893371582031,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010710935108363628,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0908943514029185,
      "backward_entropy": 0.062175983732396904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.873353958129883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010810024105012417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09088268876075745,
      "backward_entropy": 0.062221743843772194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.422933578491211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010909279808402061,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09087055921554565,
      "backward_entropy": 0.062058768489144066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.935457229614258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011008444242179394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0908584197362264,
      "backward_entropy": 0.0621937784281644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.043401718139648,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011107809841632843,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09084579348564148,
      "backward_entropy": 0.062101678414778275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.775578498840332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01120687648653984,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0908341904481252,
      "backward_entropy": 0.06208204681223089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.328125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011306061409413815,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09082162380218506,
      "backward_entropy": 0.062062171372500335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.8842134475708,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011405112221837044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0908088485399882,
      "backward_entropy": 0.06195427070964466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.833701133728027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011503838934004307,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09079649051030476,
      "backward_entropy": 0.06211928887800737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.949647903442383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011602797545492649,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09078359603881836,
      "backward_entropy": 0.06210358576341109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.289565086364746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011701486073434353,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09077153603235881,
      "backward_entropy": 0.06188711253079501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142739295959473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011799591593444347,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09076068798700969,
      "backward_entropy": 0.061864050951871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.934398651123047,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011897120624780655,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09075109163920085,
      "backward_entropy": 0.06184076179157604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.512377738952637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0119944978505373,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09074168403943379,
      "backward_entropy": 0.06181697411970659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.661005020141602,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01209206786006689,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09073175986607869,
      "backward_entropy": 0.06179259040138938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.058488845825195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012190361507236958,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09072005748748779,
      "backward_entropy": 0.061767404729669746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.711421966552734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012288013473153114,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09070982535680135,
      "backward_entropy": 0.06174197522076694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.560123443603516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012385929003357887,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09069888790448506,
      "backward_entropy": 0.06196051294153387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.05276107788086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0124839898198843,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09068743387858073,
      "backward_entropy": 0.061689219691536644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.12027359008789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012581931427121162,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09067616860071818,
      "backward_entropy": 0.061765616590326484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.114175796508789,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0126798115670681,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0906650722026825,
      "backward_entropy": 0.06189886006441983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.395246505737305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012778129428625107,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09065236647923787,
      "backward_entropy": 0.06160617958415638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.895842552185059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012876490131020546,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09063964088757832,
      "backward_entropy": 0.061577471819790924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.815174102783203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012974675744771957,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0906274418036143,
      "backward_entropy": 0.06183354421095415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.084712982177734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013072624802589417,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09061573942502339,
      "backward_entropy": 0.06181082400408658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.937424659729004,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013170999474823475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09060277541478474,
      "backward_entropy": 0.06148866089907559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.728934288024902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01326969638466835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0905888279279073,
      "backward_entropy": 0.06145702708851208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.656340599060059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01336805522441864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09057575464248657,
      "backward_entropy": 0.061424764719876374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.121376991271973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013466100208461285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09056363503138225,
      "backward_entropy": 0.06139193881641735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.041855812072754,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013564564287662506,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09054965774218242,
      "backward_entropy": 0.061479134993119675,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.339476585388184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013663357123732567,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09053455789883931,
      "backward_entropy": 0.061323816126043144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.845293045043945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01376213040202856,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09051964680353801,
      "backward_entropy": 0.06164030595259233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.193665504455566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013860641978681087,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09050564964612325,
      "backward_entropy": 0.061614188280972565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.7384672164917,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013959139585494995,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09049187103907268,
      "backward_entropy": 0.0615873553536155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.078128814697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014057876542210579,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09047735730806987,
      "backward_entropy": 0.06131258877840909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.305251121520996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014157012104988098,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09046167135238647,
      "backward_entropy": 0.06114084070379084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.71021556854248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014256082475185394,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09044593572616577,
      "backward_entropy": 0.06110145828940652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.632192611694336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014355290681123734,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09042942523956299,
      "backward_entropy": 0.06106109510768543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.074644088745117,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014454575255513191,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09041224916776021,
      "backward_entropy": 0.06144330176440152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.822964668273926,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014553641900420189,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09039533138275146,
      "backward_entropy": 0.06141356446526267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.06360149383545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014652924612164497,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09037758906682332,
      "backward_entropy": 0.060934586958451706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.332137107849121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01475201640278101,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.090360422929128,
      "backward_entropy": 0.06089068542827259,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.92947006225586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014851108193397522,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0903435746828715,
      "backward_entropy": 0.06099858067252419,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.056525230407715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014950458891689777,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09032514691352844,
      "backward_entropy": 0.06080027601935647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.35694694519043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015050123445689678,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09030516942342122,
      "backward_entropy": 0.06075354055924849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.369855880737305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015149177983403206,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09028729796409607,
      "backward_entropy": 0.06070601940155029,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.956533432006836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015248721465468407,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09026735027631123,
      "backward_entropy": 0.06118770621039651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.474410057067871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015348503366112709,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09024620056152344,
      "backward_entropy": 0.06077412041750821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.734885215759277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015448227524757385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09022480249404907,
      "backward_entropy": 0.06055352904579856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.128055572509766,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01554806623607874,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09020250042279561,
      "backward_entropy": 0.0605003454468467,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.978643417358398,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015647167339920998,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09018294016520183,
      "backward_entropy": 0.06103759462183172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.44255256652832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015746578574180603,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09016176064809163,
      "backward_entropy": 0.06099667332389138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49483585357666,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015846019610762596,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0901406208674113,
      "backward_entropy": 0.060520291328430176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.087862014770508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015945492312312126,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09011916319529216,
      "backward_entropy": 0.06091154163533991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.363323211669922,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016044767573475838,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0900980532169342,
      "backward_entropy": 0.06021783568642356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.745210647583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016143521293997765,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.09007881085077922,
      "backward_entropy": 0.06035084074193781,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.447917938232422,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016241997480392456,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.090060293674469,
      "backward_entropy": 0.060772310603748665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.720315933227539,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01634056121110916,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09004077315330505,
      "backward_entropy": 0.06003120812502774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.232412338256836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01643880270421505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.09002198775609334,
      "backward_entropy": 0.060674439777027474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.221552848815918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016537053510546684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.09000278512636821,
      "backward_entropy": 0.05989929220893166,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.559263229370117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016635309904813766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08998299638430278,
      "backward_entropy": 0.05983090400695801,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.903237342834473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016734257340431213,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08995964129765828,
      "backward_entropy": 0.05976037545637651,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.679912567138672,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01683349348604679,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08993449807167053,
      "backward_entropy": 0.060463515194979583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.678918838500977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016932377591729164,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08991081515947978,
      "backward_entropy": 0.06040723757310347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.848649978637695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01703142188489437,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08988486727078755,
      "backward_entropy": 0.059755227782509544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.213887214660645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01713022030889988,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08985952536265056,
      "backward_entropy": 0.059678966348821465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.573857307434082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017228979617357254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08983399470647176,
      "backward_entropy": 0.05938269333405928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.93519115447998,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017327379435300827,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08980997403462727,
      "backward_entropy": 0.05952112241224809,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.610769271850586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0174261424690485,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08978364864985149,
      "backward_entropy": 0.059439274397763336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.90162467956543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0175250805914402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08975597222646077,
      "backward_entropy": 0.05913619561628862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.097060203552246,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01762431301176548,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08972582221031189,
      "backward_entropy": 0.05927020853215998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.252310752868652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01772289350628853,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08969923853874207,
      "backward_entropy": 0.05896282196044922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8308892250061035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017821477726101875,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08967192967732747,
      "backward_entropy": 0.05984318798238581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.0323486328125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01791933737695217,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08964893221855164,
      "backward_entropy": 0.05977408994327892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.781902313232422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01801714301109314,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08962555726369222,
      "backward_entropy": 0.0586929971521551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.798182487487793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018114794045686722,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08960261940956116,
      "backward_entropy": 0.058600003069097344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.113992691040039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018212834373116493,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08957648277282715,
      "backward_entropy": 0.058504494753750885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.13005542755127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018310867249965668,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08954971035321553,
      "backward_entropy": 0.058407046578147194,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.575530052185059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018409445881843567,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08951890468597412,
      "backward_entropy": 0.059409011494029655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.710549354553223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01850823685526848,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08948654929796855,
      "backward_entropy": 0.058204304088245735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.99763298034668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018606742843985558,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08945570389429729,
      "backward_entropy": 0.05831220475110141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.933762550354004,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018705155700445175,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08942510684331258,
      "backward_entropy": 0.05916973135688088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.852889060974121,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018803993239998817,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0893918772538503,
      "backward_entropy": 0.0578849044713107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.379080772399902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018902640789747238,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08935943245887756,
      "backward_entropy": 0.05777396939017556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.977898597717285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019000889733433723,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08932965000470479,
      "backward_entropy": 0.058913030407645485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49052906036377,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019099051132798195,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0892998178799947,
      "backward_entropy": 0.05754748257723721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.174962043762207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01919742301106453,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08926792939503987,
      "backward_entropy": 0.0574304461479187,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.902370929718018,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01929580606520176,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08923495809237163,
      "backward_entropy": 0.05731088464910334,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.829073905944824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019393544644117355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08920655647913615,
      "backward_entropy": 0.057190456173636696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.778497695922852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01949172280728817,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08917403221130371,
      "backward_entropy": 0.0584478649226102,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.156356811523438,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019589737057685852,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08914201458295186,
      "backward_entropy": 0.05834614146839489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.301969528198242,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01968780718743801,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08910888433456421,
      "backward_entropy": 0.05824214761907404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.130633354187012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01978600211441517,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08907371759414673,
      "backward_entropy": 0.056890379298817025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.840396404266357,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019884249195456505,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08903771638870239,
      "backward_entropy": 0.05675573782487349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.008530616760254,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01998179778456688,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08900632460912068,
      "backward_entropy": 0.05791735649108887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.270694732666016,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020079374313354492,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0889736811319987,
      "backward_entropy": 0.05647718906402588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9900689125061035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020177127793431282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08893867333730061,
      "backward_entropy": 0.05613207817077637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.738692283630371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020274365320801735,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08890790740648906,
      "backward_entropy": 0.05618824742057107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.014517784118652,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02037154510617256,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08887709180514018,
      "backward_entropy": 0.05584275180643255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41495418548584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020468290895223618,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0888499915599823,
      "backward_entropy": 0.05733271078629927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.0510892868042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02056485041975975,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08882379531860352,
      "backward_entropy": 0.055545032024383545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.876145362854004,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020661599934101105,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08879515528678894,
      "backward_entropy": 0.05558089776472612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.633371353149414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02075785957276821,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08877008159955342,
      "backward_entropy": 0.055236214941198174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.170896530151367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0208546482026577,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0887389878431956,
      "backward_entropy": 0.05507643114436756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.773663520812988,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020951123908162117,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08871008952458699,
      "backward_entropy": 0.05509519577026367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.723758697509766,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02104763872921467,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08867955207824707,
      "backward_entropy": 0.0565513480793346,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.22126579284668,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02114473469555378,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08864298462867737,
      "backward_entropy": 0.05475690689953891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.926549911499023,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021241532638669014,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0886090596516927,
      "backward_entropy": 0.05458430810408159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.092576026916504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02133789472281933,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08857874075571696,
      "backward_entropy": 0.056124681776220146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.090520858764648,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021433940157294273,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08855017026265462,
      "backward_entropy": 0.05405636809088967,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.823036193847656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021529724821448326,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08852357665697734,
      "backward_entropy": 0.05387641083110462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.716610908508301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021625667810440063,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08849387367566426,
      "backward_entropy": 0.05369230833920566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.899876117706299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021721141412854195,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08846795558929443,
      "backward_entropy": 0.05367409099232067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.32217788696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021816302090883255,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08844426274299622,
      "backward_entropy": 0.05348183350129561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.76284122467041,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021911410614848137,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08841978510220845,
      "backward_entropy": 0.05328598347577182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.117171287536621,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02200673334300518,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08839170138041179,
      "backward_entropy": 0.05308688228780573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.998610973358154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022101880982518196,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08836399515469869,
      "backward_entropy": 0.0548790151422674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.945589065551758,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0221968162804842,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0883374313513438,
      "backward_entropy": 0.05267853086644953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.852982521057129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0222915131598711,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0883116324742635,
      "backward_entropy": 0.054540493271567604,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.025693893432617,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0223859790712595,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0882876714070638,
      "backward_entropy": 0.052115982229059395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25710391998291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02248034067451954,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08826407790184021,
      "backward_entropy": 0.05190499262376265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.393720626831055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022574713453650475,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08823833862940471,
      "backward_entropy": 0.05168717557733709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.700164794921875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022669196128845215,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0882099171479543,
      "backward_entropy": 0.05159316821531816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.126903533935547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02276395633816719,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08817673722902934,
      "backward_entropy": 0.0536388483914462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.148393630981445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0228586383163929,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08814285198847453,
      "backward_entropy": 0.05100408467379483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.720192909240723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022953273728489876,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08810809254646301,
      "backward_entropy": 0.050768071954900566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.245279312133789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02304757945239544,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08807442585627238,
      "backward_entropy": 0.050646944479508835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.014991760253906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023141957819461823,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0880391796429952,
      "backward_entropy": 0.05285347591746937,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.779605388641357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023236269131302834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08800385395685832,
      "backward_entropy": 0.05003886331211437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.257164001464844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02333034761250019,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08796876668930054,
      "backward_entropy": 0.04978870803659612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9496870040893555,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02342393435537815,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08793827891349792,
      "backward_entropy": 0.04953639615665783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.287059783935547,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02351747825741768,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08790592352549235,
      "backward_entropy": 0.04927816174247048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.673849105834961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023611189797520638,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0878690779209137,
      "backward_entropy": 0.049127058549360794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.881927013397217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023705294355750084,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08782534797986348,
      "backward_entropy": 0.048744900660081344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.968932151794434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02379927970468998,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08778063456217448,
      "backward_entropy": 0.051301891153508965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.6475677490234375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023893211036920547,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08773387471834819,
      "backward_entropy": 0.051065146923065186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.623793601989746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023986930027604103,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08768829703330994,
      "backward_entropy": 0.05082411115819758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.164548873901367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024080432951450348,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08764306704203288,
      "backward_entropy": 0.0476279150355946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5362629890441895,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02417345903813839,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08760143319765727,
      "backward_entropy": 0.047478654167868874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.8874616622924805,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02426629513502121,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0875597894191742,
      "backward_entropy": 0.04719026522202925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.039295673370361,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02435857616364956,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08752381801605225,
      "backward_entropy": 0.04689897732301192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.348051071166992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02445043995976448,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08749070763587952,
      "backward_entropy": 0.04957094517621127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.369720458984375,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024542126804590225,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08745712041854858,
      "backward_entropy": 0.049311394041234795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5492753982543945,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024633662775158882,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08742204308509827,
      "backward_entropy": 0.04586527022448453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2621355056762695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024725185707211494,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08738379677136739,
      "backward_entropy": 0.045695261521772904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.491898059844971,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02481653355062008,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08734519282976787,
      "backward_entropy": 0.04538561268286272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.772751808166504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024907885119318962,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08730422457059224,
      "backward_entropy": 0.04507391019300981,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.717172622680664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024998772889375687,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08726668357849121,
      "backward_entropy": 0.044758823784914886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.670962810516357,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02508922852575779,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08723321557044983,
      "backward_entropy": 0.044302116740833626,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.0169782638549805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025179270654916763,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08720347285270691,
      "backward_entropy": 0.043983581391247834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.531148910522461,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0252691600471735,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08717262744903564,
      "backward_entropy": 0.04711233485828747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.535067081451416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025358593091368675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0871446927388509,
      "backward_entropy": 0.04333484714681452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.480257987976074,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025447627529501915,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08711909254391988,
      "backward_entropy": 0.046532425013455475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.70728874206543,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02553628943860531,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08709659179051717,
      "backward_entropy": 0.04623792388222434,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.634148597717285,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025624750182032585,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08707282940546672,
      "backward_entropy": 0.04594068093733354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.602441787719727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025712335482239723,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08705942829449971,
      "backward_entropy": 0.04201230948621577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.705541133880615,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025799769908189774,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08704392115275066,
      "backward_entropy": 0.041801254857670174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.861546039581299,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02588716149330139,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08702571193377177,
      "backward_entropy": 0.04145981235937639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.596948623657227,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025973951444029808,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08701362212498982,
      "backward_entropy": 0.044718433510173454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.969064712524414,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02606070414185524,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08699850241343181,
      "backward_entropy": 0.0406565855849873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.43410062789917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026147006079554558,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08698722720146179,
      "backward_entropy": 0.04031322761015459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.53239631652832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026233233511447906,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08697404464085896,
      "backward_entropy": 0.0399666889147325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.75943660736084,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02631944976747036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08695642153422038,
      "backward_entropy": 0.03961472348733382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.567662715911865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026405135169625282,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.086943119764328,
      "backward_entropy": 0.03926100514151833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.053648948669434,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02649090439081192,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08692368865013123,
      "backward_entropy": 0.039022640748457474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.546935081481934,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026576397940516472,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08690383036931355,
      "backward_entropy": 0.03854066675359553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.045406818389893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026661310344934464,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08688973387082417,
      "backward_entropy": 0.03817992318760265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.075253963470459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026745349168777466,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08688588937123616,
      "backward_entropy": 0.03782236576080322,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.722196578979492,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0268293134868145,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08687714735666911,
      "backward_entropy": 0.037460622462359344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.464976787567139,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026912979781627655,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08686834573745728,
      "backward_entropy": 0.04106084325096824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.087855815887451,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02699616178870201,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08685945471127827,
      "backward_entropy": 0.04071400382302024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.873114585876465,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02707940898835659,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08684513966242473,
      "backward_entropy": 0.03636329824274236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.912543773651123,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027161836624145508,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08683944741884868,
      "backward_entropy": 0.03599753704938022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.516536235809326,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027244288474321365,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08682828148206075,
      "backward_entropy": 0.035627982833168724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.406458854675293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027326473966240883,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08681575457255046,
      "backward_entropy": 0.039294269951907074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.318421363830566,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027408337220549583,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08680219451586406,
      "backward_entropy": 0.038933109153400765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.825658798217773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027490587905049324,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08677524328231812,
      "backward_entropy": 0.034505134279077705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.491404056549072,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027572112157940865,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08675577243169148,
      "backward_entropy": 0.03820273551073941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8858232498168945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027653468772768974,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08673260609308879,
      "backward_entropy": 0.03783498027107932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.223701000213623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027734234929084778,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08671369155248006,
      "backward_entropy": 0.03746635805476795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.937334060668945,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027814721688628197,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08669267098108928,
      "backward_entropy": 0.037096516652540726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.046281814575195,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027894746512174606,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08667290210723877,
      "backward_entropy": 0.0326160111210563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.553199291229248,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027974437922239304,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08665136496225993,
      "backward_entropy": 0.03223740512674505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.342500686645508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02805347368121147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08663538098335266,
      "backward_entropy": 0.03186173601584001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.847621917724609,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028132518753409386,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08661107222239177,
      "backward_entropy": 0.03148255564949729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.824963569641113,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028211193159222603,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08658536275227864,
      "backward_entropy": 0.03134568171067671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.719902038574219,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02828953228890896,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.086558332045873,
      "backward_entropy": 0.03097097711129622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.389620780944824,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028367502614855766,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08653150002161662,
      "backward_entropy": 0.030345762317830868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.700387001037598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028444841504096985,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08650771776835124,
      "backward_entropy": 0.034120613878423516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.622175216674805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02852189727127552,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08648102482159932,
      "backward_entropy": 0.029592132026498966,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.397626876831055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02859862521290779,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08645070592562358,
      "backward_entropy": 0.029474914073944092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.177858829498291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028674887493252754,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08642003933588664,
      "backward_entropy": 0.028839076107198543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.09199333190918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02875056304037571,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08639211455980937,
      "backward_entropy": 0.03263986110687256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.278641223907471,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0288256723433733,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08636882901191711,
      "backward_entropy": 0.028096128593791615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.512270927429199,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02890041470527649,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08634386459986369,
      "backward_entropy": 0.027727319435639816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.112645149230957,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02897503785789013,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0863124430179596,
      "backward_entropy": 0.02735753763805736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1428704261779785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029049227014183998,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0862813691298167,
      "backward_entropy": 0.0269898230379278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9769036769866943,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02912304364144802,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08624789118766785,
      "backward_entropy": 0.026623232798142868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.623046875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029196402058005333,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08621496955553691,
      "backward_entropy": 0.026259010488336735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.016182899475098,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029269039630889893,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08618776003519694,
      "backward_entropy": 0.02618882872841575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.667785167694092,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02934138849377632,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08615733186403911,
      "backward_entropy": 0.02554071220484647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5371968746185303,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029413167387247086,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08612908919652303,
      "backward_entropy": 0.029319852590560913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9189605712890625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029484324157238007,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08610437313715617,
      "backward_entropy": 0.02895522659475153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.596179962158203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02955525368452072,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08607218662897746,
      "backward_entropy": 0.028592803261496803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3827919960021973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029625702649354935,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08603920539220174,
      "backward_entropy": 0.024132473902268844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5830955505371094,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0296955443918705,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0860098401705424,
      "backward_entropy": 0.0240969793363051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.411677837371826,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029765009880065918,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08597642183303833,
      "backward_entropy": 0.023443425243551082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3451883792877197,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02983400784432888,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08594338099161784,
      "backward_entropy": 0.023420550606467506,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.374009370803833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02990252897143364,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08591073751449585,
      "backward_entropy": 0.022764861583709717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.082406759262085,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02997066266834736,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08587673306465149,
      "backward_entropy": 0.026451257142153652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.331667900085449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030038148164749146,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08584514260292053,
      "backward_entropy": 0.02209845727140253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9195737838745117,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030105330049991608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08581044276555379,
      "backward_entropy": 0.02176919714971022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.749152183532715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030171796679496765,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08577844500541687,
      "backward_entropy": 0.021444487300786106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2006478309631348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030237454921007156,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08575193087259929,
      "backward_entropy": 0.021125350486148487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7342605590820312,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030302874743938446,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08571906884511311,
      "backward_entropy": 0.02472062815319408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.774289846420288,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030367577448487282,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0856886903444926,
      "backward_entropy": 0.024383718317205257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.547156810760498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030431712046265602,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08565998077392578,
      "backward_entropy": 0.02054841951890425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.586243152618408,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03049504943192005,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08563382426897685,
      "backward_entropy": 0.023719578981399536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.558821678161621,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030557742342352867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08560929695765178,
      "backward_entropy": 0.019578489390286533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.484890937805176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030619841068983078,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08558604121208191,
      "backward_entropy": 0.01928188448602503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5049655437469482,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03068130649626255,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08556276559829712,
      "backward_entropy": 0.022750824689865112,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.630600929260254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030742235481739044,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08553779125213623,
      "backward_entropy": 0.018699415705420754,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.538560628890991,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030802857130765915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0855078399181366,
      "backward_entropy": 0.018411519852551548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2515766620635986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030863093212246895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08547353744506836,
      "backward_entropy": 0.018125357952984898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2701642513275146,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030922668054699898,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08544262250264485,
      "backward_entropy": 0.018230753866108982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1409664154052734,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030981646850705147,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08541067441304524,
      "backward_entropy": 0.017562167211012406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.100508689880371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031039932742714882,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08537939190864563,
      "backward_entropy": 0.01728613403710452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9745688438415527,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03109753504395485,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0853474239508311,
      "backward_entropy": 0.020603992722251198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0447998046875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03115440160036087,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08531880378723145,
      "backward_entropy": 0.01674503900788047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8171849250793457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03121068701148033,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08528884251912434,
      "backward_entropy": 0.02002618529579856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8973993062973022,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03126615285873413,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0852622389793396,
      "backward_entropy": 0.016220703721046448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8332960605621338,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031321004033088684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08523553609848022,
      "backward_entropy": 0.015964963219382546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8070919513702393,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03137519583106041,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08520753184954326,
      "backward_entropy": 0.01571295749057423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8786190748214722,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03142877295613289,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0851781964302063,
      "backward_entropy": 0.01892246441407637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9825063943862915,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03148195520043373,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08514710267384847,
      "backward_entropy": 0.01521909236907959,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7619569301605225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03153495118021965,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08511010805765788,
      "backward_entropy": 0.018386632204055786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.457343339920044,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03158744052052498,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08507094780604045,
      "backward_entropy": 0.01812206886031411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.581360101699829,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03163899853825569,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08503586053848267,
      "backward_entropy": 0.014499406922947277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4897725582122803,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03168996423482895,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08500243226687114,
      "backward_entropy": 0.014268831773237749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6160162687301636,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.031740207225084305,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08496819933255513,
      "backward_entropy": 0.014042447913776745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.36738920211792,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03179004415869713,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08493015170097351,
      "backward_entropy": 0.01381864466450431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4264369010925293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03183917701244354,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08489801486333211,
      "backward_entropy": 0.013600278984416615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4820332527160645,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03188774734735489,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0848659078280131,
      "backward_entropy": 0.016619603742252697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2980074882507324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.031935881823301315,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08482867479324341,
      "backward_entropy": 0.016380855982953853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3608068227767944,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03198333829641342,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08479204773902893,
      "backward_entropy": 0.016146285967393356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.344577670097351,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032030291855335236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08475204308827718,
      "backward_entropy": 0.015915458852594547,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.164408802986145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03207677602767944,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.084707776705424,
      "backward_entropy": 0.012558220462365583,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1234428882598877,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03212250769138336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08466352025667827,
      "backward_entropy": 0.01236027479171753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1105693578720093,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03216753527522087,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08462169766426086,
      "backward_entropy": 0.015248071063648571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.140389084815979,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03221191093325615,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08458080887794495,
      "backward_entropy": 0.015033371069214561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.002177357673645,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03225572407245636,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08453599611918132,
      "backward_entropy": 0.011791192672469399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7771021127700806,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03229879215359688,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08449244499206543,
      "backward_entropy": 0.014617428183555603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1090519428253174,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032340701669454575,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08445500334103902,
      "backward_entropy": 0.014418314803730358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8297367095947266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0323823057115078,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08441214760144551,
      "backward_entropy": 0.011800100857561285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9455608129501343,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032423071563243866,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08437388141949971,
      "backward_entropy": 0.011091049421917309,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7760147452354431,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03246330842375755,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08433269460995992,
      "backward_entropy": 0.011469985951076855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8779776692390442,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03250271826982498,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08429465691248576,
      "backward_entropy": 0.011310447346080433,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7380696535110474,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032541610300540924,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08425370852152507,
      "backward_entropy": 0.01347441700371829,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8591142296791077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032579727470874786,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08421462774276733,
      "backward_entropy": 0.010450500656257977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7324810028076172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03261745348572731,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08417171239852905,
      "backward_entropy": 0.010297987271438946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6482261419296265,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032654523849487305,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08412863810857137,
      "backward_entropy": 0.012953125617720863,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6223529577255249,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03269081935286522,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08408872286478679,
      "backward_entropy": 0.012786605141379616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6388150453567505,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.032726362347602844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08405161897341411,
      "backward_entropy": 0.012623824856498024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.611843466758728,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03276124224066734,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08401332298914592,
      "backward_entropy": 0.012465002861889925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6865155100822449,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.032795511186122894,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08397647738456726,
      "backward_entropy": 0.009591765701770782,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5007396936416626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0328294038772583,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08393467466036479,
      "backward_entropy": 0.01215599612756209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5633758306503296,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03286247327923775,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08389656742413838,
      "backward_entropy": 0.009331063790754839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5932343602180481,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03289506211876869,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08386123180389404,
      "backward_entropy": 0.009205781600692055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5036066770553589,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03292722627520561,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0838219424088796,
      "backward_entropy": 0.009082355959848925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4112343490123749,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03295871615409851,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08378077546755473,
      "backward_entropy": 0.00896191122857007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5124923586845398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03298935666680336,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08374285697937012,
      "backward_entropy": 0.008845588023012335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4882831573486328,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03301960229873657,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08370349804560344,
      "backward_entropy": 0.00873126970096068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4444086253643036,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033049389719963074,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08366169532140096,
      "backward_entropy": 0.011172729459675875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.477743923664093,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033078595995903015,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08361739913622539,
      "backward_entropy": 0.008509165861389854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38442009687423706,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03310740739107132,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08356833457946777,
      "backward_entropy": 0.008400906216014515,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3603143095970154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03313559293746948,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08352045218149821,
      "backward_entropy": 0.008884160356088118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3309151232242584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033163126558065414,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08347354332605998,
      "backward_entropy": 0.008784873241728003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3737022280693054,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03318994119763374,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08342725038528442,
      "backward_entropy": 0.008094270120967518,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37949085235595703,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033216316252946854,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08337937792142232,
      "backward_entropy": 0.010450758717276833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30453717708587646,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033242352306842804,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08332955340544383,
      "backward_entropy": 0.010339716618711298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2957961857318878,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0332677848637104,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0832809607187907,
      "backward_entropy": 0.007808606732975353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2724839448928833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033292658627033234,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08323363463083903,
      "backward_entropy": 0.007718282667073337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3329319357872009,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033316951245069504,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08318829536437988,
      "backward_entropy": 0.007630646228790283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.24211522936820984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033340971916913986,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0831394096215566,
      "backward_entropy": 0.007544070482254028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2509899437427521,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03336435928940773,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08309244116147359,
      "backward_entropy": 0.007460279898210006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2023487091064453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033387187868356705,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08304468790690105,
      "backward_entropy": 0.009726590730927208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26326116919517517,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03340930491685867,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08299913505713145,
      "backward_entropy": 0.007300217043269764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20191438496112823,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033431101590394974,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0829509695370992,
      "backward_entropy": 0.007222908464345065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.23510663211345673,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033452339470386505,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08290476103623708,
      "backward_entropy": 0.009454558518799868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17179062962532043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033473215997219086,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08285599946975708,
      "backward_entropy": 0.007708048278635199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17303964495658875,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03349342942237854,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0828086684147517,
      "backward_entropy": 0.007640620524233038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1261483132839203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03351311385631561,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08276316523551941,
      "backward_entropy": 0.009203200313177977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17535950243473053,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03353206068277359,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08272237579027812,
      "backward_entropy": 0.009124661033803766,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17430609464645386,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033550526946783066,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08267862101395924,
      "backward_entropy": 0.006805539131164551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1356707513332367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03356870636343956,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08263494571050008,
      "backward_entropy": 0.006742833690209823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16900791227817535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033586326986551285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08259227871894836,
      "backward_entropy": 0.006682303818789395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13207074999809265,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03360367938876152,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08254732688268025,
      "backward_entropy": 0.008830926635048607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12652362883090973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033620577305555344,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08250326414903005,
      "backward_entropy": 0.006564839319749312,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10916704684495926,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03363710269331932,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08246126770973206,
      "backward_entropy": 0.007172762670300223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11504543572664261,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033653125166893005,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08242107927799225,
      "backward_entropy": 0.006454309279268438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10092321038246155,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0336686335504055,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08237926165262859,
      "backward_entropy": 0.006401746787808158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0970645397901535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.033683665096759796,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08233837286631267,
      "backward_entropy": 0.007025776261633093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10482589155435562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0336981937289238,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08229726552963257,
      "backward_entropy": 0.006301974031058225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08502452820539474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03371238708496094,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08225558698177338,
      "backward_entropy": 0.0062541433356025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09731165319681168,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033726099878549576,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08221453428268433,
      "backward_entropy": 0.00620804794810035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09679393470287323,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03373948857188225,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08217218518257141,
      "backward_entropy": 0.008279846473173662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07378986477851868,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0337526760995388,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08212961753209432,
      "backward_entropy": 0.006118724969300357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06743174046278,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03376542776823044,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08208796381950378,
      "backward_entropy": 0.008175883103500713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08182533085346222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03377766162157059,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08204637964566548,
      "backward_entropy": 0.00812693482095545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.051708873361349106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03378968685865402,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08200440804163615,
      "backward_entropy": 0.005994846197691831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056381311267614365,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033801138401031494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08196392158667247,
      "backward_entropy": 0.005956667390736667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0598977729678154,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033812157809734344,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08192431430021922,
      "backward_entropy": 0.007989111271771517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06571335345506668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033822838217020035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08188486099243164,
      "backward_entropy": 0.007946445183320478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06818877905607224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03383329138159752,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08184449374675751,
      "backward_entropy": 0.0058496370911598206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07587763667106628,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03384358808398247,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08180271585782369,
      "backward_entropy": 0.005815286527980457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030988646671175957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03385389968752861,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08175882697105408,
      "backward_entropy": 0.007823471318591724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0559539757668972,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03386357054114342,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08171730240186055,
      "backward_entropy": 0.007785251872106032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.033421214669942856,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03387303277850151,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08167481919129689,
      "backward_entropy": 0.005716980858282609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04655585438013077,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03388211503624916,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08163521687189738,
      "backward_entropy": 0.0077120722694830465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03997916355729103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03389101102948189,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08159578839937846,
      "backward_entropy": 0.0076769495552236385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040078483521938324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03389953821897507,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08155602216720581,
      "backward_entropy": 0.007643316279758106,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04743937775492668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03390775993466377,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.081515833735466,
      "backward_entropy": 0.005601610311053016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.031415414065122604,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033915817737579346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08147381742795308,
      "backward_entropy": 0.0055746723982420835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03423052653670311,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0339234322309494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08143192529678345,
      "backward_entropy": 0.005549145693128759,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03155752643942833,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03393087908625603,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08139092723528545,
      "backward_entropy": 0.005524219775741751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03571438416838646,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033938031643629074,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08135005831718445,
      "backward_entropy": 0.005500244823369113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0325014553964138,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03394505754113197,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08130884170532227,
      "backward_entropy": 0.007464727894826369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02222222089767456,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.033951934427022934,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08126814166704814,
      "backward_entropy": 0.00743791325525804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021645793691277504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0339585617184639,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08122970660527547,
      "backward_entropy": 0.005431414327838204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.026747923344373703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03396490216255188,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08119267721970876,
      "backward_entropy": 0.005410237407142466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020326856523752213,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03397108614444733,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08115562796592712,
      "backward_entropy": 0.007362903519110246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.020440207794308662,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03397694230079651,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08111929893493652,
      "backward_entropy": 0.006170866841619665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023546544834971428,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03398262709379196,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.081084077556928,
      "backward_entropy": 0.007317549803040244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025397859513759613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03398815169930458,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08104850848515828,
      "backward_entropy": 0.005332422866062684,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022749999538064003,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03399350121617317,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08101160327593486,
      "backward_entropy": 0.005314388397065076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017438020557165146,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.033998776227235794,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08097452918688457,
      "backward_entropy": 0.0052965855733914805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019198404625058174,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03400376811623573,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08093791206677754,
      "backward_entropy": 0.0052796825766563416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0133997593075037,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034008633345365524,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.080901434024175,
      "backward_entropy": 0.005263195796446366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015408958308398724,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034013181924819946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08086609840393066,
      "backward_entropy": 0.005247736180370504,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013881301507353783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034017547965049744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0808313141266505,
      "backward_entropy": 0.005232868546789343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018022775650024414,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034021783620119095,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08079753319422404,
      "backward_entropy": 0.007164222272959622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014709467999637127,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03402592986822128,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08076307674249013,
      "backward_entropy": 0.005204296247525649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014878029935061932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403005376458168,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08072921633720398,
      "backward_entropy": 0.00713192807002501,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014953622594475746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03403400257229805,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08069515724976857,
      "backward_entropy": 0.007116524333303625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012143170461058617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03403780236840248,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08066075046857198,
      "backward_entropy": 0.006019356575879184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015467027202248573,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03404146805405617,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08062692483266194,
      "backward_entropy": 0.00515099750323729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015547988936305046,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03404500335454941,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08059219519297282,
      "backward_entropy": 0.0060026835311542855,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010735569521784782,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03404846414923668,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08055656651655833,
      "backward_entropy": 0.007060197943990881,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013808614574372768,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03405183181166649,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08052176733811696,
      "backward_entropy": 0.005114822225137191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011187238618731499,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034055136144161224,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08048639198144276,
      "backward_entropy": 0.005103210833939639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010732672177255154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03405828773975372,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08045120040575664,
      "backward_entropy": 0.005972887982021679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009391196072101593,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340612567961216,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08041609823703766,
      "backward_entropy": 0.005081501874056729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011029561050236225,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03406412526965141,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08038167158762614,
      "backward_entropy": 0.00699950483712283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009362216107547283,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340670607984066,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0803472896416982,
      "backward_entropy": 0.005060838027433915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009283732622861862,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03406994417309761,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08031333486239116,
      "backward_entropy": 0.005050601268356497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009321048855781555,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03407261148095131,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08027945458889008,
      "backward_entropy": 0.005942273546348919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007898262701928616,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034075092524290085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0802454948425293,
      "backward_entropy": 0.006957232274792411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008330262266099453,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03407749533653259,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.08021210630734761,
      "backward_entropy": 0.006947887892072851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00817431602627039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034079816192388535,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08017894128958385,
      "backward_entropy": 0.005014681341973218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007209176197648048,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03408192843198776,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08014577627182007,
      "backward_entropy": 0.005006787113168023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007775143254548311,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03408392146229744,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08011304338773091,
      "backward_entropy": 0.00499927895990285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007350835483521223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03408583998680115,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08008037010828654,
      "backward_entropy": 0.005918363278562372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0077308062463998795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340876430273056,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.08004781603813171,
      "backward_entropy": 0.004985067316076972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006175018846988678,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034089334309101105,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.08001509308815002,
      "backward_entropy": 0.00591349263082851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006465958897024393,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034090932458639145,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07998288671175639,
      "backward_entropy": 0.006894729354164817,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005552718415856361,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0340925008058548,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07995096842447917,
      "backward_entropy": 0.00496595488353209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005378121510148048,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034094005823135376,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07991965611775716,
      "backward_entropy": 0.006882353939793326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006035862490534782,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034095488488674164,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07988894482453664,
      "backward_entropy": 0.004954080690037121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006013714242726564,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034096889197826385,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07985830307006836,
      "backward_entropy": 0.004948450760407882,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0061116898432374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03409825637936592,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.079827681183815,
      "backward_entropy": 0.006865227764303034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005531583447009325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03409957513213158,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0797971785068512,
      "backward_entropy": 0.004937519404021176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004336899612098932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03410082682967186,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07976676523685455,
      "backward_entropy": 0.00685477459972555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004498436115682125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410209342837334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07973708709081014,
      "backward_entropy": 0.0049271251667629586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004756819922477007,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410325571894646,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.079707865913709,
      "backward_entropy": 0.0049222538417035885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004000334069132805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034104350954294205,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07967886328697205,
      "backward_entropy": 0.006840375336733731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0042909313924610615,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410537540912628,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07965042193730672,
      "backward_entropy": 0.004913178357211026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003813974093645811,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341063030064106,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07962225874265035,
      "backward_entropy": 0.006832164796915921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031575809698551893,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034107182174921036,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07959458231925964,
      "backward_entropy": 0.004905105314471505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003216478042304516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410801291465759,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07956772049268086,
      "backward_entropy": 0.004901338029991497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004035961348563433,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03410884737968445,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07954148948192596,
      "backward_entropy": 0.006821266629479148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028991508297622204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03410958871245384,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07951522866884868,
      "backward_entropy": 0.004894102838906375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002501857001334429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411030024290085,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07948965827624004,
      "backward_entropy": 0.004890749738975005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027243306394666433,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411102294921875,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0794649322827657,
      "backward_entropy": 0.00488768992098895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002435601782053709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411174938082695,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07944080233573914,
      "backward_entropy": 0.004884618927132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00329634384252131,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411252424120903,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07941738267739613,
      "backward_entropy": 0.004881383343176408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026030989829450846,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034113235771656036,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07939391334851582,
      "backward_entropy": 0.006802275099537589,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002625182271003723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034113992005586624,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07937085628509521,
      "backward_entropy": 0.00487506321885369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002833226229995489,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411467745900154,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07934812704722087,
      "backward_entropy": 0.00679616697809913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0027085712645202875,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411523625254631,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07932549715042114,
      "backward_entropy": 0.004869392649693923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016793514369055629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411576896905899,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07930298646291097,
      "backward_entropy": 0.0048668238927017556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019667642191052437,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411633148789406,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07928138971328735,
      "backward_entropy": 0.004864167083393444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002126868814229965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034116897732019424,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0792603890101115,
      "backward_entropy": 0.00678621842102571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014191371155902743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03411748632788658,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07923966149489085,
      "backward_entropy": 0.004858773879029534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017937726806849241,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411808982491493,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07921976347764333,
      "backward_entropy": 0.006781085648319938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001988461706787348,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034118689596652985,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07920025785764058,
      "backward_entropy": 0.004853277043862777,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014580743154510856,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03411926329135895,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07918089628219604,
      "backward_entropy": 0.005898391658609564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019325782777741551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03411981090903282,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0791621208190918,
      "backward_entropy": 0.006773715669458563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001741391490213573,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341203436255455,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07914339005947113,
      "backward_entropy": 0.004845539277250116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017023312393575907,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034120820462703705,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0791248877843221,
      "backward_entropy": 0.004843208938837051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015781651018187404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412127122282982,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07910655935605367,
      "backward_entropy": 0.004840946332974868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001136542297899723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412172198295593,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07908845941225688,
      "backward_entropy": 0.004838700998913158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011483256239444017,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034122176468372345,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07907103498776753,
      "backward_entropy": 0.0067632448944178495,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020984343718737364,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034122612327337265,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07905414700508118,
      "backward_entropy": 0.005898682908578353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001583969104103744,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034122925251722336,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07903679211934407,
      "backward_entropy": 0.006759753281419928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010125238914042711,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412322700023651,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07901942233244579,
      "backward_entropy": 0.004830751906741749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010936184553429484,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034123495221138,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07900270819664001,
      "backward_entropy": 0.006756831299174915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009130056132562459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034123778343200684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07898641129334767,
      "backward_entropy": 0.004827466200698505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013493825681507587,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412407636642456,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07897067070007324,
      "backward_entropy": 0.004825780337507074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008400979568250477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412433713674545,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07895493507385254,
      "backward_entropy": 0.006752589886838739,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009545584907755256,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412461280822754,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07893972595532735,
      "backward_entropy": 0.006751226430589502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011301911436021328,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412487730383873,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07892487943172455,
      "backward_entropy": 0.005903466181321578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007202420383691788,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412511944770813,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07891009251276652,
      "backward_entropy": 0.006748634305867282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007593281334266067,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034125372767448425,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0788958470026652,
      "backward_entropy": 0.005904571576551957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006368363974615932,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412562236189842,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0788820485273997,
      "backward_entropy": 0.006746095012534748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008036241633817554,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412589803338051,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0788687268892924,
      "backward_entropy": 0.00481518493457274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008638420840725303,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341261625289917,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0788556436697642,
      "backward_entropy": 0.004813723266124725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004936198820360005,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034126389771699905,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07884270946184795,
      "backward_entropy": 0.006742301312359897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008237132569774985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412662819027901,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07883037130037944,
      "backward_entropy": 0.004811035977168517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008483760757371783,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412685543298721,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07881806790828705,
      "backward_entropy": 0.004809717563065616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007339080329984426,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034127041697502136,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07880579928557079,
      "backward_entropy": 0.005907461047172546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000569332274608314,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127216786146164,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07879366477330525,
      "backward_entropy": 0.0048074177043004465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008240845054388046,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341273732483387,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07878193259239197,
      "backward_entropy": 0.006737041202458468,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005523191066458821,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127507358789444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07877008616924286,
      "backward_entropy": 0.004805363714694977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005193355027586222,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412763401865959,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07875858743985494,
      "backward_entropy": 0.006735386496240442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004748363862745464,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034127749502658844,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07874743143717448,
      "backward_entropy": 0.006734604185277765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000489198777358979,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034127868711948395,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0787366231282552,
      "backward_entropy": 0.004802621562372555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006482017925009131,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412799909710884,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07872605323791504,
      "backward_entropy": 0.005912305956537073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00032675405964255333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341281034052372,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07871545354525249,
      "backward_entropy": 0.006732278926806016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005591181106865406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034128230065107346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07870534559090932,
      "backward_entropy": 0.004799981347539208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043545622611418366,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034128338098526,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07869526743888855,
      "backward_entropy": 0.004799145189198581,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004534093022812158,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03412846103310585,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07868536313374837,
      "backward_entropy": 0.005914921110326593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034809985663741827,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034128569066524506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07867564757664998,
      "backward_entropy": 0.00479746474461122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004146159626543522,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412869572639465,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07866621514161427,
      "backward_entropy": 0.004796612669121136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00042647647205740213,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341288223862648,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07865691184997559,
      "backward_entropy": 0.004795761270956559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002600951411295682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412894159555435,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07864769796530406,
      "backward_entropy": 0.004794936288486828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00033537702984176576,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034129079431295395,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07863888144493103,
      "backward_entropy": 0.00479408014904369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003169950796291232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034129224717617035,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07863021890322368,
      "backward_entropy": 0.006725426424633373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003661905066110194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03412935510277748,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0786218245824178,
      "backward_entropy": 0.004792384464632381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00044872474973089993,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412947803735733,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07861350973447163,
      "backward_entropy": 0.006723948500373147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002485733130015433,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03412957116961479,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07860508561134338,
      "backward_entropy": 0.00672331994230097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002211086539318785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034129660576581955,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07859701911608379,
      "backward_entropy": 0.004790244116024537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002720470365602523,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034129757434129715,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858927051226298,
      "backward_entropy": 0.00478956171057441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002446544240228832,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034129850566387177,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07858172059059143,
      "backward_entropy": 0.0047889172353527765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027822094853036106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034129947423934937,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07857435941696167,
      "backward_entropy": 0.004788258197632703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001976452476810664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034130048006772995,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07856701811154683,
      "backward_entropy": 0.005921826443888925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017046884750016034,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413014113903046,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078560009598732,
      "backward_entropy": 0.004787002097476612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013268660404719412,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413023799657822,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07855335374673207,
      "backward_entropy": 0.0047863928431814366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023189443163573742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413035348057747,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07854703068733215,
      "backward_entropy": 0.005923019214109941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023221563606057316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413046523928642,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07854072252909343,
      "backward_entropy": 0.0047851184552366085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020913683692924678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413056209683418,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0785344938437144,
      "backward_entropy": 0.004784524440765381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001779152371454984,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034130655229091644,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07852834463119507,
      "backward_entropy": 0.004783952778035944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002144980535376817,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034130748361349106,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07852234443028767,
      "backward_entropy": 0.006715866652402011,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001094686595024541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413083404302597,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07851637899875641,
      "backward_entropy": 0.004782853817397898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.966176392277703e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413093835115433,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07851068178812663,
      "backward_entropy": 0.0067147097804329614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020671874517574906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413105010986328,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07850533723831177,
      "backward_entropy": 0.00592530451037667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.445982141187415e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413114324212074,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0784999926884969,
      "backward_entropy": 0.004781146957115693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013888820831198245,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341312512755394,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07849488655726115,
      "backward_entropy": 0.006712891161441803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00023193919332697988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034131355583667755,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07848989963531494,
      "backward_entropy": 0.0047800215807828035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013728660997003317,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413143381476402,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0784847338994344,
      "backward_entropy": 0.005926348268985748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000106997940747533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413151204586029,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07847963770230611,
      "backward_entropy": 0.004779074679721485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017801093054004014,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413159400224686,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07847476005554199,
      "backward_entropy": 0.006710767068646171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011797928164014593,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413166105747223,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07846979796886444,
      "backward_entropy": 0.006710297004743056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001084535542759113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341317281126976,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07846497495969136,
      "backward_entropy": 0.004777757958932357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.527088018832728e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413180261850357,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07846022645632426,
      "backward_entropy": 0.004777307537468997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012124418572057039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413188457489014,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07845574120680492,
      "backward_entropy": 0.00670886446129192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012931894161738455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034131959080696106,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0784513254960378,
      "backward_entropy": 0.006708397106690841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017173246305901557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413202241063118,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0784469445546468,
      "backward_entropy": 0.00477603247219866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012159464677097276,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413206338882446,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07844238976637523,
      "backward_entropy": 0.004775700921362097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010483167716301978,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413209691643715,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07843788464864095,
      "backward_entropy": 0.006707268682393161,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.116403816733509e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034132130444049835,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07843344906965892,
      "backward_entropy": 0.004775089973753149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011031691246898845,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413216397166252,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07842909296353658,
      "backward_entropy": 0.00670660219409249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.040820517227985e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413219377398491,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07842475672562917,
      "backward_entropy": 0.005931193855675784,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.29682797100395e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413223475217819,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07842061916987102,
      "backward_entropy": 0.004774197258732535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.464684990234673e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413228318095207,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0784165511528651,
      "backward_entropy": 0.004773863337256692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.791610940126702e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413232043385506,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0784125526746114,
      "backward_entropy": 0.004773561927405271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.232407369883731e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413236513733864,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07840860883394878,
      "backward_entropy": 0.004773245616392655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.784238550812006e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413241356611252,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07840474446614583,
      "backward_entropy": 0.004772937771948901,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.465987098636106e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341324582695961,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07840092480182648,
      "backward_entropy": 0.004772614687681198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.447308987844735e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413250297307968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07839720447858174,
      "backward_entropy": 0.004772312939167023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9042653447249904e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413254767656326,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07839354872703552,
      "backward_entropy": 0.006703570485115051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.713761104037985e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034132592380046844,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07839001218477885,
      "backward_entropy": 0.004771718247370286,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.046713628573343e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413263335824013,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0783864955107371,
      "backward_entropy": 0.004771424626762217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.121069549815729e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034132666885852814,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07838291923205058,
      "backward_entropy": 0.004771164195104079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.767028051195666e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034132685512304306,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07837934295336406,
      "backward_entropy": 0.005936884067275308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.583621481899172e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0341327041387558,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07837583621342976,
      "backward_entropy": 0.005937474695118991,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6589004846755415e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034132711589336395,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07837231953938802,
      "backward_entropy": 0.0067019516771489925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.362326944828965e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413273021578789,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07836902141571045,
      "backward_entropy": 0.004770337180657821,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5947407013736665e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413275256752968,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07836584250132243,
      "backward_entropy": 0.004770131273703141,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.830858183093369e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413277864456177,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07836282253265381,
      "backward_entropy": 0.005939684808254242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.342319178045727e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413278982043266,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07835974792639415,
      "backward_entropy": 0.00670101290399378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.14819480990991e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034132808446884155,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0783567875623703,
      "backward_entropy": 0.004769563336264004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0370119424769655e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034132830798625946,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07835397124290466,
      "backward_entropy": 0.004769368266517466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7823583877761848e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413284569978714,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07835114498933156,
      "backward_entropy": 0.004769189791245894,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2281244532205164e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413286432623863,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0783484975496928,
      "backward_entropy": 0.004769025539810007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.529790774337016e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034132882952690125,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07834582030773163,
      "backward_entropy": 0.0047688595950603485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3127950296620838e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413289785385132,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07834319770336151,
      "backward_entropy": 0.006699681282043457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0122253267327324e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413292393088341,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07834076384703319,
      "backward_entropy": 0.004768493500622836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1913805034710094e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0341329462826252,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07833831508954366,
      "backward_entropy": 0.005944119258360429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5797886337386444e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413296118378639,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07833584149678548,
      "backward_entropy": 0.006699031726880507,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.144215952488594e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034132976084947586,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07833344737688701,
      "backward_entropy": 0.006698825819925828,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3177035220433027e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413298726081848,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07833109299341838,
      "backward_entropy": 0.006698643619363958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.849104566848837e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413299471139908,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07832873860994975,
      "backward_entropy": 0.004767753861167214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8854363083373755e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034133002161979675,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07832642396291097,
      "backward_entropy": 0.006698312407190149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7244577975361608e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413299843668938,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07832405964533488,
      "backward_entropy": 0.004767546938224273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7264730306342244e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133002161979675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0783218542734782,
      "backward_entropy": 0.0047674477100372314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0782124920515344e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034133002161979675,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07831962903340657,
      "backward_entropy": 0.0066978789188645105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2799800060747657e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133002161979675,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07831749320030212,
      "backward_entropy": 0.004767267880114642,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4523266145261005e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413300961256027,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07831550637880962,
      "backward_entropy": 0.005948926914821972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7981959899771027e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413302078843117,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07831359406312306,
      "backward_entropy": 0.004767035896127874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.312674521614099e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413303568959236,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0783117264509201,
      "backward_entropy": 0.004766918041489341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4419909348362125e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133054316043854,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07830997308095296,
      "backward_entropy": 0.004766785285689614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.556695315230172e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133072942495346,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0783082942167918,
      "backward_entropy": 0.004766655577854676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.823322418204043e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413309156894684,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.078306645154953,
      "backward_entropy": 0.004766533320600336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5756515495013446e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413310647010803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07830503582954407,
      "backward_entropy": 0.006696512753313238,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.881695066520479e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034133121371269226,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07830347617467244,
      "backward_entropy": 0.006696339357982983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.140357562690042e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413313999772072,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07830201586087544,
      "backward_entropy": 0.0047661987217989836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0848092642845586e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413315862417221,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07830061515172322,
      "backward_entropy": 0.0047660852697762575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.436873026250396e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133180975914,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07829923431078593,
      "backward_entropy": 0.0047659552232785654,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.171827862999635e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133199602365494,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07829786837100983,
      "backward_entropy": 0.004765845835208893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3002252671867609e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133221954107285,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07829663157463074,
      "backward_entropy": 0.004765729335221377,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2468537534005009e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413324058055878,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07829536497592926,
      "backward_entropy": 0.005953040312636982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1864533917105291e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413325548171997,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07829409837722778,
      "backward_entropy": 0.004765507849779996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.21406956674764e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133270382881165,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782928317785263,
      "backward_entropy": 0.004765424200079658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1648197869362775e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413328528404236,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0782916247844696,
      "backward_entropy": 0.006694774736057629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4814088899584021e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133296459913254,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07829039295514424,
      "backward_entropy": 0.0047652379355647345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.194777259021066e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413330018520355,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07828908165295918,
      "backward_entropy": 0.004765177992257205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.124727512244135e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413330763578415,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07828783492247264,
      "backward_entropy": 0.006694392724470658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.922748409328051e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133315086364746,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07828658819198608,
      "backward_entropy": 0.004765039817853408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.244423042924609e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413332253694534,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07828537623087566,
      "backward_entropy": 0.006694159724495627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.28230305260513e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413332626223564,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782841940720876,
      "backward_entropy": 0.004764903675426136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.589024112850893e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413333371281624,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07828307648499806,
      "backward_entropy": 0.0066939260471950875,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.15437614012626e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034133344888687134,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07828204830487569,
      "backward_entropy": 0.006693802096626975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.8510273700230755e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413335606455803,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07828104496002197,
      "backward_entropy": 0.0066936679861762305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.216005203896202e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413337096571922,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782800813515981,
      "backward_entropy": 0.00476459413766861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.971573616785463e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413338214159012,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07827910780906677,
      "backward_entropy": 0.004764511503956534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2564815885270946e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133393317461014,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07827817400296529,
      "backward_entropy": 0.0047644390301270914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.961094873578986e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413340821862221,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07827728986740112,
      "backward_entropy": 0.006693155250766061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.028450232202886e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341334231197834,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782764305671056,
      "backward_entropy": 0.0047642859545621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.745455503827543e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341334342956543,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07827556133270264,
      "backward_entropy": 0.006692912768233906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.953190571337473e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413344919681549,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07827473680178325,
      "backward_entropy": 0.004764134910973636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2828345410962356e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034133464097976685,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07827396194140117,
      "backward_entropy": 0.005957820198752664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.381595095357625e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413347899913788,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07827322681744893,
      "backward_entropy": 0.006692536175251007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.118474867529585e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413349762558937,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07827253142992656,
      "backward_entropy": 0.0047638900578022,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0875503398419823e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413351997733116,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0782719353834788,
      "backward_entropy": 0.005958198823712089,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.360628741371329e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413354232907295,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07827131946881612,
      "backward_entropy": 0.004763712598518891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.424453780098702e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413356468081474,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782707432905833,
      "backward_entropy": 0.004763624207539992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.981859779538354e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034133583307266235,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.078270157178243,
      "backward_entropy": 0.005958509716120633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.827467824317864e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413360193371773,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826956609884898,
      "backward_entropy": 0.004763517528772354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.157276412617648e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413361683487892,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826898495356242,
      "backward_entropy": 0.004763485355810685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2915046429261565e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133631736040115,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826841374238332,
      "backward_entropy": 0.004763441329652613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7324028931398061e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413364663720131,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07826785246531169,
      "backward_entropy": 0.005958905274217779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3722261630609864e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341336615383625,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826729118824005,
      "backward_entropy": 0.004763345149430362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0670011053880444e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0341336764395237,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826674977938335,
      "backward_entropy": 0.004763299768621271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1823213955940446e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413369134068489,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826621333758037,
      "backward_entropy": 0.004763251339847391,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4740952565261978e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034133706241846085,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07826570669809978,
      "backward_entropy": 0.006690960716117512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4543433053404442e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413372114300728,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826520502567291,
      "backward_entropy": 0.0047631578689271755,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.923536956383032e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413373604416847,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826473315556844,
      "backward_entropy": 0.004763107746839523,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6637818589515518e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034133750945329666,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07826428612073262,
      "backward_entropy": 0.006690649146383459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.269566723749449e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413376584649086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782638390858968,
      "backward_entropy": 0.004763010550629009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5347503676821361e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133780747652054,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826342682043712,
      "backward_entropy": 0.004762958396564831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1218351119168801e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413379564881325,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826302448908488,
      "backward_entropy": 0.004762911661104722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8151453105019755e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413381054997444,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826263705889384,
      "backward_entropy": 0.004762861539017071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.15487807761383e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413382172584534,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826223969459534,
      "backward_entropy": 0.004762817512858997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0113061534866574e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413383290171623,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0782618522644043,
      "backward_entropy": 0.006690082224932584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5488037661270937e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133847802877426,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826148470242818,
      "backward_entropy": 0.004762725735252554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3748863239015918e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413385897874832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07826109727223714,
      "backward_entropy": 0.004762693223628131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0015851330535952e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413387015461922,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0782607098420461,
      "backward_entropy": 0.005959925326434049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.217206186600379e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413388133049011,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07826034228006999,
      "backward_entropy": 0.0059599801898002625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.200866096151003e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413389250636101,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.0782599796851476,
      "backward_entropy": 0.004762575368989597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.678118549847568e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0341339036822319,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07825963695844014,
      "backward_entropy": 0.005960067564790899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.856021966290427e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0341339148581028,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07825931906700134,
      "backward_entropy": 0.005960108204321427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.992893410526449e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034133926033973694,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07825899124145508,
      "backward_entropy": 0.005960145457224412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.551812816724123e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413393720984459,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825867335001628,
      "backward_entropy": 0.004762406037612395,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.622898460293072e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034133948385715485,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0782583753267924,
      "backward_entropy": 0.005960211157798767,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.281926622861647e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413395583629608,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825805743535359,
      "backward_entropy": 0.004762344739653848,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.710393674642546e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413396328687668,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825774451096852,
      "backward_entropy": 0.004762307148088108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.894032023614272e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034133970737457275,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825744152069092,
      "backward_entropy": 0.004762273620475422,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.275365080909978e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413397818803787,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825714349746704,
      "backward_entropy": 0.006689082492481579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.266661441462929e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413398563861847,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825686534245808,
      "backward_entropy": 0.004762219095771963,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.885931043143501e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034133993089199066,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0782565971215566,
      "backward_entropy": 0.00668897886167873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.992586528056563e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413400053977966,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825632393360138,
      "backward_entropy": 0.0066889185797084465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.280790335542406e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413400799036026,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825606564680736,
      "backward_entropy": 0.0047621527178721,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.520715487567941e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413401544094086,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825582722822826,
      "backward_entropy": 0.004762121899561448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.904202566853201e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034134022891521454,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825558384259541,
      "backward_entropy": 0.006688764826817946,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.3526247850422806e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413403034210205,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825534542401631,
      "backward_entropy": 0.0047620775347406216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.748619062411308e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413403779268265,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825510700543721,
      "backward_entropy": 0.006688667291944677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7737257230219257e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034134041517972946,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825488845507304,
      "backward_entropy": 0.006688609041950919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.370477881820989e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034134045243263245,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825465500354767,
      "backward_entropy": 0.0047620203007351265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.663466318608698e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413404896855354,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825444638729095,
      "backward_entropy": 0.006688519634983756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7913710571046977e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413405641913414,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825423280398051,
      "backward_entropy": 0.0047619759359143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9057426331746683e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413406014442444,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825403412183125,
      "backward_entropy": 0.006688429550691085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1875043166328396e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034134067595005035,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825384040673573,
      "backward_entropy": 0.004761931232430718,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8501108911550546e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034134071320295334,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825364669164021,
      "backward_entropy": 0.004761918701908805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1830247476373188e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413407504558563,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07825345794359843,
      "backward_entropy": 0.005961034785617481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.074748917697434e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413408249616623,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825328906377156,
      "backward_entropy": 0.004761872643774206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9325958078297845e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413408622145653,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825311024983723,
      "backward_entropy": 0.004761856387961994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1700784575150465e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034134093672037125,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.0782529463370641,
      "backward_entropy": 0.006688182326880368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.706254858570901e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413409739732742,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825278242429097,
      "backward_entropy": 0.006688145751302893,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3225990730679769e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413410112261772,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825261354446411,
      "backward_entropy": 0.004761798815293746,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.196827265128377e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413410484790802,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825244466463725,
      "backward_entropy": 0.0066880719228224325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.939727098942967e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413410857319832,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825227578481038,
      "backward_entropy": 0.004761766303669323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9746777840955474e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413411229848862,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825212677319844,
      "backward_entropy": 0.004761754789135673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2558063506039616e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034134116023778915,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825196782747905,
      "backward_entropy": 0.004761750047857111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8721243577601854e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.034134119749069214,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825181881586711,
      "backward_entropy": 0.004761728034778075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3429962564259768e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03413412347435951,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.0782516747713089,
      "backward_entropy": 0.00596134906465357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.799773201582866e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03413412719964981,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825154066085815,
      "backward_entropy": 0.006687888367609544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2432005291884707e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413413092494011,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825141151746114,
      "backward_entropy": 0.004761702973734249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3468667248162092e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03413413465023041,
      "trajectory_length": 13,
      "branch_chosen": 2,
      "forward_entropy": 0.07825128237406413,
      "backward_entropy": 0.004761680621992458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9105594617485622e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.034134138375520706,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825116813182831,
      "backward_entropy": 0.0066877969286658545,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.181310906872568e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.034134142100811005,
      "trajectory_length": 13,
      "branch_chosen": 0,
      "forward_entropy": 0.07825104395548503,
      "backward_entropy": 0.005961470305919647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2526743375929072e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0341341458261013,
      "trajectory_length": 13,
      "branch_chosen": 1,
      "forward_entropy": 0.07825093468030293,
      "backward_entropy": 0.0066877413879741325,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 3.287022562759034e-06,
    "avg_log_Z": 0.034133723825216296,
    "success_rate": 1.0,
    "avg_reward": 47.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.14,
      "1": 0.28,
      "2": 0.58
    },
    "avg_forward_entropy": 0.0782681499918302,
    "avg_backward_entropy": 0.005470547418702731,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}