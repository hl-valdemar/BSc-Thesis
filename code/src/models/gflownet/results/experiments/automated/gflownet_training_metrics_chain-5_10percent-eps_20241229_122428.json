{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 0.45454545454545453
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 0.7272727272727273
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13658630847930908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.13696606159210206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.233596801757812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18250693877538046,
      "backward_entropy": 0.1362607955932617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.315613746643066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 9.999999747378752e-05,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1825226147969564,
      "backward_entropy": 0.13619906902313234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.131083488464355,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00020001616212539375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18253751595815024,
      "backward_entropy": 0.13647048473358153,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.816266059875488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00029998813988640904,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18255263566970825,
      "backward_entropy": 0.13607337474822997,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.810074806213379,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00039986881893128157,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18256731828053793,
      "backward_entropy": 0.1363518714904785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.190646171569824,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0004996976349502802,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18258166313171387,
      "backward_entropy": 0.13594396114349366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.491766929626465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.000599329243414104,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18259408076604208,
      "backward_entropy": 0.1358778476715088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.18079948425293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0006989137618802488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826059619585673,
      "backward_entropy": 0.13581058979034424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.963353157043457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0007983786636032164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826165517171224,
      "backward_entropy": 0.13574225902557374,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.955090045928955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0008980017155408859,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18262668450673422,
      "backward_entropy": 0.13603537082672118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.254312515258789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0009974417043849826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826347510019938,
      "backward_entropy": 0.13646823167800903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.944807052612305,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0010968331480398774,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18264206250508627,
      "backward_entropy": 0.13641387224197388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.026848793029785,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011964078294113278,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826495329538981,
      "backward_entropy": 0.13545918464660645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.893753051757812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001296167611144483,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18265668551127115,
      "backward_entropy": 0.13576858043670653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.144662857055664,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0013960630167275667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266220887502035,
      "backward_entropy": 0.1362457752227783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.00702953338623,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014957699459046125,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826674540837606,
      "backward_entropy": 0.13523576259613038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.610814094543457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0015956370625644922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18267279863357544,
      "backward_entropy": 0.1355604648590088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.517221450805664,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0016954982420429587,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826779047648112,
      "backward_entropy": 0.13508107662200927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.383888244628906,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0017953107599169016,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18268307050069174,
      "backward_entropy": 0.1354156732559204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.020181655883789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018950646044686437,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826870838801066,
      "backward_entropy": 0.13594491481781007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.845046043395996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00199494487605989,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1826928456624349,
      "backward_entropy": 0.13484015464782714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.79250431060791,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0020949405152350664,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18269753456115723,
      "backward_entropy": 0.13581072092056273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.044095039367676,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0021949626971036196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827028195063273,
      "backward_entropy": 0.13574116230010985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.793760776519775,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0022951362188905478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827078660329183,
      "backward_entropy": 0.13458735942840577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.926732063293457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0023949353490024805,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827119986216227,
      "backward_entropy": 0.13450024127960206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.917718887329102,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0024952294770628214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18271746238072714,
      "backward_entropy": 0.13552451133728027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.993647575378418,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0025959459599107504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827239990234375,
      "backward_entropy": 0.13432161808013915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.706827163696289,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0026970652397722006,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827311317125956,
      "backward_entropy": 0.13472133874893188,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.209246635437012,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0027980541344732046,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18273715178171793,
      "backward_entropy": 0.13413674831390382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.758358955383301,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002899098675698042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274335066477457,
      "backward_entropy": 0.13521528244018555,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.276810646057129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002999598393216729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18274849653244019,
      "backward_entropy": 0.1351348876953125,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.183731079101562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0031002573668956757,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827536622683207,
      "backward_entropy": 0.13436678647994996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.415279388427734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003201004583388567,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18275904655456543,
      "backward_entropy": 0.13374831676483154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.673060417175293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0033015029039233923,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18276421229044595,
      "backward_entropy": 0.13488452434539794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.71526050567627,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003402282716706395,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18277076880137125,
      "backward_entropy": 0.13408666849136353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.2320556640625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003503729123622179,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277899424235025,
      "backward_entropy": 0.13470957279205323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.265569686889648,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003605189034715295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18278674284617105,
      "backward_entropy": 0.13333768844604493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.836935997009277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003706627991050482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827950874964396,
      "backward_entropy": 0.13452850580215453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.538335800170898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0038079058285802603,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280265728632608,
      "backward_entropy": 0.13312342166900634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.2775239944458,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.003909289371222258,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281118075052896,
      "backward_entropy": 0.1330140709877014,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.683146476745605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004011084325611591,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828206181526184,
      "backward_entropy": 0.13424553871154785,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.8479390144348145,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004113002214580774,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18283013502756754,
      "backward_entropy": 0.13340123891830444,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.288307189941406,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004214263055473566,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18283752600351968,
      "backward_entropy": 0.13404934406280516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.372174263000488,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004315534606575966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18284505605697632,
      "backward_entropy": 0.13256230354309081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.774467468261719,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004416481591761112,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285048007965088,
      "backward_entropy": 0.13309140205383302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.887348175048828,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004517277702689171,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285536766052246,
      "backward_entropy": 0.13298518657684327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.276952266693115,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004617956001311541,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828604539235433,
      "backward_entropy": 0.1328767418861389,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.460359573364258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004717811476439238,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286436796188354,
      "backward_entropy": 0.13353261947631836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.083020210266113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004817509558051825,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828674872716268,
      "backward_entropy": 0.13196382522583008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.299806594848633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004916890989989042,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18286975224812826,
      "backward_entropy": 0.1333096742630005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.472702980041504,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00501653179526329,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287243445714316,
      "backward_entropy": 0.13171167373657228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.93028450012207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005115999840199947,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18287543455759683,
      "backward_entropy": 0.133076810836792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25162410736084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005216006189584732,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828791300455729,
      "backward_entropy": 0.13145034313201903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.756697177886963,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005315714981406927,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828824281692505,
      "backward_entropy": 0.13131630420684814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.314826011657715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00541495718061924,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828844944636027,
      "backward_entropy": 0.13194096088409424,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.142867088317871,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005514034070074558,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18288608392079672,
      "backward_entropy": 0.13258109092712403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.052627563476562,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005612857639789581,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828876535097758,
      "backward_entropy": 0.13168854713439943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.367255210876465,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005711401347070932,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18288942178090414,
      "backward_entropy": 0.13075790405273438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.202102661132812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005809903610497713,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828904946645101,
      "backward_entropy": 0.13061254024505614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.467151641845703,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005908745341002941,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289198478062949,
      "backward_entropy": 0.13129136562347413,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456730842590332,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006007527466863394,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289359410603842,
      "backward_entropy": 0.13115439414978028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.48691177368164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006106254179030657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18289530277252197,
      "backward_entropy": 0.1317639946937561,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.914839744567871,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00620501022785902,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18289589881896973,
      "backward_entropy": 0.13000319004058838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.342137336730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0063039097003638744,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289774656295776,
      "backward_entropy": 0.1307300090789795,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.29401969909668,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006403164006769657,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290019035339355,
      "backward_entropy": 0.13130942583084107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.156717300415039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006502271164208651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290162086486816,
      "backward_entropy": 0.12951836585998536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.39012622833252,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006601597182452679,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18290424346923828,
      "backward_entropy": 0.12935192584991456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.1703462600708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006700781639665365,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290666739145914,
      "backward_entropy": 0.13013099431991576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.80101203918457,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006800249218940735,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182908833026886,
      "backward_entropy": 0.12997546195983886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919976234436035,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006899782922118902,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829106609026591,
      "backward_entropy": 0.1298175573348999,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.145283699035645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006998900324106216,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182912548383077,
      "backward_entropy": 0.12965624332427977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.250060081481934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0070978025905787945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829137404759725,
      "backward_entropy": 0.1294924020767212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.768361568450928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007196532096713781,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291519085566202,
      "backward_entropy": 0.1299440383911133,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.442712306976318,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007294896524399519,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291590611139932,
      "backward_entropy": 0.12976016998291015,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.212176322937012,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007392717059701681,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291701873143515,
      "backward_entropy": 0.12957413196563722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.09412670135498,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00749047240242362,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291831016540527,
      "backward_entropy": 0.12938463687896729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.041741371154785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00758860819041729,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829202969868978,
      "backward_entropy": 0.12919025421142577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.71419620513916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007687107659876347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18292184670766196,
      "backward_entropy": 0.128991436958313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.620928764343262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.007785712368786335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829239328702291,
      "backward_entropy": 0.12710068225860596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.258442401885986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007884351536631584,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.182926615079244,
      "backward_entropy": 0.12806878089904786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.399052619934082,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007982362993061543,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292858203252158,
      "backward_entropy": 0.127876615524292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.271676063537598,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008080387488007545,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829306681950887,
      "backward_entropy": 0.12768112421035765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.644741535186768,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00817839615046978,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829321583112081,
      "backward_entropy": 0.12625601291656494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.93015193939209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008276069536805153,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293283383051553,
      "backward_entropy": 0.1272818326950073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.023929595947266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008374123834073544,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293301264444986,
      "backward_entropy": 0.12581048011779786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.50878620147705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008472532965242863,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293339014053345,
      "backward_entropy": 0.12687150239944459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.426810264587402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008570958860218525,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18293428421020508,
      "backward_entropy": 0.12534962892532348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.89315938949585,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008669458329677582,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829339067141215,
      "backward_entropy": 0.12644853591918945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.668689250946045,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00876716710627079,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18293295303980509,
      "backward_entropy": 0.12652137279510497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.873123168945312,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008864558301866055,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829320788383484,
      "backward_entropy": 0.1262739658355713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.975956439971924,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.008962840773165226,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293142318725586,
      "backward_entropy": 0.1257907748222351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.124073028564453,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009060914628207684,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18293070793151855,
      "backward_entropy": 0.1255645513534546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.950898170471191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009159456938505173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18292935689290366,
      "backward_entropy": 0.12549316883087158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.777840614318848,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009258300065994263,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829278071721395,
      "backward_entropy": 0.1252213954925537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.60485553741455,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00935729406774044,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292641639709473,
      "backward_entropy": 0.12486810684204101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.73622465133667,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009456304833292961,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292546272277832,
      "backward_entropy": 0.1230858564376831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.974244594573975,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009554877877235413,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18292462825775146,
      "backward_entropy": 0.12281711101531982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.921147346496582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009653182700276375,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18292405207951865,
      "backward_entropy": 0.12413368225097657,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.333670616149902,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009751824662089348,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1829226811726888,
      "backward_entropy": 0.1238815426826477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.890258312225342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009849335998296738,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18292113145192465,
      "backward_entropy": 0.12352218627929687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.734973430633545,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009946702979505062,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18291978041330972,
      "backward_entropy": 0.12336629629135132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.104584693908691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010043266229331493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1829188863436381,
      "backward_entropy": 0.12294803857803345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.853846073150635,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010139902122318745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829176346460978,
      "backward_entropy": 0.12112573385238648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.012004375457764,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01023590937256813,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18291636308034262,
      "backward_entropy": 0.1225632905960083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.793622016906738,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010331422090530396,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18291538953781128,
      "backward_entropy": 0.12228732109069824,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.256684303283691,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010427486151456833,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829142371813456,
      "backward_entropy": 0.12024562358856201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.25224494934082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010523296892642975,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18291173378626505,
      "backward_entropy": 0.12145340442657471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.618412494659424,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010619353502988815,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18290903170903525,
      "backward_entropy": 0.12144006490707397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.209059715270996,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010714692994952202,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1829068660736084,
      "backward_entropy": 0.11932520866394043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.204310417175293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010810313746333122,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290444215138754,
      "backward_entropy": 0.12051070928573608,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.654681205749512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010905659757554531,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18290154139200845,
      "backward_entropy": 0.12018876075744629,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3346848487854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011001527309417725,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1828984022140503,
      "backward_entropy": 0.118369722366333,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.55746603012085,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011097149923443794,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289506435394287,
      "backward_entropy": 0.11994884014129639,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.685139179229736,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01119267474859953,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18289156754811606,
      "backward_entropy": 0.11963871717453003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.639804363250732,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011288216337561607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1828874945640564,
      "backward_entropy": 0.11884070634841919,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.937993049621582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011383149772882462,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828836997350057,
      "backward_entropy": 0.11900805234909058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.709826946258545,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011478803120553493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18287964661916098,
      "backward_entropy": 0.11813993453979492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.985122203826904,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01157444715499878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287537495295206,
      "backward_entropy": 0.11638216972351074,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.424068450927734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011669645085930824,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18287142117818198,
      "backward_entropy": 0.11604256629943847,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.400839805603027,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01176473405212164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.182867169380188,
      "backward_entropy": 0.11569821834564209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.849959850311279,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011859715916216373,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18286263942718506,
      "backward_entropy": 0.11734880208969116,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.808548927307129,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011954848654568195,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18285771210988364,
      "backward_entropy": 0.11499264240264892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.477921485900879,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012049535289406776,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18285278479258218,
      "backward_entropy": 0.11665234565734864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.538546085357666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012143625877797604,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18284821510314941,
      "backward_entropy": 0.11426795721054077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.734336853027344,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012237802147865295,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18284322818120322,
      "backward_entropy": 0.1159388542175293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.256001472473145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012332216836512089,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18283738692601523,
      "backward_entropy": 0.11473946571350098,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.158785343170166,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012427099980413914,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1828307310740153,
      "backward_entropy": 0.11520133018493653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2032670974731445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012521195225417614,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18282459179560342,
      "backward_entropy": 0.1139186143875122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.01078987121582,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012615201994776726,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18281821409861246,
      "backward_entropy": 0.11443430185317993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.702691078186035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01270961482077837,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18281094233194986,
      "backward_entropy": 0.11196162700653076,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.796334266662598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012803579680621624,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18280410766601562,
      "backward_entropy": 0.1115610122680664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5558695793151855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012897860258817673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18279627958933511,
      "backward_entropy": 0.11221095323562622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.139917850494385,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012992189265787601,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1827882925669352,
      "backward_entropy": 0.11283576488494873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.704876899719238,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013086399994790554,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18277988831202188,
      "backward_entropy": 0.11131459474563599,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.154771327972412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013180860318243504,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18277045090993246,
      "backward_entropy": 0.10990941524505615,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.34733247756958,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01327521912753582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827605962753296,
      "backward_entropy": 0.11039284467697144,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3882575035095215,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013369599357247353,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18275010585784912,
      "backward_entropy": 0.10992332696914672,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1650261878967285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013464041985571384,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18273899952570596,
      "backward_entropy": 0.109447181224823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.615720272064209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013557162135839462,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18273029724756876,
      "backward_entropy": 0.11029551029205323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.062998294830322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.013650631532073021,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1827205022176107,
      "backward_entropy": 0.10771440267562866,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.382575988769531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013743417337536812,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18271162112553915,
      "backward_entropy": 0.10941464900970459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.794628620147705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013835195451974869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1827042500178019,
      "backward_entropy": 0.10754694938659667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.634701728820801,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013926982879638672,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18269642194112143,
      "backward_entropy": 0.10706689357757568,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.881309986114502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01401921734213829,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18268752098083496,
      "backward_entropy": 0.10806235074996948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.2052998542785645,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014110778458416462,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18267963329950967,
      "backward_entropy": 0.10760016441345215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.534120082855225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014202585443854332,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18267093102137247,
      "backward_entropy": 0.10557563304901123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.641513824462891,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014293595217168331,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18266338109970093,
      "backward_entropy": 0.10507445335388184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.983044624328613,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014384565874934196,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1826555331548055,
      "backward_entropy": 0.10456614494323731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.136831760406494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014474480412900448,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18264947334925333,
      "backward_entropy": 0.10570530891418457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.475423336029053,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01456480659544468,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18264218171437582,
      "backward_entropy": 0.10522067546844482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.7876739501953125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014655057340860367,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18263471126556396,
      "backward_entropy": 0.10243970155715942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.230416297912598,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014745466411113739,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18262646595637003,
      "backward_entropy": 0.1024998664855957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.716102123260498,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014836356975138187,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18261661132176718,
      "backward_entropy": 0.10141198635101319,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.745579242706299,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014927302487194538,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18260616064071655,
      "backward_entropy": 0.10088828802108765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.472164630889893,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015018335543572903,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18259499470392862,
      "backward_entropy": 0.10270910263061524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.538389682769775,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015109874308109283,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18258229891459146,
      "backward_entropy": 0.1002849817276001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.42496919631958,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015201283618807793,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18256928523381552,
      "backward_entropy": 0.09928281307220459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.182132720947266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015292544849216938,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18255593379338583,
      "backward_entropy": 0.09873487949371337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.755251407623291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015383526682853699,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1825424830118815,
      "backward_entropy": 0.09856738448143006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.916748523712158,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015474614687263966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18252811829249063,
      "backward_entropy": 0.09762133359909057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.940711975097656,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015565901063382626,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18251283963521323,
      "backward_entropy": 0.09740195274353028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.032092094421387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0156567245721817,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18249801794687906,
      "backward_entropy": 0.09681735038757325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3398308753967285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015747854486107826,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824816664059957,
      "backward_entropy": 0.09622247219085693,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.149136543273926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015838127583265305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1824668049812317,
      "backward_entropy": 0.09563097953796387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.3059587478637695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01592821627855301,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18245158592859903,
      "backward_entropy": 0.0947596251964569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.718293190002441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01601824164390564,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18243561188379923,
      "backward_entropy": 0.0944344162940979,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.159858703613281,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016108492389321327,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18241812785466513,
      "backward_entropy": 0.09382420778274536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.942738056182861,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01619855873286724,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18240022659301758,
      "backward_entropy": 0.09320958852767944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.387125492095947,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016289032995700836,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18238027890523276,
      "backward_entropy": 0.09238537549972534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.652514457702637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01637948490679264,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18235931793848673,
      "backward_entropy": 0.09177760481834411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4256696701049805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016470128670334816,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18233680725097656,
      "backward_entropy": 0.09116297960281372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.0115647315979,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01656074821949005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18231322367986044,
      "backward_entropy": 0.09066909551620483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.692466735839844,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016651026904582977,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18228950103123984,
      "backward_entropy": 0.09268324971199035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.177332401275635,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01674155332148075,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18226383129755655,
      "backward_entropy": 0.09208720922470093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.686370372772217,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016831830143928528,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1822376847267151,
      "backward_entropy": 0.08867846727371216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.376943111419678,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016921592876315117,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18221205472946167,
      "backward_entropy": 0.08804041147232056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.045380592346191,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017011361196637154,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18218533198038736,
      "backward_entropy": 0.08737109303474426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.421871185302734,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017100241035223007,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18216017882029215,
      "backward_entropy": 0.08675839900970458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.848080158233643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017188595607876778,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18213540315628052,
      "backward_entropy": 0.08604225516319275,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.0839715003967285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017276806756854057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18210973342259726,
      "backward_entropy": 0.08537657856941223,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.050936698913574,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017364369705319405,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18208515644073486,
      "backward_entropy": 0.08471493124961853,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.061131477355957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017451277002692223,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18206161260604858,
      "backward_entropy": 0.08716127276420593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.770341396331787,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017537621781229973,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18203888336817423,
      "backward_entropy": 0.08346822261810302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.42575740814209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01762397587299347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18201565742492676,
      "backward_entropy": 0.08273136615753174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.323031902313232,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017710117623209953,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1819920539855957,
      "backward_entropy": 0.08213155269622803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.812656402587891,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017795981839299202,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18196797370910645,
      "backward_entropy": 0.08463932871818543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.71389627456665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017881253734230995,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18194502592086792,
      "backward_entropy": 0.08078256845474244,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.396927356719971,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017965909093618393,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1819233496983846,
      "backward_entropy": 0.08336910009384155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.289427280426025,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01805051974952221,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1819001833597819,
      "backward_entropy": 0.08272976875305176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.576418399810791,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01813577115535736,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1818724274635315,
      "backward_entropy": 0.07873796820640563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.642760753631592,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018221037462353706,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18184260527292886,
      "backward_entropy": 0.081439208984375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.808964729309082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018305622041225433,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18181443214416504,
      "backward_entropy": 0.0773280143737793,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.134483814239502,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018389733508229256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18178661664326987,
      "backward_entropy": 0.07667052745819092,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.712935924530029,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018473682925105095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18175778786341348,
      "backward_entropy": 0.07593931555747986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.544395923614502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018557971343398094,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18172556161880493,
      "backward_entropy": 0.07523283958435059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.78122615814209,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018641643226146698,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18169458707173666,
      "backward_entropy": 0.0781811535358429,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.5370354652404785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018724873661994934,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1816633939743042,
      "backward_entropy": 0.07382598519325256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.845715045928955,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.018807627260684967,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18163299560546875,
      "backward_entropy": 0.0768642246723175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.854155540466309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018889302387833595,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18160609404246011,
      "backward_entropy": 0.07245608568191528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.55380916595459,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01897088997066021,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1815776228904724,
      "backward_entropy": 0.07173686027526856,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.366486549377441,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019052136689424515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18154871463775635,
      "backward_entropy": 0.07104904055595399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.315017223358154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019132882356643677,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18151992559432983,
      "backward_entropy": 0.07421267032623291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.608670234680176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01921313814818859,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18149121602376303,
      "backward_entropy": 0.0696492612361908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.211108207702637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019293207675218582,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18146081765492758,
      "backward_entropy": 0.06894725561141968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.07671594619751,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01937277615070343,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1814304987589518,
      "backward_entropy": 0.06826888918876647,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.654247760772705,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019451873376965523,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1814009149869283,
      "backward_entropy": 0.07152703404426575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.846730947494507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019531037658452988,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1813686490058899,
      "backward_entropy": 0.06684561371803284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.34102725982666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01960953325033188,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18133781353632608,
      "backward_entropy": 0.06614253520965577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6216063499450684,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019688770174980164,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18130016326904297,
      "backward_entropy": 0.06547958254814149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.257684230804443,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019767092540860176,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.181264857451121,
      "backward_entropy": 0.06478469967842101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.640749216079712,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019845182076096535,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18122782309850058,
      "backward_entropy": 0.06400331258773803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.71561336517334,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019922541454434395,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1811925768852234,
      "backward_entropy": 0.06339846849441529,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.302093744277954,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020000234246253967,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18115234375,
      "backward_entropy": 0.06270259618759155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4091289043426514,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020076962187886238,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18111578623453775,
      "backward_entropy": 0.06616122722625732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1868388652801514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02015286311507225,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18108133474985758,
      "backward_entropy": 0.06132250428199768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.5162971019744873,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020227806642651558,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18104992310206094,
      "backward_entropy": 0.0606428325176239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7275331020355225,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02030223235487938,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1810188889503479,
      "backward_entropy": 0.06416400671005248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4482922554016113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020376384258270264,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1809863050778707,
      "backward_entropy": 0.05914537906646729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9371931552886963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020450055599212646,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18095395962397257,
      "backward_entropy": 0.05846866965293884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4714770317077637,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020522795617580414,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1809251308441162,
      "backward_entropy": 0.05795152187347412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.189689636230469,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02059522271156311,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808952291806539,
      "backward_entropy": 0.057285773754119876,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3979504108428955,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02066810615360737,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1808589299519857,
      "backward_entropy": 0.05661627054214478,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6356301307678223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02074061520397663,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18082199494043985,
      "backward_entropy": 0.06018286943435669,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9437286853790283,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020813100039958954,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1807828148206075,
      "backward_entropy": 0.059522497653961184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.452742099761963,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020884767174720764,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18074562152226767,
      "backward_entropy": 0.05886597633361816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.323275089263916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020956294611096382,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18070638179779053,
      "backward_entropy": 0.053788745403289796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.761784076690674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021027471870183945,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1806650161743164,
      "backward_entropy": 0.05756078958511353,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.249746084213257,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021097762510180473,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1806258757909139,
      "backward_entropy": 0.052642011642456056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7453341484069824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021166810765862465,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.18059366941452026,
      "backward_entropy": 0.05627518892288208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7904105186462402,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02123626321554184,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18055403232574463,
      "backward_entropy": 0.051355946063995364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4543251991271973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021305063739418983,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1805151104927063,
      "backward_entropy": 0.05500170588493347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.058039903640747,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021372895687818527,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18047924836476645,
      "backward_entropy": 0.04993005990982056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1968772411346436,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021440602838993073,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18044094244639078,
      "backward_entropy": 0.049304306507110596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5896496772766113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02150833047926426,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18039840459823608,
      "backward_entropy": 0.048676544427871705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.055555820465088,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02157529816031456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1803562045097351,
      "backward_entropy": 0.048056453466415405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7849974632263184,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021642204374074936,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1803100903828939,
      "backward_entropy": 0.047435665130615236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.100435972213745,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021708767861127853,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18026244640350342,
      "backward_entropy": 0.04681847095489502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0269696712493896,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02177540771663189,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.18020995457967123,
      "backward_entropy": 0.04619936347007751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5750555992126465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02184087224304676,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1801632046699524,
      "backward_entropy": 0.050074446201324466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7513561248779297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02190587669610977,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1801150639851888,
      "backward_entropy": 0.045202475786209104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5728182792663574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021970689296722412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.18006338675816855,
      "backward_entropy": 0.044613251090049745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.520519733428955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022035110741853714,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1800096035003662,
      "backward_entropy": 0.04380705952644348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2683990001678467,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022099122405052185,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1799538532892863,
      "backward_entropy": 0.04772034287452698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5579516887664795,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02216253988444805,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17989909648895264,
      "backward_entropy": 0.042637065052986145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7549993991851807,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02222573570907116,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1798410415649414,
      "backward_entropy": 0.04657837748527527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4729666709899902,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02228769101202488,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1797881523768107,
      "backward_entropy": 0.04175439178943634,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2154107093811035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022349495440721512,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17973152796427408,
      "backward_entropy": 0.04091442227363586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6617947816848755,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022410832345485687,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17967375119527182,
      "backward_entropy": 0.04034885764122009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.226606845855713,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022470928728580475,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17962026596069336,
      "backward_entropy": 0.04011319279670715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2448878288269043,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02253076620399952,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17956405878067017,
      "backward_entropy": 0.04384424388408661,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.021810293197632,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022590382024645805,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17950421571731567,
      "backward_entropy": 0.04331223666667938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4209719896316528,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022649509832262993,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17944333950678507,
      "backward_entropy": 0.03852752447128296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.660024642944336,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022707274183630943,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17938812573750815,
      "backward_entropy": 0.042269617319107056,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8363220691680908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022764232009649277,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1793351173400879,
      "backward_entropy": 0.03751504719257355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.480798363685608,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02282075770199299,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1792814334233602,
      "backward_entropy": 0.04125977754592895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7617002725601196,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022876327857375145,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1792310873667399,
      "backward_entropy": 0.04076700210571289,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5324954986572266,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022931430488824844,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17918044328689575,
      "backward_entropy": 0.036041027307510375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.755237340927124,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02298583649098873,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.179132342338562,
      "backward_entropy": 0.035140028595924376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.712863564491272,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023039884865283966,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17908076445261636,
      "backward_entropy": 0.03932318091392517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5211312770843506,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02309355139732361,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1790261467297872,
      "backward_entropy": 0.034625059366226195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.365563154220581,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02314658835530281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17897117137908936,
      "backward_entropy": 0.03371376395225525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1406643390655518,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023198770359158516,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17891724904378256,
      "backward_entropy": 0.03325419425964356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6209560632705688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02324986271560192,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.178868035475413,
      "backward_entropy": 0.03280777335166931,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2611064910888672,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023300739005208015,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17881413300832114,
      "backward_entropy": 0.03236305117607117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2658655643463135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023350799456238747,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17876094579696655,
      "backward_entropy": 0.03242323398590088,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3796089887619019,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02340018004179001,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17870807647705078,
      "backward_entropy": 0.032006144523620605,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1439083814620972,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02344915084540844,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17865300178527832,
      "backward_entropy": 0.03573884963989258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9579086899757385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023497357964515686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17859975496927896,
      "backward_entropy": 0.030661925673484802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2736133337020874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023544520139694214,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17855089902877808,
      "backward_entropy": 0.03025963008403778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1571859121322632,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023591315373778343,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17849934101104736,
      "backward_entropy": 0.030401426553726196,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2789745330810547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023637644946575165,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17844794193903604,
      "backward_entropy": 0.030013540387153627,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9801875352859497,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023683717474341393,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17839292685190836,
      "backward_entropy": 0.03372121155261994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0615217685699463,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023728985339403152,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1783395210901896,
      "backward_entropy": 0.028696364164352416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8950851559638977,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02377365343272686,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1782850424448649,
      "backward_entropy": 0.028321143984794617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1944634914398193,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023817433044314384,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17823209365208945,
      "backward_entropy": 0.03258680105209351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1317474842071533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.023861046880483627,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17817413806915283,
      "backward_entropy": 0.0322187066078186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8345460295677185,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02390444651246071,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17811272541681925,
      "backward_entropy": 0.027819177508354186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8719030022621155,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023946980014443398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17805320024490356,
      "backward_entropy": 0.026876163482666016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1825602054595947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023988820612430573,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17799407243728638,
      "backward_entropy": 0.026530829071998597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8417577743530273,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02403070405125618,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17792787154515585,
      "backward_entropy": 0.030802839994430543,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6699923872947693,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024071818217635155,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17786133289337158,
      "backward_entropy": 0.030461877584457397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.806501030921936,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02411188930273056,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17779811223347983,
      "backward_entropy": 0.03012983500957489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7960071563720703,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02415132336318493,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17773417631785074,
      "backward_entropy": 0.025197646021842955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6820884346961975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02419019490480423,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17766944567362467,
      "backward_entropy": 0.02948336601257324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8556318283081055,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02422831952571869,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.177606463432312,
      "backward_entropy": 0.024574735760688783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6732110977172852,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024266177788376808,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17754010359446207,
      "backward_entropy": 0.024269770085811614,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8622742891311646,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024303322657942772,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1774751345316569,
      "backward_entropy": 0.028554433584213258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6642581820487976,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024340355768799782,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17740819851557413,
      "backward_entropy": 0.024386066198349,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7029607892036438,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02437669038772583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.177340567111969,
      "backward_entropy": 0.02338538020849228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8131638765335083,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02441254071891308,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1772710680961609,
      "backward_entropy": 0.02383587509393692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5519709587097168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024448249489068985,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1771962841351827,
      "backward_entropy": 0.02738223969936371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8688977360725403,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024483058601617813,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.177122433980306,
      "backward_entropy": 0.023305866122245788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5828700661659241,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024518080055713654,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17704149087270102,
      "backward_entropy": 0.023044945299625398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5546918511390686,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02455245330929756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1769609053929647,
      "backward_entropy": 0.021993035078048707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4197011888027191,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02458612620830536,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1768805185953776,
      "backward_entropy": 0.02628572881221771,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6689209342002869,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02461877092719078,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17680380741755167,
      "backward_entropy": 0.02229994535446167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46571606397628784,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02465122379362583,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17672218879063925,
      "backward_entropy": 0.022062480449676514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4188039302825928,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0246829055249691,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1766418218612671,
      "backward_entropy": 0.021831417083740236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4008958339691162,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02471376582980156,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1765636404355367,
      "backward_entropy": 0.02160667032003403,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.49306824803352356,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024743808433413506,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17648744583129883,
      "backward_entropy": 0.02051035761833191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4613454043865204,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024773428216576576,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17640960216522217,
      "backward_entropy": 0.020284295082092285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.46736136078834534,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024802470579743385,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17632979154586792,
      "backward_entropy": 0.024600431323051453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2565512955188751,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024831146001815796,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17624874909718832,
      "backward_entropy": 0.019845259189605714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2037118524312973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02485872618854046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17617319027582803,
      "backward_entropy": 0.01963742673397064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.293962299823761,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02488502860069275,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17610333363215128,
      "backward_entropy": 0.01944074034690857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45785078406333923,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02491055056452751,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17603540420532227,
      "backward_entropy": 0.01925073266029358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22352531552314758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024935949593782425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17596236864725748,
      "backward_entropy": 0.019061610102653503,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.34087035059928894,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024960428476333618,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1758940021197001,
      "backward_entropy": 0.019837361574172974,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37120336294174194,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024984391406178474,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17582348982493082,
      "backward_entropy": 0.01870247721672058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.35961776971817017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02500813826918602,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1757504940032959,
      "backward_entropy": 0.018526136875152588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2923893928527832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025031646713614464,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17567501465479532,
      "backward_entropy": 0.02284812480211258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.37984880805015564,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02505462057888508,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1755990982055664,
      "backward_entropy": 0.02267520725727081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27524250745773315,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02507743053138256,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1755182941754659,
      "backward_entropy": 0.019013305008411408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.410695880651474,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02509971894323826,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17543752988179526,
      "backward_entropy": 0.018856778740882874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2999016344547272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025122150778770447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17535070578257242,
      "backward_entropy": 0.01767348051071167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4042513966560364,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025144154205918312,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17526193459828696,
      "backward_entropy": 0.017507754266262054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2790735065937042,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025166282430291176,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1751665472984314,
      "backward_entropy": 0.021846435964107513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33524224162101746,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0251879021525383,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1750697692235311,
      "backward_entropy": 0.018244411051273345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.30455145239830017,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025209378451108932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17496895790100098,
      "backward_entropy": 0.017014828324317933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2547416090965271,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025230616331100464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17486566305160522,
      "backward_entropy": 0.016854336857795714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2251405566930771,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02525141090154648,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17476201057434082,
      "backward_entropy": 0.016697515547275544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2560180723667145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025271622464060783,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17465877532958984,
      "backward_entropy": 0.016545426845550538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21255575120449066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025291526690125465,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17455434799194336,
      "backward_entropy": 0.016395901143550873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20098648965358734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025310980156064034,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17445103327433267,
      "backward_entropy": 0.020806437730789183,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16161291301250458,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025329817086458206,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17434767882029215,
      "backward_entropy": 0.01610936373472214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.22187642753124237,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025347933173179626,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17424664894739786,
      "backward_entropy": 0.020548082888126373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1974853128194809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025365790352225304,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17414442698160806,
      "backward_entropy": 0.015841060876846315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1761113703250885,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02538321539759636,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17404129107793173,
      "backward_entropy": 0.01571122109889984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1989501714706421,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025400176644325256,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1739385724067688,
      "backward_entropy": 0.015585052967071533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.20706327259540558,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025416811928153038,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17383400599161783,
      "backward_entropy": 0.015461230278015136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15828682482242584,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025433296337723732,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1737274924914042,
      "backward_entropy": 0.019963641464710236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17937125265598297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02544930763542652,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1736216147740682,
      "backward_entropy": 0.01521971970796585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10875086486339569,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02546502836048603,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17351444562276205,
      "backward_entropy": 0.015103007853031158,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09284013509750366,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025479944422841072,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17340989907582602,
      "backward_entropy": 0.019652111828327178,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12574084103107452,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025493936613202095,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1733079751332601,
      "backward_entropy": 0.014888662099838256,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17971549928188324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025507470592856407,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17320706446965536,
      "backward_entropy": 0.01609235554933548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10682403296232224,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025521062314510345,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17310355106989542,
      "backward_entropy": 0.01938517242670059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12541954219341278,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02553403563797474,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17300124963124594,
      "backward_entropy": 0.015917709469795226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1531698852777481,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025546588003635406,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17289833227793375,
      "backward_entropy": 0.015835432708263396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11703306436538696,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025558996945619583,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17279253403345743,
      "backward_entropy": 0.014404632151126862,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.18234574794769287,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025571053847670555,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17268693447113037,
      "backward_entropy": 0.015675804018974303,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11912159621715546,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025583358481526375,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1725762883822123,
      "backward_entropy": 0.014222556352615356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11607212573289871,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025595348328351974,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17246542374293009,
      "backward_entropy": 0.018917052447795867,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12797006964683533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025606967508792877,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1723538637161255,
      "backward_entropy": 0.014045728743076325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15016575157642365,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025618519634008408,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17224133014678955,
      "backward_entropy": 0.01877410113811493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11369146406650543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025630172342061996,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17212541898091635,
      "backward_entropy": 0.013871987164020539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06130770593881607,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02564147301018238,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17200825611750284,
      "backward_entropy": 0.018633249402046203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.104373499751091,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025652002543210983,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17189466953277588,
      "backward_entropy": 0.015155678987503052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08632349967956543,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025662334635853767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1717806657155355,
      "backward_entropy": 0.01363014280796051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1115456223487854,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025672301650047302,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1716676950454712,
      "backward_entropy": 0.015026646852493285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10729747265577316,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025682244449853897,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17155333360036215,
      "backward_entropy": 0.013479968905448914,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0830010399222374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025692159309983253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17143787940343222,
      "backward_entropy": 0.014901259541511535,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0943525955080986,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025701826438307762,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17132349809010824,
      "backward_entropy": 0.013332298398017884,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07201237231492996,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025711338967084885,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1712082028388977,
      "backward_entropy": 0.013260628283023834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09995315968990326,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025720497593283653,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.171094278494517,
      "backward_entropy": 0.014723801612854004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06284470111131668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025729645043611526,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17097818851470947,
      "backward_entropy": 0.014666852355003358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.070961132645607,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025738315656781197,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.170863668123881,
      "backward_entropy": 0.013056808710098266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04664623364806175,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02574670873582363,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17074966430664062,
      "backward_entropy": 0.01801217794418335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0818164199590683,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02575433813035488,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17063748836517334,
      "backward_entropy": 0.017970387637615205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03499608486890793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025761952623724937,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1705238620440165,
      "backward_entropy": 0.01287577599287033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07132651656866074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025768933817744255,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.17041422923405966,
      "backward_entropy": 0.01789119839668274,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04137931391596794,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025775879621505737,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.17030402024586996,
      "backward_entropy": 0.014380080997943879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06288346648216248,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025782393291592598,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1701967716217041,
      "backward_entropy": 0.014340047538280488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06905407458543777,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0257888063788414,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.17008920510609946,
      "backward_entropy": 0.012666861712932586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05440293997526169,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02579525299370289,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16998048623402914,
      "backward_entropy": 0.01426132172346115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0566815622150898,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025801530107855797,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16987224419911703,
      "backward_entropy": 0.01422307938337326,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.050576094537973404,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02580769918859005,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16976392269134521,
      "backward_entropy": 0.012519057095050811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.056828778237104416,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025813711807131767,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16965623696645102,
      "backward_entropy": 0.012471883744001388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05630885437130928,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025819674134254456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1695479949315389,
      "backward_entropy": 0.012425066530704498,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.059604741632938385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025825535878539085,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16943877935409546,
      "backward_entropy": 0.012378893792629242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03947887942194939,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025831464678049088,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16932839155197144,
      "backward_entropy": 0.012332306802272796,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05097651481628418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025837037712335587,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16921931505203247,
      "backward_entropy": 0.012288130074739455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04064810648560524,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02584250643849373,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16910954316457114,
      "backward_entropy": 0.013976021111011505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05021550878882408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02584783360362053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16900118192036948,
      "backward_entropy": 0.012202174961566925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03647158294916153,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025853125378489494,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16889184713363647,
      "backward_entropy": 0.01215999647974968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.042581021785736084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025858033448457718,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16878334681193033,
      "backward_entropy": 0.01742490381002426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04194730892777443,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025862913578748703,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1686753829320272,
      "backward_entropy": 0.01208086907863617,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.039212942123413086,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025867734104394913,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16856761773427328,
      "backward_entropy": 0.012041818350553513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03194407746195793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025872400030493736,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16846009095509848,
      "backward_entropy": 0.012003743648529052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0328318327665329,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0258768443018198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16835395495096842,
      "backward_entropy": 0.013771601021289825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017309226095676422,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025881024077534676,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1682483752568563,
      "backward_entropy": 0.01731036454439163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03050355613231659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025884684175252914,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16814627250035605,
      "backward_entropy": 0.013725335896015167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03818525746464729,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025888152420520782,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16804462671279907,
      "backward_entropy": 0.011871091276407241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0363435372710228,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025891747325658798,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16794224580128989,
      "backward_entropy": 0.011840273439884186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03867083787918091,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02589535340666771,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16783903042475382,
      "backward_entropy": 0.011809348315000533,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.032132696360349655,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025899069383740425,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16773454348246256,
      "backward_entropy": 0.011777868121862411,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03298085555434227,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02590271830558777,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16763015588124594,
      "backward_entropy": 0.011746759712696075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029997890815138817,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02590644359588623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16752596696217856,
      "backward_entropy": 0.011715228110551834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028655514121055603,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025910083204507828,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16742201646169028,
      "backward_entropy": 0.013575419783592224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.029889440163969994,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025913646444678307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16731848319371542,
      "backward_entropy": 0.011653825640678406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02850915864109993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025917252525687218,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16721502939860025,
      "backward_entropy": 0.011623316258192063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024013081565499306,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025920895859599113,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16711187362670898,
      "backward_entropy": 0.01159268245100975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017424780875444412,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025924401357769966,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1670096516609192,
      "backward_entropy": 0.013491290807723998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.024736089631915092,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02592751942574978,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16690941651662192,
      "backward_entropy": 0.017098239064216612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022322725504636765,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025930630043148994,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16680949926376343,
      "backward_entropy": 0.01150883138179779,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02058442495763302,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02593369409441948,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16671043634414673,
      "backward_entropy": 0.01148223653435707,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02128511294722557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025936655700206757,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16661236683527628,
      "backward_entropy": 0.011456365138292313,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014475593343377113,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02593955211341381,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16651486357053122,
      "backward_entropy": 0.013403646647930145,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0181867778301239,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02594219520688057,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1664197544256846,
      "backward_entropy": 0.011407458037137986,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01915043778717518,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025944693014025688,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1663255492846171,
      "backward_entropy": 0.013374584913253783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02063394896686077,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025947151705622673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1662319302558899,
      "backward_entropy": 0.01136237159371376,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02142162434756756,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025949565693736076,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16613802313804626,
      "backward_entropy": 0.011340130120515823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014932387508451939,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025952167809009552,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16604425509770712,
      "backward_entropy": 0.016992983222007752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013115083798766136,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02595457248389721,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.165951669216156,
      "backward_entropy": 0.01698329150676727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015794022008776665,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025956638157367706,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16586031516393027,
      "backward_entropy": 0.016976429522037505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013849967159330845,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02595861814916134,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16576945781707764,
      "backward_entropy": 0.011255879700183869,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012229616753757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02596050314605236,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16567979256312051,
      "backward_entropy": 0.01123729944229126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015304765664041042,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025962214916944504,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1655915379524231,
      "backward_entropy": 0.011219866573810577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014416138641536236,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025963949039578438,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16550355156262717,
      "backward_entropy": 0.011202338337898254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013560166582465172,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025965651497244835,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1654159426689148,
      "backward_entropy": 0.0169505774974823,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011443034745752811,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02596733532845974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16532907883326212,
      "backward_entropy": 0.011168037354946137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011360673233866692,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025968946516513824,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16524366537729898,
      "backward_entropy": 0.01694178283214569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011716990731656551,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025970475748181343,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1651594042778015,
      "backward_entropy": 0.013226152956485748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009692925028502941,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025971954688429832,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1650759776433309,
      "backward_entropy": 0.01693452149629593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0095210624858737,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025973396375775337,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16499433914820352,
      "backward_entropy": 0.01110490933060646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01238156110048294,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025974683463573456,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1649137338002523,
      "backward_entropy": 0.011090770363807678,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.010519317351281643,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02597612701356411,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16483340660730997,
      "backward_entropy": 0.011075805127620696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011011496186256409,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025977609679102898,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16475388407707214,
      "backward_entropy": 0.011060746759176255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008814489468932152,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025979135185480118,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16467471917470297,
      "backward_entropy": 0.011045504361391068,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00849215593189001,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025980623438954353,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16459681590398154,
      "backward_entropy": 0.01690981984138489,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009282810613512993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025982074439525604,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16452011466026306,
      "backward_entropy": 0.011016134917736054,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009466433897614479,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0259835347533226,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16444418827692667,
      "backward_entropy": 0.016899779438972473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008600299246609211,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025985023006796837,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16436874866485596,
      "backward_entropy": 0.010987061262130737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008759201504290104,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025986507534980774,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16429412364959717,
      "backward_entropy": 0.01688900589942932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008419805206358433,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025988008826971054,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1642200549443563,
      "backward_entropy": 0.010957988351583481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0076938411220908165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02598951943218708,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16414648294448853,
      "backward_entropy": 0.010943453013896941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006637968588620424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025991054251790047,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16407382488250732,
      "backward_entropy": 0.010928930342197418,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006071769632399082,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02599247358739376,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16400214036305746,
      "backward_entropy": 0.01310475468635559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0063585201278328896,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02599376067519188,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1639315883318583,
      "backward_entropy": 0.013097691535949706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005480476655066013,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025994982570409775,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1638619303703308,
      "backward_entropy": 0.010889726132154465,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006376328878104687,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.025996137410402298,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16379364331563315,
      "backward_entropy": 0.013084797561168671,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005417029373347759,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025997323915362358,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1637261907259623,
      "backward_entropy": 0.010865747928619385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005540519021451473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025998461991548538,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16365991036097208,
      "backward_entropy": 0.010854097455739975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004988085478544235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02599957212805748,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16359456380208334,
      "backward_entropy": 0.010842646658420562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005896120797842741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02600056491792202,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16353008151054382,
      "backward_entropy": 0.010831918567419052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004261338617652655,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026001635938882828,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16346609592437744,
      "backward_entropy": 0.013055652379989624,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004238623660057783,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026002611964941025,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16340333223342896,
      "backward_entropy": 0.013050538301467896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004280556924641132,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02600349299609661,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1633416215578715,
      "backward_entropy": 0.016831997036933898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004699122626334429,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026004308834671974,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16328084468841553,
      "backward_entropy": 0.010791294276714325,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0043939887546002865,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026005128398537636,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16322070360183716,
      "backward_entropy": 0.01303744912147522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0045146094635128975,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026005923748016357,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16316119829813638,
      "backward_entropy": 0.016826933622360228,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004450127948075533,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026006771251559258,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1631022890408834,
      "backward_entropy": 0.010763435810804366,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003788234433159232,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026007656008005142,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16304381688435873,
      "backward_entropy": 0.010753895342350005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003677070140838623,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260084830224514,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1629860798517863,
      "backward_entropy": 0.010744762420654298,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0037196374032646418,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02600931189954281,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16292917728424072,
      "backward_entropy": 0.010735725611448288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028688430320471525,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026010185480117798,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1628731687863668,
      "backward_entropy": 0.013009993731975556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003168894210830331,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026010975241661072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16281837224960327,
      "backward_entropy": 0.010717859119176864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003159095998853445,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026011714711785316,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16276437044143677,
      "backward_entropy": 0.010709527134895324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029191356152296066,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026012452319264412,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16271118323008218,
      "backward_entropy": 0.012997885048389436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0026718403678387403,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026013141497969627,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16265871127446493,
      "backward_entropy": 0.010693396627902984,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022277680691331625,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026013797149062157,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16260715325673422,
      "backward_entropy": 0.01068577915430069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028496733866631985,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02601437084376812,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16255674759546915,
      "backward_entropy": 0.012987738847732544,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002322444226592779,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026014987379312515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1625069280465444,
      "backward_entropy": 0.012984538078308105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002694668248295784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02601557783782482,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16245810190836588,
      "backward_entropy": 0.010664460062980653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002114264527335763,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026016198098659515,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1624098022778829,
      "backward_entropy": 0.012978246808052063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021385187283158302,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02601676806807518,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16236243645350137,
      "backward_entropy": 0.01680256426334381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002078189980238676,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0260173287242651,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16231591502825418,
      "backward_entropy": 0.012972453236579895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0018293977482244372,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02601783163845539,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1622700293858846,
      "backward_entropy": 0.010637550055980683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0022305301390588284,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026018252596259117,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16222486893335977,
      "backward_entropy": 0.010631763935089111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002062076237052679,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02601872943341732,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16218021512031555,
      "backward_entropy": 0.012965093553066253,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019306869944557548,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02601923979818821,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1621360977490743,
      "backward_entropy": 0.012962345778942109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001517687225714326,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026019763201475143,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16209260622660318,
      "backward_entropy": 0.016799116134643556,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016900893533602357,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02602020651102066,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16204998890558878,
      "backward_entropy": 0.012957064807415009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014717726735398173,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026020634919404984,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16200804710388184,
      "backward_entropy": 0.010602068901062012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001466550980694592,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026021063327789307,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16196703910827637,
      "backward_entropy": 0.010596570372581483,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013375114649534225,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602146752178669,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16192669669787088,
      "backward_entropy": 0.01059129536151886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013478788314387202,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602185495197773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16188720862070718,
      "backward_entropy": 0.010586180537939072,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001288319705054164,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026022255420684814,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16184847553571066,
      "backward_entropy": 0.01058104932308197,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001144368783570826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02602263167500496,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16181039810180664,
      "backward_entropy": 0.012944279611110688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013635867508128285,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026022979989647865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16177315513292947,
      "backward_entropy": 0.010571440309286117,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013347381027415395,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026023337617516518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16173632939656576,
      "backward_entropy": 0.010566704720258713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009509245865046978,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026023751124739647,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16170001029968262,
      "backward_entropy": 0.010561689734458923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012030720245093107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026024105027318,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1616645554701487,
      "backward_entropy": 0.010557049512863159,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010462850332260132,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026024479418992996,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16162954767545065,
      "backward_entropy": 0.01293460875749588,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010312661761417985,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026024838909506798,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.161595086256663,
      "backward_entropy": 0.01679559350013733,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008478201925754547,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026025211438536644,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1615611712137858,
      "backward_entropy": 0.012930600345134735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009627668187022209,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026025567203760147,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16152803103129068,
      "backward_entropy": 0.01053878217935562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008407028508372605,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026025943458080292,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16149542729059854,
      "backward_entropy": 0.01053427904844284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007281163707375526,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026026293635368347,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16146339972813925,
      "backward_entropy": 0.010529989749193192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008215404232032597,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602660097181797,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1614320476849874,
      "backward_entropy": 0.010525967180728912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007393701816909015,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602691948413849,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16140125195185342,
      "backward_entropy": 0.010521940886974335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007601133547723293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02602722868323326,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16137105226516724,
      "backward_entropy": 0.016792820394039155,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006124185747466981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602757140994072,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16134148836135864,
      "backward_entropy": 0.01051393747329712,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006300172535702586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602788433432579,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1613125999768575,
      "backward_entropy": 0.01051008552312851,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000686011160723865,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602817490696907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16128426790237427,
      "backward_entropy": 0.010506382584571839,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006101385806687176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026028480380773544,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16125633319218954,
      "backward_entropy": 0.012913268804550172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005734419100917876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02602878212928772,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16122889518737793,
      "backward_entropy": 0.010498952120542526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004782320756930858,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026029080152511597,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1612019737561544,
      "backward_entropy": 0.01049533486366272,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005170924705453217,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026029353961348534,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16117572784423828,
      "backward_entropy": 0.010491897910833358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004698331467807293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026029637083411217,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1611500382423401,
      "backward_entropy": 0.010488466918468475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004931436851620674,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026029901579022408,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16112488508224487,
      "backward_entropy": 0.01678861826658249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00045395572669804096,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026030171662569046,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16110015908877054,
      "backward_entropy": 0.01048188954591751,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003929455124307424,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026030438020825386,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16107592980066934,
      "backward_entropy": 0.010478655993938445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004264796734787524,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026030678302049637,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16105223695437113,
      "backward_entropy": 0.016787320375442505,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003643043164629489,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603091299533844,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16102896134058634,
      "backward_entropy": 0.0104726143181324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00035507589927874506,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026031123474240303,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16100617249806723,
      "backward_entropy": 0.010469785332679749,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034128010156564415,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603132091462612,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16098385055859885,
      "backward_entropy": 0.016786856949329375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00031209870940074325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603152208030224,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1609620451927185,
      "backward_entropy": 0.010464402288198471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029240603907965124,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603171207010746,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1609407365322113,
      "backward_entropy": 0.012896695733070373,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030051698558963835,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026031892746686935,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16091994444529215,
      "backward_entropy": 0.010459324717521668,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003088673984166235,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026032067835330963,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16089961926142374,
      "backward_entropy": 0.010456889867782593,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003040973097085953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026032257825136185,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16087965170542398,
      "backward_entropy": 0.01289413422346115,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002802158996928483,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260324589908123,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1608600616455078,
      "backward_entropy": 0.010451877117156982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00029488143627531826,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026032663881778717,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16084078947703043,
      "backward_entropy": 0.012892141938209534,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002454703499097377,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603289484977722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16082181533177695,
      "backward_entropy": 0.012890933454036713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00018842503777705133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603311836719513,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16080323855082193,
      "backward_entropy": 0.010444158315658569,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002187138015870005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026033317670226097,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16078516840934753,
      "backward_entropy": 0.010441792011260987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00021955149713903666,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026033513247966766,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16076751550038657,
      "backward_entropy": 0.010439439862966537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020160932035651058,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026033708825707436,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16075019041697183,
      "backward_entropy": 0.010437137633562087,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002056356897810474,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026033906266093254,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16073325276374817,
      "backward_entropy": 0.012885892391204834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017198002024088055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603410743176937,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16071665287017822,
      "backward_entropy": 0.016781684756278992,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001590647443663329,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260342787951231,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1607003410657247,
      "backward_entropy": 0.01043042093515396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001795854332158342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026034437119960785,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16068447629610697,
      "backward_entropy": 0.01042841449379921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016635199426673353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026034606620669365,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16066884994506836,
      "backward_entropy": 0.01042635440826416,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015025025641079992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026034774258732796,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16065351168314615,
      "backward_entropy": 0.012881520390510558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001381588663207367,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603493630886078,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16063851118087769,
      "backward_entropy": 0.010422400385141372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011346942483214661,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026035089045763016,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1606238385041555,
      "backward_entropy": 0.010420508682727814,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001251134235644713,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026035215705633163,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1606095532576243,
      "backward_entropy": 0.010418781638145446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010800825839396566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026035336777567863,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1605955958366394,
      "backward_entropy": 0.016779708862304687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012285025150049478,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026035433635115623,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16058198610941568,
      "backward_entropy": 0.010415609925985336,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010185852443100885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026035549119114876,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16056866447130838,
      "backward_entropy": 0.01287766993045807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011090334737673402,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026035655289888382,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16055570046106973,
      "backward_entropy": 0.016779690980911255,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011762930080294609,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026035768911242485,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16054295500119528,
      "backward_entropy": 0.016779589653015136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010123044194187969,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026035895571112633,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16053041815757751,
      "backward_entropy": 0.01040937751531601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.337104711448774e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026036029681563377,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16051814953486124,
      "backward_entropy": 0.01677909791469574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.363923214143142e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026036158204078674,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1605061093966166,
      "backward_entropy": 0.016778846085071564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.909815030870959e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603626810014248,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1604943871498108,
      "backward_entropy": 0.012874101102352143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.271718252217397e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026036368682980537,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604829728603363,
      "backward_entropy": 0.010403413325548172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.44355857023038e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026036467403173447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16047175725301108,
      "backward_entropy": 0.010402059555053711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.855341052869335e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026036551222205162,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16046077013015747,
      "backward_entropy": 0.010400811582803727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.605309343081899e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603662945330143,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604500412940979,
      "backward_entropy": 0.010399600863456726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.9910515119554475e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260367002338171,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16043963034947714,
      "backward_entropy": 0.010398486256599426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.502946441993117e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026036765426397324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16042945782343546,
      "backward_entropy": 0.010397392511367797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.04658164572902e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260368213057518,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16041954358418783,
      "backward_entropy": 0.010396379232406616,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.853711652685888e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603686787188053,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16040988763173422,
      "backward_entropy": 0.010395438224077225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.974985495209694e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603689767420292,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1604004700978597,
      "backward_entropy": 0.010394583642482757,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.145973773323931e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026036931201815605,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16039127111434937,
      "backward_entropy": 0.012870971858501435,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.79573170398362e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603697031736374,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16038228074709573,
      "backward_entropy": 0.010392904281616211,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.435645678313449e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037024334073067,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16037340958913168,
      "backward_entropy": 0.010391955077648164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.493188341963105e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026037072762846947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16036472717920938,
      "backward_entropy": 0.012870341539382935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.617855691118166e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603711374104023,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603563129901886,
      "backward_entropy": 0.010390254855155944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.825887688435614e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026037154719233513,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16034811735153198,
      "backward_entropy": 0.012869997322559357,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.8013495213817805e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037203148007393,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16034011046091715,
      "backward_entropy": 0.010388614237308502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2662403100403026e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603725530207157,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16033230225245157,
      "backward_entropy": 0.012869518995285035,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.588645995478146e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026037313044071198,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1603247125943502,
      "backward_entropy": 0.012869259715080262,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9404449378489517e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037368923425674,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16031724214553833,
      "backward_entropy": 0.010386084020137788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.059597293031402e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037419214844704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1603099505106608,
      "backward_entropy": 0.010385265201330185,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7038962798542343e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026037465780973434,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16030283768971762,
      "backward_entropy": 0.012868496775627136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3505694116465747e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037516072392464,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1602958838144938,
      "backward_entropy": 0.0103837288916111,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7847272576764226e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037560775876045,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16028912862141928,
      "backward_entropy": 0.010383012890815734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1173651475692168e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026037603616714478,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16028249263763428,
      "backward_entropy": 0.012867794930934906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3807693651178852e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603764273226261,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16027605533599854,
      "backward_entropy": 0.010381616652011871,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9192599211237393e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026037681847810745,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1602697471777598,
      "backward_entropy": 0.012867432832717896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.212244908150751e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603771910071373,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1602636178334554,
      "backward_entropy": 0.016782137751579284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.103093902405817e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026037754490971565,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.160257617632548,
      "backward_entropy": 0.01678224802017212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7164662494906224e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260377898812294,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1602517565091451,
      "backward_entropy": 0.01037917211651802,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7105217921198346e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037827134132385,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1602460741996765,
      "backward_entropy": 0.010378552973270417,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.879029514384456e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026037858799099922,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16024050116539001,
      "backward_entropy": 0.016782599687576293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3604193554783706e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026037894189357758,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16023505727450052,
      "backward_entropy": 0.016782690584659577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.607293052074965e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026037931442260742,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1602297822634379,
      "backward_entropy": 0.010376871377229691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6664476788719185e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603796124458313,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16022459665934244,
      "backward_entropy": 0.010376330465078354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6292106010951102e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026037998497486115,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160219540198644,
      "backward_entropy": 0.012865735590457917,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5104987141967285e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026038043200969696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16021455327669779,
      "backward_entropy": 0.01678290069103241,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3211120858613867e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038099080324173,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1602096954981486,
      "backward_entropy": 0.010374511033296585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2476388292270713e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0260381530970335,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1602049469947815,
      "backward_entropy": 0.012864840030670167,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.913725989463273e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603820338845253,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16020027796427408,
      "backward_entropy": 0.010373270511627198,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0487949111848138e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038244366645813,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16019574801127115,
      "backward_entropy": 0.010372719168663025,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0615614883136004e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038283482193947,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1601913571357727,
      "backward_entropy": 0.01286405473947525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.717405191622674e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603832446038723,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16018704573313394,
      "backward_entropy": 0.012863807380199432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.802271051739808e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038363575935364,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1601828634738922,
      "backward_entropy": 0.012863557040691375,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.432469257968478e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260383989661932,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1601787507534027,
      "backward_entropy": 0.010370639711618423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.39159804652445e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026038428768515587,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1601747473080953,
      "backward_entropy": 0.016782723367214203,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.546942470071372e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038460433483124,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16017083326975504,
      "backward_entropy": 0.010369732975959778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.528599326178664e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038488373160362,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16016703844070435,
      "backward_entropy": 0.012862743437290191,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.001205176493386e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603852190077305,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16016334295272827,
      "backward_entropy": 0.010368864238262176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.921855972701451e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038551703095436,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1601597269376119,
      "backward_entropy": 0.012862366437911988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.620835054287454e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038579642772675,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1601562201976776,
      "backward_entropy": 0.010368016362190247,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.232862804405158e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038603857159615,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16015283266703287,
      "backward_entropy": 0.01036764532327652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.405777756095631e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038629934191704,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16014953454335532,
      "backward_entropy": 0.010367245227098466,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.444493126560701e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038654148578644,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16014633576075235,
      "backward_entropy": 0.010366882383823394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.918591002933681e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038678362965584,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1601431965827942,
      "backward_entropy": 0.010366501659154892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.067262009106344e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038704439997673,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1601401368776957,
      "backward_entropy": 0.010366147756576538,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.735918082587887e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038728654384613,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16013713677724203,
      "backward_entropy": 0.012861251831054688,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.961980382882757e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038752868771553,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1601341962814331,
      "backward_entropy": 0.0103654645383358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7172412703512236e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026038773357868195,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1601313352584839,
      "backward_entropy": 0.016783179342746736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.878873940266203e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038791984319687,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16012857357660928,
      "backward_entropy": 0.010364823043346405,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2102514069265453e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603881061077118,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16012587149937949,
      "backward_entropy": 0.01036451682448387,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4657870199007448e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038827374577522,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16012324889500937,
      "backward_entropy": 0.010364242643117905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9912971513113007e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038844138383865,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16012072563171387,
      "backward_entropy": 0.010363953560590744,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7745074930862756e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603885903954506,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16011824210484824,
      "backward_entropy": 0.0167834609746933,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.846683855750598e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038873940706253,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16011585791905722,
      "backward_entropy": 0.01286030411720276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4510495677532163e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038888841867447,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16011353333791098,
      "backward_entropy": 0.010363183915615082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3426205189025495e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603890374302864,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16011128822962442,
      "backward_entropy": 0.010362952947616577,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.765991439446225e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038918644189835,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16010908285776773,
      "backward_entropy": 0.012860022485256195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1302396362443687e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603893168270588,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1601069172223409,
      "backward_entropy": 0.010362483561038971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2984770566836232e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038944721221924,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16010480125745138,
      "backward_entropy": 0.010362254828214646,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9462606815068284e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603895775973797,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16010274489720663,
      "backward_entropy": 0.016783832013607024,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5059348470458644e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026038970798254013,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16010072827339172,
      "backward_entropy": 0.010361816734075546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7402355751983123e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603898011147976,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16009879112243652,
      "backward_entropy": 0.010361617058515548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8305348703506752e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026038991287350655,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16009689370791116,
      "backward_entropy": 0.01285954862833023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4338450000650482e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603899873793125,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600950558980306,
      "backward_entropy": 0.016784104704856872,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2872102388428175e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603900618851185,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16009326775868735,
      "backward_entropy": 0.010361069440841674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3614361478175852e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039013639092445,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16009153922398886,
      "backward_entropy": 0.012859389185905457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1087911389040528e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603902295231819,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16008985042572021,
      "backward_entropy": 0.010360728204250335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.195364234263252e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603903040289879,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16008822123209634,
      "backward_entropy": 0.010360552370548249,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0737296634033555e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039037853479385,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600866218407949,
      "backward_entropy": 0.012859228253364562,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0323805099687888e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039043441414833,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16008508205413818,
      "backward_entropy": 0.010360270738601685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.138729885497014e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603905089199543,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16008357206980386,
      "backward_entropy": 0.012859128415584564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.89183525032422e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039056479930878,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16008211175600687,
      "backward_entropy": 0.012859097123146057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0182330925090355e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039062067866325,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600806713104248,
      "backward_entropy": 0.010359851270914077,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.077372856656439e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039067655801773,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16007926066716513,
      "backward_entropy": 0.010359703749418258,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.585883506384562e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603907324373722,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16007791956265768,
      "backward_entropy": 0.012858973443508148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.304161613319593e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603907883167267,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16007659832636514,
      "backward_entropy": 0.016784831881523132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.313819878618233e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039084419608116,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600753366947174,
      "backward_entropy": 0.010359329730272293,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.119431870705739e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039090007543564,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16007409493128458,
      "backward_entropy": 0.016784942150115965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.648515977758507e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039093732833862,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16007287303606668,
      "backward_entropy": 0.010359101742506028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.354758284032869e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603909745812416,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16007169087727866,
      "backward_entropy": 0.01035899817943573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.138300818747666e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603909932076931,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.160070538520813,
      "backward_entropy": 0.012858781218528747,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.993244371893525e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603910304605961,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16006940603256226,
      "backward_entropy": 0.010358791798353195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.399872406997019e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039104908704758,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16006832321484885,
      "backward_entropy": 0.010358695685863496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.034134460402129e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039106771349907,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600672403971354,
      "backward_entropy": 0.010358595848083496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.858364377469115e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039108633995056,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16006620724995932,
      "backward_entropy": 0.010358531773090363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0863127992452064e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039112359285355,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16006519397099814,
      "backward_entropy": 0.010358437895774841,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1326817406807095e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039117947220802,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16006420056025186,
      "backward_entropy": 0.010358338057994843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9362598158732e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603912353515625,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16006324688593546,
      "backward_entropy": 0.012858572602272033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4223151007827255e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039130985736847,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16006233294804892,
      "backward_entropy": 0.0128585085272789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.418572305236012e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039136573672295,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600614388783773,
      "backward_entropy": 0.012858475744724273,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4701497497735545e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039142161607742,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16006057461102804,
      "backward_entropy": 0.016785618662834168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3605434168748616e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603914774954319,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600597103436788,
      "backward_entropy": 0.010357829928398132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3735016441150947e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039153337478638,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16005889574686685,
      "backward_entropy": 0.010357752442359924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8062277124263346e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039158925414085,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16005808115005493,
      "backward_entropy": 0.012858296930789947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2276192623849056e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039164513349533,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16005730628967285,
      "backward_entropy": 0.012858261168003083,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.338393585432641e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603917010128498,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600565711657206,
      "backward_entropy": 0.016785728931427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9324808420151385e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603917568922043,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16005584597587585,
      "backward_entropy": 0.010357389599084854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0197316530357057e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039179414510727,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16005513072013855,
      "backward_entropy": 0.010357330739498138,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.509084708890441e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039183139801025,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16005444526672363,
      "backward_entropy": 0.016785797476768494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7302524213391735e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039186865091324,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16005377968152365,
      "backward_entropy": 0.010357198864221573,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8554317193775205e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039190590381622,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16005313396453857,
      "backward_entropy": 0.010357125103473664,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7460715184824949e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603919431567192,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16005249818166098,
      "backward_entropy": 0.012858037650585175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3956621103261568e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603919804096222,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600518822669983,
      "backward_entropy": 0.016785913705825807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7698087617645797e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039201766252518,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16005130608876547,
      "backward_entropy": 0.016785928606987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2771400292876933e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039203628897667,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16005072991053262,
      "backward_entropy": 0.010356901586055756,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2899407408895058e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039205491542816,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600501537322998,
      "backward_entropy": 0.016786018013954164,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2973630703072558e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039207354187965,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600495974222819,
      "backward_entropy": 0.010356801003217697,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1467268734577374e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039209216833115,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600490709145864,
      "backward_entropy": 0.010356765985488892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.326045691030231e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039211079478264,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600485642751058,
      "backward_entropy": 0.01678615212440491,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0020619356509997e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039212942123413,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600480576356252,
      "backward_entropy": 0.01035667210817337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.61125926121531e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039214804768562,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.160047580798467,
      "backward_entropy": 0.010356617718935012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.445868360240638e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603921666741371,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16004711389541626,
      "backward_entropy": 0.012857845425605774,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.517295586012551e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603921853005886,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.160046656926473,
      "backward_entropy": 0.01035655289888382,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.208630847799213e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603922039270401,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004621982574463,
      "backward_entropy": 0.010356488823890685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.303909654865492e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603922225534916,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600458025932312,
      "backward_entropy": 0.01678631007671356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.889994625363215e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02603922411799431,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600454052289327,
      "backward_entropy": 0.010356399416923522,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.436481925220505e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039225980639458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600450078646342,
      "backward_entropy": 0.010356377065181731,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.555431752985896e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039227843284607,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004463036855063,
      "backward_entropy": 0.010356341302394868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.584811984566841e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039229705929756,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004425287246704,
      "backward_entropy": 0.010356292873620988,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.604938107557246e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039231568574905,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600438952445984,
      "backward_entropy": 0.010356267541646957,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.205996072594644e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039233431220055,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16004353761672974,
      "backward_entropy": 0.012857690453529358,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.505267625631859e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039235293865204,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16004319985707602,
      "backward_entropy": 0.016786491870880126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.6258040953262025e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039237156510353,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16004286209742227,
      "backward_entropy": 0.012857671082019805,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.653750013654644e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039239019155502,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004255414009094,
      "backward_entropy": 0.01035614162683487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.41680789720067e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603924088180065,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600422461827596,
      "backward_entropy": 0.016786572337150574,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.56584601238319e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600419282913208,
      "backward_entropy": 0.010356077551841735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.028392552868354e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004165013631186,
      "backward_entropy": 0.010356054455041886,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7487200899022355e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16004136204719543,
      "backward_entropy": 0.012857602536678314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.811912918649796e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600410838921865,
      "backward_entropy": 0.01035601943731308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.99314990570565e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.160040815671285,
      "backward_entropy": 0.010356003791093827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.282618621369693e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004055738449097,
      "backward_entropy": 0.010355961322784425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7742951047571296e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16004029909769693,
      "backward_entropy": 0.016786746680736542,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.93441644316772e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16004005074501038,
      "backward_entropy": 0.010355928540229797,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.967835044387357e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003980239232382,
      "backward_entropy": 0.016786779463291168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.999339360736485e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003957390785217,
      "backward_entropy": 0.012857547402381897,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2709684799337992e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003936529159546,
      "backward_entropy": 0.010355883836746215,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2860161763560427e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003912687301636,
      "backward_entropy": 0.010355841368436813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9174766663354603e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003891825675964,
      "backward_entropy": 0.01035582199692726,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.781025638081246e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392427444458,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003870964050293,
      "backward_entropy": 0.010355812311172486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4787694624374126e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02603924460709095,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003851095835367,
      "backward_entropy": 0.012857483327388763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3369145790420589e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0260392464697361,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003831227620444,
      "backward_entropy": 0.010355777293443679,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5127710639717407e-08,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02603924833238125,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.1600381334622701,
      "backward_entropy": 0.016786934435367586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5835212252568454e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039250195026398,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600379745165507,
      "backward_entropy": 0.010355728864669799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2965898577022017e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039252057671547,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003777583440146,
      "backward_entropy": 0.010355710983276367,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4653437574452255e-08,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003761688868204,
      "backward_entropy": 0.010355697572231292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.51689208047901e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600374380747477,
      "backward_entropy": 0.012857428193092347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2714984620743053e-08,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003729899724325,
      "backward_entropy": 0.01285742074251175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.073556045928854e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003714005152384,
      "backward_entropy": 0.012857389450073243,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.15173359317123e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003701090812683,
      "backward_entropy": 0.01035563051700592,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.759219210536685e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600368618965149,
      "backward_entropy": 0.010355624556541442,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.715591721080273e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600367228190104,
      "backward_entropy": 0.012857374548912049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.795289664296433e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003660360972086,
      "backward_entropy": 0.016787052154541016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41331626588726e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600364844004313,
      "backward_entropy": 0.010355591773986816,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.454619949636253e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600363552570343,
      "backward_entropy": 0.012857355177402496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.726857293415378e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600362459818522,
      "backward_entropy": 0.010355564951896667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.823889009410777e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003612677256265,
      "backward_entropy": 0.01035556048154831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.3409294764605875e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003601749738058,
      "backward_entropy": 0.010355553030967713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.969642640797247e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003592809041342,
      "backward_entropy": 0.016787117719650267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.343338216334814e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003582874933878,
      "backward_entropy": 0.01285732388496399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.460766144300578e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003572940826416,
      "backward_entropy": 0.01285731941461563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.54282655937277e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003562013308206,
      "backward_entropy": 0.010355497896671294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6285712212702492e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003552079200745,
      "backward_entropy": 0.01035548821091652,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.210789938952075e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003543138504028,
      "backward_entropy": 0.016787153482437134,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.568889266920451e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003533204396567,
      "backward_entropy": 0.012857270240783692,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.882338089373661e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003525257110596,
      "backward_entropy": 0.010355465859174729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.830166406260105e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600351631641388,
      "backward_entropy": 0.012857267260551452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6596574659597536e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003509362538657,
      "backward_entropy": 0.012857258319854736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1307791914514382e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600350042184194,
      "backward_entropy": 0.010355447232723237,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9623095088027185e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600349247455597,
      "backward_entropy": 0.01285725086927414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.849716906894173e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003485520680746,
      "backward_entropy": 0.016787214577198027,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1855299792150618e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003477573394775,
      "backward_entropy": 0.01285724639892578,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.663050224782637e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003471612930298,
      "backward_entropy": 0.010355397313833236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9146178803785006e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003464659055075,
      "backward_entropy": 0.012857238948345184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7509656774782343e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600345770517985,
      "backward_entropy": 0.010355385392904282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.929642223785777e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003451744715372,
      "backward_entropy": 0.016787244379520415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.258325082493684e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.1600344479084015,
      "backward_entropy": 0.012857219576835633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1431105778901838e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003439823786417,
      "backward_entropy": 0.012857219576835633,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5361791838586214e-09,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 0,
      "forward_entropy": 0.16003432869911194,
      "backward_entropy": 0.016787272691726685,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6316406004079909e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003427902857462,
      "backward_entropy": 0.01035536602139473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5543264453299344e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.1600342094898224,
      "backward_entropy": 0.010355359315872193,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.21740129088721e-09,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 1,
      "forward_entropy": 0.16003415981928507,
      "backward_entropy": 0.012857182323932648,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.290310081003554e-09,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026039253920316696,
      "trajectory_length": 7,
      "branch_chosen": 2,
      "forward_entropy": 0.16003412008285522,
      "backward_entropy": 0.010355352610349654,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 8.939898522797307e-08,
    "avg_log_Z": 0.026039223447442056,
    "success_rate": 1.0,
    "avg_reward": 44.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.19,
      "1": 0.28,
      "2": 0.53
    },
    "avg_forward_entropy": 0.16004369219144185,
    "avg_backward_entropy": 0.012278432555496694,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}