{
  "metrics_history": [
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 0.4666666666666667
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 0.7333333333333333
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891632625034877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09891943420682635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.099167823791504,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731591403484344,
      "backward_entropy": 0.09885413306100028,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.20003890991211,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00010000000474974513,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731707632541656,
      "backward_entropy": 0.09891210283551898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.72220230102539,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00020001796656288207,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373182088136673,
      "backward_entropy": 0.09884045805249896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.454975128173828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0002999376447405666,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731922209262848,
      "backward_entropy": 0.09890638930456978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.610383033752441,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00039975333493202925,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373201310634613,
      "backward_entropy": 0.09882589748927526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.974555969238281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0004995386698283255,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13732093572616577,
      "backward_entropy": 0.09881860869271415,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.708178520202637,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0005994021776132286,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732163608074188,
      "backward_entropy": 0.0988914966583252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.071453094482422,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00069925602292642,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732226192951202,
      "backward_entropy": 0.0988862259047372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.33477783203125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0007992048049345613,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373228132724762,
      "backward_entropy": 0.09879592486790248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.690632820129395,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0008990096393972635,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.137323260307312,
      "backward_entropy": 0.0988743645804269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.223811149597168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0009990909602493048,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13732361793518066,
      "backward_entropy": 0.09877991676330566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.11593246459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.001098948298022151,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13732387125492096,
      "backward_entropy": 0.09877158062798637,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.946949005126953,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0011985839810222387,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1373240053653717,
      "backward_entropy": 0.09885799884796143,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.838186264038086,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0012983210617676377,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13732407987117767,
      "backward_entropy": 0.09875404834747314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.47037124633789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.001398098305799067,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373240351676941,
      "backward_entropy": 0.09884442601885114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.676592826843262,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0014977875398471951,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732390105724335,
      "backward_entropy": 0.09884021963391985,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.325967788696289,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0015974938869476318,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732369244098663,
      "backward_entropy": 0.09883396966116768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.839493751525879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00169674726203084,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732343912124634,
      "backward_entropy": 0.09882725136620658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.40912914276123,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0017957888776436448,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13732309639453888,
      "backward_entropy": 0.09881994553974696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.748734474182129,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0018948809010908008,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732272386550903,
      "backward_entropy": 0.09880787134170532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.38260269165039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0019944789819419384,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732227683067322,
      "backward_entropy": 0.09879995243889945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.550996780395508,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.002094381023198366,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13732177019119263,
      "backward_entropy": 0.09867320741925921,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.931059837341309,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0021942334715276957,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1373211294412613,
      "backward_entropy": 0.09866201877593994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.778166770935059,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0022938214242458344,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13732042908668518,
      "backward_entropy": 0.09877490145819527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.259976387023926,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0023931446485221386,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731969892978668,
      "backward_entropy": 0.09876587561198644,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.360600471496582,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0024927742779254913,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731884956359863,
      "backward_entropy": 0.09876021317073277,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.13002872467041,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0025927177630364895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731792569160461,
      "backward_entropy": 0.09875047206878662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.529091835021973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002692481270059943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731694221496582,
      "backward_entropy": 0.09873579229627337,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.778412818908691,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002792214509099722,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731583952903748,
      "backward_entropy": 0.0987250804901123,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.447159767150879,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.002892010146752,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1373145878314972,
      "backward_entropy": 0.09871399402618408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.084988594055176,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0029921550303697586,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13731323182582855,
      "backward_entropy": 0.0987084252493722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.975364685058594,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003092462196946144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13731178641319275,
      "backward_entropy": 0.09869035652705602,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.01195240020752,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.003192856442183256,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13731026649475098,
      "backward_entropy": 0.09853267669677734,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.17647647857666,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0032933088950812817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13730855286121368,
      "backward_entropy": 0.09867383752550397,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.105504035949707,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00339393294416368,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13730677962303162,
      "backward_entropy": 0.09850460290908813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.10232162475586,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.003494265954941511,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730503618717194,
      "backward_entropy": 0.09863663571221488,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.453694343566895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0035943416878581047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730333745479584,
      "backward_entropy": 0.09862215178353446,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.302413940429688,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0036943398881703615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13730157911777496,
      "backward_entropy": 0.0986072335924421,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.446353912353516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0037946042139083147,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729968667030334,
      "backward_entropy": 0.09859189816883632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.73621654510498,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00389476353302598,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13729776442050934,
      "backward_entropy": 0.09842813866479057,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.725244522094727,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0039945244789123535,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372958868741989,
      "backward_entropy": 0.09858132260186332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.38748550415039,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004094317555427551,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13729381561279297,
      "backward_entropy": 0.0985666002546038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.783306121826172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004194458946585655,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13729164004325867,
      "backward_entropy": 0.09852571146828788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.97143268585205,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004294658079743385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372893750667572,
      "backward_entropy": 0.09850787264960152,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.879310607910156,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004394540563225746,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728712499141693,
      "backward_entropy": 0.09848942926951818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.612934112548828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00449456786736846,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13728481531143188,
      "backward_entropy": 0.09847050053732735,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69807243347168,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004595009610056877,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13728231191635132,
      "backward_entropy": 0.09829800469534737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.39255428314209,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004695391282439232,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13727962970733643,
      "backward_entropy": 0.09846877200262887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.162764549255371,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.004796027671545744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13727670907974243,
      "backward_entropy": 0.09841009548732213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.752118110656738,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.004896398168057203,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372738629579544,
      "backward_entropy": 0.09843224287033081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.339679718017578,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.004996786825358868,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372709572315216,
      "backward_entropy": 0.0982119015284947,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.37748384475708,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005097443703562021,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13726790249347687,
      "backward_entropy": 0.09818923473358154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.120609283447266,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005197039805352688,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13726533949375153,
      "backward_entropy": 0.09832162516457695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.733652114868164,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0052968780510127544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1372624635696411,
      "backward_entropy": 0.09835326671600342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.659614562988281,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005396789871156216,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13725951313972473,
      "backward_entropy": 0.09811740262167794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.104613304138184,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005496686790138483,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13725638389587402,
      "backward_entropy": 0.0983107260295323,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.85732364654541,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005596787668764591,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372530162334442,
      "backward_entropy": 0.098223158291408,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.610785484313965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.005696967709809542,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13724949955940247,
      "backward_entropy": 0.09819654907499041,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.191396713256836,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005797116085886955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724589347839355,
      "backward_entropy": 0.09824303218296596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.704679489135742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.005897494498640299,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13724210858345032,
      "backward_entropy": 0.09821893487657819,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.28465461730957,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.005997873842716217,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1372382640838623,
      "backward_entropy": 0.09795715979167394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.56106185913086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006098009645938873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13723431527614594,
      "backward_entropy": 0.09816881588527135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.717906951904297,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006197621580213308,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1372305005788803,
      "backward_entropy": 0.09805241652897426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.445642471313477,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006297800689935684,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722646236419678,
      "backward_entropy": 0.09811607428959437,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.948375701904297,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.006397895514965057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13722246885299683,
      "backward_entropy": 0.09808874130249023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.49726676940918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0064980946481227875,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13721820712089539,
      "backward_entropy": 0.09795675107410975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.009349822998047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0065981606021523476,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13721373677253723,
      "backward_entropy": 0.0980322275842939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.84876823425293,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006698412820696831,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720917701721191,
      "backward_entropy": 0.09774138246263776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.94351863861084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006798298563808203,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720488548278809,
      "backward_entropy": 0.09770784207752772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.415987968444824,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.006898790132254362,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13720010221004486,
      "backward_entropy": 0.09767368861607142,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.824346542358398,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.006999148987233639,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371954083442688,
      "backward_entropy": 0.09778296947479248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.872983455657959,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007099993526935577,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13719022274017334,
      "backward_entropy": 0.09760337216513497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.283124923706055,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007199850864708424,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13718529045581818,
      "backward_entropy": 0.09756662164415632,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.981531143188477,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007300089113414288,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371803730726242,
      "backward_entropy": 0.09752961567470006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.313408851623535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007399961352348328,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13717547059059143,
      "backward_entropy": 0.09762823581695557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.96110725402832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007499671541154385,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1371704787015915,
      "backward_entropy": 0.09745258944375175,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.198633193969727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0075985705479979515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716578483581543,
      "backward_entropy": 0.09754528318132673,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.631922721862793,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007697349414229393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13716094195842743,
      "backward_entropy": 0.09750229971749443,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.368331909179688,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0077962493523955345,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1371559053659439,
      "backward_entropy": 0.0976245743887765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.69776725769043,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.007895177230238914,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13715095818042755,
      "backward_entropy": 0.09741316522870745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.071578979492188,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.007994295097887516,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13714599609375,
      "backward_entropy": 0.0972424064363752,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.04575252532959,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00809319969266653,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13714087009429932,
      "backward_entropy": 0.09731996059417725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 11.037006378173828,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00819292850792408,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13713516294956207,
      "backward_entropy": 0.09727144241333008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.547941207885742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008293386548757553,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13712893426418304,
      "backward_entropy": 0.09741643496922084,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.457296371459961,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.00839281640946865,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13712359964847565,
      "backward_entropy": 0.0970599821635655,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.475388526916504,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008492738008499146,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371181160211563,
      "backward_entropy": 0.097119859286717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.657855033874512,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008592572994530201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13711214065551758,
      "backward_entropy": 0.0972801787512643,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.564485549926758,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008691982366144657,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1371064931154251,
      "backward_entropy": 0.09701390777315412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.977797508239746,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008791420608758926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13710063695907593,
      "backward_entropy": 0.09695933546338763,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.313706398010254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.008890639990568161,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13709509372711182,
      "backward_entropy": 0.09690378393445696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.439879417419434,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.008990300819277763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370891034603119,
      "backward_entropy": 0.09708516938345772,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.412093162536621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.00908989179879427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13708287477493286,
      "backward_entropy": 0.0970339264188494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.856463432312012,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.009189444594085217,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13707639276981354,
      "backward_entropy": 0.09665368284497942,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.17218017578125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009289165027439594,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.137069433927536,
      "backward_entropy": 0.09666742597307477,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.492881774902344,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009388725273311138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13706256449222565,
      "backward_entropy": 0.09660506248474121,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.709610939025879,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009488306939601898,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1370556652545929,
      "backward_entropy": 0.0968172379902431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.947175979614258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009588006883859634,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13704852759838104,
      "backward_entropy": 0.09675986426217216,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.455449104309082,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009686934761703014,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13704213500022888,
      "backward_entropy": 0.09641060658863612,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.034045219421387,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.00978549849241972,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13703665137290955,
      "backward_entropy": 0.09634448800768171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.779747009277344,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.009883951395750046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13703109323978424,
      "backward_entropy": 0.09658076081957136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.891345024108887,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.009982702322304249,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13702517747879028,
      "backward_entropy": 0.0962057454245431,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.762511253356934,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010081754066050053,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13701874017715454,
      "backward_entropy": 0.09612512588500977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.42990779876709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010181033052504063,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13701209425926208,
      "backward_entropy": 0.09605797699519567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.288761138916016,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010280345566570759,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1370052993297577,
      "backward_entropy": 0.0959816575050354,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.66569995880127,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01038011908531189,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13699780404567719,
      "backward_entropy": 0.09593158108847481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.980131149291992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010479466989636421,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13699059188365936,
      "backward_entropy": 0.09618314674922399,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.870448112487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.010578598827123642,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13698339462280273,
      "backward_entropy": 0.0958005700792585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.706789016723633,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.010677470825612545,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369762122631073,
      "backward_entropy": 0.09566023520060948,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.955235481262207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010776571929454803,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.136968731880188,
      "backward_entropy": 0.09596538543701172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.788477897644043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010875475592911243,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13696128129959106,
      "backward_entropy": 0.09588961941855294,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.081476211547852,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.010974662378430367,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13695356249809265,
      "backward_entropy": 0.09581205674580165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.042059898376465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011073199100792408,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13694645464420319,
      "backward_entropy": 0.09544977119990758,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05078125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.011171207763254642,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13694052398204803,
      "backward_entropy": 0.09537649154663086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.082427024841309,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011268715374171734,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13693556189537048,
      "backward_entropy": 0.09557120289121356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.088233947753906,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011366785503923893,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692939281463623,
      "backward_entropy": 0.0954878670828683,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.127960205078125,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011465326882898808,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13692185282707214,
      "backward_entropy": 0.09540280273982457,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.017927169799805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.011563367210328579,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1369154453277588,
      "backward_entropy": 0.09485794816698347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.975287437438965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01166131254285574,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1369084119796753,
      "backward_entropy": 0.09522834845951625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.219791412353516,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011759224347770214,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13690131902694702,
      "backward_entropy": 0.0951387711933681,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.154658317565918,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.011856731958687305,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13689486682415009,
      "backward_entropy": 0.09504754202706474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.474766731262207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01195437740534544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13688835501670837,
      "backward_entropy": 0.09495425224304199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.348238945007324,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012052281759679317,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368812918663025,
      "backward_entropy": 0.09485901253564018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.551149368286133,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012150377035140991,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368740051984787,
      "backward_entropy": 0.09476202726364136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.783191680908203,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012248740531504154,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368662267923355,
      "backward_entropy": 0.09466302394866943,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.904144287109375,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012346996925771236,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368589848279953,
      "backward_entropy": 0.09437342200960432,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.106200218200684,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012445163913071156,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13685183227062225,
      "backward_entropy": 0.09391399792262486,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.749767303466797,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012543350458145142,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13684426248073578,
      "backward_entropy": 0.09379861184528895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.13623046875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012641828507184982,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368352174758911,
      "backward_entropy": 0.09424782650811332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.49072265625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.012739811092615128,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1368269920349121,
      "backward_entropy": 0.09413976328713554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.42464542388916,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.012837039306759834,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13682031631469727,
      "backward_entropy": 0.09344129051480975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.161510467529297,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.012934064492583275,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368139684200287,
      "backward_entropy": 0.09374092306409564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.861331939697266,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013031248934566975,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1368069350719452,
      "backward_entropy": 0.09362801483699254,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.812067031860352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013128967024385929,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13679896295070648,
      "backward_entropy": 0.0935128927230835,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.3162841796875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01322662178426981,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1367911994457245,
      "backward_entropy": 0.0935697044645037,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.804211616516113,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01332448422908783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13678282499313354,
      "backward_entropy": 0.09279836927141462,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.858407020568848,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013422233052551746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13677412271499634,
      "backward_entropy": 0.09315160342625209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.456687927246094,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.013519403524696827,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13676628470420837,
      "backward_entropy": 0.0925222294671195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.41075325012207,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01361638493835926,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13675858080387115,
      "backward_entropy": 0.092381409236363,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.830728530883789,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.013713245280086994,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13675165176391602,
      "backward_entropy": 0.09276872021811348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.929322242736816,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01381017081439495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13674448430538177,
      "backward_entropy": 0.09209396157945905,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.200611114501953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01390718761831522,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13673675060272217,
      "backward_entropy": 0.09250358172825404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.598958015441895,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014004472643136978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13672854006290436,
      "backward_entropy": 0.0925393956048148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 10.409075736999512,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014101635664701462,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13672012090682983,
      "backward_entropy": 0.09223355565752302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.965328216552734,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01419964712113142,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13670951128005981,
      "backward_entropy": 0.092096175466265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.434045791625977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014297676272690296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13669846951961517,
      "backward_entropy": 0.09211071048464094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.514973640441895,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014394913800060749,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366891860961914,
      "backward_entropy": 0.09115843261991229,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.244693756103516,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01449259277433157,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13667908310890198,
      "backward_entropy": 0.09099287646157402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.791054725646973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.014589888975024223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1366688758134842,
      "backward_entropy": 0.09082481690815516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.274234771728516,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01468721590936184,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13665859401226044,
      "backward_entropy": 0.09137310300554548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.462172508239746,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.014784297905862331,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13664887845516205,
      "backward_entropy": 0.09122100046702794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.075357437133789,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0148812560364604,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13663935661315918,
      "backward_entropy": 0.09030418736594063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.742243766784668,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.014977844431996346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13662999868392944,
      "backward_entropy": 0.09102928638458252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.71706485748291,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015074488706886768,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13662031292915344,
      "backward_entropy": 0.09074773107256208,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.413994789123535,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015171704813838005,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1366088092327118,
      "backward_entropy": 0.09069854872567314,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.65872859954834,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01526873279362917,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13659733533859253,
      "backward_entropy": 0.08955375637326922,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.77940845489502,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01536630094051361,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1365843564271927,
      "backward_entropy": 0.0902482271194458,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.978715896606445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015463829971849918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1365707516670227,
      "backward_entropy": 0.0901794263294765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.41160774230957,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015560888685286045,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13655763864517212,
      "backward_entropy": 0.09000091893332345,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.323741912841797,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.015658333897590637,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13654333353042603,
      "backward_entropy": 0.0897057397024972,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.90960168838501,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015755528584122658,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13652943074703217,
      "backward_entropy": 0.08852345602852958,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.16374683380127,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.015852289274334908,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13651639223098755,
      "backward_entropy": 0.08944582939147949,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.125763893127441,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.015949316322803497,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13650193810462952,
      "backward_entropy": 0.08808755874633789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.24569320678711,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016046598553657532,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13648653030395508,
      "backward_entropy": 0.08905964238303048,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.391054153442383,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016143612563610077,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13647137582302094,
      "backward_entropy": 0.08886156763349261,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.488615989685059,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016240527853369713,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13645686209201813,
      "backward_entropy": 0.08865949085780553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.377042770385742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016337359324097633,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1364421248435974,
      "backward_entropy": 0.08845419543130058,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.327765464782715,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016434041783213615,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13642707467079163,
      "backward_entropy": 0.0882459282875061,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.24354362487793,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016530632972717285,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13641247153282166,
      "backward_entropy": 0.08788074765886579,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.188801288604736,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01662701927125454,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1363975554704666,
      "backward_entropy": 0.08643561601638794,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.1729154586792,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.016722628846764565,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13638415932655334,
      "backward_entropy": 0.08760161059243339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.783320903778076,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.016818169504404068,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13637109100818634,
      "backward_entropy": 0.08721091066087995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.751577377319336,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.016913414001464844,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13635878264904022,
      "backward_entropy": 0.08568200043269567,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.941813945770264,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017007775604724884,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13634875416755676,
      "backward_entropy": 0.08674850634166173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.91939640045166,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017102019861340523,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13633838295936584,
      "backward_entropy": 0.08517810276576451,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.723093032836914,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01719614863395691,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1363275647163391,
      "backward_entropy": 0.08626975331987653,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.860972881317139,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017290646210312843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13631486892700195,
      "backward_entropy": 0.08465266227722168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.023902893066406,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017385009676218033,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13630248606204987,
      "backward_entropy": 0.08577549457550049,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.371127128601074,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017479339614510536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13629008829593658,
      "backward_entropy": 0.08410972356796265,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.800423622131348,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017573826014995575,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362764537334442,
      "backward_entropy": 0.08549739633287702,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.690532684326172,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.017668120563030243,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1362626701593399,
      "backward_entropy": 0.08524612018040248,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.641298294067383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.017761588096618652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13625091314315796,
      "backward_entropy": 0.08326082570212227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.533063888549805,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01785494014620781,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13623972237110138,
      "backward_entropy": 0.08297231367656163,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.05289363861084,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.017948664724826813,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1362265646457672,
      "backward_entropy": 0.08417173794337682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.5151543617248535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01804245263338089,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13621261715888977,
      "backward_entropy": 0.08388937371117729,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.445948600769043,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01813536137342453,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13620078563690186,
      "backward_entropy": 0.08394846745899745,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.055047988891602,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018228651955723763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1361868977546692,
      "backward_entropy": 0.08368073190961565,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.016725540161133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01832207851111889,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13617214560508728,
      "backward_entropy": 0.08147171565464564,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.091148376464844,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.01841564103960991,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13615703582763672,
      "backward_entropy": 0.08116040059498378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.356046676635742,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01850931905210018,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13614065945148468,
      "backward_entropy": 0.08241407360349383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5727996826171875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.018602672964334488,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13612473011016846,
      "backward_entropy": 0.08257198333740234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.90630578994751,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01869593746960163,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13610956072807312,
      "backward_entropy": 0.08228573628834315,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.875119686126709,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.018789272755384445,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13609346747398376,
      "backward_entropy": 0.0798717907496861,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.80681037902832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01888265833258629,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13607650995254517,
      "backward_entropy": 0.08115003790174212,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.295146465301514,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.01897544041275978,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360611766576767,
      "backward_entropy": 0.08139574527740479,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.3560967445373535,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019067982211709023,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13604606688022614,
      "backward_entropy": 0.07886452334267753,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.919980525970459,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019160330295562744,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1360306292772293,
      "backward_entropy": 0.08078503608703613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.71299409866333,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019252868369221687,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13601359724998474,
      "backward_entropy": 0.08046942097800118,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.179113388061523,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019345462322235107,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13599564135074615,
      "backward_entropy": 0.07945455823625837,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.713772773742676,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01943843625485897,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359761357307434,
      "backward_entropy": 0.07910214151654925,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.186227798461914,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019530819728970528,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13595843315124512,
      "backward_entropy": 0.07948286192757743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.163320541381836,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.01962297409772873,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1359410285949707,
      "backward_entropy": 0.07838319880621773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.12402057647705,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019715506583452225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13592088222503662,
      "backward_entropy": 0.07634285518101283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.4912261962890625,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.019808359444141388,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13589827716350555,
      "backward_entropy": 0.0784529617854527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.205943584442139,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.019901160150766373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13587568700313568,
      "backward_entropy": 0.07726662499564034,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.026389122009277,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.019993741065263748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13585415482521057,
      "backward_entropy": 0.07515797444752284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.9595513343811035,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020085355266928673,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13583604991436005,
      "backward_entropy": 0.07737874133246285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.336145401000977,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020177306607365608,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13581514358520508,
      "backward_entropy": 0.07701249633516584,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4133620262146,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020269222557544708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13579398393630981,
      "backward_entropy": 0.07664070810590472,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.90877628326416,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020360497757792473,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13577479124069214,
      "backward_entropy": 0.07531933273587908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.820339202880859,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020452143624424934,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13575267791748047,
      "backward_entropy": 0.07588315861565727,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.71218204498291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020543446764349937,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13573116064071655,
      "backward_entropy": 0.07266201291765485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.901683330535889,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020634334534406662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1357097029685974,
      "backward_entropy": 0.07223004102706909,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.104021072387695,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020725009962916374,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13568809628486633,
      "backward_entropy": 0.07366360936846052,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.893957614898682,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.020815599709749222,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13566505908966064,
      "backward_entropy": 0.07431565012250628,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.016486644744873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.020906023681163788,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13564185798168182,
      "backward_entropy": 0.07090411015919276,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.037143230438232,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.020996343344449997,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13561731576919556,
      "backward_entropy": 0.07234667880194527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.60785436630249,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021085957065224648,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13559502363204956,
      "backward_entropy": 0.07189794949122838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.94883918762207,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02117534540593624,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355731338262558,
      "backward_entropy": 0.07268511397497994,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.145010948181152,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021264752373099327,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1355501264333725,
      "backward_entropy": 0.07098959173474993,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.549488067626953,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02135363034904003,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13552847504615784,
      "backward_entropy": 0.07052905218941825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.735683441162109,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021442346274852753,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1355070173740387,
      "backward_entropy": 0.07140354599271502,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.240444660186768,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021531015634536743,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13548439741134644,
      "backward_entropy": 0.0695974954536983,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.74389123916626,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021619312465190887,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13546225428581238,
      "backward_entropy": 0.0705269021647317,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.88542366027832,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.021706970408558846,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13544276356697083,
      "backward_entropy": 0.07008386084011622,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.806419849395752,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021794825792312622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13542094826698303,
      "backward_entropy": 0.06621752040726799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.205605506896973,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.021882127970457077,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13540098071098328,
      "backward_entropy": 0.06769007444381714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.716715335845947,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.021969186142086983,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13538044691085815,
      "backward_entropy": 0.06524335060800825,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.757925510406494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.022055719047784805,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13536164164543152,
      "backward_entropy": 0.06671459334237236,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.203340530395508,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022142484784126282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.135339617729187,
      "backward_entropy": 0.06425626788820539,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.722874641418457,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022229792550206184,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13531309366226196,
      "backward_entropy": 0.06733623147010803,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.599515914916992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02231655828654766,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13528800010681152,
      "backward_entropy": 0.0668639327798571,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.836462497711182,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022402776405215263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13526490330696106,
      "backward_entropy": 0.06272959283420018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.510105133056641,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022488655522465706,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352420151233673,
      "backward_entropy": 0.06589915922709874,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.727346420288086,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022573990747332573,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1352202445268631,
      "backward_entropy": 0.06540933677128383,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.633972644805908,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.022659044712781906,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13519906997680664,
      "backward_entropy": 0.06491506951195854,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.697684288024902,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022743673995137215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351768672466278,
      "backward_entropy": 0.06067226614270892,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.718311786651611,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022828061133623123,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1351546049118042,
      "backward_entropy": 0.060151559965951104,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.051898002624512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02291223220527172,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13513165712356567,
      "backward_entropy": 0.05962750741413662,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.34739875793457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.022995753213763237,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13511130213737488,
      "backward_entropy": 0.05910562191690717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.367452621459961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02307887189090252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13509103655815125,
      "backward_entropy": 0.058581914220537455,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.709217071533203,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02316162921488285,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13507013022899628,
      "backward_entropy": 0.05805558817727225,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.45672607421875,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023244325071573257,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350467950105667,
      "backward_entropy": 0.061401690755571635,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.240633010864258,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023326782509684563,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1350221335887909,
      "backward_entropy": 0.06089194757597787,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.819577217102051,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02340964414179325,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1349925547838211,
      "backward_entropy": 0.060376380171094625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.662447452545166,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023491818457841873,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13496540486812592,
      "backward_entropy": 0.059860246522086005,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.101150035858154,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023574022576212883,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349359005689621,
      "backward_entropy": 0.05535801819392613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.232748508453369,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023655802011489868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1349063217639923,
      "backward_entropy": 0.05481194172586713,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.67478609085083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023737311363220215,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13487571477890015,
      "backward_entropy": 0.05426396216664996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.30070686340332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023818152025341988,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13484688103199005,
      "backward_entropy": 0.05371865204402378,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.382796287536621,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.023898888379335403,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13481591641902924,
      "backward_entropy": 0.05725025279181344,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.752209186553955,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.023978810757398605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13478775322437286,
      "backward_entropy": 0.05262581791196551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.510553359985352,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02405831776559353,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13476000726222992,
      "backward_entropy": 0.05393228360584804,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.933485984802246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02413729391992092,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13473427295684814,
      "backward_entropy": 0.051541379519871304,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.701030731201172,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02421613782644272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13470745086669922,
      "backward_entropy": 0.05099885378565107,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6461687088012695,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024294642731547356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13467997312545776,
      "backward_entropy": 0.05045577032225473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.289138317108154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024371976032853127,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13465803861618042,
      "backward_entropy": 0.05167821901185172,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.176904678344727,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02444956637918949,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13462981581687927,
      "backward_entropy": 0.04937941261700222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.404295921325684,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024526556953787804,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13460367918014526,
      "backward_entropy": 0.05054633106504168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.463598251342773,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024603232741355896,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1345781534910202,
      "backward_entropy": 0.04830522196633475,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.400864601135254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02467963844537735,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13455159962177277,
      "backward_entropy": 0.04776841402053833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.2304511070251465,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02475578896701336,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13452477753162384,
      "backward_entropy": 0.04886398145130703,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.888566493988037,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.024832425639033318,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.134491965174675,
      "backward_entropy": 0.05088454484939575,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.783803701400757,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.024909187108278275,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1344548910856247,
      "backward_entropy": 0.04614001086780003,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.378913879394531,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.024985142052173615,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13442137837409973,
      "backward_entropy": 0.04719141125679016,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.849407196044922,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02506084553897381,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13438567519187927,
      "backward_entropy": 0.04663644518171038,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.562917947769165,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025136737152934074,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13434426486492157,
      "backward_entropy": 0.0445103475025722,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.923882007598877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02521171234548092,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1343068778514862,
      "backward_entropy": 0.048182930265154154,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.225369930267334,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025286193937063217,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13427016139030457,
      "backward_entropy": 0.044979367937360494,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.505075693130493,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02536049671471119,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13423116505146027,
      "backward_entropy": 0.04290127754211426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.595632791519165,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025433920323848724,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13419374823570251,
      "backward_entropy": 0.043885997363499234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.7835311889648438,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025506680831313133,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13415729999542236,
      "backward_entropy": 0.043342420033046176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.317781448364258,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02557905949652195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13412043452262878,
      "backward_entropy": 0.04132385764803205,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.9521195888519287,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02565155178308487,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13407772779464722,
      "backward_entropy": 0.04079676525933402,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.547434091567993,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02572387456893921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1340329796075821,
      "backward_entropy": 0.04027037535394941,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6832706928253174,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025795718654990196,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13399001955986023,
      "backward_entropy": 0.0411919185093471,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0399556159973145,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.025867177173495293,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13394533097743988,
      "backward_entropy": 0.039230487176350186,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.6948275566101074,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.025938663631677628,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13389602303504944,
      "backward_entropy": 0.040132654564721246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.129578113555908,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.026009835302829742,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13384443521499634,
      "backward_entropy": 0.03960444246019636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.252272367477417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026080161333084106,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1337948739528656,
      "backward_entropy": 0.03767794370651245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.836313486099243,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02614983730018139,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1337452232837677,
      "backward_entropy": 0.03717067837715149,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.132948875427246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02621854655444622,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13369935750961304,
      "backward_entropy": 0.036672770977020264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0263800621032715,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02628665789961815,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13365302979946136,
      "backward_entropy": 0.03753046904291425,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2680532932281494,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02635423094034195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13360866904258728,
      "backward_entropy": 0.03569079509803227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8319597244262695,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026421530172228813,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13356217741966248,
      "backward_entropy": 0.03936226453099932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7741997241973877,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02648806758224964,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1335163116455078,
      "backward_entropy": 0.03887060710362026,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6369898319244385,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02655390277504921,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13347169756889343,
      "backward_entropy": 0.034242089305605204,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0253310203552246,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026618968695402145,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13342928886413574,
      "backward_entropy": 0.033772291881697517,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.1224536895751953,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02668374963104725,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13338370621204376,
      "backward_entropy": 0.033303599272455485,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.670673131942749,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02674841322004795,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1333339810371399,
      "backward_entropy": 0.03407597116061619,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.424207925796509,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0268124770373106,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13328465819358826,
      "backward_entropy": 0.036470928362437656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.447421073913574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.026875684037804604,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13323700428009033,
      "backward_entropy": 0.03600435597555978,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6160202026367188,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.026938142254948616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1331898272037506,
      "backward_entropy": 0.03146696729319436,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3410115242004395,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0270001869648695,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1331416368484497,
      "backward_entropy": 0.03220049185412271,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.14561128616333,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027061522006988525,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13309474289417267,
      "backward_entropy": 0.030582604663712636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2744317054748535,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02712196484208107,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13305026292800903,
      "backward_entropy": 0.03129622553076063,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.326925277709961,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02718172036111355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13300488889217377,
      "backward_entropy": 0.029726547854287282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.5832912921905518,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027241019532084465,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1329592764377594,
      "backward_entropy": 0.03331563089575086,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0542852878570557,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027300262823700905,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13291007280349731,
      "backward_entropy": 0.03288045951298305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6358067989349365,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027358725666999817,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13286221027374268,
      "backward_entropy": 0.03245154448917934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0223515033721924,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027417266741394997,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1328079104423523,
      "backward_entropy": 0.02805808186531067,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8454123735427856,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027475055307149887,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13275426626205444,
      "backward_entropy": 0.028706233416284834,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9568527936935425,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027532000094652176,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13270428776741028,
      "backward_entropy": 0.027252182364463806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.9089760780334473,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027588291093707085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13265448808670044,
      "backward_entropy": 0.026859681521143233,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0743939876556396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02764388918876648,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13260383903980255,
      "backward_entropy": 0.030369935291154043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0832314491271973,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.027699226513504982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13255204260349274,
      "backward_entropy": 0.02608916163444519,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0024750232696533,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.027754342183470726,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1324981451034546,
      "backward_entropy": 0.026706280452864512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7219719886779785,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02780904248356819,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13244038820266724,
      "backward_entropy": 0.025325613362448558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4513410329818726,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02786301076412201,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1323833167552948,
      "backward_entropy": 0.024951666593551636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.742504596710205,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027915913611650467,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13233014941215515,
      "backward_entropy": 0.028383584959166392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5880974531173706,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.027968334034085274,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13227608799934387,
      "backward_entropy": 0.028002653803144182,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8644084930419922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028020111843943596,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13222333788871765,
      "backward_entropy": 0.027626335620880127,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.7619192600250244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028071686625480652,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13216537237167358,
      "backward_entropy": 0.023522151368004934,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.587959885597229,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02812303975224495,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1321057826280594,
      "backward_entropy": 0.023172823446137563,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4697365760803223,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02817382663488388,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1320447027683258,
      "backward_entropy": 0.023785761424473355,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5482969284057617,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028223859146237373,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13198228180408478,
      "backward_entropy": 0.023442015051841736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5532608032226562,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028273452073335648,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13191857933998108,
      "backward_entropy": 0.02215561270713806,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4618372917175293,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028322605416178703,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13185155391693115,
      "backward_entropy": 0.02545712036745889,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.984740674495697,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028371229767799377,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13178256154060364,
      "backward_entropy": 0.021498844027519226,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.355069875717163,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028418568894267082,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13172028958797455,
      "backward_entropy": 0.024779762540544783,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2048215866088867,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028465421870350838,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.131656676530838,
      "backward_entropy": 0.024450025388172696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3190114498138428,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02851162478327751,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13159500062465668,
      "backward_entropy": 0.02149892279079982,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5722187757492065,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028557397425174713,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13153085112571716,
      "backward_entropy": 0.02027233157839094,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2005363702774048,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02860325202345848,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13145838677883148,
      "backward_entropy": 0.01997166020529611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9008668065071106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028648462146520615,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13138428330421448,
      "backward_entropy": 0.01967630216053554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1845488548278809,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028692668303847313,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13131730258464813,
      "backward_entropy": 0.019391102450234548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1441771984100342,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02873639576137066,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13124722242355347,
      "backward_entropy": 0.019109593970435008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.779874324798584,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.028779733926057816,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13117657601833344,
      "backward_entropy": 0.02226865291595459,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0055898427963257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028821846470236778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13111016154289246,
      "backward_entropy": 0.018564762813704356,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.9524691700935364,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02886331081390381,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13104142248630524,
      "backward_entropy": 0.02169809809752873,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.817406415939331,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.028904179111123085,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13097217679023743,
      "backward_entropy": 0.01804449941430773,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7738609910011292,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02894425392150879,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13090617954730988,
      "backward_entropy": 0.01779404708317348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8616081476211548,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.028983496129512787,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13084299862384796,
      "backward_entropy": 0.01846679619380406,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7888721823692322,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029022181406617165,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1307792216539383,
      "backward_entropy": 0.01822694710322789,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7594287991523743,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029060129076242447,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13071462512016296,
      "backward_entropy": 0.017078212329319546,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6720548272132874,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029097406193614006,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13065049052238464,
      "backward_entropy": 0.016849938247885023,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.8552312254905701,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.02913389541208744,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13058888912200928,
      "backward_entropy": 0.016628001417432512,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.7094913721084595,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029170116409659386,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13052362203598022,
      "backward_entropy": 0.01961416006088257,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6763189435005188,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02920578420162201,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13045905530452728,
      "backward_entropy": 0.01937276337827955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6528775691986084,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02924078144133091,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13039374351501465,
      "backward_entropy": 0.019136922700064524,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6028850078582764,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029275119304656982,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13032843172550201,
      "backward_entropy": 0.015775630516665324,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5236839652061462,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02930874191224575,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13026440143585205,
      "backward_entropy": 0.01649202299969537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6081271767616272,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029341597110033035,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13020393252372742,
      "backward_entropy": 0.015380073870931352,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.6374590396881104,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029373953118920326,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.13014256954193115,
      "backward_entropy": 0.018245669347899302,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5507331490516663,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029405927285552025,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.13007843494415283,
      "backward_entropy": 0.015000482755047935,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.5511687994003296,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02943737432360649,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.13001485168933868,
      "backward_entropy": 0.015741647354194095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.4934663772583008,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029468243941664696,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1299489438533783,
      "backward_entropy": 0.01556436504636492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.40663737058639526,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029498474672436714,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12988322973251343,
      "backward_entropy": 0.017423261489186968,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3651275336742401,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029527895152568817,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12982062995433807,
      "backward_entropy": 0.014288902282714844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.48666369915008545,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029556255787611008,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12975874543190002,
      "backward_entropy": 0.017044812440872192,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.32670536637306213,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02958429791033268,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12969624996185303,
      "backward_entropy": 0.016861980514866964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.45215144753456116,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029611531645059586,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12963852286338806,
      "backward_entropy": 0.01475581739630018,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3820914030075073,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029638351872563362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12957827746868134,
      "backward_entropy": 0.013656686459268843,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.33463186025619507,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029664626345038414,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12951867282390594,
      "backward_entropy": 0.013507862176213945,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.26687636971473694,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029690295457839966,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12946169078350067,
      "backward_entropy": 0.0133634124483381,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38483765721321106,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029714984819293022,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12940672039985657,
      "backward_entropy": 0.013225157346044267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.43164515495300293,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029739368706941605,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1293502300977707,
      "backward_entropy": 0.013088817042963845,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3378002941608429,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029763663187623024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1292898803949356,
      "backward_entropy": 0.015698918274470737,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.38425737619400024,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02978738397359848,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12922760844230652,
      "backward_entropy": 0.01380034748997007,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3191601634025574,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02981092594563961,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12916292250156403,
      "backward_entropy": 0.015398150043828147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.3940492868423462,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029834086075425148,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12909860908985138,
      "backward_entropy": 0.012559650199753898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2836037874221802,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029857199639081955,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12903061509132385,
      "backward_entropy": 0.013432604925973075,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2886228859424591,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.029879724606871605,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12896259129047394,
      "backward_entropy": 0.014964536896773748,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.27792078256607056,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.029901733621954918,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12889364361763,
      "backward_entropy": 0.012183919548988342,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1962064504623413,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.02992323413491249,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1288238912820816,
      "backward_entropy": 0.014693282544612885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2719378173351288,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.0299438014626503,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1287556290626526,
      "backward_entropy": 0.012987021889005388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2510868310928345,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.02996417135000229,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12868766486644745,
      "backward_entropy": 0.012883976101875305,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.28730717301368713,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.029984120279550552,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12861895561218262,
      "backward_entropy": 0.012783706188201904,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.2676452398300171,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030003918334841728,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12854774296283722,
      "backward_entropy": 0.014194423598902566,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1853722482919693,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03002358041703701,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12847557663917542,
      "backward_entropy": 0.011514328420162201,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1729121208190918,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030042601749300957,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12840527296066284,
      "backward_entropy": 0.011410773864814214,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.19536393880844116,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030060861259698868,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12833592295646667,
      "backward_entropy": 0.011311613023281097,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.21423760056495667,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030078653246164322,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12826666235923767,
      "backward_entropy": 0.012316930506910597,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17634162306785583,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03009619191288948,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12819650769233704,
      "backward_entropy": 0.013631389609404973,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.17335575819015503,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030113069340586662,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12812544405460358,
      "backward_entropy": 0.011028841137886047,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.16626496613025665,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030129460617899895,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12805432081222534,
      "backward_entropy": 0.013430496411664146,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14866021275520325,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030145330354571342,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12798282504081726,
      "backward_entropy": 0.010854330446038927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1578349769115448,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030160551890730858,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12791118025779724,
      "backward_entropy": 0.010771991951125008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13144633173942566,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030175533145666122,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1278405636548996,
      "backward_entropy": 0.01185914980513709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15315060317516327,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03019006736576557,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12777167558670044,
      "backward_entropy": 0.010613096611840385,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.15897585451602936,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030204055830836296,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12770070135593414,
      "backward_entropy": 0.01053763713155474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.13509175181388855,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030217889696359634,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1276291012763977,
      "backward_entropy": 0.010463058948516846,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1392119824886322,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03023127093911171,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12755712866783142,
      "backward_entropy": 0.01282140931912831,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.14292150735855103,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030244356021285057,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12748470902442932,
      "backward_entropy": 0.012743937117712838,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.170181006193161,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030257154256105423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12741099298000336,
      "backward_entropy": 0.01025109738111496,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11070404946804047,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030269956216216087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12733423709869385,
      "backward_entropy": 0.012593465191977364,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.105660580098629,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030282162129878998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1272575855255127,
      "backward_entropy": 0.010115444660186768,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08177810162305832,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03029397316277027,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12718215584754944,
      "backward_entropy": 0.01133225645337786,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.1128866970539093,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030305087566375732,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12710845470428467,
      "backward_entropy": 0.011285600917679923,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11035211384296417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03031596541404724,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.127034530043602,
      "backward_entropy": 0.009932067777429308,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11961975693702698,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03032652474939823,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12695983052253723,
      "backward_entropy": 0.01226246463400977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.11503785103559494,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030336912721395493,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1268836110830307,
      "backward_entropy": 0.01115397470338004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.09391441941261292,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03034716285765171,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1268063485622406,
      "backward_entropy": 0.011112140757696969,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.12411979585886002,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030357040464878082,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12672920525074005,
      "backward_entropy": 0.009707802108355932,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.10389361530542374,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030367007479071617,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1266501247882843,
      "backward_entropy": 0.009653194674423762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0946928858757019,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03037680871784687,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12657034397125244,
      "backward_entropy": 0.009599429156099046,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07054941356182098,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030386388301849365,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12649047374725342,
      "backward_entropy": 0.009546838700771332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.07924016565084457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030395522713661194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12641234695911407,
      "backward_entropy": 0.00949668139219284,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06299693882465363,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03040456585586071,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1263357251882553,
      "backward_entropy": 0.011813488389764513,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08276024460792542,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03041282296180725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1262594610452652,
      "backward_entropy": 0.011766099504062108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.08222915232181549,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030420929193496704,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1261829137802124,
      "backward_entropy": 0.011719690901892526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0772513598203659,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030428806319832802,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12610556185245514,
      "backward_entropy": 0.011674687266349792,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0962333083152771,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03043634258210659,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12602737545967102,
      "backward_entropy": 0.010764188000134059,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06286916881799698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03044399991631508,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12594716250896454,
      "backward_entropy": 0.009228024099554335,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.052845634520053864,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030451441183686256,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12586836516857147,
      "backward_entropy": 0.009186415800026484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0633804202079773,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030458398163318634,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12579108774662018,
      "backward_entropy": 0.010685016001973833,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049898795783519745,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030465036630630493,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12571385502815247,
      "backward_entropy": 0.010662548243999481,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06613009423017502,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03047124482691288,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12563800811767578,
      "backward_entropy": 0.00907440802880696,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05730508267879486,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03047730028629303,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12556155025959015,
      "backward_entropy": 0.009039758571556636,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06004496291279793,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03048340603709221,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1254863291978836,
      "backward_entropy": 0.011363755379404341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.06712770462036133,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030489547178149223,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12541167438030243,
      "backward_entropy": 0.008970409631729126,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05299004539847374,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030495723709464073,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1253361999988556,
      "backward_entropy": 0.01129424465554101,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.049026597291231155,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030501719564199448,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1252613216638565,
      "backward_entropy": 0.008901234183992659,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04405746981501579,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03050760179758072,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.125187486410141,
      "backward_entropy": 0.011227482131549291,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04885553941130638,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030513091012835503,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12511436641216278,
      "backward_entropy": 0.008836438613278525,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.05471349507570267,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030518529936671257,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12504181265830994,
      "backward_entropy": 0.010485030710697174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.041658952832221985,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03052382543683052,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1249682754278183,
      "backward_entropy": 0.008774904268128532,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04657734930515289,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030528724193572998,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12489520013332367,
      "backward_entropy": 0.008746340870857239,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04034785181283951,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030533529818058014,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1248222291469574,
      "backward_entropy": 0.010439255407878332,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04354586824774742,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03053826279938221,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12475031614303589,
      "backward_entropy": 0.008690646716526576,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.040665555745363235,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030542802065610886,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12467829883098602,
      "backward_entropy": 0.011029338198048728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034385282546281815,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030546899884939194,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12460586428642273,
      "backward_entropy": 0.00863930263689586,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.030895991250872612,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030550925061106682,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12453490495681763,
      "backward_entropy": 0.008615119648831231,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03882427513599396,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03055456094443798,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12446503341197968,
      "backward_entropy": 0.008592815803630012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04911888390779495,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030558260157704353,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1243954598903656,
      "backward_entropy": 0.008570287376642227,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.034483592957258224,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030562248080968857,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12432447075843811,
      "backward_entropy": 0.008546367819820131,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.04020031541585922,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030566120520234108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12425408512353897,
      "backward_entropy": 0.010897279850074224,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03790324926376343,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030570045113563538,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12418339401483536,
      "backward_entropy": 0.008499625538076674,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028609110042452812,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03057403303682804,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12411276996135712,
      "backward_entropy": 0.01033135609967368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03217786177992821,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030577870085835457,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12404339015483856,
      "backward_entropy": 0.01032064003603799,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02809046395123005,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030581602826714516,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12397431582212448,
      "backward_entropy": 0.008430289902857371,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03315740451216698,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03058508411049843,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12390594184398651,
      "backward_entropy": 0.008409070117133004,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02429177612066269,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030588628724217415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12383752316236496,
      "backward_entropy": 0.010772301682404109,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.025386497378349304,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03059205785393715,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12377054989337921,
      "backward_entropy": 0.010753346340996879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02136123925447464,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03059532679617405,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12370443344116211,
      "backward_entropy": 0.008346818387508392,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.028985559940338135,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030598459765315056,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12363991141319275,
      "backward_entropy": 0.010717950761318207,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.03127744793891907,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030601518228650093,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12357498705387115,
      "backward_entropy": 0.010259060987404414,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022998876869678497,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03060474991798401,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12350945174694061,
      "backward_entropy": 0.008289060954536711,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.02384459227323532,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03060760349035263,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12344428896903992,
      "backward_entropy": 0.008271210427795137,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022727418690919876,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030610457062721252,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12337981164455414,
      "backward_entropy": 0.008253356175763267,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.021188775077462196,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03061324916779995,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12331598997116089,
      "backward_entropy": 0.01023094994681222,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.022077269852161407,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030616002157330513,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1232530027627945,
      "backward_entropy": 0.010224510516439165,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01532010268419981,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030618490651249886,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12319003790616989,
      "backward_entropy": 0.00820246764591762,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.023184917867183685,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030620792880654335,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12312886863946915,
      "backward_entropy": 0.010215611330100469,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01821143738925457,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030622975900769234,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12306719273328781,
      "backward_entropy": 0.008172869682312012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.017993712797760963,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030625054612755775,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12300629913806915,
      "backward_entropy": 0.008158853011471885,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013426111079752445,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030626919120550156,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12294591218233109,
      "backward_entropy": 0.010559935654912676,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.019510112702846527,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030628597363829613,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12288722395896912,
      "backward_entropy": 0.008133836090564728,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01931040734052658,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03063012845814228,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12282830476760864,
      "backward_entropy": 0.008122390934399195,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.018912993371486664,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030631622299551964,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12276927381753922,
      "backward_entropy": 0.010207583861691611,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015714189037680626,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030633125454187393,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12271013855934143,
      "backward_entropy": 0.008099807160241264,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01890835352241993,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030634509399533272,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1226515918970108,
      "backward_entropy": 0.010208622685500554,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.014167525805532932,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030636023730039597,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12259283661842346,
      "backward_entropy": 0.008077834333692278,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015358098782598972,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030637435615062714,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12253496050834656,
      "backward_entropy": 0.00806707569531032,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013909891247749329,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0306390393525362,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12247781455516815,
      "backward_entropy": 0.008055571466684341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.015267742797732353,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030640508979558945,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1224212571978569,
      "backward_entropy": 0.008044707455805369,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01533968560397625,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030642032623291016,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12236496061086655,
      "backward_entropy": 0.01020660251379013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012257875874638557,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030643584206700325,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12230871617794037,
      "backward_entropy": 0.008022521223340715,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.013861339539289474,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030645061284303665,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12225341796875,
      "backward_entropy": 0.008011775357382638,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011413181200623512,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03064657934010029,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12219849228858948,
      "backward_entropy": 0.00800082300390516,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011646654456853867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03064798004925251,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12214446067810059,
      "backward_entropy": 0.010202826133796148,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008630522526800632,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030649296939373016,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12209102511405945,
      "backward_entropy": 0.007980620754616601,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012592549435794353,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03065050207078457,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12203913927078247,
      "backward_entropy": 0.010424056223460607,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.01060626469552517,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030651457607746124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12198691070079803,
      "backward_entropy": 0.010418264993599482,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.012914864346385002,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030652368441224098,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12193527817726135,
      "backward_entropy": 0.010412733469690596,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011866454966366291,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065338358283043,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12188337743282318,
      "backward_entropy": 0.007946815873895372,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009632718749344349,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03065439499914646,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12183143943548203,
      "backward_entropy": 0.01040061456816537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.011250301264226437,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030655354261398315,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12178023159503937,
      "backward_entropy": 0.010394851011889321,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008700517006218433,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065638244152069,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12172907590866089,
      "backward_entropy": 0.007921978831291199,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008418687619268894,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03065740503370762,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12167893350124359,
      "backward_entropy": 0.01038271508046559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008867992088198662,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03065842017531395,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1216297596693039,
      "backward_entropy": 0.007905529545886176,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008581500500440598,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030659398064017296,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1215810775756836,
      "backward_entropy": 0.010371012347085136,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007910970598459244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030660340562462807,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12153290212154388,
      "backward_entropy": 0.007889833833490099,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007105551660060883,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03066123276948929,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1214853972196579,
      "backward_entropy": 0.010360130241939,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.008559556677937508,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03066216967999935,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12143899500370026,
      "backward_entropy": 0.010354673223836082,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00792455393821001,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03066314198076725,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12139273434877396,
      "backward_entropy": 0.010349055486066001,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006681320257484913,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030664123594760895,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1213468462228775,
      "backward_entropy": 0.007859393954277039,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.009060405194759369,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030665090307593346,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12130177021026611,
      "backward_entropy": 0.007851832679339818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005926006007939577,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030666153877973557,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12125633656978607,
      "backward_entropy": 0.010216578841209412,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.006953011732548475,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030667170882225037,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1212119609117508,
      "backward_entropy": 0.007836119404860906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005415103863924742,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030668215826153755,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12116803228855133,
      "backward_entropy": 0.010320075920649938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.007230306509882212,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030669094994664192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12112495303153992,
      "backward_entropy": 0.007821302328790938,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0051459018141031265,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03066994436085224,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12108176946640015,
      "backward_entropy": 0.010216365967478071,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005818834528326988,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030670734122395515,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12103952467441559,
      "backward_entropy": 0.007807858820472445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005712883546948433,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030671576038002968,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1209978312253952,
      "backward_entropy": 0.007801138928958348,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004668385721743107,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030672572553157806,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12095679342746735,
      "backward_entropy": 0.007793807557650975,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005220678634941578,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030673518776893616,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12091662734746933,
      "backward_entropy": 0.010289613689695085,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005323823541402817,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030674465000629425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12087695300579071,
      "backward_entropy": 0.010284338678632463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.005045787896960974,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030675530433654785,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12083771079778671,
      "backward_entropy": 0.00777233498437064,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0051089124754071236,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03067648969590664,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1207987517118454,
      "backward_entropy": 0.010212176612445287,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004922226071357727,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030677445232868195,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12076009064912796,
      "backward_entropy": 0.010211148432322912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004366182256489992,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030678343027830124,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12072160840034485,
      "backward_entropy": 0.010262844817978995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0036616420838981867,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030679134652018547,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12068353593349457,
      "backward_entropy": 0.01021036079951695,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004786388948559761,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030679861083626747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12064631283283234,
      "backward_entropy": 0.010254142539841788,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004618392791599035,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030680622905492783,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12060913443565369,
      "backward_entropy": 0.007733728204454694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003961778711527586,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030681392177939415,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12057206779718399,
      "backward_entropy": 0.010245348726000105,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.004603741690516472,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03068210370838642,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12053538858890533,
      "backward_entropy": 0.010241209396294184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.003683679737150669,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030682871118187904,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1204986572265625,
      "backward_entropy": 0.007716027753693717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028139306232333183,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030683578923344612,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12046241015195847,
      "backward_entropy": 0.007710370634283338,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0031203138642013073,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03068418987095356,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12042712420225143,
      "backward_entropy": 0.010229009602751051,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002752748318016529,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03068479336798191,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12039250135421753,
      "backward_entropy": 0.010211921163967677,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0029152752831578255,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030685322359204292,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1203586608171463,
      "backward_entropy": 0.007695391774177551,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0021630695555359125,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03068580850958824,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12032540142536163,
      "backward_entropy": 0.007690893220049995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002941651502624154,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030686259269714355,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12029324471950531,
      "backward_entropy": 0.010215041892869132,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002488141180947423,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030686737969517708,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12026146799325943,
      "backward_entropy": 0.010213708238942283,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0028512240387499332,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030687207356095314,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1202303022146225,
      "backward_entropy": 0.007678051612206868,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020995037630200386,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030687712132930756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12019939720630646,
      "backward_entropy": 0.0102079553263528,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0023326652590185404,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030688181519508362,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12016928195953369,
      "backward_entropy": 0.010205196482794625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002149874111637473,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03068866953253746,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12013967335224152,
      "backward_entropy": 0.010218467031206404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002364994725212455,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030689161270856857,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.12011069059371948,
      "backward_entropy": 0.010199548942702157,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.002389493165537715,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03068968839943409,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12008200585842133,
      "backward_entropy": 0.007656813200031008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0020184137392789125,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03069021925330162,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.12005354464054108,
      "backward_entropy": 0.010218851268291473,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016784067265689373,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030690757557749748,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.12002560496330261,
      "backward_entropy": 0.00764824024268559,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001690915785729885,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03069128841161728,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11999841034412384,
      "backward_entropy": 0.010187574795314245,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0019096413161605597,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030691837891936302,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1199718564748764,
      "backward_entropy": 0.01018455092396055,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001843032892793417,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030692363157868385,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11994560062885284,
      "backward_entropy": 0.007635707301752908,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017784279771149158,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030692866072058678,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11991962790489197,
      "backward_entropy": 0.007631710065262658,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014809941640123725,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03069334849715233,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11989393830299377,
      "backward_entropy": 0.010176144540309906,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017652884125709534,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030693816021084785,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11986885964870453,
      "backward_entropy": 0.01021750909941537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0017149820923805237,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03069431334733963,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11984400451183319,
      "backward_entropy": 0.007620201579162053,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0016912453575059772,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030694734305143356,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11981925368309021,
      "backward_entropy": 0.007616662553378514,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015247534029185772,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030695123597979546,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11979462206363678,
      "backward_entropy": 0.010217826281275069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0012458107667043805,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03069545328617096,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11977024376392365,
      "backward_entropy": 0.010164120367595128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0015578335151076317,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03069576434791088,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11974640190601349,
      "backward_entropy": 0.010219393031937736,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0014230119995772839,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030696077272295952,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11972267925739288,
      "backward_entropy": 0.0076041338699204585,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011532867792993784,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030696412548422813,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11969920992851257,
      "backward_entropy": 0.007601055183580944,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001122411573305726,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030696749687194824,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11967627704143524,
      "backward_entropy": 0.010156340897083282,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0013759852154180408,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03069707378745079,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11965382099151611,
      "backward_entropy": 0.007595071835177285,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.001006494858302176,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030697355046868324,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11963139474391937,
      "backward_entropy": 0.007592315120356423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0011553452350199223,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03069760650396347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11960947513580322,
      "backward_entropy": 0.007589722318308694,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0010698509868234396,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03069784678518772,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11958780884742737,
      "backward_entropy": 0.010149611958435603,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009887699270620942,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03069807030260563,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11956645548343658,
      "backward_entropy": 0.007584752248866218,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0009027478517964482,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030698273330926895,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11954542994499207,
      "backward_entropy": 0.010227390698024206,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007167381700128317,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030698461458086967,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11952488124370575,
      "backward_entropy": 0.007580186639513288,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0008443236583843827,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030698608607053757,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11950492858886719,
      "backward_entropy": 0.010230121867997306,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000883689965121448,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030698735266923904,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11948534846305847,
      "backward_entropy": 0.010143609983580453,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007146962452679873,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030698858201503754,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11946602165699005,
      "backward_entropy": 0.007574419890131269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007798187434673309,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03069901652634144,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11944723129272461,
      "backward_entropy": 0.007572431649480548,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.000826577190309763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030699172988533974,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11942873895168304,
      "backward_entropy": 0.007570456181253705,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007028942345641553,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030699316412210464,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1194104328751564,
      "backward_entropy": 0.007568572248731341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007121196249499917,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030699504539370537,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1193925216794014,
      "backward_entropy": 0.0075665249356201714,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0007908272673375905,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030699726194143295,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11937494575977325,
      "backward_entropy": 0.010137070502553667,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006963501800782979,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030699951574206352,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11935745924711227,
      "backward_entropy": 0.00756213760801724,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006204354576766491,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030700189992785454,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1193402111530304,
      "backward_entropy": 0.01013424779687609,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006400085403583944,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070041909813881,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11932328343391418,
      "backward_entropy": 0.0075577252677508765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006483730394393206,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030700668692588806,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11930660158395767,
      "backward_entropy": 0.010240480303764343,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006675571203231812,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070092387497425,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1192900761961937,
      "backward_entropy": 0.01012987962790898,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0006711080204695463,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030701138079166412,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11927357316017151,
      "backward_entropy": 0.01012854597398213,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00046806770842522383,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070136532187462,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1192571222782135,
      "backward_entropy": 0.007549148052930832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004887974937446415,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070162422955036,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11924116313457489,
      "backward_entropy": 0.007546967161553246,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005171686061657965,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070186823606491,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11922553926706314,
      "backward_entropy": 0.010124161839485168,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00043145124800503254,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070209175348282,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11921010911464691,
      "backward_entropy": 0.007542858166354043,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0005394753534346819,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030702298507094383,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11919502913951874,
      "backward_entropy": 0.010121528591428484,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004153762711212039,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030702484771609306,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11918000876903534,
      "backward_entropy": 0.007539142455373492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004327745409682393,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030702663585543633,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11916530132293701,
      "backward_entropy": 0.010244992162500108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00040778692346066236,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030702844262123108,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11915083974599838,
      "backward_entropy": 0.010118052363395691,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0004912285949103534,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030702996999025345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11913660168647766,
      "backward_entropy": 0.0075340137950011665,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002503328723832965,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030703134834766388,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11912235617637634,
      "backward_entropy": 0.007532454494919095,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00030800915556028485,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070327453315258,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11910870671272278,
      "backward_entropy": 0.0075309186109474725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003278299991507083,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030703401193022728,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11909541487693787,
      "backward_entropy": 0.007529478520154953,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00026796525344252586,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030703511089086533,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11908237636089325,
      "backward_entropy": 0.010249766920294081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00028345780447125435,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070361539721489,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11906973272562027,
      "backward_entropy": 0.007526814937591553,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00034819182474166155,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030703721567988396,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11905739456415176,
      "backward_entropy": 0.007525513214724404,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0003314706846140325,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070385567843914,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11904515326023102,
      "backward_entropy": 0.010252049991062709,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002658280427567661,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030703959986567497,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11903296411037445,
      "backward_entropy": 0.010252886584826879,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0002169609215343371,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070404939353466,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11902101337909698,
      "backward_entropy": 0.01025378704071045,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00022791206720285118,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030704142525792122,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11900945007801056,
      "backward_entropy": 0.01010903183903013,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00020328642858657986,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070426732301712,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.118998222053051,
      "backward_entropy": 0.010255135595798492,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00027646857779473066,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030704358592629433,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11898726224899292,
      "backward_entropy": 0.0075179822742938995,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001644507865421474,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030704444274306297,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11897634714841843,
      "backward_entropy": 0.010106931839670454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001970672601601109,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070453368127346,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11896583437919617,
      "backward_entropy": 0.010106312377112252,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019827118376269937,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070460818707943,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11895554512739182,
      "backward_entropy": 0.007514738078628268,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00019892740237992257,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030704662203788757,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1189454048871994,
      "backward_entropy": 0.007513815803187234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016535777831450105,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070472553372383,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11893545091152191,
      "backward_entropy": 0.007512870643820081,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016806658823043108,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030704787001013756,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11892575025558472,
      "backward_entropy": 0.010104291141033173,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016038249304983765,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030704867094755173,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11891630291938782,
      "backward_entropy": 0.010103715317589896,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00017782783834263682,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070494718849659,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11890706419944763,
      "backward_entropy": 0.007509979286364147,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.0001697760890237987,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0307050421833992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11889796704053879,
      "backward_entropy": 0.007508955363716398,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016422521730419248,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070513904094696,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1188889816403389,
      "backward_entropy": 0.010262749024799891,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00014065297727938741,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030705248937010765,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11888013780117035,
      "backward_entropy": 0.00750684312411717,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015613574942108244,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030705338343977928,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11887144297361374,
      "backward_entropy": 0.007505853793450764,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012685406545642763,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070542775094509,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11886284500360489,
      "backward_entropy": 0.0075048889432634625,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00016074963787104934,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030705526471138,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11885447800159454,
      "backward_entropy": 0.010099312024457114,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00015114231791812927,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070562332868576,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1188461109995842,
      "backward_entropy": 0.010264823479311807,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012345542199909687,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030705735087394714,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11883780360221863,
      "backward_entropy": 0.010265122566904341,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00013004658103454858,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030705858021974564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11882969737052917,
      "backward_entropy": 0.010097181158406394,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00012156437151134014,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030705999583005905,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11882174015045166,
      "backward_entropy": 0.007499592644827706,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00010994406329700723,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030706141144037247,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11881386488676071,
      "backward_entropy": 0.007498472396816526,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 0.00011199087020941079,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030706269666552544,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1188061386346817,
      "backward_entropy": 0.010094682020800454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.664471144787967e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070640377700329,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11879850178956985,
      "backward_entropy": 0.007496308535337448,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.342354365391657e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030706526711583138,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11879102885723114,
      "backward_entropy": 0.0074952760977404454,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.234682900365442e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030706649646162987,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11878382414579391,
      "backward_entropy": 0.0074942708015441895,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.616098107770085e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030706776306033134,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1187768280506134,
      "backward_entropy": 0.007493257522583008,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.659322000108659e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030706893652677536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1187700629234314,
      "backward_entropy": 0.007492315024137497,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.305304411100224e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030707022175192833,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11876349151134491,
      "backward_entropy": 0.010265965546880449,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.598621207056567e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070715256035328,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11875694990158081,
      "backward_entropy": 0.010265930422714778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.663738895440474e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030707286670804024,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11875049769878387,
      "backward_entropy": 0.010088562965393066,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.223439024528489e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030707424506545067,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11874422430992126,
      "backward_entropy": 0.007488331092255456,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.360563565976918e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070756047964096,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11873804777860641,
      "backward_entropy": 0.007487356130565915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.582178320968524e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030707696452736855,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1187320202589035,
      "backward_entropy": 0.010265448263713292,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.595674494747072e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0307078268378973,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11872608959674835,
      "backward_entropy": 0.007485402481896537,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.7413126594619825e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030707957223057747,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11872024089097977,
      "backward_entropy": 0.0100847099508558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.707049058401026e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030708078294992447,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1187145859003067,
      "backward_entropy": 0.010265079992158073,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.299493932398036e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030708182603120804,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11870898306369781,
      "backward_entropy": 0.0074827394315174645,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.850469122175127e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03070828691124916,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11870348453521729,
      "backward_entropy": 0.010265094893319266,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.508536924025975e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030708393082022667,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186981275677681,
      "backward_entropy": 0.007481117333684649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4170115870656446e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070850670337677,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11869284510612488,
      "backward_entropy": 0.010081491300037928,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.2213308915961534e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030708614736795425,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11868767440319061,
      "backward_entropy": 0.010264891598905836,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.228292527841404e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030708715319633484,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1186826080083847,
      "backward_entropy": 0.010264868182795388,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.221715062158182e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030708812177181244,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11867764592170715,
      "backward_entropy": 0.007477974785225732,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.86663232347928e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030708907172083855,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11867277324199677,
      "backward_entropy": 0.007477237709930965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.201043728040531e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070899285376072,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11866798996925354,
      "backward_entropy": 0.010078645178249903,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.0669332772959024e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030709076672792435,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11866334080696106,
      "backward_entropy": 0.0074758801077093396,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.2237348932540044e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030709154903888702,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11865882575511932,
      "backward_entropy": 0.010077685117721558,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.509797534206882e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070923313498497,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11865441501140594,
      "backward_entropy": 0.010077209344932012,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.827621210599318e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030709315091371536,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11865005642175674,
      "backward_entropy": 0.007473984999316079,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.200212449883111e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030709389597177505,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186458021402359,
      "backward_entropy": 0.007473376180444445,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.567804949649144e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030709469690918922,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11864162981510162,
      "backward_entropy": 0.007472758846623557,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7028954718844034e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03070954792201519,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11863754689693451,
      "backward_entropy": 0.007472154817410878,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2261574486037716e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070962429046631,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11863355338573456,
      "backward_entropy": 0.010074919887951441,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8205026208306663e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030709700658917427,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11862966418266296,
      "backward_entropy": 0.010074489883014135,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.6472365789231844e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03070976957678795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11862592399120331,
      "backward_entropy": 0.01007408116544996,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.111481808242388e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030709844082593918,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11862222850322723,
      "backward_entropy": 0.010073647967406682,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1667730834451504e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030709924176335335,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11861862242221832,
      "backward_entropy": 0.010073208383151464,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.6873904314707033e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710000544786453,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11861507594585419,
      "backward_entropy": 0.007468745112419128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.497665809642058e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710075050592422,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186116486787796,
      "backward_entropy": 0.007468196962560926,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.819614954001736e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710136517882347,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11860819160938263,
      "backward_entropy": 0.007467692451817649,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.8136193830287084e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030710194259881973,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11860480159521103,
      "backward_entropy": 0.010071670370442527,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5224330127239227e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071025013923645,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1186014711856842,
      "backward_entropy": 0.007466754743031093,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5538993466179818e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071030043065548,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11859822273254395,
      "backward_entropy": 0.007466343896729606,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.656191670917906e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030710343271493912,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11859504878520966,
      "backward_entropy": 0.010070765657084329,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.393777256453177e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071039356291294,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11859193444252014,
      "backward_entropy": 0.010070469762597765,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5373343558167107e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030710440129041672,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1185888946056366,
      "backward_entropy": 0.010070183447429113,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.664607407292351e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0307104904204607,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11858591437339783,
      "backward_entropy": 0.010069887552942549,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2038055501761846e-05,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030710535123944283,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11858293414115906,
      "backward_entropy": 0.010264897985117776,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4326254131447058e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710577964782715,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11858002841472626,
      "backward_entropy": 0.007463968225887844,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3542564374802168e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071061335504055,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11857713758945465,
      "backward_entropy": 0.007463614855493818,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1044594430131838e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710643157362938,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11857430636882782,
      "backward_entropy": 0.00746330086674009,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1749953955586534e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030710671097040176,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11857151985168457,
      "backward_entropy": 0.01006874761411122,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.067973153112689e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710700899362564,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1185687929391861,
      "backward_entropy": 0.007462680339813232,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.008626804832602e-05,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071073442697525,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1185661107301712,
      "backward_entropy": 0.010068315480436598,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.0565528100414667e-05,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710771679878235,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11856351047754288,
      "backward_entropy": 0.007462034268038613,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.629842679714784e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071081079542637,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11856095492839813,
      "backward_entropy": 0.0074616777045386174,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.867184417089447e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030710846185684204,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11855843663215637,
      "backward_entropy": 0.00746135413646698,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.050828910199925e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071087971329689,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1185559630393982,
      "backward_entropy": 0.010067400123391832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.952128842385719e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030710915103554726,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1185535341501236,
      "backward_entropy": 0.010067175541605269,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.5892230597673915e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071095235645771,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11855119466781616,
      "backward_entropy": 0.010066956281661987,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 7.76312572270399e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030710989609360695,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11854889988899231,
      "backward_entropy": 0.010066714669976915,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.983279152133036e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071102499961853,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11854664981365204,
      "backward_entropy": 0.007459790046725955,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.870670065633021e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711056664586067,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11854447424411774,
      "backward_entropy": 0.010066317660467965,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.1942870413768105e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711086466908455,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11854234337806702,
      "backward_entropy": 0.010066120752266474,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.4064483922265936e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711118131875992,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11854028701782227,
      "backward_entropy": 0.007458971015044621,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.163206878933124e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071114793419838,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1185382604598999,
      "backward_entropy": 0.01006575460944857,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.482675987877883e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071117401123047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11853627860546112,
      "backward_entropy": 0.007458450538771493,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.692658421845408e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03071119822561741,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11853434145450592,
      "backward_entropy": 0.010266314659799849,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.08509674546076e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0307112205773592,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1185324639081955,
      "backward_entropy": 0.007458033306258065,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.683511633629678e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071124479174614,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11853060126304626,
      "backward_entropy": 0.010065151112420219,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1864168451866135e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03071126714348793,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11852879822254181,
      "backward_entropy": 0.010266533919743128,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.151313078182284e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711285769939423,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11852703243494034,
      "backward_entropy": 0.007457400006907327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.4813245949626435e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711300671100616,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11852528899908066,
      "backward_entropy": 0.007457207356180463,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.800114766112529e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711309984326363,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11852359771728516,
      "backward_entropy": 0.007457053022725242,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.3799553875724087e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711321160197258,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11852186918258667,
      "backward_entropy": 0.010064612541879927,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4036545457638567e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711330473423004,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11852022260427475,
      "backward_entropy": 0.007456740098340171,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.109046474492061e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.0307113416492939,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11851862072944641,
      "backward_entropy": 0.0074565862970692775,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.026442755071912e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711352825164795,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11851704865694046,
      "backward_entropy": 0.010064344320978438,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.997607680299552e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071136400103569,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1185155138373375,
      "backward_entropy": 0.007456299449716296,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.28520184464287e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711373314261436,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11851402372121811,
      "backward_entropy": 0.007456153099025998,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.1556231786235003e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711384490132332,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1185125857591629,
      "backward_entropy": 0.007456008344888687,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.947345819848124e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711397528648376,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11851119995117188,
      "backward_entropy": 0.007455865719488689,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.380538944635191e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711408704519272,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850984394550323,
      "backward_entropy": 0.007455722561904362,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.4393182229687227e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711418017745018,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850851029157639,
      "backward_entropy": 0.007455595369849887,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.137313458661083e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711427330970764,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850718408823013,
      "backward_entropy": 0.00745546179158347,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.880161448752915e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071143664419651,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850591003894806,
      "backward_entropy": 0.007455327681132725,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.988481699299882e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711444094777107,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850467324256897,
      "backward_entropy": 0.007455223373004368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.948291355802212e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030711453408002853,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11850345879793167,
      "backward_entropy": 0.010268339088984899,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5649993656552397e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071146085858345,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850227415561676,
      "backward_entropy": 0.007454992405005864,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.514178165962221e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711468309164047,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11850112676620483,
      "backward_entropy": 0.0074548689382416865,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.5030932445370127e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711475759744644,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1185000091791153,
      "backward_entropy": 0.010063397032873971,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.646902546781348e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071148507297039,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11849893629550934,
      "backward_entropy": 0.007454666708196912,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.300946337323694e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711494386196136,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11849786341190338,
      "backward_entropy": 0.010063260793685913,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.687970211605716e-06,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030711503699421883,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.118496835231781,
      "backward_entropy": 0.010268804218087877,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4870151971990708e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711514875292778,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11849583685398102,
      "backward_entropy": 0.00745431227343423,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4759463056179811e-06,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711526051163673,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11849483102560043,
      "backward_entropy": 0.007454206900937217,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2908725466331816e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711539089679718,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11849385499954224,
      "backward_entropy": 0.010062961706093379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.1260526662226766e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711552128195763,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11849288642406464,
      "backward_entropy": 0.010062879749706813,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.3195475503380294e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711567029356956,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11849195510149002,
      "backward_entropy": 0.010062778634684426,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.2031092637698748e-06,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071158193051815,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1184910386800766,
      "backward_entropy": 0.01006269348519189,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.731428238206718e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711594969034195,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11849012970924377,
      "backward_entropy": 0.0074535975498812536,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.588386546965921e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071160800755024,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848925054073334,
      "backward_entropy": 0.00745348898427827,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 9.951994570656097e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711621046066284,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848839372396469,
      "backward_entropy": 0.007453363920961108,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.717514224874321e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711635947227478,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848755180835724,
      "backward_entropy": 0.007453253226620811,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.600206911069108e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030711648985743523,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11848675459623337,
      "backward_entropy": 0.010269066052777427,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 8.500915669173992e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711663886904716,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848597228527069,
      "backward_entropy": 0.007453017468963351,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.423878176065045e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071167692542076,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11848519742488861,
      "backward_entropy": 0.01006210595369339,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.776498142040509e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711691826581955,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11848445981740952,
      "backward_entropy": 0.010062001645565033,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.813624284201069e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071170672774315,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848373711109161,
      "backward_entropy": 0.0074526747422558924,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.078600449654914e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711719766259193,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1184830516576767,
      "backward_entropy": 0.010061843054635184,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.56477595839533e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711732804775238,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848237365484238,
      "backward_entropy": 0.007452474108764103,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.993588049728714e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711747705936432,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848170310258865,
      "backward_entropy": 0.007452355963843209,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 6.215540793164109e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711760744452477,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848104745149612,
      "backward_entropy": 0.007452259638479778,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.905903321945516e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071177378296852,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11848041415214539,
      "backward_entropy": 0.007452164909669331,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.172556711841025e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711786821484566,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11847978830337524,
      "backward_entropy": 0.010061454560075487,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 5.180105517865741e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03071179986000061,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.1184791773557663,
      "backward_entropy": 0.010269001126289368,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.472084356166306e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711811035871506,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847856640815735,
      "backward_entropy": 0.007451882319790977,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.041125123421807e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.0307118222117424,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.1184779703617096,
      "backward_entropy": 0.01006124700818743,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1209972323486e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.030711833387613297,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11847738921642303,
      "backward_entropy": 0.010269007512501307,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.1385777649338706e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711844563484192,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847682297229767,
      "backward_entropy": 0.007451634321893964,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.502884394241846e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711855739355087,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11847627907991409,
      "backward_entropy": 0.010061044778142656,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 4.0128983869180956e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711866915225983,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847572773694992,
      "backward_entropy": 0.007451470409120832,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7045024353355984e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711878091096878,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11847518384456635,
      "backward_entropy": 0.010060910667691911,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.9908798637734435e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711889266967773,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847466230392456,
      "backward_entropy": 0.007451310753822327,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 3.4836332929444325e-07,
      "terminal_state_reached": true,
      "terminal_reward": 10,
      "log_Z": 0.03071190044283867,
      "trajectory_length": 9,
      "branch_chosen": 0,
      "forward_entropy": 0.11847416311502457,
      "backward_entropy": 0.010268979838916234,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.8185164069327584e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711911618709564,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11847367882728577,
      "backward_entropy": 0.010060710566384452,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.831859262641956e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.03071192279458046,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11847318708896637,
      "backward_entropy": 0.010060645639896393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.544336155096971e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711933970451355,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847271025180817,
      "backward_entropy": 0.007450989314488002,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.7700244231709803e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071194514632225,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847224831581116,
      "backward_entropy": 0.00745091587305069,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.3741985444303282e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711954459547997,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11847179383039474,
      "backward_entropy": 0.010060473212174006,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.0251999899301154e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.030711963772773743,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.11847135424613953,
      "backward_entropy": 0.007450769522360393,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 2.2185592740697757e-07,
      "terminal_state_reached": true,
      "terminal_reward": 70,
      "log_Z": 0.03071197122335434,
      "trajectory_length": 9,
      "branch_chosen": 2,
      "forward_entropy": 0.1184709221124649,
      "backward_entropy": 0.007450699806213379,
      "exploration_ratio": 1.0
    },
    {
      "trajectory_balance_loss": 1.4245436830151448e-07,
      "terminal_state_reached": true,
      "terminal_reward": 20,
      "log_Z": 0.030711978673934937,
      "trajectory_length": 9,
      "branch_chosen": 1,
      "forward_entropy": 0.11847048997879028,
      "backward_entropy": 0.010060321007456099,
      "exploration_ratio": 1.0
    }
  ],
  "summary_stats": {
    "avg_loss": 5.385602145366875e-06,
    "avg_log_Z": 0.03071125015616417,
    "success_rate": 1.0,
    "avg_reward": 45.6,
    "branch_dist": {
      "-1": 0.0,
      "0": 0.09,
      "1": 0.38,
      "2": 0.53
    },
    "avg_forward_entropy": 0.11852301649749279,
    "avg_backward_entropy": 0.008701173114989484,
    "avg_exploration_ratio": 1.0
  },
  "window_size": 100
}